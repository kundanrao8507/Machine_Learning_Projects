{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCwGmKm92VFXHUtUOVZzUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kundanrao8507/Machine_Learning_Projects/blob/main/PDF_qa_System/PDF_QA_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ],
      "metadata": {
        "id": "F_ZfOjtnNvFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oGcp2q-6IgfU"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxC0-aLoNtv4",
        "outputId": "829b8e8b-d234-4bb6-adae-aef01cb4f890"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "#To load the pdf and understand it\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ],
      "metadata": {
        "id": "HXWNekSMNYX4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:fBJuFaKSNXebxZALldmsfHre:70d8ff9a11d517fcd5dd3a8e0f869d605fd582b5c0daafa9a78f48a2756c8c23\"\n",
        "ASTRA_DB_ID = \"d3bac6cf-987f-416b-8425-d6b9abb53ff1\"\n",
        "OPENAI_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "2c-h-pOcOKkw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('Research-Methodology-CR-Kothari.pdf')"
      ],
      "metadata": {
        "id": "Ahm6dykwPsxI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "Cy6g7G_rPtnH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "viNZghx3Ptpv",
        "outputId": "13879e93-03a5-4cf6-a4f8-9554b9ff86b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This page\\nintentionally left\\nblankCopyright © 2004, 1990, 1985, New Age International (P) Ltd., Publishers\\nPublished by New Age International (P) Ltd., Publishers\\nAll rights reserved.\\nNo part of this ebook may be reproduced in any form, by photostat, microfilm,\\nxerography, or any other means, or incorporated into any information retrievalsystem, electronic or mechanical, without the written permission of the publisher.All inquiries should be emailed to  rights@newagepublishers.com\\nPUBLISHING  FOR ONE WORLD\\nNEW AGE INTERNATIONAL (P) LIMITED, PUBLISHERS4835/24, Ansari Road, Daryaganj, New Delhi - 110002Visit us at  www.newagepublishers.comISBN (13) : 978-81-224-2488-1In loving memory of\\nmy revered father\\n(The fountain of inspiration)This page\\nintentionally left\\nblankPreface to the Second Edition vii\\nPreface to the Second Edition\\nI feel encouraged by the widespread response from teachers and students alike to the first edition. I\\nam presenting this second edition, thoroughly revised and enlarged, to my readers in all humbleness.All possible efforts have been made to enhance further the usefulness of the book. The feedbackreceived from different sources has been incorporated.\\nIn this edition a new chapter on “ The Computer: Its role in Research ” have been added in view\\nof the fact that electronic computers by now, for students of economics, management and othersocial sciences, constitute an indispensable part of research equipment.\\nThe other highlights of this revised edition are ( i) the subject contents has been developed,\\nrefined and restructured at several points, ( ii) several new problems have also been added at the end\\nof various chapters for the benefit of students, and ( iii) every page of the book has been read very\\ncarefully so as to improve its quality.\\nI am grateful to all those who have helped me directly and/or indirectly in preparing this revised\\nedition. I firmly believe that there is always scope for improvement and accordingly I shall lookforward to received suggestions, (which shall be thankfully acknowledged) for further enriching thequality of the text.\\nJaipur C.R. K\\nOTHARI\\nMay 1990This page\\nintentionally left\\nblankPreface to the First Edition ix\\nPreface to the First Edition\\nQuite frequently these days people talk of research, both in academic institutions and outside. Several\\nresearch studies are undertaken and accomplished year after year. But in most cases very littleattention is paid to an important dimension relaing to research, namely, that of research methodology.The result is that much of research, particularly in social sciences, contains endless word-spinningand too many quotations. Thus a great deal of research tends to be futile. It may be noted, in thecontext of planning and development, that the significance of research lies in its quality and not inquantity. The need, therefore, is for those concerned with research to pay due attention to designingand adhering to the appropriate methodology throughout for improving the quality of research. Themethodology may differ from problem to problem, yet the basic approach towards research remainsthe same.\\nKeeping all this in view, the present book has been written with two clear objectives, viz., (i) to\\nenable researchers, irrespective of their discipline, in developing the most appropriate methodologyfor their research studies; and (ii) to make them familiar with the art of using different research-methods and techniques. It is hoped that the humble effort made in the form of this book will assist inthe accomplishment of exploratory as well as result-oriented research studies.\\nRegarding the organization, the book consists of fourteen chapters, well arranged in a coherent\\nmanner. Chapter One is an introduction, presenting an overview of the research methodology. ChapterTwo explains the technique of defining a research problem. Chapter Three dwells on various researchdesigns, highlighting their main characteristics. Chapter Four presents the details of several samplingdesigns. Different measurement and scaling techniques, along with multidimensional scaling, havebeen lucidly described in Chapter Five. Chapter Six presents a comparative study of the differentmethods of data collection. It also provides in its appendices guidelines for successful interviewing aswell as for constructing questionnaire/schedules. Chapter Seven deals with processing and analysisof data. Sampling fundamentals, along with the theory of estimation, constitutes the subject-matter ofChapter Eight. Chapter Nine has been exclusively devoted to several parametric tests of hypotheses,followed by Chapter Ten concerning Chi-square test. In Chapter Eleven important features of ANOVAand ANOCOVA techniques have been explained and illustrated. Important non-parametric tests,generally used by researchers have been described and illustrated in Chapter Twelve. In ChapterThirteen, an effort has been made to present the conceptual aspects and circumstances under whichx Preface to the First Edition\\nvarious multivariate techniques can appropriate be utilized in research studies, specially in behavioural\\nand social sciences. Factor analysis has been dealt with in relatively more detail. Chapter Fourteenhas been devoted to the task of interpretation and the art of writing research reports.\\nThe book is primarily intended to serve as a textbook for graduate and M.Phil. students of\\nResearch Methodology in all disciplines of various universities. It is hoped that the book shall provideguidelines to all interested in research studies of one sort or the other. The book is, in fact, anoutgrowth of my experience of teaching the subject to M.Phil. students for the last several years.\\nI am highly indebted to my students and learned colleagues in the Department for providing the\\nnecessary stimulus for writing this book. I am grateful to all those persons whose writings and workshave helped me in the preparation of this book. I am equally grateful to the reviewer of the manuscriptof this book who made extremely valuable suggestions and has thus contributed in enhancing thestandard of the book. I thankfully acknowledge the assistance provided by the University GrantsCommission in the form of ‘on account’ grant in the preparation of the manuscript of this book.\\nI shall feel amply rewarded if the book proves helpful in the development of genuine research\\nstudies. I look forward to suggestions from all readers, specially from experienced researchers andscholars for further improving the subject content as well as the presentation of this book.\\nC.R. K\\nOTHARIContents xi\\nContents\\nPreface to the Second Edition vii\\nPreface to the First Edition ix\\n1. Research Methodology: An Introduction 1\\nMeaning of Research 1\\nObjectives of Research 2\\nMotivation in Research 2\\nTypes of Research 2\\nResearch Approaches 5\\nSignificance of Research 5\\nResearch Methods versus Methodology 7\\nResearch and Scientific Method 9\\nImportance of Knowing How Research is Done 10\\nResearch Process 10\\nCriteria of Good Research 20\\nProblems Encountered by Researchers in India 21\\n2. Defining the Research Problem 24\\nWhat is a Research Problem? 24\\nSelecting the Problem 25\\nNecessity of Defining the Problem 26\\nTechnique Involved in Defining a Problem 27\\nAn Illustration 29\\nConclusion 29\\n3. Research Design 31\\nMeaning of Research Design 31\\nNeed for Research Design 32xii Research Methodology\\nFeatures of a Good Design 33\\nImportant Concepts Relating to Research Design 33\\nDifferent Research Designs 35\\nBasic Principles of Experimental Designs 39\\nConclusion 52\\nAppendix\\nDeveloping a Research Plan 53\\n4. Sampling Design 55\\nCensus and Sample Survey 55\\nImplications of a Sample Design 55\\nSteps in Sampling Design 56\\nCriteria of Selecting a Sampling Procedure 57\\nCharacteristics of a Good Sample Design 58\\nDifferent Types of Sample Designs 58\\nHow to Select a Random Sample? 60\\nRandom Sample from an Infinite Universe 61\\nComplex Random Sampling Designs 62\\nConclusion 67\\n5. Measurement and Scaling Techniques 69\\nMeasurement in Research 69\\nMeasurement Scales 71\\nSources of Error in Measurement 72\\nTests of Sound Measurement 73\\nTechnique of Developing Measurement Tools 75\\nScaling 76\\nMeaning of Scaling 76\\nScale Classification Bases 77\\nImportant Scaling Techniques 78\\nScale Construction Techniques 82\\n6. Methods of Data Collection 95\\nCollection of Primary Data 95\\nObservation Method 96\\nInterview Method 97\\nCollection of Data through Questionnaires 100\\nCollection of Data through Schedules 104\\nDifference between Questionnaires and Schedules 104\\nSome Other Methods of Data Collection 106\\nCollection of Secondary Data 111Contents xiii\\nSelection of Appropriate Method for Data Collection 112\\nCase Study Method 113\\nAppendices\\n(i) Guidelines for Constructing Questionnaire/Schedule 118\\n(ii)Guidelines for Successful Interviewing 119\\n(iii)Difference between Survey and Experiment 120\\n7. Processing and Analysis of Data 122\\nProcessing Operations 122\\nSome Problems in Processing 129\\nElements/Types of Analysis 130\\nStatistics in Research 131\\nMeasures of Central Tendency 132\\nMeasures of Dispersion 134\\nMeasures of Asymmetry (Skewness) 136\\nMeasures of Relationship 138\\nSimple Regression Analysis 141\\nMultiple Correlation and Regression 142\\nPartial Correlation 143\\nAssociation in Case of Attributes 144\\nOther Measures 147\\nAppendix : Summary Chart Concerning Analysis of Data 151\\n8. Sampling Fundamentals 152\\nNeed for Sampling 152\\nSome Fundamental Definitions 152\\nImportant Sampling Distributions 155\\nCentral Limit Theorem 157\\nSampling Theory 158\\nSandler’s A-test162\\nConcept of Standard Error 163\\nEstimation 167\\nEstimating the Population Mean ()µ168\\nEstimating Population Proportion 172\\nSample Size and its Determination 174\\nDetermination of Sample Size through the Approach\\nBased on Precision Rate and Confidence Level 175\\nDetermination of Sample Size through the Approach\\nBased on Bayesian Statistics 180xiv Research Methodology\\n9. Testing of Hypotheses-I (Parametric or 184\\nStandard Tests of Hypotheses)\\nWhat is a Hypothesis? 184\\nBasic Concepts Concerning Testing of Hypotheses 185\\nProcedure for Hypothesis Testing 191\\nFlow Diagram for Hypothesis Testing 192\\nMeasuring the Power of a Hypothesis Test 193\\nTests of Hypotheses 195\\nImportant Parametric Tests 195\\nHypothesis Testing of Means 197\\nHypothesis Testing for Differences between Means 207\\nHypothesis Testing for Comparing Two Related Samples 214\\nHypothesis Testing of Proportions 218\\nHypothesis Testing for Difference between Proportions 220\\nHypothesis Testing for Comparing a Variance to\\nSome Hypothesized Population Variance 224\\nTesting the Equality of Variances of Two Normal Populations 225\\nHypothesis Testing of Correlation Coefficients 228\\nLimitations of the Tests of Hypotheses 229\\n10. Chi-square Test 233\\nChi-square as a Test for Comparing Variance 233\\nChi-square as a Non-parametric Test 236\\nConditions for the Application of χ2 Test238\\nSteps Involved in Applying Chi-square Test 238\\nAlternative Formula 246\\nYates’ Correction 246\\nConversion of χ2 into Phi Coefficient 249\\nConversion of χ2 into Coefficient by Contingency 250\\nImportant Characteristics of χ2 Test250\\nCaution in Using χ2 Test250\\n11. Analysis of Variance and Covariance 256\\nAnalysis of Variance (ANOVA) 256\\nWhat is ANOVA? 256\\nThe Basic Principle of ANOVA 257\\nANOVA Technique 258\\nSetting up Analysis of Variance Table 259\\nShort-cut Method for One-way ANOVA 260\\nCoding Method 261\\nTwo-way ANOVA 264Contents xv\\nANOVA in Latin-Square Design 271\\nAnalysis of Co-variance (ANOCOVA) 275\\nANOCOVA Technique 275\\nAssumptions in ANOCOVA 276\\n12. Testing of Hypotheses-II 283\\n(Nonparametric or Distribution-free Tests)\\nImportant Nonparametric or Distribution-free Test 284\\nRelationship between Spearman’s r’s and Kendall’s W 310\\nCharacteristics of Distribution-free or Non-parametric Tests 311\\nConclusion 313\\n13. Multivariate Analysis Techniques 315\\nGrowth of Multivariate Techniques 315\\nCharacteristics and Applications 316\\nClassification of Multivariate Techniques 316\\nVariables in Multivariate Analysis 318\\nImportant Multivariate Techniques 318\\nImportant Methods of Factor Analysis 323\\nRotation in Factor Analysis 335\\nR-type and Q-type Factor Analyses 336\\nPath Analysis 339\\nConclusion 340\\nAppendix : Summary Chart: Showing the Appropriateness\\nof a Particular Multivariate Technique 343\\n14. Interpretation and Report Writing 344\\nMeaning of Interpretation 344\\nWhy Interpretation? 344\\nTechnique of Interpretation: 345\\nPrecaution in Interpretation 345\\nSignificance of Report Writing 346\\nDifferent Steps in Writing Report 347\\nLayout of the Research Report 348\\nTypes of Reports 351\\nOral Presentation 353\\nMechanics of Writing a Research Report 353\\nPrecautions for Writing Research Reports 358\\nConclusions 359xvi Research Methodology\\n15. The Computer: Its Role in Research 361\\nIntroduction 361\\nThe Computer and Computer Technology 361\\nThe Computer System 363\\nImportant Characteristics 364\\nThe Binary Number System 365\\nComputer Applications 370\\nComputers and Researcher 371\\nAppendix—Selected Statistical Tables 375\\nSelected References and Recommended Readings 390\\nAuthor Index 395\\nSubject Index 398Research Methodology: An Introduction 1\\n1\\nResearch Methodology:\\nAn Introduction\\nMEANING OF RESEARCH\\nResearch in common parlance refers to a search for knowledge. Once can also define research as\\na scientific and systematic search for pertinent information on a specific topic. In fact, research is anart of scientific investigation. The Advanced Learner’s Dictionary of Current English lays down the\\nmeaning of research as “a careful investigation or inquiry specially through search for new facts in\\nany branch of knowledge.”\\n1 Redman and Mory define research as a “systematized effort to gain\\nnew knowledge.”2 Some people consider research as a movement, a movement from the known to\\nthe unknown. It is actually a voyage of discovery. We all possess the vital instinct of inquisitivenessfor, when the unknown confronts us, we wonder and our inquisitiveness makes us probe and attainfull and fuller understanding of the unknown. This inquisitiveness is the mother of all knowledge andthe method, which man employs for obtaining the knowledge of whatever the unknown, can betermed as research.\\nResearch is an academic activity and as such the term should be used in a technical sense.\\nAccording to Clifford Woody research comprises defining and redefining problems, formulatinghypothesis or suggested solutions; collecting, organising and evaluating data; making deductions andreaching conclusions; and at last carefully testing the conclusions to determine whether they fit theformulating hypothesis. D. Slesinger and M. Stephenson in the Encyclopaedia of Social Sciencesdefine research as “the manipulation of things, concepts or symbols for the purpose of generalising toextend, correct or verify knowledge, whether that knowledge aids in construction of theory or in thepractice of an art.”\\n3 Research is, thus, an original contribution to the existing stock of knowledge\\nmaking for its advancement. It is the persuit of truth with the help of study, observation, comparisonand experiment. In short, the search for knowledge through objective and systematic method offinding solution to a problem is research. The systematic approach concerning generalisation and theformulation of a theory is also research. As such the term ‘research’ refers to the systematic method\\n1 The Advanced Learner’s Dictionary of Current English , Oxford, 1952, p. 1069.\\n2 L.V. Redman and A.V.H. Mory, The Romance of Research , 1923, p.10.\\n3 The Encyclopaedia of Social Sciences , Vol. IX, MacMillan, 1930.2 Research Methodology\\nconsisting of enunciating the problem, formulating a hypothesis, collecting the facts or data, analysing\\nthe facts and reaching certain conclusions either in the form of solutions(s) towards the concernedproblem or in certain generalisations for some theoretical formulation.\\nOBJECTIVES OF RESEARCH\\nThe purpose of research is to discover answers to questions through the application of scientificprocedures. The main aim of research is to find out the truth which is hidden and which has not beendiscovered as yet. Though each research study has its own specific purpose, we may think ofresearch objectives as falling into a number of following broad groupings:\\n1. To gain familiarity with a phenomenon or to achieve new insights into it (studies with this\\nobject in view are termed as exploratory  or formulative  research studies);\\n2. To portray accurately the characteristics of a particular individual, situation or a group\\n(studies with this object in view are known as descriptive research studies);\\n3. To determine the frequency with which something occurs or with which it is associated\\nwith something else (studies with this object in view are known as diagnostic research\\nstudies);\\n4. To test a hypothesis of a causal relationship between variables (such studies are known as\\nhypothesis-testing  research studies).\\nMOTIVATION IN RESEARCH\\nWhat makes people to undertake research? This is a question of fundamental importance. Thepossible motives for doing research may be either one or more of the following:\\n1. Desire to get a research degree along with its consequential benefits;\\n2. Desire to face the challenge in solving the unsolved problems, i.e., concern over practical\\nproblems initiates research;\\n3. Desire to get intellectual joy of doing some creative work;\\n4. Desire to be of service to society;\\n5. Desire to get respectability.\\nHowever, this is not an exhaustive list of factors motivating people to undertake research studies.\\nMany more factors such as directives of government, employment conditions, curiosity about new\\nthings, desire to understand causal relationships, social thinking and awakening, and the like may aswell motivate (or at times compel) people to perform research operations.\\nTYPES OF RESEARCH\\nThe basic types of research are as follows:\\n(i)Descriptive vs. Analytical:  Descriptive research includes surveys and fact-finding enquiries\\nof different kinds. The major purpose of descriptive research is description of the state ofaffairs as it exists at present. In social science and business research we quite often useResearch Methodology: An Introduction 3\\nthe term Ex post facto research  for descriptive research studies. The main characteristic\\nof this method is that the researcher has no control over the variables; he can only report\\nwhat has happened or what is happening. Most ex post facto research  projects are used\\nfor descriptive studies in which the researcher seeks to measure such items as, for example,frequency of shopping, preferences of people, or similar data. Ex post facto studies  also\\ninclude attempts by researchers to discover causes even when they cannot control thevariables. The methods of research utilized in descriptive research are survey methods ofall kinds, including comparative and correlational methods. In analytical research , on the\\nother hand, the researcher has to use facts or information already available, and analyzethese to make a critical evaluation of the material.\\n(ii)Applied vs. Fundamental: Research can either be applied (or action) research orfundamental (to basic or pure) research. Applied research  aims at finding a solution for an\\nimmediate problem facing a society or an industrial/business organisation, whereas fundamental\\nresearch is mainly concerned with generalisations and with the formulation of a theory.\\n“Gathering knowledge for knowledge’s sake is termed ‘pure’ or ‘basic’ research.”\\n4 Research\\nconcerning some natural phenomenon or relating to pure mathematics are examples offundamental research. Similarly, research studies, concerning human behaviour carried onwith a view to make generalisations about human behaviour, are also examples offundamental research, but research aimed at certain conclusions (say, a solution) facing aconcrete social or business problem is an example of applied research. Research to identifysocial, economic or political trends that may affect a particular institution or the copy research(research to find out whether certain communications will be read and understood) or themarketing research or evaluation research are examples of applied research. Thus, thecentral aim of applied research is to discover a solution for some pressing practical problem,whereas basic research is directed towards finding information that has a broad base ofapplications and thus, adds to the already existing organized body of scientific knowledge.\\n(iii)Quantitative vs. Qualitative:  Quantitative research is based on the measurement of quantity\\nor amount. It is applicable to phenomena that can be expressed in terms of quantity.Qualitative research, on the other hand, is concerned with qualitative phenomenon, i.e.,phenomena relating to or involving quality or kind. For instance, when we are interested ininvestigating the reasons for human behaviour (i.e., why people think or do certain things),we quite often talk of ‘Motivation Research’, an important type of qualitative research.This type of research aims at discovering the underlying motives and desires, using in depthinterviews for the purpose. Other techniques of such research are word association tests,sentence completion tests, story completion tests and similar other projective techniques.Attitude or opinion research i.e., research designed to find out how people feel or whatthey think about a particular subject or institution is also qualitative research. Qualitativeresearch is specially important in the behavioural sciences where the aim is to discover theunderlying motives of human behaviour. Through such research we can analyse the variousfactors which motivate people to behave in a particular manner or which make people likeor dislike a particular thing. It may be stated, however, that to apply qualitative research in\\n4 Pauline V. Young, Scientific Social Surveys and Research , p. 30.4 Research Methodology\\npractice is relatively a difficult job and therefore, while doing such research, one should\\nseek guidance from experimental psychologists.\\n(iv)Conceptual vs. Empirical:  Conceptual research is that related to some abstract idea(s) or\\ntheory. It is generally used by philosophers and thinkers to develop new concepts or toreinterpret existing ones. On the other hand, empirical research relies on experience orobservation alone, often without due regard for system and theory. It is data-based research,coming up with conclusions which are capable of being verified by observation or experiment.We can also call it as experimental type of research. In such a research it is necessary toget at facts firsthand, at their source, and actively to go about doing certain things tostimulate the production of desired information. In such a research, the researcher mustfirst provide himself with a working hypothesis or guess as to the probable results. He thenworks to get enough facts (data) to prove or disprove his hypothesis. He then sets upexperimental designs which he thinks will manipulate the persons or the materials concernedso as to bring forth the desired information. Such research is thus characterised by theexperimenter’s control over the variables under study and his deliberate manipulation ofone of them to study its effects. Empirical research is appropriate when proof is sought thatcertain variables affect other variables in some way. Evidence gathered through experimentsor empirical studies is today considered to be the most powerful support possible for agiven hypothesis.\\n(v)Some Other Types of Research:  All other types of research are variations of one or more\\nof the above stated approaches, based on either the purpose of research, or the timerequired to accomplish research, on the environment in which research is done, or on thebasis of some other similar factor. Form the point of view of time, we can think of researcheither as one-time research or longitudinal research . In the former case the research is\\nconfined to a single time-period, whereas in the latter case the research is carried on overseveral time-periods. Research can be field-setting research or laboratory research or\\nsimulation research , depending upon the environment in which it is to be carried out.\\nResearch can as well be understood as clinical or diagnostic research. Such research\\nfollow case-study methods or indepth approaches to reach the basic causal relations. Suchstudies usually go deep into the causes of things or events that interest us, using very smallsamples and very deep probing data gathering devices. The research may be exploratory\\nor it may be formalized. The objective of exploratory research is the development ofhypotheses rather than their testing, whereas formalized research studies are those withsubstantial structure and with specific hypotheses to be tested. Historical research  is that\\nwhich utilizes historical sources like documents, remains, etc. to study events or ideas ofthe past, including the philosophy of persons and groups at any remote point of time. Researchcan also be classified as conclusion-oriented  and decision-oriented. While doing conclusion-\\noriented research, a researcher is free to pick up a problem, redesign the enquiry as heproceeds and is prepared to conceptualize as he wishes. Decision-oriented research isalways for the need of a decision maker and the researcher in this case is not free toembark upon research according to his own inclination. Operations research is an exampleof decision oriented research since it is a scientific method of providing executive departmentswith a quantitative basis for decisions regarding operations under their control.Research Methodology: An Introduction 5\\nResearch Approaches\\nThe above description of the types of research brings to light the fact that there are two basic\\napproaches to research, viz., quantitative approach and the qualitative approach . The former\\ninvolves the generation of data in quantitative form which can be subjected to rigorous quantitativeanalysis in a formal and rigid fashion. This approach can be further sub-classified into inferential ,\\nexperimental and simulation approaches to research. The purpose of inferential approach  to\\nresearch is to form a data base from which to infer characteristics or relationships of population. Thisusually means survey research where a sample of population is studied (questioned or observed) todetermine its characteristics, and it is then inferred that the population has the same characteristics.Experimental approach is characterised by much greater control over the research environment\\nand in this case some variables are manipulated to observe their effect on other variables. Simulation\\napproach involves the construction of an artificial environment within which relevant informationand data can be generated. This permits an observation of the dynamic behaviour of a system (or itssub-system) under controlled conditions. The term ‘simulation’ in the context of business and socialsciences applications refers to “the operation of a numerical model that represents the structure of adynamic process. Given the values of initial conditions, parameters and exogenous variables, asimulation is run to represent the behaviour of the process over time.”\\n5 Simulation approach can also\\nbe useful in building models for understanding future conditions.\\nQualitative approach  to research is concerned with subjective assessment of attitudes, opinions\\nand behaviour. Research in such a situation is a function of researcher’s insights and impressions.Such an approach to research generates results either in non-quantitative form or in the form whichare not subjected to rigorous quantitative analysis. Generally, the techniques of focus group interviews,projective techniques and depth interviews are used. All these are explained at length in chaptersthat follow.\\nSignificance of Research\\n“All progress is born of inquiry. Doubt is often better than overconfidence, for it leads to inquiry, andinquiry leads to invention” is a famous Hudson Maxim in context of which the significance of researchcan well be understood. Increased amounts of research make progress possible. Research inculcates\\nscientific and inductive thinking and it promotes the development of logical habits of thinkingand organisation .\\nThe role of research in several fields of applied economics, whether related to business or\\nto the economy as a whole,  has greatly increased in modern times . The increasingly complex\\nnature of business and government has focused attention on the use of research in solving operationalproblems. Research, as an aid to economic policy, has gained added importance, both for governmentand business.\\nResearch provides the basis for nearly all government policies in our economic system .\\nFor instance, government’s budgets rest in part on an analysis of the needs and desires of the peopleand on the availability of revenues to meet these needs. The cost of needs has to be equated toprobable revenues and this is a field where research is most needed. Through research we candevise alternative policies and can as well examine the consequences of each of these alternatives.\\n5 Robert C. Meir, William T. Newell and Harold L. Dazier, Simulation in Business and Economics,  p. 1.6 Research Methodology\\nDecision-making may not be a part of research, but research certainly facilitates the decisions of the\\npolicy maker. Government has also to chalk out programmes for dealing with all facets of the country’sexistence and most of these will be related directly or indirectly to economic conditions. The plight ofcultivators, the problems of big and small business and industry, working conditions, trade unionactivities, the problems of distribution, even the size and nature of defence services are mattersrequiring research. Thus, research is considered necessary with regard to the allocation of nation’sresources. Another area in government, where research is necessary, is collecting information on theeconomic and social structure of the nation. Such information indicates what is happening in theeconomy and what changes are taking place. Collecting such statistical information is by no means aroutine task, but it involves a variety of research problems. These day nearly all governments maintainlarge staff of research technicians or experts to carry on this work. Thus, in the context of government,research as a tool to economic policy has three distinct phases of operation, viz., (i) investigation ofeconomic structure through continual compilation of facts; (ii) diagnosis of events that are takingplace and the analysis of the forces underlying them; and (iii) the prognosis, i.e., the prediction offuture developments.\\nResearch has its special significance in solving various operational and planning problems\\nof business and industry . Operations research and market research, along with motivational research,\\nare considered crucial and their results assist, in more than one way, in taking business decisions.Market research is the investigation of the structure and development of a market for the purpose offormulating efficient policies for purchasing, production and sales. Operations research refers to theapplication of mathematical, logical and analytical techniques to the solution of business problems ofcost minimisation or of profit maximisation or what can be termed as optimisation problems. Motivationalresearch of determining why people behave as they do is mainly concerned with market characteristics.In other words, it is concerned with the determination of motivations underlying the consumer (market)behaviour. All these are of great help to people in business and industry who are responsible fortaking business decisions. Research with regard to demand and market factors has great utility inbusiness. Given knowledge of future demand, it is generally not difficult for a firm, or for an industryto adjust its supply schedule within the limits of its projected capacity. Market analysis has becomean integral tool of business policy these days. Business budgeting, which ultimately results in aprojected profit and loss account, is based mainly on sales estimates which in turn depends onbusiness research. Once sales forecasting is done, efficient production and investment programmescan be set up around which are grouped the purchasing and financing plans. Research, thus, replacesintuitive business decisions by more logical and scientific decisions.\\nResearch is equally important for social scientists in studying social relationships and in\\nseeking answers to various social problems . It provides the intellectual satisfaction of knowing a\\nfew things just for the sake of knowledge and also has practical utility for the social scientist to knowfor the sake of being able to do something better or in a more efficient manner. Research in socialsciences is concerned both with knowledge for its own sake and with knowledge for what it cancontribute to practical concerns. “This double emphasis is perhaps especially appropriate in the caseof social science. On the one hand, its responsibility as a science is to develop a body of principlesthat make possible the understanding and prediction of the whole range of human interactions. Onthe other hand, because of its social orientation, it is increasingly being looked to for practical guidancein solving immediate problems of human relations.”\\n6\\n6 Marie Jahoda, Morton Deutsch and Stuart W. Cook, Research Methods in Social Relations,  p. 4.Research Methodology: An Introduction 7\\nIn addition to what has been stated above, the significance of research can also be understood\\nkeeping in view the following points:\\n(a) To those students who are to write a master’s or Ph.D. thesis, research may mean a\\ncareerism or a way to attain a high position in the social structure;\\n(b) To professionals in research methodology, research may mean a source of livelihood;\\n(c) To philosophers and thinkers, research may mean the outlet for new ideas and insights;\\n(d) To literary men and women, research may mean the development of new styles and creative\\nwork;\\n(e) To analysts and intellectuals, research may mean the generalisations of new theories.\\nThus, research is the fountain of knowledge for the sake of knowledge and an important source\\nof providing guidelines for solving different business, governmental and social problems. It is a sort of\\nformal training which enables one to understand the new developments in one’s field in a better way.\\nResearch Methods versus Methodology\\nIt seems appropriate at this juncture to explain the difference between research methods and researchmethodology. Research methods may be understood as all those methods/techniques that are used\\nfor conduction of research. Research methods or techniques *, thus, refer to the methods the r esearchers\\n*At times, a distinction is also made between research techniques and research methods. Research techniques  refer to\\nthe behaviour and instruments we use in performing research operations such as making observations, recording data,techniques of processing data and the like. Research methods refer to the behaviour and instruments used in selecting and\\nconstructing research technique. For instance, the difference between methods and techniques of data collection can betterbe understood from the details given in the following chart—\\nType Methods Techniques\\n1.  Library (i) Analysis of historical Recording of notes, Content analysis, Tape and Film listening and\\n     Research records analysis.\\n(ii) Analysis of documents Statistical compilations and manipulations, reference and abstract\\nguides, contents analysis.\\n2. Field (i) Non-participant direct Observational behavioural scales, use of score cards, etc.\\n    Research observation\\n(ii) Participant observation Interactional recording, possible use of tape recorders, photo graphic\\ntechniques.\\n(iii) Mass observation Recording mass behaviour, interview using independent observers in\\npublic places.\\n(iv)Mail questionnaire Identification of social and economic background of respondents.\\n(v) Opinionnaire Use of attitude scales, projective techniques, use of sociometric scales.\\n(vi)Personal interview Interviewer uses a detailed schedule with open and closed questions.\\n(vii)Focused interview Interviewer focuses attention upon a given experience and its effects.\\n(viii) Group interview Small groups of respondents are interviewed simultaneously.\\n(ix) Telephone survey Used as a survey technique for information and for discerning\\nopinion; may also be used as a follow up of questionnaire.\\n(x) Case study and life history Cross sectional collection of data for intensive analysis, longitudinal\\ncollection of data of intensive character.\\n3. Laboratory Small group study of random Use of audio-visual recording devices, use of observers, etc.\\n    Research behaviour, play and role analysis\\nFrom what has been stated above, we can say that methods are more general. It is the methods that generate techniques.\\nHowever, in practice, the two terms are taken as interchangeable and when we talk of research methods we do, by\\nimplication, include research techniques within their compass.8 Research Methodology\\nuse in performing research operations . In other words, all those methods which are used by the\\nresearcher during the course of studying his research problem are termed as research methods.\\nSince the object of research, particularly the applied research, it to arrive at a solution for a givenproblem, the available data and the unknown aspects of the problem have to be related to each otherto make a solution possible. Keeping this in view, research methods can be put into the followingthree groups:\\n1. In the first group we include those methods which are concerned with the collection of\\ndata. These methods will be used where the data already available are not sufficient toarrive at the required solution;\\n2. The second group consists of those statistical techniques which are used for establishing\\nrelationships between the data and the unknowns;\\n3. The third group consists of those methods which are used to evaluate the accuracy of the\\nresults obtained.\\nResearch methods falling in the above stated last two groups are generally taken as the analyticaltools of research.\\nResearch methodology  is a way to systematically solve the research problem. It may be\\nunderstood as a science of studying how research is done scientifically. In it we study the varioussteps that are generally adopted by a researcher in studying his research problem along with the logicbehind them. It is necessary for the researcher to know not only the research methods/techniquesbut also the methodology. Researchers not only need to know how to develop certain indices or tests,how to calculate the mean, the mode, the median or the standard deviation or chi-square, how toapply particular research techniques, but they also need to know which of these methods or techniques,are relevant and which are not, and what would they mean and indicate and why. Researchers alsoneed to understand the assumptions underlying various techniques and they need to know the criteriaby which they can decide that certain techniques and procedures will be applicable to certain problemsand others will not. All this means that it is necessary for the researcher to design his methodologyfor his problem as the same may differ from problem to problem. For example, an architect, whodesigns a building, has to consciously evaluate the basis of his decisions, i.e., he has to evaluate whyand on what basis he selects particular size, number and location of doors, windows and ventilators,uses particular materials and not others and the like. Similarly, in research the scientist has to exposethe research decisions to evaluation before they are implemented. He has to specify very clearly andprecisely what decisions he selects and why he selects them so that they can be evaluated by others also.\\nFrom what has been stated above, we can say that research methodology has many dimensions\\nand research methods do constitute a part of the research methodology. The scope of researchmethodology is wider than that of research methods. Thus, when we talk of research methodology\\nwe not only talk of the research methods but also consider the logic behind the methods we usein the context of our research study and explain why we are using a particular method ortechnique and why we are not using others so that research results are capable of beingevaluated either by the researcher himself or by others . Why a research study has been undertaken,\\nhow the research problem has been defined, in what way and why the hypothesis has been formulated,what data have been collected and what particular method has been adopted, why particular techniqueof analysing data has been used and a host of similar other questions are usually answered when wetalk of research methodology concerning a research problem or study.Research Methodology: An Introduction 9\\nResearch and Scientific Method\\nFor a clear perception of the term research, one should know the meaning of scientific method. The\\ntwo terms, research and scientific method, are closely related. Research, as we have already stated,can be termed as “an inquiry into the nature of, the reasons for, and the consequences of anyparticular set of circumstances, whether these circumstances are experimentally controlled or recordedjust as they occur. Further, research implies the researcher is interested in more than particularresults; he is interested in the repeatability of the results and in their extension to more complicatedand general situations.”\\n7 On the other hand, the philosophy common to all research methods and\\ntechniques, although they may vary considerably from one science to another, is usually given thename of scientific method. In this context, Karl Pearson writes, “The scientific method is one andsame in the branches (of science) and that method is the method of all logically trained minds … theunity of all sciences consists alone in its methods, not its material; the man who classifies facts of anykind whatever, who sees their mutual relation and describes their sequences, is applying the ScientificMethod and is a man of science.”\\n8 Scientific method is the pursuit of truth as determined by logical\\nconsiderations. The ideal of science is to achieve a systematic interrelation of facts. Scientific methodattempts to achieve “this ideal by experimentation, observation, logical arguments from acceptedpostulates and a combination of these three in varying proportions.”\\n9 In scientific method, logic aids\\nin formulating propositions explicitly and accurately so that their possible alternatives become clear.Further, logic develops the consequences of such alternatives, and when these are compared withobservable phenomena, it becomes possible for the researcher or the scientist to state which alternativeis most in harmony with the observed facts. All this is done through experimentation and surveyinvestigations which constitute the integral parts of scientific method.\\nExperimentation is done to test hypotheses and to discover new relationships. If any, among\\nvariables. But the conclusions drawn on the basis of experimental data are generally criticized foreither faulty assumptions, poorly designed experiments, badly executed experiments or faultyinterpretations. As such the researcher must pay all possible attention while developing the experimentaldesign and must state only probable inferences. The purpose of survey investigations may also be toprovide scientifically gathered information to work as a basis for the researchers for their conclusions.\\nThe scientific method is, thus, based on certain basic postulates which can be stated as under:\\n1. It relies on empirical evidence;\\n2. It utilizes relevant concepts;\\n3. It is committed to only objective considerations;\\n4. It presupposes ethical neutrality, i.e., it aims at nothing but making only adequate and correct\\nstatements about population objects;\\n5. It results into probabilistic predictions;\\n6. Its methodology is made known to all concerned for critical scrutiny are for use in testing\\nthe conclusions through replication;\\n7. It aims at formulating most general axioms or what can be termed as scientific theories.\\n7 Bernard Ostle and Richard W. Mensing, Statistics in Research , p. 2\\n8 Karl Pearson, The Grammar of Science , Part I, pp. 10–12.\\n9 Ostle and Mensing: op. cit., p. 2.10 Research Methodology\\nThus, “the scientific method encourages a rigorous, impersonal mode of procedure dictated by\\nthe demands of logic and objective procedure.”10 Accordingly, scientific method implies an objective,\\nlogical and systematic method, i.e., a method free from personal bias or prejudice, a method to\\nascertain demonstrable qualities of a phenomenon capable of being verified, a method wherein theresearcher is guided by the rules of logical reasoning, a method wherein the investigation proceeds inan orderly manner and a method that implies internal consistency.\\nImportance of Knowing How Research is Done\\nThe study of research methodology gives the student the necessary training in gathering material andarranging or card-indexing them, participation in the field work when required, and also training intechniques for the collection of data appropriate to particular problems, in the use of statistics,questionnaires and controlled experimentation and in recording evidence, sorting it out and interpretingit. In fact, importance of knowing the methodology of research or how research is done stems fromthe following considerations:\\n(i) For one who is preparing himself for a career of carrying out research, the importance of\\nknowing research methodology and research techniques is obvious since the same constitutethe tools of his trade. The knowledge of methodology provides good training specially to thenew research worker and enables him to do better research. It helps him to develop disciplinedthinking or a ‘bent of mind’ to observe the field objectively. Hence, those aspiring forcareerism in research must develop the skill of using research techniques and must thoroughlyunderstand the logic behind them.\\n(ii)Knowledge of how to do research will inculcate the ability to evaluate and use researchresults with reasonable confidence. In other words, we can state that the knowledge ofresearch methodology is helpful in various fields such as government or businessadministration, community development and social work where persons are increasinglycalled upon to evaluate and use research results for action.\\n(iii)When one knows how research is done, then one may have the satisfaction of acquiring anew intellectual tool which can become a way of looking at the world and of judging everyday experience. Accordingly, it enables use to make intelligent decisions concerning problemsfacing us in practical life at different points of time. Thus, the knowledge of researchmethodology provides tools to took at things in life objectively.\\n(iv) In this scientific age, all of us are in many ways consumers of research results and we can\\nuse them intelligently provided we are able to judge the adequacy of the methods by whichthey have been obtained. The knowledge of methodology helps the consumer of researchresults to evaluate them and enables him to take rational decisions.\\nResearch Process\\nBefore embarking on the details of research methodology and techniques, it seems appropriate topresent a brief overview of the research process. Research process consists of series of actions orsteps necessary to effectively carry out research and the desired sequencing of these steps. Thechart shown in Figure 1.1 well illustrates a research process.\\n10 Carlos L. Lastrucci, The Scientific Approach : Basic Principles of the Scientific Method,  p. 7.Research Methodology: An Introduction 11Fig. 1.1Review concepts\\nand theories\\nReview previous\\nresearch findingFormulate\\nhypothesesDesign research\\n(includingsample design)Collect data\\n(Execution)Analyse data(Test hypothesesif any)\\nF FReview the literature\\nIIIIIIVVVIVIIInterpret\\nand reportDefine\\nresearch\\nproblem\\nIFF\\nFFF\\nFFFWhere        = feed back (Helps in controlling the sub-system\\nto which it is transmitted)\\n= feed forward (Serves the vital function of\\nproviding criteria for evaluation)RESEARCH PROCESS IN FLOW CHART12 Research Methodology\\nThe chart indicates that the research process consists of a number of closely related activities,\\nas shown through I to VII. But such activities overlap continuously rather than following a strictly\\nprescribed sequence. At times, the first step determines the nature of the last step to be undertaken.If subsequent procedures have not been taken into account in the early stages, serious difficultiesmay arise which may even prevent the completion of the study. One should remember that thevarious steps involved in a research process are not mutually exclusive; nor they are separate anddistinct. They do not necessarily follow each other in any specific order and the researcher has to beconstantly anticipating at each step in the research process the requirements of the subsequentsteps. However, the following order concerning various steps provides a useful procedural guidelineregarding the research process: (1) formulating the research problem; (2) extensive literature survey;(3) developing the hypothesis; (4) preparing the research design; (5) determining sample design;(6) collecting the data; (7) execution of the project; (8) analysis of data; (9) hypothesis testing;(10)generalisations and interpretation, and (11) preparation of the report or presentation of the results,i.e., formal write-up of conclusions reached.\\nA brief description of the above stated steps will be helpful.\\n1. Formulating the research problem:  There are two types of research problems, viz., those\\nwhich relate to states of nature and those which relate to relationships between variables. At thevery outset the researcher must single out the problem he wants to study, i.e., he must decide thegeneral area of interest or aspect of a subject-matter that he would like to inquire into. Initially theproblem may be stated in a broad general way and then the ambiguities, if any, relating to the problembe resolved. Then, the feasibility of a particular solution has to be considered before a workingformulation of the problem can be set up. The formulation of a general topic into a specific researchproblem, thus, constitutes the first step in a scientific enquiry. Essentially two steps are involved informulating the research problem, viz., understanding the problem thoroughly, and rephrasing thesame into meaningful terms from an analytical point of view.\\nThe best way of understanding the problem is to discuss it with one’s own colleagues or with\\nthose having some expertise in the matter. In an academic institution the researcher can seek thehelp from a guide who is usually an experienced man and has several research problems in mind.Often, the guide puts forth the problem in general terms and it is up to the researcher to narrow itdown and phrase the problem in operational terms. In private business units or in governmentalorganisations, the problem is usually earmarked by the administrative agencies with whom theresearcher can discuss as to how the problem originally came about and what considerations areinvolved in its possible solutions.\\nThe researcher must at the same time examine all available literature to get himself acquainted\\nwith the selected problem. He may review two types of literature—the conceptual literature concerningthe concepts and theories, and the empirical literature consisting of studies made earlier which aresimilar to the one proposed. The basic outcome of this review will be the knowledge as to what dataand other materials are available for operational purposes which will enable the researcher to specifyhis own research problem in a meaningful context. After this the researcher rephrases the probleminto analytical or operational terms i.e., to put the problem in as specific terms as possible. This taskof formulating, or defining, a research problem is a step of greatest importance in the entire researchprocess. The problem to be investigated must be defined unambiguously for that will help discriminatingrelevant data from irrelevant ones. Care must, however, be taken to verify the objectivity and validityof the background facts concerning the problem. Professor W.A. Neiswanger correctly states thatResearch Methodology: An Introduction 13\\nthe statement of the objective is of basic importance because it determines the data which are to be\\ncollected, the characteristics of the data which are relevant, relations which are to be explored, thechoice of techniques to be used in these explorations and the form of the final report. If there arecertain pertinent terms, the same should be clearly defined along with the task of formulating theproblem. In fact, formulation of the problem often follows a sequential pattern where a number offormulations are set up, each formulation more specific than the preceeding one, each one phrased inmore analytical terms, and each more realistic in terms of the available data and resources.\\n2. Extensive literature survey:  Once the problem is formulated, a brief summary of it should be\\nwritten down. It is compulsory for a research worker writing a thesis for a Ph.D. degree to write a\\nsynopsis of the topic and submit it to the necessary Committee or the Research Board for approval.At this juncture the researcher should undertake extensive literature survey connected with theproblem. For this purpose, the abstracting and indexing journals and published or unpublishedbibliographies are the first place to go to. Academic journals, conference proceedings, governmentreports, books etc., must be tapped depending on the nature of the problem. In this process, it shouldbe remembered that one source will lead to another. The earlier studies, if any, which are similar tothe study in hand should be carefully studied. A good library will be a great help to the researcher atthis stage.\\n3. Development of working hypotheses:  After extensive literature survey, researcher should\\nstate in clear terms the working hypothesis or hypotheses. Working hypothesis is tentative assumptionmade in order to draw out and test its logical or empirical consequences. As such the manner inwhich research hypotheses are developed is particularly important since they provide the focal pointfor research. They also affect the manner in which tests must be conducted in the analysis of dataand indirectly the quality of data which is required for the analysis. In most types of research, thedevelopment of working hypothesis plays an important role. Hypothesis should be very specific andlimited to the piece of research in hand because it has to be tested. The role of the hypothesis is toguide the researcher by delimiting the area of research and to keep him on the right track. It sharpenshis thinking and focuses attention on the more important facets of the problem. It also indicates thetype of data required and the type of methods of data analysis to be used.\\nHow does one go about developing working hypotheses? The answer is by using the following\\napproach:\\n(a) Discussions with colleagues and experts about the problem, its origin and the objectives in\\nseeking a solution;\\n(b) Examination of data and records, if available, concerning the problem for possible trends,\\npeculiarities and other clues;\\n(c) Review of similar studies in the area or of the studies on similar problems; and\\n(d) Exploratory personal investigation which involves original field interviews on a limited scale\\nwith interested parties and individuals with a view to secure greater insight into the practical\\naspects of the problem.\\nThus, working hypotheses arise as a result of a-priori thinking about the subject, examination of theavailable data and material including related studies and the counsel of experts and interested parties.Working hypotheses are more useful when stated in precise and clearly defined terms. It may as wellbe remembered that occasionally we may encounter a problem where we do not need working14 Research Methodology\\nhypotheses, specially in the case of exploratory or formulative researches which do not aim at testing\\nthe hypothesis. But as a general rule, specification of working hypotheses in another basic step of theresearch process in most research problems.\\n4. Preparing the research design:  The research problem having been formulated in clear cut\\nterms, the researcher will be required to prepare a research design, i.e., he will have to state the\\nconceptual structure within which research would be conducted. The preparation of such a designfacilitates research to be as efficient as possible yielding maximal information. In other words, thefunction of research design is to provide for the collection of relevant evidence with minimal expenditureof effort, time and money. But how all these can be achieved depends mainly on the researchpurpose. Research purposes may be grouped into four categories, viz., (i) Exploration, (ii) Description,(iii) Diagnosis, and (iv) Experimentation. A flexible research design which provides opportunity forconsidering many different aspects of a problem is considered appropriate if the purpose of theresearch study is that of exploration. But when the purpose happens to be an accurate description ofa situation or of an association between variables, the suitable design will be one that minimises biasand maximises the reliability of the data collected and analysed.\\nThere are several research designs, such as, experimental and non-experimental hypothesis\\ntesting. Experimental designs can be either informal designs (such as before-and-after without control,after-only with control, before-and-after with control) or formal designs (such as completely randomizeddesign, randomized block design, Latin square design, simple and complex factorial designs), out ofwhich the researcher must select one for his own project.\\nThe preparation of the research design, appropriate for a particular research problem, involves\\nusually the consideration of the following:\\n(i) the means of obtaining the information;\\n(ii)the availability and skills of the researcher and his staff (if any);\\n(iii)explanation of the way in which selected means of obtaining information will be organisedand the reasoning leading to the selection;\\n(iv)the time available for research; and\\n(v) the cost factor relating to research, i.e., the finance available for the purpose.\\n5. Determining sample design:  All the items under consideration in any field of inquiry constitute\\na ‘universe’ or ‘population’. A complete enumeration of all the items in the ‘population’ is known asa census inquiry. It can be presumed that in such an inquiry when all the items are covered noelement of chance is left and highest accuracy is obtained. But in practice this may not be true. Eventhe slightest element of bias in such an inquiry will get larger and larger as the number of observationsincreases. Moreover, there is no way of checking the element of bias or its extent except through aresurvey or use of sample checks. Besides, this type of inquiry involves a great deal of time, moneyand energy. Not only this, census inquiry is not possible in practice under many circumstances. Forinstance, blood testing is done only on sample basis. Hence, quite often we select only a few itemsfrom the universe for our study purposes. The items so selected constitute what is technically calleda sample.\\nThe researcher must decide the way of selecting a sample or what is popularly known as the\\nsample design. In other words, a sample design is a definite plan determined before any data areactually collected for obtaining a sample from a given population. Thus, the plan to select 12 of aResearch Methodology: An Introduction 15\\ncity’s 200 drugstores in a certain way constitutes a sample design. Samples can be either probability\\nsamples or non-probability samples. With probability samples each element has a known probabilityof being included in the sample but the non-probability samples do not allow the researcher to determinethis probability. Probability samples are those based on simple random sampling, systematic sampling,stratified sampling, cluster/area sampling whereas non-probability samples are those based onconvenience sampling, judgement sampling and quota sampling techniques. A brief mention of theimportant sample designs is as follows:\\n(i)Deliberate sampling:  Deliberate sampling is also known as purposive or non-probability\\nsampling. This sampling method involves purposive or deliberate selection of particularunits of the universe for constituting a sample which represents the universe. When populationelements are selected for inclusion in the sample based on the ease of access, it can becalled convenience sampling . If a researcher wishes to secure data from, say, gasoline\\nbuyers, he may select a fixed number of petrol stations and may conduct interviews atthese stations. This would be an example of convenience sample of gasoline buyers. Attimes such a procedure may give very biased results particularly when the population is nothomogeneous. On the other hand, in judgement sampling  the researcher’s judgement is\\nused for selecting items which he considers as representative of the population. For example,a judgement sample of college students might be taken to secure reactions to a new methodof teaching. Judgement sampling is used quite frequently in qualitative research where thedesire happens to be to develop hypotheses rather than to generalise to larger populations.\\n(ii)Simple random sampling:  This type of sampling is also known as chance sampling or\\nprobability sampling where each and every item in the population has an equal chance ofinclusion in the sample and each one of the possible samples, in case of finite universe, hasthe same probability of being selected. For example, if we have to select a sample of 300items from a universe of 15,000 items, then we can put the names or numbers of all the15,000 items on slips of paper and conduct a lottery. Using the random number tables isanother method of random sampling. To select the sample, each item is assigned a numberfrom 1 to 15,000. Then, 300 five digit random numbers are selected from the table. To dothis we select some random starting point and then a systematic pattern is used in proceedingthrough the table. We might start in the 4th row, second column and proceed down thecolumn to the bottom of the table and then move to the top of the next column to the right.When a number exceeds the limit of the numbers in the frame, in our case over 15,000, it issimply passed over and the next number selected that does fall within the relevant range.Since the numbers were placed in the table in a completely random fashion, the resultingsample is random. This procedure gives each item an equal probability of being selected. Incase of infinite population, the selection of each item in a random sample is controlled bythe same probability and that successive selections are independent of one another.\\n(iii)Systematic sampling:  In some instances the most practical way of sampling is to select\\nevery 15th name on a list, every 10th house on one side of a street and so on. Sampling ofthis type is known as systematic sampling. An element of randomness is usually introducedinto this kind of sampling by using random numbers to pick up the unit with which to start.This procedure is useful when sampling frame is available in the form of a list. In such adesign the selection process starts by picking some random point in the list and then everynth element is selected until the desired number is secured.16 Research Methodology\\n(iv)Stratified sampling:  If the population from which a sample is to be drawn does not constitute\\na homogeneous group, then stratified sampling technique is applied so as to obtain a\\nrepresentative sample. In this technique, the population is stratified into a number of non-overlapping subpopulations or strata and sample items are selected from each stratum. Ifthe items selected from each stratum is based on simple random sampling the entire procedure,first stratification and then simple random sampling, is known as stratified random sampling .\\n(v)Quota sampling:  In stratified sampling the cost of taking random samples from individual\\nstrata is often so expensive that interviewers are simply given quota to be filled fromdifferent strata, the actual selection of items for sample being left to the interviewer’sjudgement. This is called quota sampling. The size of the quota for each stratum is generallyproportionate to the size of that stratum in the population. Quota sampling is thus an importantform of non-probability sampling. Quota samples generally happen to be judgement samplesrather than random samples.\\n(vi)Cluster sampling and area sampling:  Cluster sampling involves grouping the population\\nand then selecting the groups or the clusters rather than individual elements for inclusion inthe sample. Suppose some departmental store wishes to sample its credit card holders. Ithas issued its cards to 15,000 customers. The sample size is to be kept say 450. For clustersampling this list of 15,000 card holders could be formed into 100 clusters of 150 cardholders each. Three clusters might then be selected for the sample randomly. The samplesize must often be larger than the simple random sample to ensure the same level ofaccuracy because is cluster sampling procedural potential for order bias and other sourcesof error is usually accentuated. The clustering approach can, however, make the samplingprocedure relatively easier and increase the efficiency of field work, specially in the caseof personal interviews.\\nArea sampling is quite close to cluster sampling and is often talked about when the total\\ngeographical area of interest happens to be big one. Under area sampling we first dividethe total area into a number of smaller non-overlapping areas, generally called geographicalclusters, then a number of these smaller areas are randomly selected, and all units in thesesmall areas are included in the sample. Area sampling is specially helpful where we do nothave the list of the population concerned. It also makes the field interviewing more efficientsince interviewer can do many interviews at each location.\\n(vii)Multi-stage sampling:  This is a further development of the idea of cluster sampling. This\\ntechnique is meant for big inquiries extending to a considerably large geographical area likean entire country. Under multi-stage sampling the first stage may be to select large primarysampling units such as states, then districts, then towns and finally certain families withintowns. If the technique of random-sampling is applied at all stages, the sampling procedureis described as multi-stage random sampling.\\n(viii)Sequential sampling:  This is somewhat a complex sample design where the ultimate size\\nof the sample is not fixed in advance but is determined according to mathematical decisionson the basis of information yielded as survey progresses. This design is usually adoptedunder acceptance sampling plan in the context of statistical quality control.\\nIn practice, several of the methods of sampling described above may well be used in the same\\nstudy in which case it can be called mixed sampling. It may be pointed out here that normally oneResearch Methodology: An Introduction 17\\nshould resort to random sampling so that bias can be eliminated and sampling error can be estimated.\\nBut purposive sampling is considered desirable when the universe happens to be small and a knowncharacteristic of it is to be studied intensively. Also, there are conditions under which sample designsother than random sampling may be considered better for reasons like convenience and low costs.The sample design to be used must be decided by the researcher taking into consideration thenature of the inquiry and other related factors .\\n6. Collecting the data:  In dealing with any real life problem it is often found that data at hand are\\ninadequate, and hence, it becomes necessary to collect data that are appropriate. There are severalways of collecting the appropriate data which differ considerably in context of money costs, time andother resources at the disposal of the researcher.\\nPrimary data can be collected either through experiment or through survey. If the researcher\\nconducts an experiment, he observes some quantitative measurements, or the data, with the help ofwhich he examines the truth contained in his hypothesis. But in the case of a survey, data can becollected by any one or more of the following ways:\\n(i)By observation:  This method implies the collection of information by way of investigator’s\\nown observation, without interviewing the respondents. The information obtained relates towhat is currently happening and is not complicated by either the past behaviour or futureintentions or attitudes of respondents. This method is no doubt an expensive method andthe information provided by this method is also very limited. As such this method is notsuitable in inquiries where large samples are concerned.\\n(ii)Through personal interview:  The investigator follows a rigid procedure and seeks answers\\nto a set of pre-conceived questions through personal interviews. This method of collectingdata is usually carried out in a structured way where output depends upon the ability of theinterviewer to a large extent.\\n(iii)Through telephone interviews:  This method of collecting information involves contacting\\nthe respondents on telephone itself. This is not a very widely used method but it plays animportant role in industrial surveys in developed regions, particularly, when the survey hasto be accomplished in a very limited time.\\n(iv)By mailing of questionnaires:  The researcher and the respondents do come in contact\\nwith each other if this method of survey is adopted. Questionnaires are mailed to therespondents with a request to return after completing the same. It is the most extensivelyused method in various economic and business surveys. Before applying this method, usuallya Pilot Study for testing the questionnaire is conduced which reveals the weaknesses, ifany, of the questionnaire. Questionnaire to be used must be prepared very carefully so thatit may prove to be effective in collecting the relevant information.\\n(v)Through schedules: Under this method the enumerators are appointed and given training.They are provided with schedules containing relevant questions. These enumerators go torespondents with these schedules. Data are collected by filling up the schedules byenumerators on the basis of replies given by respondents. Much depends upon the capabilityof enumerators so far as this method is concerned. Some occasional field checks on thework of the enumerators may ensure sincere work.18 Research Methodology\\nThe researcher should select one of these methods of collecting the data taking into\\nconsideration the nature of investigation, objective and scope of the inquiry, finanical resources,\\navailable time and the desired degree of accuracy. Though he should pay attention to all thesefactors but much depends upon the ability and experience of the researcher. In this context Dr A.L.\\nBowley very aptly remarks that in collection of statistical data commonsense is the chief requisite\\nand experience the chief teacher.\\n7. Execution of the project: Execution of the project is a very important step in the researchprocess. If the execution of the project proceeds on correct lines, the data to be collected would beadequate and dependable. The researcher should see that the project is executed in a systematicmanner and in time. If the survey is to be conducted by means of structured questionnaires, data canbe readily machine-processed. In such a situation, questions as well as the possible answers may becoded. If the data are to be collected through interviewers, arrangements should be made for properselection and training of the interviewers. The training may be given with the help of instructionmanuals which explain clearly the job of the interviewers at each step. Occasional field checksshould be made to ensure that the interviewers are doing their assigned job sincerely and efficiently.A careful watch should be kept for unanticipated factors in order to keep the survey as muchrealistic as possible. This, in other words, means that steps should be taken to ensure that the surveyis under statistical control so that the collected information is in accordance with the pre-definedstandard of accuracy. If some of the respondents do not cooperate, some suitable methods should bedesigned to tackle this problem. One method of dealing with the non-response problem is to make alist of the non-respondents and take a small sub-sample of them, and then with the help of expertsvigorous efforts can be made for securing response.\\n8. Analysis of data:  After the data have been collected, the researcher turns to the task of analysing\\nthem. The analysis of data requires a number of closely related operations such as establishment of\\ncategories, the application of these categories to raw data through coding, tabulation and then drawingstatistical inferences. The unwieldy data should necessarily be condensed into a few manageablegroups and tables for further analysis. Thus, researcher should classify the raw data into somepurposeful and usable categories. Coding operation is usually done at this stage through which the\\ncategories of data are transformed into symbols that may be tabulated and counted. Editing is the\\nprocedure that improves the quality of the data for coding. With coding the stage is ready for tabulation.Tabulation  is a part of the technical procedure wherein the classified data are put in the form of\\ntables. The mechanical devices can be made use of at this juncture. A great deal of data, specially inlarge inquiries, is tabulated by computers. Computers not only save time but also make it possible tostudy large number of variables affecting a problem simultaneously.\\nAnalysis work after tabulation is generally based on the computation of various percentages,\\ncoefficients, etc., by applying various well defined statistical formulae. In the process of analysis,relationships or differences supporting or conflicting with original or new hypotheses should be subjectedto tests of significance to determine with what validity data can be said to indicate any conclusion(s).For instance, if there are two samples of weekly wages, each sample being drawn from factories indifferent parts of the same city, giving two different mean values, then our problem may be whetherthe two mean values are significantly different or the difference is just a matter of chance. Throughthe use of statistical tests we can establish whether such a difference is a real one or is the result ofrandom fluctuations. If the difference happens to be real, the inference will be that the two samplesResearch Methodology: An Introduction 19\\ncome from different universes and if the difference is due to chance, the conclusion would be that\\nthe two samples belong to the same universe. Similarly, the technique of analysis of variance canhelp us in analysing whether three or more varieties of seeds grown on certain fields yield significantlydifferent results or not. In brief, the researcher can analyse the collected data with the help ofvarious statistical measures.\\n9. Hypothesis-testing:  After analysing the data as stated above, the researcher is in a position to\\ntest the hypotheses, if any, he had formulated earlier. Do the facts support the hypotheses or they\\nhappen to be contrary? This is the usual question which should be answered while testing hypotheses.Various tests, such as Chi square test, t-test, F-test, have been developed by statisticians for the\\npurpose. The hypotheses may be tested through the use of one or more of such tests, depending uponthe nature and object of research inquiry. Hypothesis-testing will result in either accepting the hypothesisor in rejecting it. If the researcher had no hypotheses to start with, generalisations established on thebasis of data may be stated as hypotheses to be tested by subsequent researches in times to come.\\n10. Generalisations and interpretation:  If a hypothesis is tested and upheld several times, it may\\nbe possible for the researcher to arrive at generalisation, i.e., to build a theory. As a matter of fact,\\nthe real value of research lies in its ability to arrive at certain generalisations. If the researcher had nohypothesis to start with, he might seek to explain his findings on the basis of some theory. It is knownas interpretation. The process of interpretation may quite often trigger off new questions which inturn may lead to further researches.\\n11. Preparation of the report or the thesis:  Finally, the researcher has to prepare the report of\\nwhat has been done by him. Writing of report must be done with great care keeping in view the\\nfollowing:\\n1. The layout of the report should be as follows: ( i) the preliminary pages; ( ii) the main text,\\nand (iii) the end matter.\\nIn its preliminary pages  the report should carry title and date followed by acknowledgements\\nand foreword. Then there should be a table of contents followed by a list of tables and listof graphs and charts, if any, given in the report.\\nThe main text of the report  should have the following parts:\\n(a)Introduction:  It should contain a clear statement of the objective of the research and\\nan explanation of the methodology adopted in accomplishing the research. The scope\\nof the study along with various limitations should as well be stated in this part.\\n(b)Summary of findings:  After introduction there would appear a statement of findings\\nand recommendations in non-technical language. If the findings are extensive, theyshould be summarised.\\n(c)Main report: The main body of the report should be presented in logical sequence andbroken-down into readily identifiable sections.\\n(d)Conclusion:  Towards the end of the main text, researcher should again put down the\\nresults of his research clearly and precisely. In fact, it is the final summing up.\\nAt the end of the report , appendices should be enlisted in respect of all technical data. Bibliography,\\ni.e., list of books, journals, reports, etc., consulted, should also be given in the end. Index should alsobe given specially in a published research report.20 Research Methodology\\n2. Report should be written in a concise and objective style in simple language avoiding vague\\nexpressions such as ‘it seems,’ ‘there may be’, and the like.\\n3. Charts and illustrations in the main report should be used only if they present the information\\nmore clearly and forcibly.\\n4. Calculated ‘confidence limits’ must be mentioned and the various constraints experienced\\nin conducting research operations may as well be stated.\\nCriteria of Good Research\\nWhatever may be the types of research works and studies, one thing that is important is that they all\\nmeet on the common ground of scientific method employed by them. One expects scientific researchto satisfy the following criteria:\\n11\\n1. The purpose of the research should be clearly defined and common concepts be used.\\n2. The research procedure used should be described in sufficient detail to permit another\\nresearcher to repeat the research for further advancement, keeping the continuity of what\\nhas already been attained.\\n3. The procedural design of the research should be carefully planned to yield results that are\\nas objective as possible.\\n4. The researcher should report with complete frankness, flaws in procedural design and\\nestimate their effects upon the findings.\\n5. The analysis of data should be sufficiently adequate to reveal its significance and the\\nmethods of analysis used should be appropriate. The validity and reliability of the datashould be checked carefully.\\n6. Conclusions should be confined to those justified by the data of the research and limited to\\nthose for which the data provide an adequate basis.\\n7. Greater confidence in research is warranted if the researcher is experienced, has a good\\nreputation in research and is a person of integrity.\\nIn other words, we can state the qualities of a good research\\n12 as under:\\n1.Good research is systematic:  It means that research is structured with specified steps to\\nbe taken in a specified sequence in accordance with the well defined set of rules. Systematiccharacteristic of the research does not rule out creative thinking but it certainly does rejectthe use of guessing and intuition in arriving at conclusions.\\n2.Good research is logical:  This implies that research is guided by the rules of logical\\nreasoning and the logical process of induction and deduction are of great value in carryingout research. Induction is the process of reasoning from a part to the whole whereasdeduction is the process of reasoning from some premise to a conclusion which followsfrom that very premise. In fact, logical reasoning makes research more meaningful in thecontext of decision making.\\n11 James Harold Fox, Criteria of Good Research, Phi Delta Kappan, Vol. 39 (March, 1958), pp. 285–86.\\n12 See, Danny N. Bellenger and Barnett, A. Greenberg, “ Marketing Research—A Management Information Approach ”,\\np. 107–108.Research Methodology: An Introduction 21\\n3.Good research is empirical:  It implies that research is related basically to one or more\\naspects of a real situation and deals with concrete data that provides a basis for external\\nvalidity to research results.\\n4.Good research is replicable:  This characteristic allows research results to be verified by\\nreplicating the study and thereby building a sound basis for decisions.\\nProblems Encountered by Researchers in India\\nResearchers in India, particularly those engaged in empirical research, are facing several problems.Some of the important problems are as follows:\\n1.The lack of a scientific training in the methodology of research  is a great impediment\\nfor researchers in our country. There is paucity of competent researchers. Many researcherstake a leap in the dark without knowing research methods. Most of the work, which goesin the name of research is not methodologically sound. Research to many researchers andeven to their guides, is mostly a scissor and paste job without any insight shed on thecollated materials. The consequence is obvious, viz., the research results, quite often, donot reflect the reality or realities. Thus, a systematic study of research methodology is anurgent necessity. Before undertaking research projects, researchers should be well equippedwith all the methodological aspects. As such, efforts should be made to provide short-\\nduration intensive courses for meeting this requirement .\\n2. There is insufficient interaction  between the university research departments on one side\\nand business establishments, government departments and research institutions on the otherside. A great deal of primary data of non-confidential nature remain untouched/untreatedby the researchers for want of proper contacts. Efforts should be made to develop\\nsatisfactory liaison among all concerned for better and realistic researches. There isneed for developing some mechanisms of a university—industry interaction programme sothat academics can get ideas from practitioners on what needs to be researched andpractitioners can apply the research done by the academics.\\n3. Most of the business units in our country do not have the confidence that the material\\nsupplied by them to researchers will not be misused and as such they are often reluctant insupplying the needed information to researchers. The concept of secrecy seems to besacrosanct to business organisations in the country so much so that it proves an impermeablebarrier to researchers. Thus, there is the need for generating the confidence that the\\ninformation/data obtained from a business unit will not be misused .\\n4.Research studies overlapping one another are undertaken quite often for want ofadequate information . This results in duplication and fritters away resources. This problem\\ncan be solved by proper compilation and revision, at regular intervals, of a list of subjects onwhich and the places where the research is going on. Due attention should be given towardidentification of research problems in various disciplines of applied science which are ofimmediate concern to the industries.\\n5.There does not exist a code of conduct for researchers  and inter-university and inter-\\ndepartmental rivalries are also quite common. Hence, there is need for developing a codeof conduct for researchers which, if adhered sincerely, can win over this problem.22 Research Methodology\\n6. Many researchers in our country also face the difficulty of adequate and timely secretarial\\nassistance,  including computerial assistance. This causes unnecessary delays in the\\ncompletion of research studies. All possible efforts be made in this direction so that efficient\\nsecretarial assistance is made available to researchers and that too well in time. UniversityGrants Commission must play a dynamic role in solving this difficulty.\\n7.Library management and functioning is not satisfactory at many places  and much of\\nthe time and energy of researchers are spent in tracing out the books, journals, reports, etc.,rather than in tracing out relevant material from them.\\n8.There is also the problem that many of our libraries are not able to get copies of oldand new Acts/Rules, reports and other government publications in time . This problem\\nis felt more in libraries which are away in places from Delhi and/or the state capitals. Thus,efforts should be made for the regular and speedy supply of all governmental publicationsto reach our libraries.\\n9.There is also the difficulty of timely availability of published data  from various\\ngovernment and other agencies doing this job in our country. Researcher also faces theproblem on account of the fact that the published data vary quite significantly because ofdifferences in coverage by the concerning agencies.\\n10. There may, at times, take place the problem of conceptualization  and also problems\\nrelating to the process of data collection and related things.\\nQuestions\\n1.Briefly describe the different steps involved in a research process.\\n2.What do you mean by research? Explain its significance in modern times.\\n3.Distinguish between Research methods and Research methodology.\\n4.Describe the different types of research, clearly pointing out the difference between an experiment and asurvey.\\n5.Write short notes on:\\n(1) Design of the research project;\\n(2) Ex post facto research;\\n(3) Motivation in research;\\n(4) Objectives of research;(5) Criteria of good research;\\n(7) Research and scientific method.\\n6.“Empirical research in India in particular creates so many problems for the researchers”. State the problems\\nthat are usually faced by such researchers.\\n(Raj. Univ. EAFM., M. Phil. Exam., 1979 )\\n7.“A research scholar has to work as a judge and derive the truth and not as a pleader who is only eagerto prove his case in favour of his plaintiff.” Discuss the statement pointing out the objectives ofresearch.Research Methodology: An Introduction 23\\n8.“Creative management, whether in public administration or private industry, depends on methods of\\ninquiry that maintain objectivity, clarity, accuracy and consistency”. Discuss this statement and examinethe significance of research”.\\n(Raj. Univ. EAFM., M. Phil. Exam., 1978 )\\n9.“Research is much concerned with proper fact finding, analysis and evaluation.” Do you agree with thisstatement? Give reasons in support of your answer.\\n10.It is often said that there is not a proper link between some of the activities under way in the world ofacademics and in most business in our country. Account for this state of affairs and give suggestions forimprovement.24 Research Methodology\\n2\\nDefining the Research Problem\\nIn research process, the first and foremost step happens to be that of selecting and properly defining\\na research problem.* A researcher must find the problem and formulate it so that it becomes susceptibleto research. Like a medical doctor, a researcher must examine all the symptoms (presented to him orobserved by him) concerning a problem before he can diagnose correctly. To define a problemcorrectly, a researcher must know: what a problem is?\\nWHAT IS A RESEARCH PROBLEM?\\nA research problem, in general, refers to some difficulty which a researcher experiences in thecontext of either a theoretical or practical situation and wants to obtain a solution for the same.Usually we say that a research problem does exist if the following conditions are met with:\\n(i) There must be an individual (or a group or an organisation), let us call it ‘ I,’ to whom the\\nproblem can be attributed. The individual or the organisation, as the case may be, occupiesan environment, say ‘ N’, which is defined by values of the uncontrolled variables, Y\\nj.\\n(ii)There must be at least two courses of action, say C1 and C2, to be pursued. A course of\\naction is defined by one or more values of the controlled variables. For example, the numberof items purchased at a specified time is said to be one course of action.\\n(iii)There must be at least two possible outcomes, say O\\n1 and O2, of the course of action, of\\nwhich one should be preferable to the other. In other words, this means that there must beat least one outcome that the researcher wants, i.e., an objective.\\n(iv)The courses of action available must provides some chance of obtaining the objective, butthey cannot provide the same chance, otherwise the choice would not matter. Thus, ifP(O\\nj | I, Cj, N) represents the probability that an outcome Oj will occur, if I select Cj in N,\\nthen PO IC N PO IC N11 12||,, ,, bg b g ≠ . In simple words, we can say that the choices\\nmust have unequal efficiencies for the desired outcomes.\\n* We talk of a research problem or hypothesis in case of descriptive or hypothesis testing research studies. Exploratory\\nor formulative research studies do not start with a problem or hypothesis, their problem is to find a problem or thehypothesis to be tested. One should make a clear statement to this effect. This aspect has been dealt with in chapter entitled“Research Design”.Defining the Research Problem 25\\nOver and above these conditions, the individual or the organisation can be said to have the\\nproblem only if ‘ I’ does not know what course of action is best, i.e., ‘ I’, must be in doubt about the\\nsolution. Thus, an individual or a group of persons can be said to have a problem which can be\\ntechnically described as a research problem, if they (individual or the group), having one or moredesired outcomes, are confronted with two or more courses of action that have some but not equalefficiency for the desired objective(s) and are in doubt about which course of action is best.\\nWe can, thus, state the components\\n1 of a research problem as under:\\n(i) There must be an individual or a group which has some difficulty or the problem.\\n(ii)There must be some objective(s) to be attained at. If one wants nothing, one cannot havea problem.\\n(iii)There must be alternative means (or the courses of action) for obtaining the objective(s)one wishes to attain. This means that there must be at least two means  available to a\\nresearcher for if he has no choice of means, he cannot have a problem.\\n(iv)There must remain some doubt in the mind of a researcher with regard to the selection ofalternatives. This means that research must answer the question concerning the relativeefficiency of the possible alternatives.\\n(v) There must be some environment(s) to which the difficulty pertains.\\nThus, a research problem is one which requires a researcher to find out the best solution for the\\ngiven problem, i.e., to find out by which course of action the objective can be attained optimally in the\\ncontext of a given environment. There are several factors which may result in making the problem\\ncomplicated. For instance, the environment may change affecting the efficiencies of the courses ofaction or the values of the outcomes; the number of alternative courses of action may be very large;persons not involved in making the decision may be affected by it and react to it favourably orunfavourably, and similar other factors. All such elements (or at least the important ones) may bethought of in context of a research problem.\\nSELECTING THE PROBLEM\\nThe research problem undertaken for study must be carefully selected. The task is a difficult one,although it may not appear to be so. Help may be taken from a research guide in this connection.Nevertheless, every researcher must find out his own salvation for research problems cannot beborrowed. A problem must spring from the researcher’s mind like a plant springing from its ownseed. If our eyes need glasses, it is not the optician alone who decides about the number of the lenswe require. We have to see ourselves and enable him to prescribe for us the right number bycooperating with him. Thus, a research guide can at the most only help a researcher choose asubject. However, the following points may be observed by a researcher in selecting a researchproblem or a subject for research:\\n(i) Subject which is overdone should not be normally chosen, for it will be a difficult task to\\nthrow any new light in such a case.\\n(ii)Controversial subject should not become the choice of an average researcher.\\n1 R.L. Ackoff, The Design of Social Research , Chicago University Press, Chicago, 1961.26 Research Methodology\\n(iii) Too narrow or too vague problems should be avoided.\\n(iv)The subject selected for research should be familiar and feasible so that the related research\\nmaterial or sources of research are within one’s reach. Even then it is quite difficult tosupply definitive ideas concerning how a researcher should obtain ideas for his research.For this purpose, a researcher should contact an expert or a professor in the Universitywho is already engaged in research. He may as well read articles published in currentliterature available on the subject and may think how the techniques and ideas discussedtherein might be applied to the solution of other problems. He may discuss with others whathe has in mind concerning a problem. In this way he should make all possible efforts inselecting a problem.\\n(v) The importance of the subject, the qualifications and the training of a researcher, the costs\\ninvolved, the time factor are few other criteria that must also be considered in selecting aproblem. In other words, before the final selection of a problem is done, a researcher mustask himself the following questions:\\n(a) Whether he is well equipped in terms of his background to carry out the research?\\n(b) Whether the study falls within the budget he can afford?\\n(c) Whether the necessary cooperation can be obtained from those who must participate\\nin research as subjects?\\nIf the answers to all these questions are in the affirmative, one may become sure so far as\\nthe practicability of the study is concerned.\\n(vi)The selection of a problem must be preceded by a preliminary study. This may not benecessary when the problem requires the conduct of a research closely similar to one thathas already been done. But when the field of inquiry is relatively new and does not haveavailable a set of well developed techniques, a brief feasibility study must always beundertaken.\\nIf the subject for research is selected properly by observing the above mentioned points, the\\nresearch will not be a boring drudgery, rather it will be love’s labour. In fact, zest for work is a must.The subject or the problem selected must involve the researcher and must have an upper most placein his mind so that he may undertake all pains needed for the study.\\nNECESSITY OF DEFINING THE PROBLEM\\nQuite often we all hear that a problem clearly stated is a problem half solved. This statement signifiesthe need for defining a research problem. The problem to be investigated must be definedunambiguously for that will help to discriminate relevant data from the irrelevant ones. A properdefinition of research problem will enable the researcher to be on the track whereas an ill-definedproblem may create hurdles. Questions like: What data are to be collected? What characteristics ofdata are relevant and need to be studied? What relations are to be explored. What techniques are tobe used for the purpose? and similar other questions crop up in the mind of the researcher who canwell plan his strategy and find answers to all such questions only when the research problem hasbeen well defined. Thus, defining a research problem properly is a prerequisite for any study and isa step of the highest importance. In fact, formulation of a problem is often more essential than itsDefining the Research Problem 27\\nsolution. It is only on careful detailing the research problem that we can work out the research design\\nand can smoothly carry on all the consequential steps involved while doing research.\\nTECHNIQUE INVOLVED IN DEFINING A PROBLEM\\nLet us start with the question: What does one mean when he/she wants to define a research problem?The answer may be that one wants to state the problem along with the bounds within which it is to bestudied. In other words, defining a problem involves the task of laying down boundaries within whicha researcher shall study the problem with a pre-determined objective in view.\\nHow to define a research problem is undoubtedly a herculean task. However, it is a task that\\nmust be tackled intelligently to avoid the perplexity encountered in a research operation. The usualapproach is that the researcher should himself pose a question (or in case someone else wants theresearcher to carry on research, the concerned individual, organisation or an authority should posethe question to the researcher) and set-up techniques and procedures for throwing light on thequestion concerned for formulating or defining the research problem. But such an approach generallydoes not produce definitive results because the question phrased in such a fashion is usually in broadgeneral terms and as such may not be in a form suitable for testing.\\nDefining a research problem properly and clearly is a crucial part of a research study and must\\nin no case be accomplished hurriedly. However, in practice this a frequently overlooked which causesa lot of problems later on. Hence, the research problem should be defined in a systematic manner,giving due weightage to all relating points. The technique for the purpose involves the undertaking ofthe following steps generally one after the other: (i) statement of the problem in a general way; (ii)understanding the nature of the problem; (iii) surveying the available literature (iv) developing theideas through discussions; and (v) rephrasing the research problem into a working proposition.\\nA brief description of all these points will be helpful.\\n(i) Statement of the problem in a general way: First of all the problem should be stated in a\\nbroad general way, keeping in view either some practical concern or some scientific or intellectualinterest. For this purpose, the researcher must immerse himself thoroughly in the subject matterconcerning which he wishes to pose a problem. In case of social research, it is considered advisableto do some field observation and as such the researcher may undertake some sort of preliminarysurvey or what is often called pilot survey . Then the researcher can himself state the problem or he\\ncan seek the guidance of the guide or the subject expert in accomplishing this task. Often, the guideputs forth the problem in general terms, and it is then up to the researcher to narrow it down andphrase the problem in operational terms. In case there is some directive from an organisationalauthority, the problem then can be stated accordingly. The problem stated in a broad general waymay contain various ambiguities which must be resolved by cool thinking and rethinking over theproblem. At the same time the feasibility of a particular solution has to be considered and the sameshould be kept in view while stating the problem.\\n(ii) Understanding the nature of the problem: The next step in defining the problem is to\\nunderstand its origin and nature clearly. The best way of understanding the problem is to discuss itwith those who first raised it in order to find out how the problem originally came about and with whatobjectives in view. If the researcher has stated the problem himself, he should consider once again allthose points that induced him to make a general statement concerning the problem. For a better28 Research Methodology\\nunderstanding of the nature of the problem involved, he can enter into discussion with those who\\nhave a good knowledge of the problem concerned or similar other problems. The researcher shouldalso keep in view the environment within which the problem is to be studied and understood.\\n(iii) Surveying the available literature: All available literature concerning the problem at hand\\nmust necessarily be surveyed and examined before a definition of the research problem is given.\\nThis means that the researcher must be well-conversant with relevant theories in the field, reportsand records as also all other relevant literature. He must devote sufficient time in reviewing ofresearch already undertaken on related problems. This is done to find out what data and othermaterials, if any, are available for operational purposes. “Knowing what data are available oftenserves to narrow the problem itself as well as the technique that might be used.”\\n2. This would also\\nhelp a researcher to know if there are certain gaps in the theories, or whether the existing theoriesapplicable to the problem under study are inconsistent with each other, or whether the findings of thedifferent studies do not follow a pattern consistent with the theoretical expectations and so on. Allthis will enable a researcher to take new strides in the field for furtherance of knowledge i.e., he canmove up starting from the existing premise. Studies on related problems are useful for indicating thetype of difficulties that may be encountered in the present study as also the possible analyticalshortcomings. At times such studies may also suggest useful and even new lines of approach to thepresent problem.\\n(iv) Developing the ideas through discussions: Discussion concerning a problem often produces\\nuseful information. Various new ideas can be developed through such an exercise. Hence, a researcher\\nmust discuss his problem with his colleagues and others who have enough experience in the samearea or in working on similar problems. This is quite often known as an experience survey . People\\nwith rich experience are in a position to enlighten the researcher on different aspects of his proposedstudy and their advice and comments are usually invaluable to the researcher. They help him sharpenhis focus of attention on specific aspects within the field. Discussions with such persons should notonly be confined to the formulation of the specific problem at hand, but should also be concerned withthe general approach to the given problem, techniques that might be used, possible solutions, etc.\\n(v) Rephrasing the research problem: Finally, the researcher must sit to rephrase the research\\nproblem into a working proposition. Once the nature of the problem has been clearly understood, theenvironment (within which the problem has got to be studied) has been defined, discussions over theproblem have taken place and the available literature has been surveyed and examined, rephrasingthe problem into analytical or operational terms is not a difficult task. Through rephrasing, the researcherputs the research problem in as specific terms as possible so that it may become operationally viableand may help in the development of working hypotheses.*\\nIn addition to what has been stated above, the following points must also be observed while\\ndefining a research problem:\\n2 Robert Ferber and P.J. Verdoorn, Research Methods in Economics and Business , p. 33–34.\\n* Working hypotheses are a set of suggested tentative solutions of explanations of a research problem which may or may\\nnot be the real solutions. The task of research is to test and establish such hypotheses. Hypotheses should be clearly andprecisely stated in simple terms, they should be testable, limited in scope and should state relationship between variables.They should be amenable to testing within a reasonable time and should be consistent with most of the known facts(Testing of hypotheses has been dealt with later in the book).Defining the Research Problem 29\\n(a) Technical terms and words or phrases, with special meanings used in the statement of the\\nproblem, should be clearly defined.\\n(b) Basic assumptions or postulates (if any) relating to the research problem should be clearly\\nstated.\\n(c) A straight forward statement of the value of the investigation (i.e., the criteria for the\\nselection of the problem) should be provided.\\n(d) The suitability of the time-period and the sources of data available must also be considered\\nby the researcher in defining the problem.\\n(e) The scope of the investigation or the limits within which the problem is to be studied must\\nbe mentioned explicitly in defining a research problem.\\nAN ILLUSTRATION\\nThe technique of defining a problem outlined above can be illustrated for better understanding by\\ntaking an example as under:\\nLet us suppose that a research problem in a broad general way is as follows:\\n“Why is productivity in Japan so much higher than in India”?\\nIn this form the question has a number of ambiguities such as: What sort of productivity\\nis being referred to? With what industries the same is related? With what period of time\\nthe productivity is being talked about? In view of all such ambiguities the given statement\\nor the question is much too general to be amenable to analysis. Rethinking and discussionsabout the problem may result in narrowing down the question to:\\n“What factors were responsible for the higher labour productivity of Japan’s manufacturing\\nindustries during the decade 1971 to 1980 relative to India’s manufacturing industries?”\\nThis latter version of the problem is definitely an improvement over its earlier version for\\nthe various ambiguities have been removed to the extent possible. Further rethinking andrephrasing might place the problem on a still better operational basis as shown below:\\n“To what extent did labour productivity in 1971 to 1980 in Japan exceed that of India in\\nrespect of 15 selected manufacturing industries? What factors were responsible for theproductivity differentials between the two countries by industries?”\\nWith this sort of formulation, the various terms involved such as ‘labour productivity’, ‘productivity\\ndifferentials’, etc. must be explained clearly. The researcher must also see that the necessary dataare available. In case the data for one or more industries selected are not available for the concerningtime-period, then the said industry or industries will have to be substituted by other industry or industries.The suitability of the time-period must also be examined. Thus, all relevant factors must be consideredby a researcher before finally defining a research problem.\\nCONCLUSION\\nWe may conclude by saying that the task of defining a research problem, very often, follows asequential pattern—the problem is stated in a general way, the ambiguities are resolved, thinking andrethinking process results in a more specific formulation of the problem so that it may be a realistic30 Research Methodology\\none in terms of the available data and resources and is also analytically meaningful. All this results in\\na well defined research problem that is not only meaningful from an operational point of view, but isequally capable of paving the way for the development of working hypotheses and for means ofsolving the problem itself.\\nQuestions\\n1.Describe fully the techniques of defining a research problem.\\n2.What is research problem? Define the main issues which should receive the attention of the researcher informulating the research problem. Give suitable examples to elucidate your points.\\n(Raj. Uni. EAFM, M. Phil. Exam.  1979)\\n3.How do you define a research problem? Give three examples to illustrate your answer.\\n(Raj. Uni. EAFM, M. Phil. Exam.  1978)\\n4.What is the necessity of defining a research problem? Explain.\\n5.Write short notes on:\\n(a) Experience survey;\\n(b) Pilot survey;\\n(c) Components of a research problem;\\n(d) Rephrasing the research problem.\\n6.“The task of defining the research problem often follows a sequential pattern”. Explain.\\n7.“Knowing what data are available often serves to narrow down the problem itself as well as the techniquethat might be used.” Explain the underlying idea in this statement in the context of defining a researchproblem.\\n8.Write a comprehensive note on the “Task of defining a research problem”.Research Design 31\\n3\\nResearch Design\\nMEANING OF RESEARCH DESIGN\\nThe formidable problem that follows the task of defining the research problem is the preparation of\\nthe design of the research project, popularly known as the “research design”. Decisions regardingwhat, where, when, how much, by what means concerning an inquiry or a research study constitutea research design. “A research design is the arrangement of conditions for collection and analysis ofdata in a manner that aims to combine relevance to the research purpose with economy in procedure.”\\n1\\nIn fact, the research design is the conceptual structure within which research is conducted; it constitutesthe blueprint for the collection, measurement and analysis of data. As such the design includes anoutline of what the researcher will do from writing the hypothesis and its operational implications tothe final analysis of data. More explicitly, the desing decisions happen to be in respect of:\\n(i) What is the study about?\\n(ii)Why is the study being made?\\n(iii)Where will the study be carried out?\\n(iv)What type of data is required?\\n(v) Where can the required data be found?\\n(vi)What periods of time will the study include?\\n(vii)What will be the sample design?\\n(viii)What techniques of data collection will be used?\\n(ix)How will the data be analysed?\\n(x) In what style will the report be prepared?\\nKeeping in view the above stated design decisions, one may split the overall research design into\\nthe following parts:\\n(a)the sampling design  which deals with the method of selecting items to be observed for the\\ngiven study;\\n1 Claire Selltiz and others, Research Methods in Social Sciences , 1962, p. 50.32 Research Methodology\\n(b)the observational design  which relates to the conditions under which the observations\\nare to be made;\\n(c)the statistical design  which concerns with the question of how many items are to be\\nobserved and how the information and data gathered are to be analysed; and\\n(d)the operational design  which deals with the techniques by which the procedures specified\\nin the sampling, statistical and observational designs can be carried out.\\nFrom what has been stated above, we can state the important features of a research design as\\nunder:\\n(i) It is a plan that specifies the sources and types of information relevant to the research\\nproblem.\\n(ii) It is a strategy specifying which approach will be used for gathering and analysing the data.\\n(iii) It also includes the time and cost budgets since most studies are done under these two\\nconstraints.\\nIn brief, research design must, at least, contain—(a) a clear statement of the research problem;\\n(b) procedures and techniques to be used for gathering information; (c) the population to be studied;\\nand (d) methods to be used in processing and analysing data.\\nNEED FOR RESEARCH DESIGN\\nResearch design is needed because it facilitates the smooth sailing of the various research operations,thereby making research as efficient as possible yielding maximal information with minimal expenditureof effort, time and money. Just as for better, economical and attractive construction of a house, weneed a blueprint (or what is commonly called the map of the house) well thought out and prepared byan expert architect, similarly we need a research design or a plan in advance of data collection andanalysis for our research project. Research design stands for advance planning of the methods to beadopted for collecting the relevant data and the techniques to be used in their analysis, keeping inview the objective of the research and the availability of staff, time and money. Preparation of theresearch design should be done with great care as any error in it may upset the entire project.Research design, in fact, has a great bearing on the reliability of the results arrived at and as suchconstitutes the firm foundation of the entire edifice of the research work.\\nEven then the need for a well thought out research design is at times not realised by many. The\\nimportance which this problem deserves is not given to it. As a result many researches do not servethe purpose for which they are undertaken. In fact, they may even give misleading conclusions.Thoughtlessness in designing the research project may result in rendering the research exercisefutile. It is, therefore, imperative that an efficient and appropriate design must be prepared beforestarting research operations. The design helps the researcher to organize his ideas in a form wherebyit will be possible for him to look for flaws and inadequacies. Such a design can even be given toothers for their comments and critical evaluation. In the absence of such a course of action, it will bedifficult for the critic to provide a comprehensive review of the proposed study.Research Design 33\\nFEATURES OF A GOOD DESIGN\\nA good design is often characterised by adjectives like flexible, appropriate, efficient, economical\\nand so on. Generally, the design which minimises bias and maximises the reliability of the datacollected and analysed is considered a good design. The design which gives the smallest experimentalerror is supposed to be the best design in many investigations. Similarly, a design which yields maximalinformation and provides an opportunity for considering many different aspects of a problem isconsidered most appropriate and efficient design in respect of many research problems. Thus, thequestion of good design is related to the purpose or objective of the research problem and also withthe nature of the problem to be studied. A design may be quite suitable in one case, but may be foundwanting in one respect or the other in the context of some other research problem. One single designcannot serve the purpose of all types of research problems.\\nA research design appropriate for a particular research problem, usually involves the consideration\\nof the following factors:\\n(i) the means of obtaining information;\\n(ii)the availability and skills of the researcher and his staff, if any;\\n(iii)the objective of the problem to be studied;\\n(iv)the nature of the problem to be studied; and\\n(v) the availability of time and money for the research work.\\nIf the research study happens to be an exploratory or a formulative one, wherein the major\\nemphasis is on discovery of ideas and insights, the research design most appropriate must be flexibleenough to permit the consideration of many different aspects of a phenomenon. But when the purposeof a study is accurate description of a situation or of an association between variables (or in what arecalled the descriptive studies), accuracy becomes a major consideration and a research design whichminimises bias and maximises the reliability of the evidence collected is considered a good design.Studies involving the testing of a hypothesis of a causal relationship between variables require adesign which will permit inferences about causality in addition to the minimisation of bias andmaximisation of reliability. But in practice it is the most difficult task to put a particular study in aparticular group, for a given research may have in it elements of two or more of the functions ofdifferent studies. It is only on the basis of its primary function that a study can be categorised eitheras an exploratory or descriptive or hypothesis-testing study and accordingly the choice of a researchdesign may be made in case of a particular study. Besides, the availability of time, money, skills of theresearch staff and the means of obtaining the information must be given due weightage while workingout the relevant details of the research design such as experimental design, survey design, sampledesign and the like.\\nIMPORTANT CONCEPTS RELATING TO RESEARCH DESIGN\\nBefore describing the different research designs, it will be appropriate to explain the various conceptsrelating to designs so that these may be better and easily understood.\\n1. Dependent and independent variables: A concept which can take on different quantitative\\nvalues is called a variable. As such the concepts like weight, height, income are all examples of\\nvariables. Qualitative phenomena (or the attributes) are also quantified on the basis of the presence34 Research Methodology\\nor absence of the concerning attribute(s). Phenomena which can take on quantitatively different\\nvalues even in decimal points are called ‘continuous variables’.* But all variables are not continuous.\\nIf they can only be expressed in integer values, they are non-continuous variables or in statisticallanguage ‘discrete variables’.\\n** Age is an example of continuous variable, but the number of children\\nis an example of non-continuous variable. If one variable depends upon or is a consequence of theother variable, it is termed as a dependent variable, and the variable that is antecedent to the dependentvariable is termed as an independent variable. For instance, if we say that height depends upon age,then height is a dependent variable and age is an independent variable. Further, if in addition to beingdependent upon age, height also depends upon the individual’s sex, then height is a dependent variableand age and sex are independent variables. Similarly, readymade films and lectures are examples ofindependent variables, whereas behavioural changes, occurring as a result of the environmentalmanipulations, are examples of dependent variables.\\n2. Extraneous variable: Independent variables that are not related to the purpose of the study, but\\nmay affect the dependent variable are termed as extraneous variables. Suppose the researcher\\nwants to test the hypothesis that there is a relationship between children’s gains in social studiesachievement and their self-concepts. In this case self-concept is an independent variable and socialstudies achievement is a dependent variable. Intelligence may as well affect the social studiesachievement, but since it is not related to the purpose of the study undertaken by the researcher, itwill be termed as an extraneous variable. Whatever effect is noticed on dependent variable as aresult of extraneous variable(s) is technically described as an ‘experimental error’. A study mustalways be so designed that the effect upon the dependent variable is attributed entirely to the\\nindependent variable(s), and not to some extraneous variable or variables .\\n3. Control: One important characteristic of a good research design is to minimise the influence or\\neffect of extraneous variable(s). The technical term ‘control’ is used when we design the studyminimising the effects of extraneous independent variables. In experimental researches, the term‘control’ is used to refer to restrain experimental conditions.\\n4. Confounded relationship: When the dependent variable is not free from the influence of\\nextraneous variable(s), the relationship between the dependent and independent variables is said to\\nbe confounded by an extraneous variable(s).\\n5.Research hypothesis: When a prediction or a hypothesised relationship is to be tested by scientific\\nmethods, it is termed as research hypothesis. The research hypothesis is a predictive statement that\\nrelates an independent variable to a dependent variable. Usually a research hypothesis must contain,at least, one independent and one dependent variable. Predictive statements which are not to beobjectively verified or the relationships that are assumed but not to be tested, are not termed researchhypotheses.\\n6. Experimental and non-experimental hypothesis-testing research: When the purpose of\\nresearch is to test a research hypothesis, it is termed as hypothesis-testing research. It can be of the\\nexperimental design or of the non-experimental design. Research in which the independent variableis manipulated is termed ‘experimental hypothesis-testing research’ and a research in which anindependent variable is not manipulated is called ‘non-experimental hypothesis-testing research’. Forinstance, suppose a researcher wants to study whether intelligence affects reading ability for a group\\n* A continuous variable is that which can assume any numerical value within a specific range.\\n** A variable for which the individual values fall on the scale only with distinct gaps is called a discrete variable.Research Design 35\\nof students and for this purpose he randomly selects 50 students and tests their intelligence and\\nreading ability by calculating the coefficient of correlation between the two sets of scores. This is anexample of non-experimental hypothesis-testing research because herein the independent variable,intelligence, is not manipulated. But now suppose that our researcher randomly selects 50 studentsfrom a group of students who are to take a course in statistics and then divides them into two groupsby randomly assigning 25 to Group A, the usual studies programme, and 25 to Group B, the specialstudies programme. At the end of the course, he administers a test to each group in order to judge theeffectiveness of the training programme on the student’s performance-level. This is an example ofexperimental hypothesis-testing research because in this case the independent variable, viz., the typeof training programme, is manipulated.\\n7. Experimental and control groups: In an experimental hypothesis-testing research when a\\ngroup is exposed to usual conditions, it is termed a ‘control group’, but when the group is exposed to\\nsome novel or special condition, it is termed an ‘experimental group’. In the above illustration, theGroup A can be called a control group and the Group B an experimental group. If both groups A andB are exposed to special studies programmes, then both groups would be termed ‘experimentalgroups.’ It is possible to design studies which include only experimental groups or studies whichinclude both experimental and control groups.\\n8. Treatments: The different conditions under which experimental and control groups are put are\\nusually referred to as ‘treatments’. In the illustration taken above, the two treatments are the usual\\nstudies programme and the special studies programme. Similarly, if we want to determine through anexperiment the comparative impact of three varieties of fertilizers on the yield of wheat, in that casethe three varieties of fertilizers will be treated as three treatments.\\n9. Experiment: The process of examining the truth of a statistical hypothesis, relating to some\\nresearch problem, is known as an experiment. For example, we can conduct an experiment to\\nexamine the usefulness of a certain newly developed drug. Experiments can be of two types viz.,absolute experiment and comparative experiment. If we want to determine the impact of a fertilizeron the yield of a crop, it is a case of absolute experiment; but if we want to determine the impact ofone fertilizer as compared to the impact of some other fertilizer, our experiment then will be termedas a comparative experiment. Often, we undertake comparative experiments when we talk of designsof experiments.\\n10. Experimental unit(s): The pre-determined plots or the blocks, where different treatments are\\nused, are known as experimental units. Such experimental units must be selected (defined) verycarefully.\\nDIFFERENT RESEARCH DESIGNS\\nDifferent research designs can be conveniently described if we categorize them as: (1) researchdesign in case of exploratory research studies; (2) research design in case of descriptive and diagnosticresearch studies, and (3) research design in case of hypothesis-testing research studies.\\nWe take up each category separately.\\n1. Research design in case of exploratory research studies: Exploratory research studies are\\nalso termed as formulative research studies. The main purpose of such studies is that of formulatinga problem for more precise investigation or of developing the working hypotheses from an operational36 Research Methodology\\npoint of view. The major emphasis in such studies is on the discovery of ideas and insights. As such\\nthe research design appropriate for such studies must be flexible enough to provide opportunity forconsidering different aspects of a problem under study. Inbuilt flexibility in research design is neededbecause the research problem, broadly defined initially, is transformed into one with more precisemeaning in exploratory studies, which fact may necessitate changes in the research procedure forgathering relevant data. Generally, the following three methods in the context of research design forsuch studies are talked about: (a) the survey of concerning literature; (b) the experience survey and(c) the analysis of ‘insight-stimulating’ examples.\\nThe survey of concerning literature happens to be the most simple and fruitful method of\\nformulating precisely the research problem or developing hypothesis. Hypotheses stated by earlierworkers may be reviewed and their usefulness be evaluated as a basis for further research. It mayalso be considered whether the already stated hypotheses suggest new hypothesis. In this way theresearcher should review and build upon the work already done by others, but in cases wherehypotheses have not yet been formulated, his task is to review the available material for deriving therelevant hypotheses from it.\\nBesides, the bibliographical survey of studies, already made in one’s area of interest may as well\\nas made by the researcher for precisely formulating the problem. He should also make an attempt toapply concepts and theories developed in different research contexts to the area in which he ishimself working. Sometimes the works of creative writers also provide a fertile ground for hypothesis-formulation and as such may be looked into by the researcher.\\nExperience survey means the survey of people who have had practical experience with the\\nproblem to be studied. The object of such a survey is to obtain insight into the relationships betweenvariables and new ideas relating to the research problem. For such a survey people who are competentand can contribute new ideas may be carefully selected as respondents to ensure a representation ofdifferent types of experience. The respondents so selected may then be interviewed by the investigator.The researcher must prepare an interview schedule for the systematic questioning of informants.But the interview must ensure flexibility in the sense that the respondents should be allowed to raiseissues and questions which the investigator has not previously considered. Generally, the experience-collecting interview is likely to be long and may last for few hours. Hence, it is often considereddesirable to send a copy of the questions to be discussed to the respondents well in advance. This willalso give an opportunity to the respondents for doing some advance thinking over the various issuesinvolved so that, at the time of interview, they may be able to contribute effectively. Thus, an experiencesurvey may enable the researcher to define the problem more concisely and help in the formulationof the research hypothesis. This survey may as well provide information about the practical possibilitiesfor doing different types of research.\\nAnalysis of ‘insight-stimulating’ examples  is also a fruitful method for suggesting hypotheses\\nfor research. It is particularly suitable in areas where there is little experience to serve as a guide.This method consists of the intensive study of selected instances of the phenomenon in which one isinterested. For this purpose the existing records, if any, may be examined, the unstructured interviewingmay take place, or some other approach may be adopted. Attitude of the investigator, the intensity ofthe study and the ability of the researcher to draw together diverse information into a unifiedinterpretation are the main features which make this method an appropriate procedure for evokinginsights.Research Design 37\\nNow, what sort of examples are to be selected and studied? There is no clear cut answer to it.\\nExperience indicates that for particular problems certain types of instances are more appropriate\\nthan others. One can mention few examples of ‘insight-stimulating’ cases such as the reactions ofstrangers, the reactions of marginal individuals, the study of individuals who are in transition from onestage to another, the reactions of individuals from different social strata and the like. In general,cases that provide sharp contrasts or have striking features are considered relatively more usefulwhile adopting this method of hypotheses formulation.\\nThus, in an exploratory of formulative research study which merely leads to insights or hypotheses,\\nwhatever method or research design outlined above is adopted, the only thing essential is that it mustcontinue to remain flexible so that many different facets of a problem may be considered as andwhen they arise and come to the notice of the researcher.\\n2. Research design in case of descriptive and diagnostic research studies: Descriptive research\\nstudies are those studies which are concerned with describing the characteristics of a particular\\nindividual, or of a group, whereas diagnostic research studies determine the frequency with whichsomething occurs or its association with something else. The studies concerning whether certainvariables are associated are examples of diagnostic research studies. As against this, studies concernedwith specific predictions, with narration of facts and characteristics concerning individual, group orsituation are all examples of descriptive research studies. Most of the social research comes underthis category. From the point of view of the research design, the descriptive as well as diagnosticstudies share common requirements and as such we may group together these two types of researchstudies. In descriptive as well as in diagnostic studies, the researcher must be able to define clearly,what he wants to measure and must find adequate methods for measuring it along with a clear cutdefinition of ‘population’ he wants to study. Since the aim is to obtain complete and accurate informationin the said studies, the procedure to be used must be carefully planned. The research design mustmake enough provision for protection against bias and must maximise reliability, with due concern forthe economical completion of the research study. The design in such studies must be rigid and notflexible and must focus attention on the following:\\n(a) Formulating the objective of the study (what the study is about and why is it being made?)\\n(b) Designing the methods of data collection (what techniques of gathering data will be adopted?)\\n(c) Selecting the sample (how much material will be needed?)(d) Collecting the data (where can the required data be found and with what time period should\\nthe data be related?)\\n(e) Processing and analysing the data.\\n(f) Reporting the findings.\\nIn a descriptive/diagnostic study the first step is to specify the objectives with sufficient precision\\nto ensure that the data collected are relevant. If this is not done carefully, the study may not provide\\nthe desired information.\\nThen comes the question of selecting the methods by which the data are to be obtained. In other\\nwords, techniques for collecting the information must be devised. Several methods (viz., observation,questionnaires, interviewing, examination of records, etc.), with their merits and limitations, are availablefor the purpose and the researcher may user one or more of these methods which have been discussedin detail in later chapters. While designing data-collection procedure, adequate safeguards against38 Research Methodology\\nbias and unreliability must be ensured. Whichever method is selected, questions must be well examined\\nand be made unambiguous; interviewers must be instructed not to express their own opinion; observersmust be trained so that they uniformly record a given item of behaviour. It is always desirable to pre-test the data collection instruments before they are finally used for the study purposes. In otherwords, we can say that “ structured instruments ” are used in such studies.\\nIn most of the descriptive/diagnostic studies the researcher takes out sample(s) and then wishes\\nto make statements about the population on the basis of the sample analysis or analyses. More oftenthan not, sample has to be designed. Different sample designs have been discussed in detail in aseparate chapter in this book. Here we may only mention that the problem of designing samplesshould be tackled in such a fashion that the samples may yield accurate information with a minimumamount of research effort. Usually one or more forms of probability sampling, or what is oftendescribed as random sampling, are used.\\nTo obtain data free from errors introduced by those responsible for collecting them, it is necessary\\nto supervise closely the staff of field workers as they collect and record information. Checks may beset up to ensure that the data collecting staff perform their duty honestly and without prejudice. “Asdata are collected, they should be examined for completeness, comprehensibility, consistency andreliability.”\\n2\\nThe data collected must be processed and analysed. This includes steps like coding the interview\\nreplies, observations, etc.; tabulating the data; and performing several statistical computations. Tothe extent possible, the processing and analysing procedure should be planned in detail before actualwork is started. This will prove economical in the sense that the researcher may avoid unnecessary\\nlabour such as preparing tables for which he later finds he has no use or on the other hand, re-doing\\nsome tables because he failed to include relevant data. Coding should be done carefully to avoiderror in coding and for this purpose the reliability of coders needs to be checked. Similarly, theaccuracy of tabulation may be checked by having a sample of the tables re-done. In case of mechanicaltabulation the material (i.e., the collected data or information) must be entered on appropriate cardswhich is usually done by punching holes corresponding to a given code. The accuracy of punching isto be checked and ensured. Finally, statistical computations are needed and as such averages,percentages and various coefficients must be worked out. Probability and sampling analysis may aswell be used. The appropriate statistical operations, along with the use of appropriate tests ofsignificance should be carried out to safeguard the drawing of conclusions concerning the study.\\nLast of all comes the question of reporting the findings. This is the task of communicating the\\nfindings to others and the researcher must do it in an efficient manner. The layout of the report needsto be well planned so that all things relating to the research study may be well presented in simple andeffective style.\\nThus, the research design in case of descriptive/diagnostic studies is a comparative design throwing\\nlight on all points narrated above and must be prepared keeping in view the objective(s) of the studyand the resources available. However, it must ensure the minimisation of bias and maximisation ofreliability of the evidence collected. The said design can be appropriately referred to as a survey\\ndesign since it takes into account all the steps involved in a survey concerning a phenomenon to be\\nstudied.\\n2 Claire Selltiz et al., op. cit.,  p. 74.Research Design 39\\nThe difference between research designs in respect of the above two types of research studies\\ncan be conveniently summarised in tabular form as under:\\nTable 3.1\\nType of study\\nResearch Design Exploratory of Formulative Descriptive/Diagnostic\\nOverall design Flexible design (design must provide Rigid design (design must make\\nopportunity for considering different enough provision for protection\\naspects of the problem) against bias and must maximise\\nreliability)\\n(i) Sampling design Non-probability sampling design Probability sampling design (random\\n(purposive or judgement sampling) sampling)\\n(ii) Statistical design No pre-planned design for analysis Pre-planned design for analysis\\n(iii) Observational Unstructured instruments for Structured or well thought out\\n       design collection of data instruments for collection of data\\n(iv) Operational design No fixed decisions about the Advanced decisions about\\noperational procedures operational procedures.\\n3. Research design in case of hypothesis-testing research studies: Hypothesis-testing research\\nstudies (generally known as experimental studies) are those where the researcher tests the hypotheses\\nof causal relationships between variables. Such studies require procedures that will not only reducebias and increase reliability, but will permit drawing inferences about causality. Usually experimentsmeet this requirement. Hence, when we talk of research design in such studies, we often mean thedesign of experiments.\\nProfessor R.A. Fisher’s name is associated with experimental designs. Beginning of such designs\\nwas made by him when he was working at Rothamsted Experimental Station (Centre for AgriculturalResearch in England). As such the study of experimental designs has its origin in agricultural research.Professor Fisher found that by dividing agricultural fields or plots into different blocks and then byconducting experiments in each of these blocks, whatever information is collected and inferencesdrawn from them, happens to be more reliable. This fact inspired him to develop certain experimentaldesigns for testing hypotheses concerning scientific investigations. Today, the experimental designsare being used in researches relating to phenomena of several disciplines. Since experimental designsoriginated in the context of agricultural operations, we still use, though in a technical sense, severalterms of agriculture (such as treatment, yield, plot, block etc.) in experimental designs.\\nBASIC PRINCIPLES OF EXPERIMENTAL DESIGNS\\nProfessor Fisher has enumerated three principles of experimental designs: (1) the Principle ofReplication; (2) the Principle of Randomization; and the (3) Principle of Local Control.40 Research Methodology\\nAccording to the Principle of Replication , the experiment should be repeated more than once.\\nThus, each treatment is applied in many experimental units instead of one. By doing so the statistical\\naccuracy of the experiments is increased. For example, suppose we are to examine the effect of twovarieties of rice. For this purpose we may divide the field into two parts and grow one variety in onepart and the other variety in the other part. We can then compare the yield of the two parts and drawconclusion on that basis. But if we are to apply the principle of replication to this experiment, then wefirst divide the field into several parts, grow one variety in half of these parts and the other variety inthe remaining parts. We can then collect the data of yield of the two varieties and draw conclusion bycomparing the same. The result so obtained will be more reliable in comparison to the conclusion wedraw without applying the principle of replication. The entire experiment can even be repeatedseveral times for better results. Conceptually replication does not present any difficulty, butcomputationally it does. For example, if an experiment requiring a two-way analysis of variance isreplicated, it will then require a three-way analysis of variance since replication itself may be asource of variation in the data. However, it should be remembered that replication is introduced inorder to increase the precision of a study; that is to say, to increase the accuracy with which the maineffects and interactions can be estimated.\\nThe Principle of Randomization  provides protection, when we conduct an experiment, against\\nthe effect of extraneous factors by randomization. In other words, this principle indicates that weshould design or plan the experiment in such a way that the variations caused by extraneous factorscan all be combined under the general heading of “chance.” For instance, if we grow one variety ofrice, say, in the first half of the parts of a field and the other variety is grown in the other half, then itis just possible that the soil fertility may be different in the first half in comparison to the other half. Ifthis is so, our results would not be realistic. In such a situation, we may assign the variety of rice tobe grown in different parts of the field on the basis of some random sampling technique i.e., we mayapply randomization principle and protect ourselves against the effects of the extraneous factors (soilfertility differences in the given case). As such, through the application of the principle of randomization,we can have a better estimate of the experimental error.\\nThe Principle of Local Control  is another important principle of experimental designs. Under it\\nthe extraneous factor, the known source of variability, is made to vary deliberately over as wide arange as necessary and this needs to be done in such a way that the variability it causes can bemeasured and hence eliminated from the experimental error. This means that we should plan theexperiment in a manner that we can perform a two-way analysis of variance, in which the totalvariability of the data is divided into three components attributed to treatments (varieties of rice in ourcase), the extraneous factor (soil fertility in our case) and experimental error.\\n* In other words,\\naccording to the principle of local control, we first divide the field into several homogeneous parts,known as blocks, and then each such block is divided into parts equal to the number of treatments.Then the treatments are randomly assigned to these parts of a block. Dividing the field into severalhomogenous parts is known as ‘blocking’. In general, blocks are the levels at which we hold anextraneous factor fixed, so that we can measure its contribution to the total variability of the data bymeans of a two-way analysis of variance. In brief, through the principle of local control we can\\neliminate the variability due to extraneous factor(s) from the experimental error.\\n* See Chapter Analysis of Variance for details.Research Design 41\\nImportant Experimental Designs\\nExperimental design refers to the framework or structure of an experiment and as such there are\\nseveral experimental designs. We can classify experimental designs into two broad categories, viz.,informal experimental designs and formal experimental designs. Informal experimental designs arethose designs that normally use a less sophisticated form of analysis based on differences in magnitudes,whereas formal experimental designs offer relatively more control and use precise statisticalprocedures for analysis. Important experiment designs are as follows:\\n(a) Informal experimental designs:\\n(i) Before-and-after without control design.\\n(ii)After-only with control design.\\n(iii)Before-and-after with control design.\\n(b) Formal experimental designs:\\n(i) Completely randomized design (C.R. Design).\\n(ii)Randomized block design (R.B. Design).\\n(iii)Latin square design (L.S. Design).\\n(iv)Factorial designs.\\nWe may briefly deal with each of the above stated informal as well as formal experimental designs.\\n1. Before-and-after without control design: In such a design a single test group or area is\\nselected and the dependent variable is measured before the introduction of the treatment. The treatmentis then introduced and the dependent variable is measured again after the treatment has beenintroduced. The effect of the treatment would be equal to the level of the phenomenon after thetreatment minus the level of the phenomenon before the treatment. The design can be represented thus:\\nFig. 3.1\\nThe main difficulty of such a design is that with the passage of time considerable extraneous\\nvariations may be there in its treatment effect.\\n2. After-only with control design: In this design two groups or areas (test area and control area)\\nare selected and the treatment is introduced into the test area only. The dependent variable is then\\nmeasured in both the areas at the same time. Treatment impact is assessed by subtracting the valueof the dependent variable in the control area from its value in the test area. This can be exhibited inthe following form:Test area: Level of phenomenon\\nbefore treatment (X)\\nTreatment Effect = (Y) – (X)Treatment\\nintroducedLevel of phenomenon\\nafter treatment (Y)42 Research Methodology\\nFig. 3.2\\nThe basic assumption in such a design is that the two areas are identical with respect to their\\nbehaviour towards the phenomenon considered. If this assumption is not true, there is the possibility\\nof extraneous variation entering into the treatment effect. However, data can be collected in such adesign without the introduction of problems with the passage of time. In this respect the design issuperior to before-and-after without control design.\\n3. Before-and-after with control design: In this design two areas are selected and the dependent\\nvariable is measured in both the areas for an identical time-period before the treatment. The treatment\\nis then introduced into the test area only, and the dependent variable is measured in both for anidentical time-period after the introduction of the treatment. The treatment effect is determined bysubtracting the change in the dependent variable in the control area from the change in the dependentvariable in test area. This design can be shown in this way:\\nFig. 3.3\\nThis design is superior to the above two designs for the simple reason that it avoids extraneous\\nvariation resulting both from the passage of time and from non-comparability of the test and controlareas. But at times, due to lack of historical data, time or a comparable control area, we should preferto select one of the first two informal designs stated above.\\n4. Completely randomized design (C.R. design): Involves only two principles viz., the principle\\nof replication and the principle of randomization of experimental designs. It is the simplest possible\\ndesign and its procedure of analysis is also easier. The essential characteristic of the design is thatsubjects are randomly assigned to experimental treatments (or vice-versa). For instance, if we have10 subjects and if we wish to test 5 under treatment A and 5 under treatment B, the randomizationprocess gives every possible group of 5 subjects selected from a set of 10 an equal opportunity ofbeing assigned to treatment A and treatment B. One-way analysis of variance (or one-way ANOVA)\\n*\\nis used to analyse such a design. Even unequal replications can also work in this design. It providesmaximum number of degrees of freedom to the error. Such a design is generally used whenexperimental areas happen to be homogeneous. Technically, when all the variations due to uncontrolled\\n* See Chapter 11 for one-way ANOVA technique.Test area:\\nControl area:Treatment introduced\\nTreatment Effect = (Y) – (Z)Level of phenomenon after\\ntreatment (Y)\\nLevel of phenomenon without\\ntreatment (Z)\\nTest area:\\nControl area:Treatment\\nintroduced\\nTreatment Effect = (Y – X) – (Z – A)Level of phenomenonafter treatment (Y)Level of phenomenonbefore treatment (X)Time Period I Time Period II\\nLevel of phenomenonwithout treatment\\n(Z)Level of phenomenonwithout treatment\\n(A)Research Design 43\\nextraneous factors are included under the heading of chance variation, we refer to the design of\\nexperiment as C.R. design.\\nWe can present a brief description of the two forms of such a design as given in Fig 3.4.\\n(i) Two-group simple randomized design: In a two-group simple randomized design, first\\nof all the population is defined and then from the population a sample is selected randomly.Further, requirement of this design is that items, after being selected randomly from thepopulation, be randomly assigned to the experimental and control groups (Such randomassignment of items to two groups is technically described as principle of randomization).Thus, this design yields two groups as representatives of the population. In a diagram formthis design can be shown in this way:\\nFig. 3.4: Two-group simple randomized experimental design (in diagram form)\\nSince in the sample randomized design the elements constituting the sample are randomly\\ndrawn from the same population and randomly assigned to the experimental and controlgroups, it becomes possible to draw conclusions on the basis of samples applicable for thepopulation. The two groups (experimental and control groups) of such a design are givendifferent treatments of the independent variable. This design of experiment is quite commonin research studies concerning behavioural sciences. The merit of such a design is that it issimple and randomizes the differences among the sample items. But the limitation of it isthat the individual differences among those conducting the treatments are not eliminated,i.e., it does not control the extraneous variable and as such the result of the experiment maynot depict a correct picture. This can be illustrated by taking an example. Suppose theresearcher wants to compare two groups of students who have been randomly selectedand randomly assigned. Two different treatments viz., the usual training and the specialisedtraining are being given to the two groups. The researcher hypothesises greater gains forthe group receiving specialised training. To determine this, he tests each group before andafter the training, and then compares the amount of gain for the two groups to accept orreject his hypothesis. This is an illustration of the two-groups randomized design, whereinindividual differences among students are being randomized. But this does not control thedifferential effects of the extraneous independent variables (in this case, the individualdifferences among those conducting the training programme).Randomly\\nselectedRandomlyassignedPopulation\\nSample\\nControl\\ngroup\\nTreatmentB\\nIndependent variableTreatmentA\\nExperimental\\ngroup44 Research Methodology\\nFig. 3.5: Random replication design (in diagram form)\\n(ii)Random replications design: The limitation of the two-group randomized design is usually\\neliminated within the random replications design. In the illustration just cited above, the\\nteacher differences  on the dependent variable were ignored, i.e., the extraneous variable\\nwas not controlled. But in a random replications design, the effect of such differences areminimised (or reduced) by providing a number of repetitions for each treatment. Eachrepetition is technically called a ‘replication’. Random replication design serves two purposesviz., it provides controls for the differential effects of the extraneous independent variablesand secondly, it randomizes any individual differences among those conducting the treatments.Diagrammatically we can illustrate the random replications design thus: (Fig. 3.5)Population\\n(Available\\nfor study)Population\\n(Available to\\nconduct\\ntreatments)\\nRandom selection Random selection\\nSample\\n(To be studied)Sample\\n(To conduct\\ntreatments)\\nRandom\\nassignmentRandom\\nassignmentGroup 1    E\\nGroup 2    EGroup 3    EGroup 4    E\\nGroup 5    C\\nGroup 6    CGroup 7    CGroup 8    CE = Experimental group\\nC = Control group\\nTreatment\\nB Treatment A\\nIndependent variable\\nor causal variableResearch Design 45\\nFrom the diagram it is clear that there are two populations in the replication design. The\\nsample is taken randomly from the population available for study and is randomly assigned\\nto, say, four experimental and four control groups. Similarly, sample is taken randomly fromthe population available to conduct experiments (because of the eight groups eight suchindividuals be selected) and the eight individuals so selected should be randomly assigned tothe eight groups. Generally, equal number of items are put in each group so that the size ofthe group is not likely to affect the result of the study. Variables relating to both populationcharacteristics are assumed to be randomly distributed among the two groups. Thus, thisrandom replication design is, in fact, an extension of the two-group simple randomizeddesign.\\n5. Randomized block design (R.B. design)  is an improvement over the C.R. design. In the R.B.\\ndesign the principle of local control can be applied along with the other two principles of experimentaldesigns. In the R.B. design, subjects are first divided into groups, known as blocks, such that withineach group the subjects are relatively homogeneous in respect to some selected variable. The variableselected for grouping the subjects is one that is believed to be related to the measures to be obtainedin respect of the dependent variable. The number of subjects in a given block would be equal to thenumber of treatments and one subject in each block would be randomly assigned to each treatment.In general, blocks are the levels at which we hold the extraneous factor fixed, so that its contributionto the total variability of data can be measured. The main feature of the R.B. design is that in thiseach treatment appears the same number of times in each block. The R.B. design is analysed by thetwo-way analysis of variance (two-way ANOVA)\\n* technique.\\nLet us illustrate the R.B. design with the help of an example. Suppose four different forms of a\\nstandardised test in statistics were given to each of five students (selected one from each of the fiveI.Q. blocks) and following are the scores which they obtained.\\nFig. 3.6\\nIf each student separately randomized the order in which he or she took the four tests (by using\\nrandom numbers or some similar device), we refer to the design of this experiment as a R.B. design.The purpose of this randomization is to take care of such possible extraneous factors (say as fatigue)or perhaps the experience gained from repeatedly taking the test.\\n* See Chapter 11 for the two-way ANOVA technique.Very low\\nI.Q.\\nStudent\\nALow\\nI.Q.\\nStudent\\nBAverage\\nI.Q.\\nStudent\\nCHigh\\nI.Q.\\nStudent\\nDVery high\\nI.Q.\\nStudent\\nE\\n82\\n90869367687377575451607170696573818471Form 1Form 2Form 3Form 446 Research Methodology\\n6. Latin square design (L.S. design)  is an experimental design very frequently used in agricultural\\nresearch. The conditions under which agricultural investigations are carried out are different from\\nthose in other studies for nature plays an important role in agriculture. For instance, an experimenthas to be made through which the effects of five different varieties of fertilizers on the yield of acertain crop, say wheat, it to be judged. In such a case the varying fertility of the soil in differentblocks in which the experiment has to be performed must be taken into consideration; otherwise theresults obtained may not be very dependable because the output happens to be the effect not only offertilizers, but it may also be the effect of fertility of soil. Similarly, there may be impact of varyingseeds on the yield. To overcome such difficulties, the L.S. design is used when there are two majorextraneous factors such as the varying soil fertility and varying seeds.\\nThe Latin-square design is one wherein each fertilizer, in our example, appears five times but is\\nused only once in each row and in each column of the design. In other words, the treatments in a L.S.design are so allocated among the plots that no treatment occurs more than once in any one row orany one column. The two blocking factors may be represented through rows and columns (onethrough rows and the other through columns). The following is a diagrammatic form of such a designin respect of, say, five types of fertilizers, viz., A, B, C, D and E and the two blocking factor viz., thevarying soil fertility and the varying seeds:\\nFig. 3.7\\nThe above diagram clearly shows that in a L.S. design the field is divided into as many blocks as\\nthere are varieties of fertilizers and then each block is again divided into as many parts as there arevarieties of fertilizers in such a way that each of the fertilizer variety is used in each of the block(whether column-wise or row-wise) only once. The analysis of the L.S. design is very similar to thetwo-way ANOVA technique.\\nThe merit of this experimental design is that it enables differences in fertility gradients in the field\\nto be eliminated in comparison to the effects of different varieties of fertilizers on the yield of thecrop. But this design suffers from one limitation, and it is that although each row and each columnrepresents equally all fertilizer varieties, there may be considerable difference in the row and columnmeans both up and across the field. This, in other words, means that in L.S. design we must assumethat there is no interaction between treatments and blocking factors. This defect can, however, beremoved by taking the means of rows and columns equal to the field mean by adjusting the results.Another limitation of this design is that it requires number of rows, columns and treatments to beX1\\nX2\\nX3\\nX4\\nX5AI\\nB\\nCDEBII\\nC\\nDEACIII\\nD\\nEABDIV\\nE\\nABCEV\\nA\\nBCD\\nFERTILITY LEVEL\\nSeeds differencesResearch Design 47\\nequal. This reduces the utility of this design. In case of (2 × 2) L.S. design, there are no degrees of\\nfreedom available for the mean square error and hence the design cannot be used. If treatments are10 or more, than each row and each column will be larger in size so that rows and columns may notbe homogeneous. This may make the application of the principle of local control ineffective. Therefore,L.S. design of orders (5 × 5) to (9 × 9) are generally used.\\n7. Factorial designs: Factorial designs are used in experiments where the effects of varying more\\nthan one factor are to be determined. They are specially important in several economic and social\\nphenomena where usually a large number of factors affect a particular problem. Factorial designscan be of two types: (i) simple factorial designs and (ii) complex factorial designs. We take themseparately\\n(i)Simple factorial designs: In case of simple factorial designs, we consider the effects of\\nvarying two factors on the dependent variable, but when an experiment is done with morethan two factors, we use complex factorial designs. Simple factorial design is also termedas a ‘two-factor-factorial design’, whereas complex factorial design is known as ‘multi-factor-factorial design.’ Simple factorial design may either be a 2 × 2 simple factorialdesign, or it may be, say, 3 × 4 or 5 × 3 or the like type of simple factorial design. Weillustrate some simple factorial designs as under:\\nIllustration 1:  (2 × 2 simple factorial design).\\nA 2 × 2 simple factorial design can graphically be depicted as follows:\\nFig. 3.8\\nIn this design the extraneous variable to be controlled by homogeneity is called the control\\nvariable and the independent variable, which is manipulated, is called the experimental variable. Thenthere are two treatments of the experimental variable and two levels of the control variable. As suchthere are four cells into which the sample is divided. Each of the four combinations would provideone treatment or experimental condition. Subjects are assigned at random to each treatment in thesame manner as in a randomized group design. The means for different cells may be obtained alongwith the means for different rows and columns. Means of different cells represent the mean scoresfor the dependent variable and the column means in the given design are termed the main effect fortreatments without taking into account any differential effect that is due to the level of the controlvariable. Similarly, the row means in the said design are termed the main effects for levels withoutregard to treatment. Thus, through this design we can study the main effects of treatments as well asControl variables\\nLevel I\\nLevel IIExperimentalVariable\\nTreatment A Treatment B\\nCell 1\\nCell 2Cell 3Cell 42 × 2 SIMPLE FACTORIAL DESIGN48 Research Methodology\\nthe main effects of levels. An additional merit of this design is that one can examine the interaction\\nbetween treatments and levels, through which one may say whether the treatment and levels areindependent of each other or they are not so. The following examples make clear the interactioneffect between treatments and levels. The data obtained in case of two (2 × 2) simple factorialstudies may be as given in Fig. 3.9.\\nFig. 3.9\\nAll the above figures (the study I data and the study II data) represent the respective means.\\nGraphically, these can be represented as shown in Fig. 3.10.\\nFig. 3.10Level I (Low)\\nLevel II (High)Column mean10.430.620.520.640.430.5STUDY I DATA\\nSTUDY II DATATraining\\nTrainingTreatment\\nA\\nTreatment\\nATreatment\\nB\\nTreatment\\nBRow\\nMean\\nRow\\nMeanControl\\n(Intelligence)\\nControl(Intelligence)Level I (Low)\\nLevel II (High)Column mean15.535.825.623.330.226.719.433.0\\n15.5\\n35.5\\n60 60\\n50 50\\n40 40\\n30 30\\n20 20\\n10 10\\n00Mean scores of\\ndependent variables\\n(say ability)Study I Study II\\n(Low)\\nI(Low)\\nI(High)\\nII(High)\\nII\\nControl level\\n(Intelligence)Control level\\n(Intelligence)B\\nBBBAA\\nAAResearch Design 49\\nThe graph relating to Study I indicates that there is an interaction between the treatment and the\\nlevel which, in other words, means that the treatment and the level are not independent of each other.\\nThe graph relating to Study II shows that there is no interaction effect which means that treatmentand level in this study are relatively independent of each other.\\nThe 2 × 2 design need not be restricted in the manner as explained above i.e., having one\\nexperimental variable and one control variable, but it may also be of the type having two experimentalvariables or two control variables. For example, a college teacher compared the effect of the class-size as well as the introduction of the new instruction technique on the learning of research methodology.For this purpose he conducted a study using a 2 × 2 simple factorial design. His design in the graphicform would be as follows:\\nFig. 3.11\\nBut if the teacher uses a design for comparing males and females and the senior and junior\\nstudents in the college as they relate to the knowledge of research methodology, in that case we willhave a 2 × 2 simple factorial design wherein both the variables are control variables as no manipulationis involved in respect of both the variables.\\nIllustration 2:  (4 × 3 simple factorial design).\\nThe 4 × 3 simple factorial design will usually include four treatments of the experimental variable\\nand three levels of the control variable. Graphically it may take the following form:\\nFig. 3.12\\nThis model of a simple factorial design includes four treatments viz., A, B, C, and D of the\\nexperimental variable and three levels viz., I, II, and III of the control variable and has 12 different\\ncells as shown above. This shows that a 2 × 2 simple factorial design can be generalised to anynumber of treatments and levels. Accordingly we can name it as such and such (–×–) design. InExperimentalVariable I\\n(Class Size)\\nSmall Usual\\nExperimentalVariable II\\n(Instruction technique)New\\nUsual\\nExperimentalVariable\\nTreatment\\nA\\nCell 1\\nCell 2Cell 3Control\\nVariable\\nLevel ILevel IILevel IIITreatment\\nB\\nCell 4Cell 5Cell 6Treatment\\nC\\nCell 7Cell 8Cell 9Treatment\\nD\\nCell 10Cell 11Cell 12\\n4 × 3 SIMPLE FACTORIAL DESIGN50 Research Methodology\\nsuch a design the means for the columns provide the researcher with an estimate of the main effects\\nfor treatments and the means for rows provide an estimate of the main effects for the levels. Such adesign also enables the researcher to determine the interaction between treatments and levels.\\n(ii)Complex factorial designs: Experiments with more than two factors at a time involve\\nthe use of complex factorial designs. A design which considers three or more independentvariables simultaneously is called a complex factorial design. In case of three factors withone experimental variable having two treatments and two control variables, each one ofwhich having two levels, the design used will be termed 2 × 2 × 2 complex factorial designwhich will contain a total of eight cells as shown below in Fig. 3.13.\\nFig. 3.13\\nIn Fig. 3.14 a pictorial presentation is given of the design shown below.\\nFig. 3.14ExperimentalVariable\\nTreatment A Treatment B\\nControl\\nVariable 12 × 2 × 2 COMPLEX FACTORIAL DESIGN\\nControlVariable2Level I\\nCell 1Cell 2Control\\nVariable2Level II\\nCell 3Cell 4Control\\nVariable2Level I\\nCell 5Cell 6Control\\nVariable2Level II\\nCell 7Cell 8Level ILevel II\\nExperimentalVariable\\nTreatment\\nATreatment\\nB\\nLevel ILevel I\\nLevel IILevel IIControlVariable IControl\\nVariable 2Research Design 51\\nThe dotted line cell in the diagram corresponds to Cell 1 of the above stated 2 × 2 × 2 design and\\nis for Treatment A, level I of the control variable 1, and level I of the control variable 2. From this\\ndesign it is possible to determine the main effects for three variables i.e., one experimental and twocontrol variables. The researcher can also determine the interactions between each possible pair ofvariables (such interactions are called ‘First Order interactions’) and interaction between variabletaken in triplets (such interactions are called Second Order interactions). In case of a 2 × 2 × 2design, the further given first order interactions are possible:\\nExperimental variable with control variable 1(or EV × CV 1);\\nExperimental variable with control variable 2(or EV × CV 2);\\nControl variable 1 with control variable 2 (or CV1 × CV2);\\nThree will be one second order interaction as well in the given design (it is between all the three\\nvariables i.e., EV × CV1 × CV2).\\nTo determine the main effects for the experimental variable, the researcher must necessarily\\ncompare the combined mean of data in cells 1, 2, 3 and 4 for Treatment A with the combined mean\\nof data in cells 5, 6, 7 and 8 for Treatment B. In this way the main effect for experimental variable,independent of control variable 1 and variable 2, is obtained. Similarly, the main effect for controlvariable 1, independent of experimental variable and control variable 2, is obtained if we compare thecombined mean of data in cells 1, 3, 5 and 7 with the combined mean of data in cells 2, 4, 6 and 8 ofour 2 × 2 × 2 factorial design. On similar lines, one can determine the main effect for the controlvariable 2 independent of experimental variable and control variable 1, if the combined mean of datain cells 1, 2, 5 and 6 are compared with the combined mean of data in cells 3, 4, 7 and 8.\\nTo obtain the first order interaction, say, for EV × CV1 in the above stated design, the researcher\\nmust necessarily ignore control variable 2 for which purpose he may develop 2 × 2 design from the2 × 2 × 2 design by combining the data of the relevant cells of the latter design as shown in Fig. 3.15.\\nFig. 3.15\\nSimilarly, the researcher can determine other first order interactions. The analysis of the first\\norder interaction, in the manner described above, is essentially a sample factorial analysis as only twovariables are considered at a time and the remaining one is ignored. But the analysis of the secondorder interaction would not ignore one of the three independent variables in case of a 2 × 2 × 2design. The analysis would be termed as a complex factorial analysis.\\nIt may, however, be remembered that the complex factorial design need not necessarily be of\\n2 × 2 × 2 type design, but can be generalised to any number and combination of experimental andcontrol independent variables. Of course, the greater the number of independent variables includedin a complex factorial design, the higher the order of the interaction analysis possible. But the overalltask goes on becoming more and more complicated with the inclusion of more and more independentvariables in our design.ExperimentalVariables\\nTreatment A Treatment B\\nControl\\nVariable 1Cells 1, 3Cells 2, 4Cells 5, 7Cells 6, 8Level ILevel II52 Research Methodology\\nFactorial designs are used mainly because of the two advantages. (i) They provide equivalent\\naccuracy (as happens in the case of experiments with only one factor) with less labour and as such\\nare a source of economy. Using factorial designs, we can determine the main effects of two (insimple factorial design) or more (in case of complex factorial design) factors (or variables) in onesingle experiment. (ii) They permit various other comparisons of interest. For example, they giveinformation about such effects which cannot be obtained by treating one single factor at a time. Thedetermination of interaction effects is possible in case of factorial designs.\\nCONCLUSION\\nThere are several research designs and the researcher must decide in advance of collection andanalysis of data as to which design would prove to be more appropriate for his research project. Hemust give due weight to various points such as the type of universe and its nature, the objective of hisstudy, the resource list or the sampling frame, desired standard of accuracy and the like when takinga decision in respect of the design for his research project.\\nQuestions\\n1.Explain the meaning and significance of a Research design.\\n2.Explain the meaning of the following in context of Research design.\\n(a) Extraneous variables;\\n(b) Confounded relationship;\\n(c) Research hypothesis;\\n(d) Experimental and Control groups;\\n(e) Treatments.\\n3.Describe some of the important research designs used in experimental hypothesis-testing researchstudy.\\n4.“Research design in exploratory studies must be flexible but in descriptive studies, it must minimise biasand maximise reliability.” Discuss.\\n5.Give your understanding of a good research design. Is single research design suitable in all researchstudies? If not, why?\\n6.Explain and illustrate the following research designs:\\n(a) Two group simple randomized design;\\n(b) Latin square design;\\n(c) Random replications design;\\n(d) Simple factorial design;\\n(e) Informal experimental designs.\\n7.Write a short note on ‘Experience Survey’ explaining fully its utility in exploratory research studies.\\n8.What is research design? Discuss the basis of stratification to be employed in sampling public opinionon inflation.\\n(Raj. Uni. EAFM M.  Phil, Exam. 1978)Appendix: Developing a Research Plan 53\\nAppendix\\nDeveloping a Research Plan*\\nAfter identifying and defining the problem as also accomplishing the relating task, researcher must\\narrange his ideas in order and write them in the form of an experimental plan or what can bedescribed as ‘Research Plan’. This is essential specially for new researcher because of the following:\\n(a) It helps him to organize his ideas in a form whereby it will be possible for him to look for\\nflaws and inadequacies, if any.\\n(b) It provides an inventory of what must be done and which materials have to be collected as\\na preliminary step.\\n(c) It is a document that can be given to others for comment.\\nResearch plan must contain the following items.\\n1. Research objective should be clearly stated in a line or two which tells exactly what it is\\nthat the researcher expects to do.\\n2. The problem to be studied by researcher must be explicitly stated so that one may know\\nwhat information is to be obtained for solving the problem.\\n3. Each major concept which researcher wants to measure should be defined in operational\\nterms in context of the research project.\\n4. The plan should contain the method to be used in solving the problem. An overall description\\nof the approach to be adopted is usually given and assumptions, if any, of the concerningmethod to be used are clearly mentioned in the research plan.\\n5. The plan must also state the details of the techniques to be adopted. For instance, if interview\\nmethod is to be used, an account of the nature of the contemplated interview procedureshould be given. Similarly, if tests are to be given, the conditions under which they are to beadministered should be specified along with the nature of instruments to be used. If publicrecords are to be consulted as sources of data, the fact should be recorded in the researchplan. Procedure for quantifying data should also be written out in all details.\\n* Based on the matter given in the following two books:\\n(i) Robert M.W. Travers, An Introduction to Educational Research,  p. 82–84.\\n(ii) C. William Emory, Business Research Methods,  p. 415–416.54 Research Methodology\\n6. A clear mention of the population to be studied should be made. If the study happens to be\\nsample based, the research plan should state the sampling plan i.e., how the sample is to be\\nidentified. The method of identifying the sample should be such that generalisation from thesample to the original population is feasible.\\n7. The plan must also contain the methods to be used in processing the data. Statistical and\\nother methods to be used must be indicated in the plan. Such methods should not be leftuntil the data have been collected. This part of the plan may be reviewed by experts in thefield, for they can often suggest changes that result in substantial saving of time and effort.\\n8. Results of pilot test, if any, should be reported. Time and cost budgets for the research\\nproject should also be prepared and laid down in the plan itself.Sampling Design 55\\n4\\nSampling Design\\nCENSUS AND SAMPLE SURVEY\\nAll items in any field of inquiry constitute a ‘Universe’ or ‘Population.’ A complete enumeration of\\nall items in the ‘population’ is known as a census inquiry. It can be presumed that in such an inquiry,when all items are covered, no element of chance is left and highest accuracy is obtained. But inpractice this may not be true. Even the slightest element of bias in such an inquiry will get larger andlarger as the number of observation increases. Moreover, there is no way of checking the element ofbias or its extent except through a resurvey or use of sample checks. Besides, this type of inquiryinvolves a great deal of time, money and energy. Therefore, when the field of inquiry is large, thismethod becomes difficult to adopt because of the resources involved. At times, this method is practicallybeyond the reach of ordinary researchers. Perhaps, government is the only institution which can getthe complete enumeration carried out. Even the government adopts this in very rare cases such aspopulation census conducted once in a decade. Further, many a time it is not possible to examineevery item in the population, and sometimes it is possible to obtain sufficiently accurate results bystudying only a part of total population. In such cases there is no utility of census surveys.\\nHowever, it needs to be emphasised that when the universe is a small one, it is no use resorting\\nto a sample survey. When field studies are undertaken in practical life, considerations of time andcost almost invariably lead to a selection of respondents i.e., selection of only a few items. Therespondents selected should be as representative of the total population as possible in order to producea miniature cross-section. The selected respondents constitute what is technically called a ‘sample’and the selection process is called ‘sampling technique.’ The survey so conducted is known as‘sample survey’. Algebraically, let the population size be N and if a part of size n (which is <  N) of\\nthis population is selected according to some rule for studying some characteristic of the population,the group consisting of these n units is known as ‘sample’. Researcher must prepare a sample design\\nfor his study i.e., he must plan how a sample should be selected and of what size such a sample would be.\\nIMPLICATIONS OF A SAMPLE DESIGN\\nA sample design is a definite plan for obtaining a sample from a given population. It refers to thetechnique or the procedure the researcher would adopt in selecting items for the sample. Sample56 Research Methodology\\ndesign may as well lay down the number of items to be included in the sample i.e., the size of the\\nsample. Sample design is determined before data are collected. There are many sample designsfrom which a researcher can choose. Some designs are relatively more precise and easier to applythan others. Researcher must select/prepare a sample design which should be reliable and appropriatefor his research study.\\nSTEPS IN SAMPLE DESIGN\\nWhile developing a sampling design, the researcher must pay attention to the following points:\\n(i)Type of universe: The first step in developing any sample design is to clearly define the\\nset of objects, technically called the Universe, to be studied. The universe can be finite orinfinite. In finite universe the number of items is certain, but in case of an infinite universethe number of items is infinite, i.e., we cannot have any idea about the total number ofitems. The population of a city, the number of workers in a factory and the like are examplesof finite  universes, whereas the number of stars in the sky, listeners of a specific radioprogramme, throwing of a dice etc. are examples of infinite universes.\\n(ii)Sampling unit: A decision has to be taken concerning a sampling unit before selecting\\nsample. Sampling unit may be a geographical one such as state, district, village, etc., or aconstruction unit such as house, flat, etc., or it may be a social unit such as family, club,school, etc., or it may be an individual. The researcher will have to decide one or more ofsuch units that he has to select for his study.\\n(iii)Source list: It is also known as ‘sampling frame’ from which sample is to be drawn. It\\ncontains the names of all items of a universe (in case of finite universe only). If source listis not available, researcher has to prepare it. Such a list should be comprehensive, correct,reliable and appropriate. It is extremely important for the source list to be as representativeof the population as possible.\\n(iv)Size of sample: This refers to the number of items to be selected from the universe to\\nconstitute a sample. This a major problem before a researcher. The size of sample shouldneither be excessively large, nor too small. It should be optimum. An optimum sample isone which fulfills the requirements of efficiency, representativeness, reliability and flexibility.While deciding the size of sample, researcher must determine the desired precision as alsoan acceptable confidence level for the estimate. The size of population variance needs tobe considered as in case of larger variance usually a bigger sample is needed. The size ofpopulation must be kept in view for this also limits the sample size. The parameters ofinterest in a research study must be kept in view, while deciding the size of the sample.Costs too dictate the size of sample that we can draw. As such, budgetary constraint mustinvariably be taken into consideration when we decide the sample size.\\n(v)Parameters of interest: In determining the sample design, one must consider the question\\nof the specific population parameters which are of interest. For instance, we may beinterested in estimating the proportion of persons with some characteristic in the population,or we may be interested in knowing some average or the other measure concerning thepopulation. There may also be important sub-groups in the population about whom weSampling Design 57\\nwould like to make estimates. All this has a strong impact upon the sample design we\\nwould accept.\\n(vi)Budgetary constraint: Cost considerations, from practical point of view, have a major\\nimpact upon decisions relating to not only the size of the sample but also to the type ofsample. This fact can even lead to the use of a non-probability sample.\\n(vii)Sampling procedure: Finally, the researcher must decide the type of sample he will use\\ni.e., he must decide about the technique to be used in selecting the items for the sample. Infact, this technique or procedure stands for the sample design itself. There are severalsample designs (explained in the pages that follow) out of which the researcher mustchoose one for his study. Obviously, he must select that design which, for a given samplesize and for a given cost, has a smaller sampling error.\\nCRITERIA OF SELECTING A SAMPLING PROCEDURE\\nIn this context one must remember that two costs are involved in a sampling analysis viz., the cost ofcollecting the data and the cost of an incorrect inference resulting from the data. Researcher mustkeep in view the two causes of incorrect inferences viz., systematic bias and sampling error. Asystematic bias  results from errors in the sampling procedures, and it cannot be reduced or eliminated\\nby increasing the sample size. At best the causes responsible for these errors can be detected andcorrected. Usually a systematic bias is the result of one or more of the following factors:\\n1. Inappropriate sampling frame: If the sampling frame is inappropriate i.e., a biased representation\\nof the universe, it will result in a systematic bias.\\n2. Defective measuring device: If the measuring device is constantly in error, it will result in\\nsystematic bias. In survey work, systematic bias can result if the questionnaire or the interviewer is\\nbiased. Similarly, if the physical measuring device is defective there will be systematic bias in thedata collected through such a measuring device.\\n3. Non-respondents: If we are unable to sample all the individuals initially included in the sample,\\nthere may arise a systematic bias. The reason is that in such a situation the likelihood of establishing\\ncontact or receiving a response from an individual is often correlated with the measure of what is tobe estimated.\\n4. Indeterminancy principle: Sometimes we find that individuals act differently when kept under\\nobservation than what they do when kept in non-observed situations. For instance, if workers areaware that somebody is observing them in course of a work study on the basis of which the averagelength of time to complete a task will be determined and accordingly the quota will be set for piecework, they generally tend to work slowly in comparison to the speed with which they work if keptunobserved. Thus, the indeterminancy principle may also be a cause of a systematic bias.\\n5. Natural bias in the reporting of data: Natural bias of respondents in the reporting of data is\\noften the cause of a systematic bias in many inquiries. There is usually a downward bias in the\\nincome data collected by government taxation department, whereas we find an upward bias in theincome data collected by some social organisation. People in general understate their incomes ifasked about it for tax purposes, but they overstate the same if asked for social status or their affluence.Generally in psychological surveys, people tend to give what they think is the ‘correct’ answer ratherthan revealing their true feelings.58 Research Methodology\\nSampling errors are the random variations in the sample estimates around the true population\\nparameters. Since they occur randomly and are equally likely to be in either direction, their nature\\nhappens to be of compensatory type and the expected value of such errors happens to be equal tozero. Sampling error decreases with the increase in the size of the sample, and it happens to be of asmaller magnitude in case of homogeneous population.\\nSampling error can be measured for a given sample design and size. The measurement of\\nsampling error is usually called the ‘precision of the sampling plan’. If we increase the sample size,the precision can be improved. But increasing the size of the sample has its own limitations viz., alarge sized sample increases the cost of collecting data and also enhances the systematic bias. Thusthe effective way to increase precision is usually to select a better sampling design which has asmaller sampling error for a given sample size at a given cost. In practice, however, people prefer aless precise design because it is easier to adopt the same and also because of the fact that systematicbias can be controlled in a better way in such a design.\\nIn brief, while selecting a sampling procedure, researcher must ensure that the procedure\\ncauses a relatively small sampling error and helps to control the systematic bias in a betterway.\\nCHARACTERISTICS OF A GOOD SAMPLE DESIGN\\nFrom what has been stated above, we can list down the characteristics of a good sample design asunder:\\n(a) Sample design must result in a truly representative sample.\\n(b) Sample design must be such which results in a small sampling error.\\n(c) Sample design must be viable in the context of funds available for the research study.\\n(d) Sample design must be such so that systematic bias can be controlled in a better way.(e) Sample should be such that the results of the sample study can be applied, in general, for\\nthe universe with a reasonable level of confidence.\\nDIFFERENT TYPES OF SAMPLE DESIGNS\\nThere are different types of sample designs based on two factors viz., the representation basis and\\nthe element selection technique. On the representation basis, the sample may be probability samplingor it may be non-probability sampling. Probability sampling is based on the concept of random selection,whereas non-probability sampling is ‘non-random’ sampling. On element selection basis, the samplemay be either unrestricted or restricted. When each sample element is drawn individually from thepopulation at large, then the sample so drawn is known as ‘unrestricted sample’, whereas all otherforms of sampling are covered under the term ‘restricted sampling’. The following chart exhibits thesample designs as explained above.\\nThus, sample designs are basically of two types viz., non-probability sampling and probability\\nsampling. We take up these two designs separately.Sampling Design 59\\nFig. 4.1\\nNon-probability sampling:  Non-probability sampling is that sampling procedure which does\\nnot afford any basis for estimating the probability that each item in the population has of being\\nincluded in the sample. Non-probability sampling is also known by different names such as deliberatesampling, purposive sampling and judgement sampling. In this type of sampling, items for the sampleare selected deliberately by the researcher; his choice concerning the items remains supreme. Inother words, under non-probability sampling the organisers of the inquiry purposively choose theparticular units of the universe for constituting a sample on the basis that the small mass that they soselect out of a huge one will be typical or representative of the whole. For instance, if economicconditions of people living in a state are to be studied, a few towns and villages may be purposivelyselected for intensive study on the principle that they can be representative of the entire state. Thus,the judgement of the organisers of the study plays an important part in this sampling design.\\nIn such a design, personal element has a great chance of entering into the selection of the\\nsample. The investigator may select a sample which shall yield results favourable to his point of viewand if that happens, the entire inquiry may get vitiated. Thus, there is always the danger of biasentering into this type of sampling technique. But in the investigators are impartial, work without biasand have the necessary experience so as to take sound judgement, the results obtained from ananalysis of deliberately selected sample may be tolerably reliable. However, in such a sampling, thereis no assurance that every element has some specifiable chance of being included. Sampling error inthis type of sampling cannot be estimated and the element of bias, great or small, is always there. Assuch this sampling design in rarely adopted in large inquires of importance. However, in small inquiriesand researches by individuals, this design may be adopted because of the relative advantage of timeand money inherent in this method of sampling. Quota sampling  is also an example of non-probability\\nsampling. Under quota sampling the interviewers are simply given quotas to be filled from the differentstrata, with some restrictions on how they are to be filled. In other words, the actual selection of theitems for the sample is left to the interviewer’s discretion. This type of sampling is very convenientand is relatively inexpensive. But the samples so selected certainly do not possess the characteristicof random samples. Quota samples are essentially judgement samples and inferences drawn on theirbasis are not amenable to statistical treatment in a formal way.CHART SHOWING BASIC SAMPLING DESIGNS\\nRepresentation basis\\nProbability sampling Non-probability sampling\\nSimple random sampling Haphazard sampling or\\nconvenience sampling\\nComplex random sampling(such as cluster sampling,systematic sampling,stratified sampling etc.)Purposive sampling (such asquota sampling, judgementsampling)Element selectiontechnique\\nUnrestricted sampling\\nRestricted sampling60 Research Methodology\\nProbability sampling:  Probability sampling is also known as ‘random sampling’ or ‘chance\\nsampling’. Under this sampling design, every item of the universe has an equal chance of inclusion in\\nthe sample. It is, so to say, a lottery method in which individual units are picked up from the wholegroup not deliberately but by some mechanical process. Here it is blind chance alone that determineswhether one item or the other is selected. The results obtained from probability or random samplingcan be assured in terms of probability i.e., we can measure the errors of estimation or the significanceof results obtained from a random sample, and this fact brings out the superiority of random samplingdesign over the deliberate sampling design. Random sampling ensures the law of Statistical Regularitywhich states that if on an average the sample chosen is a random one, the sample will have the samecomposition and characteristics as the universe. This is the reason why random sampling is consideredas the best technique of selecting a representative sample.\\nRandom sampling from a finite population refers to that method of sample selection which gives\\neach possible sample combination an equal probability of being picked up and each item in the entirepopulation to have an equal chance of being included in the sample. This applies to sampling withoutreplacement i.e., once an item is selected for the sample, it cannot appear in the sample again(Sampling with replacement is used less frequently in which procedure the element selected for thesample is returned to the population before the next element is selected. In such a situation the sameelement could appear twice in the same sample before the second element is chosen). In brief, theimplications of random sampling (or simple random sampling) are:\\n(a) It gives each element in the population an equal probability of getting into the sample; and\\nall choices are independent of one another.\\n(b) It gives each possible sample combination an equal probability of being chosen.\\nKeeping this in view we can define a simple random sample (or simply a random sample) from\\na finite population as a sample which is chosen in such a way that each of the \\nNCn possible samples\\nhas the same probability, 1/NCn, of being selected. To make it more clear we take a certain finite\\npopulation consisting of six elements (say a, b, c, d, e, f) i.e., N = 6. Suppose that we want to take a\\nsample of size n = 3 from it. Then there are 6C3 = 20 possible distinct samples of the required size,\\nand they consist of the elements abc, abd, abe, abf, acd, ace, acf, ade, adf, aef, bcd, bce, bcf, bde,\\nbdf, bef, cde, cdf, cef, and def. If we choose one of these samples in such a way that each has the\\nprobability 1/20 of being chosen, we will then call this a random sample.\\nHOW TO SELECT A RANDOM SAMPLE  ?\\nWith regard to the question of how to take a random sample in actual practice, we could, in simplecases like the one above, write each of the possible samples on a slip of paper, mix these slipsthoroughly in a container and then draw as a lottery either blindfolded or by rotating a drum or by anyother similar device. Such a procedure is obviously impractical, if not altogether impossible in complexproblems of sampling. In fact, the practical utility of such a method is very much limited.\\nFortunately, we can take a random sample in a relatively easier way without taking the trouble of\\nenlisting all possible samples on paper-slips as explained above. Instead of this, we can write thename of each element of a finite population on a slip of paper, put the slips of paper so prepared intoa box or a bag and mix them thoroughly and then draw (without looking) the required number of slipsfor the sample one after the other without replacement. In doing so we must make sure that inSampling Design 61\\nsuccessive drawings each of the remaining elements of the population has the same chance of being\\nselected. This procedure will also result in the same probability for each possible sample. We canverify this by taking the above example. Since we have a finite population of 6 elements and we wantto select a sample of size 3, the probability of drawing any one element for our sample in the firstdraw is 3/6, the probability of drawing one more element in the second draw is 2/5, (the first elementdrawn is not replaced) and similarly the probability of drawing one more element in the third draw is1/4. Since these draws are independent, the joint probability of the three elements which constituteour sample is the product of their individual probabilities and this works out to 3/6 × 2/5 × 1/4 = 1/20.This verifies our earlier calculation.\\nEven this relatively easy method of obtaining a random sample can be simplified in actual practice\\nby the use of random number tables. Various statisticians like Tippett, Yates, Fisher have preparedtables of random numbers which can be used for selecting a random sample. Generally, Tippett’srandom number tables are used for the purpose. Tippett gave10400 four figure numbers. He selected41600 digits from the census reports and combined them into fours to give his random numberswhich may be used to obtain a random sample.\\nWe can illustrate the procedure by an example. First of all we reproduce the first thirty sets of\\nTippett’s numbers\\n2952 6641 3992 9792 7979 5911\\n3170 5624 4167 9525 1545 13967203 5356 1300 2693 2370 74833408 2769 3563 6107 6913 7691\\n0560 5246 1112 9025 6008 8126\\nSuppose we are interested in taking a sample of 10 units from a population of 5000 units, bearing\\nnumbers from 3001 to 8000. We shall select 10 such figures from the above random numbers which\\nare not less than 3001 and not greater than 8000. If we randomly decide to read the table numbersfrom left to right, starting from the first row itself, we obtain the following numbers: 6641, 3992, 7979,5911, 3170, 5624, 4167, 7203, 5356, and 7483.\\nThe units bearing the above serial numbers would then constitute our required random sample.\\nOne may note that it is easy to draw random samples from finite populations with the aid of\\nrandom number tables only when lists are available and items are readily numbered. But in some\\nsituations it is often impossible to proceed in the way we have narrated above. For example, if wewant to estimate the mean height of trees in a forest, it would not be possible to number the trees, andchoose random numbers to select a random sample. In such situations what we should do is to selectsome trees for the sample haphazardly without aim or purpose, and should treat the sample as arandom sample for study purposes.\\nRANDOM SAMPLE FROM AN INFINITE UNIVERSE\\nSo far we have talked about random sampling, keeping in view only the finite populations. But whatabout random sampling in context of infinite populations? It is relatively difficult to explain the conceptof random sample from an infinite population. However, a few examples will show the basiccharacteristic of such a sample. Suppose we consider the 20 throws of a fair dice as a sample fromthe hypothetically infinite population which consists of the results of all possible throws of the dice. If62 Research Methodology\\nthe probability of getting a particular number, say 1, is the same for each throw and the 20 throws are\\nall independent, then we say that the sample is random. Similarly, it would be said to be sampling froman infinite population if we sample with replacement from a finite population and our sample wouldbe considered as a random sample if in each draw all elements of the population have the sameprobability of being selected and successive draws happen to be independent. In brief, one can saythat the selection of each item in a random sample from an infinite population is controlled by thesame probabilities and that successive selections are independent of one another.\\nCOMPLEX RANDOM SAMPLING DESIGNS\\nProbability sampling under restricted sampling techniques, as stated above, may result in complexrandom sampling designs. Such designs may as well be called ‘mixed sampling designs’ for many ofsuch designs may represent a combination of probability and non-probability sampling procedures inselecting a sample. Some of the popular complex random sampling designs are as follows:\\n(i) Systematic sampling: In some instances, the most practical way of sampling is to select every\\nith item on a list. Sampling of this type is known as systematic sampling. An element of randomness\\nis introduced into this kind of sampling by using random numbers to pick up the unit with which to\\nstart. For instance, if a 4 per cent sample is desired, the first item would be selected randomly fromthe first twenty-five and thereafter every 25th item would automatically be included in the sample.Thus, in systematic sampling only the first unit is selected randomly and the remaining units of the\\nsample are selected at fixed intervals. Although a systematic sample is not a random sample in the\\nstrict sense of the term, but it is often considered reasonable to treat systematic sample as if it werea random sample.\\nSystematic sampling has certain plus points. It can be taken as an improvement over a simple\\nrandom sample in as much as the systematic sample is spread more evenly over the entire population.It is an easier and less costlier method of sampling and can be conveniently used even in case oflarge populations. But there are certain dangers too in using this type of sampling. If there is a hiddenperiodicity in the population, systematic sampling will prove to be an inefficient method of sampling.For instance, every 25th item produced by a certain production process is defective. If we are toselect a 4% sample of the items of this process in a systematic manner, we would either get alldefective items or all good items in our sample depending upon the random starting position. If allelements of the universe are ordered in a manner representative of the total population, i.e., thepopulation list is in random order, systematic sampling is considered equivalent to random sampling.But if this is not so, then the results of such sampling may, at times, not be very reliable. In practice,systematic sampling is used when lists of population are available and they are of considerablelength.\\n(ii) Stratified sampling: If a population from which a sample is to be drawn does not constitute a\\nhomogeneous group, stratified sampling technique is generally applied in order to obtain a representative\\nsample. Under stratified sampling the population is divided into several sub-populations that areindividually more homogeneous than the total population (the different sub-populations are called‘strata’) and then we select items from each stratum to constitute a sample. Since each stratum ismore homogeneous than the total population, we are able to get more precise estimates for eachstratum and by estimating more accurately each of the component parts, we get a better estimate ofthe whole. In brief, stratified sampling results in more reliable and detailed information.Sampling Design 63\\nThe following three questions are highly relevant in the context of stratified sampling:\\n(a) How to form strata?\\n(b) How should items be selected from each stratum?\\n(c) How many items be selected from each stratum or how to allocate the sample size of each\\nstratum?\\nRegarding the first question, we can say that the strata be formed on the basis of common\\ncharacteristic(s) of the items to be put in each stratum. This means that various strata be formed insuch a way as to ensure elements being most homogeneous within each stratum and mostheterogeneous between the different strata. Thus, strata are purposively formed and are usuallybased on past experience and personal judgement of the researcher. One should always rememberthat careful consideration of the relationship between the characteristics of the population and thecharacteristics to be estimated are normally used to define the strata. At times, pilot study may beconducted for determining a more appropriate and efficient stratification plan. We can do so bytaking small samples of equal size from each of the proposed strata and then examining the varianceswithin and among the possible stratifications, we can decide an appropriate stratification plan for ourinquiry.\\nIn respect of the second question, we can say that the usual method, for selection of items for the\\nsample from each stratum, resorted to is that of simple random sampling. Systematic sampling canbe used if it is considered more appropriate in certain situations.\\nRegarding the third question, we usually follow the method of proportional allocation under which\\nthe sizes of the samples from the different strata are kept proportional to the sizes of the strata. Thatis, if P\\ni represents the proportion of population included in stratum i, and n represents the total sample\\nsize, the number of elements selected from stratum i is n . Pi. To illustrate it, let us suppose that we\\nwant a sample of size n = 30 to be drawn from a population of size N = 8000 which is divided into\\nthree strata of size N1 = 4000, N2 = 2400 and N3 = 1600. Adopting proportional allocation, we shall\\nget the sample sizes as under for the different strata:\\nFor strata with N1 = 4000, we have P1 = 4000/8000\\nand hence n1 = n . P1 = 30 (4000/8000) = 15\\nSimilarly, for strata with N2 = 2400, we have\\nn2 = n . P2 = 30 (2400/8000) = 9, and\\nfor strata with N3 = 1600, we have\\nn3 = n . P3 = 30 (1600/8000) = 6.\\nThus, using proportional allocation, the sample sizes for different strata are 15, 9 and 6 respectively\\nwhich is in proportion to the sizes of the strata viz., 4000 : 2400 : 1600. Proportional allocation isconsidered most efficient and an optimal design when the cost of selecting an item is equal for eachstratum, there is no difference in within-stratum variances, and the purpose of sampling happens tobe to estimate the population value of some characteristic. But in case the purpose happens to be tocompare the differences among the strata, then equal sample selection from each stratum would bemore efficient even if the strata differ in sizes. In cases where strata differ not only in size but alsoin variability and it is considered reasonable to take larger samples from the more variable strata andsmaller samples from the less variable strata, we can then account for both (differences in stratumsize and differences in stratum variability) by using disproportionate sampling design by requiring:64 Research Methodology\\nnN nN nNkk k 11 1 22 2/ / ......... /σσ σ== =\\nwhere σσ12,,... and σk denote the standard deviations of the k strata, N1, N2,…, Nk denote the\\nsizes of the k strata and n1, n2,…, nk denote the sample sizes of k strata. This is called ‘ optimum\\nallocation ’ in the context of disproportionate sampling. The allocation in such a situation results in\\nthe following formula for determining the sample sizes different strata:\\nnnN\\nNN Niii\\nkk=⋅\\n++ +σ\\nσσ σ11 22 ...for i = 1, 2, … and k.\\nWe may illustrate the use of this by an example.\\nIllustration 1\\nA population is divided into three strata so that N1 = 5000, N2 = 2000 and N3 = 3000. Respective\\nstandard deviations are:\\nσσ σ12 315 18 5== =,a n d .\\nHow should a sample of size n = 84 be allocated to the three strata, if we want optimum allocation\\nusing disproportionate sampling design?\\nSolution:  Using the disproportionate sampling design for optimum allocation, the sample sizes for\\ndifferent strata will be determined as under:\\nSample size for strata with N1 = 5000\\nn184 5000 15\\n5000 15 2000 18 3000 5=++bg b gbg b g bg b g bg b g\\n  = 6300000/126000 = 50\\nSample size for strata with N2 = 2000\\nn284 2000 18\\n5000 15 2000 18 3000 5=++bg b gbg b g bg b g bg b g\\n     = 3024000/126000 = 24\\nSample size for strata with N3 = 3000\\nn384 3000 5\\n5000 15 2000 18 3000 5=++bg b gbg b g bg b g bg b g\\n  = 1260000/126000 = 10\\nIn addition to differences in stratum size and differences in stratum variability, we may have\\ndifferences in stratum sampling cost, then we can have cost optimal disproportionate sampling design\\nby requiring\\nn\\nNCn\\nNCn\\nNCk\\nkk k1\\n11 12\\n22 2 σσ σ== = ...Sampling Design 65\\nwhere\\nC1 = Cost of sampling in stratum 1\\nC2 = Cost of sampling in stratum 2\\nCk = Cost of sampling in stratum k\\nand all other terms remain the same as explained earlier. The allocation in such a situation results in\\nthe following formula for determining the sample sizes for different strata:\\nnnN C\\nNC NC N Ciii i\\nkk k=⋅\\n++ +σ\\nσσ σ/\\n/ / ... /11 1 22 2 for i = 1, 2, ..., k\\nIt is not necessary that stratification be done keeping in view a single characteristic. Populations\\nare often stratified according to several characteristics. For example, a system-wide survey designedto determine the attitude of students toward a new teaching plan, a state college system with 20colleges might stratify the students with respect to class, sec and college. Stratification of this type isknown as cross-stratification , and up to a point such stratification increases the reliability of estimates\\nand is much used in opinion surveys.\\nFrom what has been stated above in respect of stratified sampling, we can say that the sample so\\nconstituted is the result of successive application of purposive (involved in stratification of items) andrandom sampling methods. As such it is an example of mixed sampling. The procedure wherein wefirst have stratification and then simple random sampling is known as stratified random sampling.\\n(iii) Cluster sampling: If the total area of interest happens to be a big one, a convenient way in\\nwhich a sample can be taken is to divide the area into a number of smaller non-overlapping areas andthen to randomly select a number of these smaller areas (usually called clusters), with the ultimatesample consisting of all (or samples of) units in these small areas or clusters.\\nThus in cluster sampling the total population is divided into a number of relatively small subdivisions\\nwhich are themselves clusters of still smaller units and then some of these clusters are randomlyselected for inclusion in the overall sample. Suppose we want to estimate the proportion of machine-parts in an inventory which are defective. Also assume that there are 20000 machine parts in theinventory at a given point of time, stored in 400 cases of 50 each. Now using a cluster sampling, wewould consider the 400 cases as clusters and randomly select ‘ n’ cases and examine all the machine-\\nparts in each randomly selected case.\\nCluster sampling, no doubt, reduces cost by concentrating surveys in selected clusters. But\\ncertainly it is less precise than random sampling. There is also not as much information in ‘ n’\\nobservations within a cluster as there happens to be in ‘ n’ randomly drawn observations. Cluster\\nsampling is used only because of the economic advantage it possesses; estimates based on clustersamples are usually more reliable per unit cost.\\n(iv) Area sampling: If clusters happen to be some geographic subdivisions, in that case cluster\\nsampling is better known as area sampling. In other words, cluster designs, where the primary\\nsampling unit represents a cluster of units based on geographic area, are distinguished as area sampling.The plus and minus points of cluster sampling are also applicable to area sampling.\\n(v) Multi-stage sampling: Multi-stage sampling is a further development of the principle of cluster\\nsampling. Suppose we want to investigate the working efficiency of nationalised banks in India andwe want to take a sample of few banks for this purpose. The first stage is to select large primary66 Research Methodology\\nsampling unit such as states in a country. Then we may select certain districts and interview all banks\\nin the chosen districts. This would represent a two-stage sampling design with the ultimate samplingunits being clusters of districts.\\nIf instead of taking a census of all banks within the selected districts, we select certain towns and\\ninterview all banks in the chosen towns. This would represent a three-stage sampling design. Ifinstead of taking a census of all banks within the selected towns, we randomly sample banks fromeach selected town, then it is a case of using a four-stage sampling plan. If we select randomly at allstages, we will have what is known as ‘multi-stage random sampling design’.\\nOrdinarily multi-stage sampling is applied in big inquires extending to a considerable large\\ngeographical area, say, the entire country. There are two advantages of this sampling design viz.,(a)It is easier to administer than most single stage designs mainly because of the fact that samplingframe under multi-stage sampling is developed in partial units. (b) A large number of units can besampled for a given cost under multistage sampling because of sequential clustering, whereas this isnot possible in most of the simple designs.\\n(vi) Sampling with probability proportional to size: In case the cluster sampling units do not\\nhave the same number or approximately the same number of elements, it is considered appropriate to\\nuse a random selection process where the probability of each cluster being included in the sample isproportional to the size of the cluster. For this purpose, we have to list the number of elements in eachcluster irrespective of the method of ordering the cluster. Then we must sample systematically theappropriate number of elements from the cumulative totals. The actual numbers selected in this waydo not refer to individual elements, but indicate which clusters and how many from the cluster are to\\nbe selected by simple random sampling or by systematic sampling. The results of this type of sampling\\nare equivalent to those of a simple random sample and the method is less cumbersome and is alsorelatively less expensive. We can illustrate this with the help of an example.\\nIllustration 2\\nThe following are the number of departmental stores in 15 cities: 35, 17, 10, 32, 70, 28, 26, 19, 26,\\n66, 37, 44, 33, 29 and 28. If we want to select a sample of 10 stores, using cities as clusters and\\nselecting within clusters proportional to size, how many stores from each city should be chosen?(Use a starting point of 10).\\nSolution:  Let us put the information as under (Table 4.1):\\nSince in the given problem, we have 500 departmental stores from which we have to select a\\nsample of 10 stores, the appropriate sampling interval is 50. As we have to use the starting point of10\\n*, so we add successively increments of 50 till 10 numbers have been selected. The numbers, thus,\\nobtained are: 10, 60, 110, 160, 210, 260, 310, 360, 410 and 460 which have been shown in the lastcolumn of the table (Table 4.1) against the concerning cumulative totals. From this we can say thattwo stores should be selected randomly from city number five and one each from city number 1, 3, 7,9, 10, 11, 12, and 14. This sample of 10 stores is the sample with probability proportional to size.\\n*If the starting point is not mentioned, then the same can randomly be selected.Sampling Design 67\\nTable 4.1\\nCity number No. of departmental stores Cumulative total Sample\\n13 53 5 1 0\\n21 75 2\\n31 06 2 6 0\\n43 29 4\\n5 70 164 110 160\\n6 28 192\\n7 26 218 210\\n8 19 237\\n9 26 263 260\\n10 66 329 310\\n11 37 366 360\\n12 44 410 410\\n13 33 443\\n14 29 472 460\\n15 28 500\\n(vii) Sequential sampling: This sampling design is some what complex sample design. The ultimate\\nsize of the sample under this technique is not fixed in advance, but is determined according to\\nmathematical decision rules on the basis of information yielded as survey progresses. This is usuallyadopted in case of acceptance sampling plan in context of statistical quality control. When a particularlot is to be accepted or rejected on the basis of a single sample, it is known as single sampling; whenthe decision is to be taken on the basis of two samples, it is known as double sampling and in case thedecision rests on the basis of more than two samples but the number of samples is certain anddecided in advance, the sampling is known as multiple sampling. But when the number of samples ismore than two but it is neither certain nor decided in advance, this type of system is often referred toas sequential sampling. Thus, in brief, we can say that in sequential sampling, one can go on takingsamples one after another as long as one desires to do so.\\nCONCLUSION\\nFrom a brief description of the various sample designs presented above, we can say that normallyone should resort to simple random sampling because under it bias is generally eliminated and thesampling error can be estimated. But purposive sampling is considered more appropriate when theuniverse happens to be small and a known characteristic of it is to be studied intensively. There aresituations in real life under which sample designs other than simple random samples may be consideredbetter (say easier to obtain, cheaper or more informative) and as such the same may be used. In asituation when random sampling is not possible, then we have to use necessarily a sampling designother than random sampling. At times, several methods of sampling may well be used in the samestudy.68 Research Methodology\\nQuestions\\n1.What do you mean by ‘Sample Design’? What points should be taken into consideration by a researcher\\nin developing a sample design for this research project.\\n2.How would you differentiate between simple random sampling and complex random sampling designs?Explain clearly giving examples.\\n3.Why probability sampling is generally preferred in comparison to non-probability sampling? Explain theprocedure of selecting a simple random sample.\\n4.Under what circumstances stratified random sampling design is considered appropriate? How would youselect such sample? Explain by means of an example.\\n5.Distinguish between:\\n(a) Restricted and unrestricted sampling;\\n(b) Convenience and purposive sampling;\\n(c) Systematic and stratified sampling;\\n(d) Cluster and area sampling.\\n6.Under what circumstances would you recommend:\\n(a) A probability sample?\\n(b) A non-probability sample?\\n(c) A stratified sample?\\n(d) A cluster sample?\\n7.Explain and illustrate the procedure of selecting a random sample.\\n8.“A systematic bias results from errors in the sampling procedures”. What do you mean by such asystematic bias? Describe the important causes responsible for such a bias.\\n9.(a) The following are the number of departmental stores in 10 cities: 35, 27, 24, 32, 42, 30, 34, 40, 29 and 38.If we want to select a sample of 15 stores using cities as clusters and selecting within clusters proportionalto size, how many stores from each city should be chosen? (Use a starting point of 4).\\n(b)What sampling design might be used to estimate the weight of a group of men and women?\\n10.A certain population is divided into five strata so that N\\n1 = 2000, N2 = 2000, N3 = 1800, N4 = 1700, and\\nN5= 2500. Respective standard deviations are: σσσσσ1234516 20 44 48 60=====.....,,,,\\nand further the expected sampling cost in the first two strata is Rs 4 per interview and in the remaining\\nthree strata the sampling cost is Rs 6 per interview. How should a sample of size n = 226 be allocated to\\nfive strata if we adopt proportionate sampling design; if we adopt disproportionate sampling designconsidering (i) only the differences in stratum variability (ii) differences in stratum variability as well asthe differences in stratum sampling costs.Measurement and Scaling Techniques 69\\n5\\nMeasurement and Scaling\\nTechniques\\nMEASUREMENT IN RESEARCH\\nIn our daily life we are said to measure when we use some yardstick to determine weight, height, or\\nsome other feature of a physical object. We also measure when we judge how well we like a song,a painting or the personalities of our friends. We, thus, measure physical objects as well as abstract\\nconcepts. Measurement is a relatively complex and demanding task, specially so when it concerns\\nqualitative or abstract phenomena. By measurement we mean the process of assigning numbers toobjects or observations, the level of measurement being a function of the rules under which thenumbers are assigned.\\nIt is easy to assign numbers in respect of properties of some objects, but it is relatively difficult in\\nrespect of others. For instance, measuring such things as social conformity, intelligence, or maritaladjustment is much less obvious and requires much closer attention than measuring physical weight,biological age or a person’s financial assets. In other words, properties like weight, height, etc., canbe measured directly with some standard unit of measurement, but it is not that easy to measureproperties like motivation to succeed, ability to stand stress and the like. We can expect high accuracyin measuring the length of pipe with a yard stick, but if the concept is abstract and the measurementtools are not standardized, we are less confident about the accuracy of the results of measurement.\\nTechnically speaking, measurement is a process of mapping aspects of a domain onto other\\naspects of a range according to some rule of correspondence. In measuring, we devise some form ofscale in the range (in terms of set theory, range may refer to some set) and then transform or map theproperties of objects from the domain (in terms of set theory, domain may refer to some other set)onto this scale. For example, in case we are to find the male to female attendance ratio whileconducting a study of persons who attend some show, then we may tabulate those who come to theshow according to sex. In terms of set theory, this process is one of mapping the observed physicalproperties of those coming to the show (the domain) on to a sex classification (the range). The ruleof correspondence is: If the object in the domain appears to be male, assign to “0” and if femaleassign to “1”. Similarly, we can record a person’s marital status as 1, 2, 3 or 4, depending on whether70 Research Methodology\\nthe person is single, married, widowed or divorced. We can as well record “Yes or No” answers to\\na question as “0” and “1” (or as 1 and 2 or perhaps as 59 and 60). In this artificial or nominal way,categorical data (qualitative or descriptive) can be made into numerical data and if we thus code thevarious categories, we refer to the numbers we record as nominal data. Nominal data are numerical\\nin name only, because they do not share any of the properties of the numbers we deal in ordinaryarithmetic. For instance if we record marital status as 1, 2, 3, or 4 as stated above, we cannot write4 > 2 or 3 < 4 and we cannot write 3 – 1 = 4 – 2, 1 + 3 = 4 or 4 \\n÷ 2 = 2.\\nIn those situations when we cannot do anything except set up inequalities, we refer to the data as\\nordinal data. For instance, if one mineral can scratch another, it receives a higher hardness number\\nand on Mohs’ scale the numbers from 1 to 10 are assigned respectively to talc, gypsum, calcite,fluorite, apatite, feldspar, quartz, topaz, sapphire and diamond. With these numbers we can write5> 2 or 6 < 9 as apatite is harder than gypsum and feldspar is softer than sapphire, but we cannotwrite for example 10 – 9 = 5 – 4, because the difference in hardness between diamond and sapphireis actually much greater than that between apatite and fluorite. It would also be meaningless to saythat topaz is twice as hard as fluorite simply because their respective hardness numbers on Mohs’scale are 8 and 4. The greater than symbol (i.e., >) in connection with ordinal data may be used todesignate “happier than” “preferred to” and so on.\\nWhen in addition to setting up inequalities we can also form differences, we refer to the data as\\ninterval data. Suppose we are given the following temperature readings (in degrees Fahrenheit):\\n58°, 63°, 70°, 95°, 110°, 126° and 135°. In this case, we can write 100° > 70° or 95° < 135° whichsimply means that 110° is warmer than 70° and that 95° is cooler than 135°. We can also write forexample 95° – 70° = 135° – 110°, since equal temperature differences are equal in the sense that thesame amount of heat is required to raise the temperature of an object from 70° to 95° or from 110°to 135°. On the other hand, it would not mean much if we said that 126° is twice as hot as 63°, eventhough 126° \\n÷ 63° = 2. To show the reason, we have only to change to the centigrade scale, where\\nthe first temperature becomes 5/9 (126 – 32) = 52°, the second temperature becomes 5/9 (63 –32) =17° and the first figure is now more than three times the second. This difficulty arises from thefact that Fahrenheit and Centigrade scales both have artificial origins (zeros) i.e., the number 0 ofneither scale is indicative of the absence of whatever quantity we are trying to measure.\\nWhen in addition to setting up inequalities and forming differences we can also form quotients\\n(i.e., when we can perform all the customary operations of mathematics), we refer to such data asratio data. In this sense, ratio data includes all the usual measurement (or determinations) of length,\\nheight, money amounts, weight, volume, area, pressures etc.\\nThe above stated distinction between nominal, ordinal, interval and ratio data is important for the\\nnature of a set of data may suggest the use of particular statistical techniques\\n*. A researcher has to\\nbe quite alert about this aspect while measuring properties of objects or of abstract concepts.\\n* When data can be measured in units which are interchangeable e.g., weights (by ratio scales), temperatures (by interval\\nscales), that data is said to be parametric and can be subjected to most kinds of statistical and mathematical processes. Butwhen data is measured in units which are not interchangeable, e.g., product preferences (by ordinal scales), the data is saidto be non-parametric and is susceptible only to a limited extent to mathematical and statistical treatment.Measurement and Scaling Techniques 71\\nMEASUREMENT SCALES\\nFrom what has been stated above, we can write that scales of measurement can be considered in\\nterms of their mathematical properties. The most widely used classification of measurement scalesare: (a) nominal scale; (b) ordinal scale; (c) interval scale; and (d) ratio scale.\\n(a) Nominal scale: Nominal scale is simply a system of assigning number symbols to events in\\norder to label them. The usual example of this is the assignment of numbers of basketball players in\\norder to identify them. Such numbers cannot be considered to be associated with an ordered scalefor their order is of no consequence; the numbers are just convenient labels for the particular class ofevents and as such have no quantitative value. Nominal scales provide convenient ways of keepingtrack of people, objects and events. One cannot do much with the numbers involved. For example,one cannot usefully average the numbers on the back of a group of football players and come up witha meaningful value. Neither can one usefully compare the numbers assigned to one group with thenumbers assigned to another. The counting of members in each group is the only possible arithmeticoperation when a nominal scale is employed. Accordingly, we are restricted to use mode as themeasure of central tendency. There is no generally used measure of dispersion for nominal scales.Chi-square test is the most common test of statistical significance that can be utilized, and for themeasures of correlation, the contingency coefficient can be worked out.\\nNominal scale is the least powerful level of measurement. It indicates no order or distance\\nrelationship and has no arithmetic origin. A nominal scale simply describes differences betweenthings by assigning them to categories. Nominal data are, thus, counted data. The scale wastes anyinformation that we may have about varying degrees of attitude, skills, understandings, etc. In spiteof all this, nominal scales are still very useful and are widely used in surveys and other ex-post-facto\\nresearch when data are being classified by major sub-groups of the population.\\n(b) Ordinal scale: The lowest level of the ordered scale that is commonly used is the ordinal scale.\\nThe ordinal scale places events in order, but there is no attempt to make the intervals of the scale\\nequal in terms of some rule. Rank orders represent ordinal scales and are frequently used in researchrelating to qualitative phenomena. A student’s rank in his graduation class involves the use of anordinal scale. One has to be very careful in making statement about scores based on ordinal scales.For instance, if Ram’s position in his class is 10 and Mohan’s position is 40, it cannot be said thatRam’s position is four times as good as that of Mohan. The statement would make no sense at all.Ordinal scales only permit the ranking of items from highest to lowest. Ordinal measures have noabsolute values, and the real differences between adjacent ranks may not be equal. All that can besaid is that one person is higher or lower on the scale than another, but more precise comparisonscannot be made.\\nThus, the use of an ordinal scale implies a statement of ‘greater than’ or ‘less than’ (an equality\\nstatement is also acceptable) without our being able to state how much greater or less. The realdifference between ranks 1 and 2 may be more or less than the difference between ranks 5 and 6.Since the numbers of this scale have only a rank meaning, the appropriate measure of central tendencyis the median. A percentile or quartile measure is used for measuring dispersion. Correlations arerestricted to various rank order methods. Measures of statistical significance are restricted to thenon-parametric methods.\\n(c) Interval scale:  In the case of interval scale, the intervals are adjusted in terms of some rule that\\nhas been established as a basis for making the units equal. The units are equal only in so far as one72 Research Methodology\\naccepts the assumptions on which the rule is based. Interval scales can have an arbitrary zero, but it\\nis not possible to determine for them what may be called an absolute zero or the unique origin. Theprimary limitation of the interval scale is the lack of a true zero; it does not have the capacity tomeasure the complete absence of a trait or characteristic. The Fahrenheit scale is an example of aninterval scale and shows similarities in what one can and cannot do with it. One can say that anincrease in temperature from 30° to 40° involves the same increase in temperature as an increasefrom 60° to 70°, but one cannot say that the temperature of 60° is twice as warm as the temperatureof 30° because both numbers are dependent on the fact that the zero on the scale is set arbitrarily atthe temperature of the freezing point of water. The ratio of the two temperatures, 30° and 60°,means nothing because zero is an arbitrary point.\\nInterval scales provide more powerful measurement than ordinal scales for interval scale also\\nincorporates the concept of equality of interval. As such more powerful statistical measures can beused with interval scales. Mean is the appropriate measure of central tendency, while standarddeviation is the most widely used measure of dispersion. Product moment correlation techniques areappropriate and the generally used tests for statistical significance are the ‘t’ test and ‘F’ test.\\n(d) Ratio scale: Ratio scales have an absolute or true zero of measurement. The term ‘absolute\\nzero’ is not as precise as it was once believed to be. We can conceive of an absolute zero of length\\nand similarly we can conceive of an absolute zero of time. For example, the zero point on a centimeterscale indicates the complete absence of length or height. But an absolute zero of temperature istheoretically unobtainable and it remains a concept existing only in the scientist’s mind. The numberof minor traffic-rule violations and the number of incorrect letters in a page of type script representscores on ratio scales. Both these scales have absolute zeros and as such all minor traffic violationsand all typing errors can be assumed to be equal in significance. With ratio scales involved one canmake statements like “Jyoti’s” typing performance was twice as good as that of “Reetu.” The ratioinvolved does have significance and facilitates a kind of comparison which is not possible in case ofan interval scale.\\nRatio scale represents the actual amounts of variables. Measures of physical dimensions such as\\nweight, height, distance, etc. are examples. Generally, all statistical techniques are usable with ratioscales and all manipulations that one can carry out with real numbers can also be carried out withratio scale values. Multiplication and division can be used with this scale but not with other scalesmentioned above. Geometric and harmonic means can be used as measures of central tendency andcoefficients of variation may also be calculated.\\nThus, proceeding from the nominal scale (the least precise type of scale) to ratio scale (the most\\nprecise), relevant information is obtained increasingly. If the nature of the variables permits, theresearcher should use the scale that provides the most precise description. Researchers in physicalsciences have the advantage to describe variables in ratio scale form but the behavioural sciencesare generally limited to describe variables in interval scale form, a less precise type of measurement.\\nSources of Error in Measurement\\nMeasurement should be precise and unambiguous in an ideal research study. This objective, however,is often not met with in entirety. As such the researcher must be aware about the sources of error inmeasurement. The following are the possible sources of error in measurement.Measurement and Scaling Techniques 73\\n(a) Respondent: At times the respondent may be reluctant to express strong negative feelings or\\nit is just possible that he may have very little knowledge but may not admit his ignorance. All this\\nreluctance is likely to result in an interview of ‘guesses.’ Transient factors like fatigue, boredom,anxiety, etc. may limit the ability of the respondent to respond accurately and fully.\\n(b) Situation: Situational factors may also come in the way of correct measurement. Any condition\\nwhich places a strain on interview can have serious effects on the interviewer-respondent rapport.For instance, if someone else is present, he can distort responses by joining in or merely by beingpresent. If the respondent feels that anonymity is not assured, he may be reluctant to express certainfeelings.\\n(c) Measurer: The interviewer can distort responses by rewording or reordering questions. His\\nbehaviour, style and looks may encourage or discourage certain replies from respondents. Careless\\nmechanical processing may distort the findings. Errors may also creep in because of incorrect coding,faulty tabulation and/or statistical calculations, particularly in the data-analysis stage.\\n(d) Instrument: Error may arise because of the defective measuring instrument. The use of complex\\nwords, beyond the comprehension of the respondent, ambiguous meanings, poor printing, inadequatespace for replies, response choice omissions, etc. are a few things that make the measuring instrumentdefective and may result in measurement errors. Another type of instrument deficiency is the poorsampling of the universe of items of concern.\\nResearcher must know that correct measurement depends on successfully meeting all of the\\nproblems listed above. He must, to the extent possible, try to eliminate, neutralize or otherwise dealwith all the possible sources of error so that the final results may not be contaminated.\\nTests of Sound Measurement\\nSound measurement must meet the tests of validity, reliability and practicality. In fact, these are thethree major considerations one should use in evaluating a measurement tool. “Validity refers to theextent to which a test measures what we actually wish to measure. Reliability has to do with theaccuracy and precision of a measurement procedure ... Practicality is concerned with a wide rangeof factors of economy, convenience, and interpretability ...”\\n1 We briefly take up the relevant details\\nconcerning these tests of sound measurement.\\n1. Test of Validity*\\nValidity is the most critical criterion and indicates the degree to which an instrument measures what\\nit is supposed to measure. Validity can also be thought of as utility. In other words, validity is theextent to which differences found with a measuring instrument reflect true differences among thosebeing tested. But the question arises: how can one determine validity without direct confirmingknowledge? The answer may be that we seek other relevant evidence that confirms the answers wehave found with our measuring tool. What is relevant, evidence often depends upon the nature of the\\n1 Robert L. Thorndike and Elizabeth Hagen: Measurement and Evaluation in Psychology and Education, 3rd Ed., p. 162.\\n* Two forms of validity are usually mentioned in research literature viz., the external validity and the internal validity.\\nExternal validity of research findings is their generalizability to populations, settings, treatment variables and measurementvariables. We shall talk about it in the context of significance tests later on. The internal validity of a research design is itsability to measure what it aims to measure. We shall deal with this validity only in the present chapter.74 Research Methodology\\nresearch problem and the judgement of the researcher. But one can certainly consider three types of\\nvalidity in this connection: (i) Content validity; (ii) Criterion-related validity and (iii) Construct validity.\\n(i) Content validity is the extent to which a measuring instrument provides adequate coverage of\\nthe topic under study. If the instrument contains a representative sample of the universe, the content\\nvalidity is good. Its determination is primarily judgemental and intuitive. It can also be determined byusing a panel of persons who shall judge how well the measuring instrument meets the standards, butthere is no numerical way to express it.\\n(ii) Criterion-related validity relates to our ability to predict some outcome or estimate the existence\\nof some current condition. This form of validity reflects the success of measures used for some\\nempirical estimating purpose. The concerned criterion must possess the following qualities:\\nRelevance: (A criterion is relevant if it is defined in terms we judge to be the proper measure.)\\nFreedom from bias: (Freedom from bias is attained when the criterion gives each subject an equal\\nopportunity to score well.)\\nReliability: (A reliable criterion is stable or reproducible.)\\nAvailability: (The information specified by the criterion must be available.)\\nIn fact, a Criterion-related validity is a broad term that actually refers to (i) Predictive validity\\nand (ii) Concurrent validity. The former refers to the usefulness of a test in predicting some future\\nperformance whereas the latter refers to the usefulness of a test in closely relating to other measures\\nof known validity. Criterion-related validity is expressed as the coefficient of correlation betweentest scores and some measure of future performance or between test scores and scores on anothermeasure of known validity.\\n(iii) Construct validity is the most complex and abstract. A measure is said to possess construct\\nvalidity to the degree that it confirms to predicted correlations with other theoretical propositions.\\nConstruct validity is the degree to which scores on a test can be accounted for by the explanatoryconstructs of a sound theory. For determining construct validity, we associate a set of other propositionswith the results received from using our measurement instrument. If measurements on our devisedscale correlate in a predicted way with these other propositions, we can conclude that there is someconstruct validity.\\nIf the above stated criteria and tests are met with, we may state that our measuring instrument\\nis valid and will result in correct measurement; otherwise we shall have to look for more informationand/or resort to exercise of judgement.\\n2. Test of Reliability\\nThe test of reliability is another important test of sound measurement. A measuring instrument is\\nreliable if it provides consistent results. Reliable measuring instrument does contribute to validity, buta reliable instrument need not be a valid instrument. For instance, a scale that consistently overweighsobjects by five kgs., is a reliable scale, but it does not give a valid measure of weight. But the otherway is not true i.e., a valid instrument is always reliable. Accordingly reliability is not as valuable asvalidity, but it is easier to assess reliability in comparison to validity. If the quality of reliability issatisfied by an instrument, then while using it we can be confident that the transient and situationalfactors are not interfering.Measurement and Scaling Techniques 75\\nTwo aspects of reliability viz., stability and equivalence deserve special mention. The stability\\naspect is concerned with securing consistent results with repeated measurements of the same person\\nand with the same instrument. We usually determine the degree of stability by comparing the results\\nof repeated measurements. The equivalence aspect considers how much error may get introduced\\nby different investigators or different samples of the items being studied. A good way to test for theequivalence of measurements by two investigators is to compare their observations of the sameevents. Reliability can be improved in the following two ways:\\n(i) By standardising the conditions under which the measurement takes place i.e., we must\\nensure that external sources of variation such as boredom, fatigue, etc., are minimised tothe extent possible. That will improve stability aspect.\\n(ii) By carefully designed directions for measurement with no variation from group to group,\\nby using trained and motivated persons to conduct the research and also by broadening thesample of items used. This will improve equivalence aspect.\\n3. Test of Practicality\\nThe practicality characteristic of a measuring instrument can be judged in terms of economy,\\nconvenience and interpretability. From the operational point of view, the measuring instrument oughtto be practical i.e., it should be economical, convenient and interpretable. Economy consideration\\nsuggests that some trade-off is needed between the ideal research project and that which the budgetcan afford. The length of measuring instrument is an important area where economic pressures arequickly felt. Although more items give greater reliability as stated earlier, but in the interest of limitingthe interview or observation time, we have to take only few items for our study purpose. Similarly,data-collection methods to be used are also dependent at times upon economic factors. Convenience\\ntest suggests that the measuring instrument should be easy to administer. For this purpose one shouldgive due attention to the proper layout of the measuring instrument. For instance, a questionnaire,with clear instructions (illustrated by examples), is certainly more effective and easier to completethan one which lacks these features. Interpretability consideration is specially important when\\npersons other than the designers of the test are to interpret the results. The measuring instrument, inorder to be interpretable, must be supplemented by (a) detailed instructions for administering the test;(b) scoring keys; (c) evidence about the reliability and (d) guides for using the test and for interpretingresults.\\nTECHNIQUE OF DEVELOPING MEASUREMENT TOOLS\\nThe technique of developing measurement tools involves a four-stage process, consisting of thefollowing:\\n(a) Concept development;\\n(b) Specification of concept dimensions;\\n(c) Selection of indicators; and\\n(d) Formation of index.\\nThe first and foremost step is that of concept development which means that the researcher\\nshould arrive at an understanding of the major concepts pertaining to his study. This step of concept76 Research Methodology\\ndevelopment is more apparent in theoretical studies than in the more pragmatic research, where the\\nfundamental concepts are often already established.\\nThe second step requires the researcher to specify the dimensions of the concepts that he\\ndeveloped in the first stage. This task may either be accomplished by deduction i.e., by adopting amore or less intuitive approach or by empirical correlation of the individual dimensions with the totalconcept and/or the other concepts. For instance, one may think of several dimensions such as productreputation, customer treatment, corporate leadership, concern for individuals, sense of socialresponsibility and so forth when one is thinking about the image of a certain company.\\nOnce the dimensions of a concept have been specified, the researcher must develop indicators\\nfor measuring each concept element. Indicators are specific questions, scales, or other devices bywhich respondent’s knowledge, opinion, expectation, etc., are measured. As there is seldom a perfectmeasure of a concept, the researcher should consider several alternatives for the purpose. The useof more than one indicator gives stability to the scores and it also improves their validity.\\nThe last step is that of combining the various indicators into an index, i.e., formation of an\\nindex. When we have several dimensions of a concept or different measurements of a dimension,\\nwe may need to combine them into a single index. One simple way for getting an overall index is toprovide scale values to the responses and then sum up the corresponding scores. Such an overallindex would provide a better measurement tool than a single indicator because of the fact that an“individual indicator has only a probability relation to what we really want to know.”\\n2 This way we\\nmust obtain an overall index for the various concepts concerning the research study.\\nScaling\\nIn research we quite often face measurement problem (since we want a valid measurement but maynot obtain it), specially when the concepts to be measured are complex and abstract and we do notpossess the standardised measurement tools. Alternatively, we can say that while measuring attitudesand opinions, we face the problem of their valid measurement. Similar problem may be faced by aresearcher, of course in a lesser degree, while measuring physical or institutional concepts. As suchwe should study some procedures which may enable us to measure abstract concepts more accurately.This brings us to the study of scaling techniques.\\nMeaning of Scaling\\nScaling describes the procedures of assigning numbers to various degrees of opinion, attitude andother concepts. This can be done in two ways viz., (i) making a judgement about some characteristicof an individual and then placing him directly on a scale that has been defined in terms of thatcharacteristic and (ii) constructing questionnaires in such a way that the score of individual’s responsesassigns him a place on a scale. It may be stated here that a scale is a continuum, consisting of thehighest point (in terms of some characteristic e.g., preference, favourableness, etc.) and the lowestpoint along with several intermediate points between these two extreme points. These scale-pointpositions are so related to each other that when the first point happens to be the highest point, thesecond point indicates a higher degree in terms of a given characteristic as compared to the third\\n2 Lazersfeld, Evidence and Inference, p. 112.Measurement and Scaling Techniques 77\\npoint and the third point indicates a higher degree as compared to the fourth and so on. Numbers for\\nmeasuring the distinctions of degree in the attitudes/opinions are, thus, assigned to individualscorresponding to their scale-positions. All this is better understood when we talk about scalingtechnique(s). Hence the term ‘scaling’ is applied to the procedures for attempting to determinequantitative measures of subjective abstract concepts. Scaling has been defined as a “procedure forthe assignment of numbers (or other symbols) to a property of objects in order to impart some of thecharacteristics of numbers to the properties in question.”\\n3\\nScale Classification Bases\\nThe number assigning procedures or the scaling procedures may be broadly classified on one ormore of the following bases: (a) subject orientation; (b) response form; (c) degree of subjectivity;(d) scale properties; (e) number of dimensions and (f) scale construction techniques. We take upeach of these separately.\\n(a) Subject orientation: Under it a scale may be designed to measure characteristics of the respondent\\nwho completes it or to judge the stimulus object which is presented to the respondent. In respect of\\nthe former, we presume that the stimuli presented are sufficiently homogeneous so that the between-stimuli variation is small as compared to the variation among respondents. In the latter approach, weask the respondent to judge some specific object in terms of one or more dimensions and we presumethat the between-respondent variation will be small as compared to the variation among the different\\nstimuli presented to respondents for judging.\\n(b) Response form: Under this we may classify the scales as categorical and comparative.\\nCategorical scales are also known as rating scales. These scales are used when a respondent scores\\nsome object without direct reference to other objects. Under comparative scales, which are alsoknown as ranking scales, the respondent is asked to compare two or more objects. In this sense therespondent may state that one object is superior to the other or that three models of pen rank in order1, 2 and 3. The essence of ranking is, in fact, a relative comparison of a certain property of two ormore objects.\\n(c) Degree of subjectivity: With this basis the scale data may be based on whether we measure\\nsubjective personal preferences or simply make non-preference judgements. In the former case, the\\nrespondent is asked to choose which person he favours or which solution he would like to seeemployed, whereas in the latter case he is simply asked to judge which person is more effective insome aspect or which solution will take fewer resources without reflecting any personal preference.\\n(d) Scale properties: Considering scale properties, one may classify the scales as nominal, ordinal,\\ninterval and ratio scales. Nominal scales merely classify without indicating order, distance or unique\\norigin. Ordinal scales indicate magnitude relationships of ‘more than’ or ‘less than’, but indicate nodistance or unique origin. Interval scales have both order and distance values, but no unique origin.Ratio scales possess all these features.\\n(e) Number of dimensions: In respect of this basis, scales can be classified as ‘unidimensional’\\nand ‘multidimensional’ scales. Under the former we measure only one attribute of the respondent or\\nobject, whereas multidimensional scaling recognizes that an object might be described better by usingthe concept of an attribute space of ‘n’ dimensions, rather than a single-dimension continuum.\\n3 Bernard S. Phillips, Social Research Strategy and Tactics, 2nd ed., p. 205.78 Research Methodology\\n(f) Scale construction techniques: Following are the five main techniques by which scales can\\nbe developed.\\n(i)Arbitrary approach: It is an approach where scale is developed on ad hoc basis. This is\\nthe most widely used approach. It is presumed that such scales measure the concepts for\\nwhich they have been designed, although there is little evidence to support such an assumption.\\n(ii)Consensus approach: Here a panel of judges evaluate the items chosen for inclusion in\\nthe instrument in terms of whether they are relevant to the topic area and unambiguous inimplication.\\n(iii)Item analysis approach: Under it a number of individual items are developed into a test\\nwhich is given to a group of respondents. After administering the test, the total scores arecalculated for every one. Individual items are then analysed to determine which itemsdiscriminate between persons or objects with high total scores and those with low scores.\\n(iv)Cumulative scales are chosen on the basis of their conforming to some ranking of items\\nwith ascending and descending discriminating power. For instance, in such a scale theendorsement of an item representing an extreme position should also result in theendorsement of all items indicating a less extreme position.\\n(v)Factor scales may be constructed on the basis of intercorrelations of items which indicate\\nthat a common factor accounts for the relationship between items. This relationship istypically measured through factor analysis method.\\nImportant Scaling Techniques\\nWe now take up some of the important scaling techniques often used in the context of researchspecially in context of social or business research.\\nRating scales: The rating scale involves qualitative description of a limited number of aspects of a\\nthing or of traits of a person. When we use rating scales (or categorical scales), we judge an object\\nin absolute terms against some specified criteria i.e., we judge properties of objects without referenceto other similar objects. These ratings may be in such forms as “like-dislike”, “above average, average,below average”, or other classifications with more categories such as “like very much—like somewhat—neutral—dislike somewhat—dislike very much”; “excellent—good—average—belowaverage—poor”, “always—often—occasionally—rarely—never”, and so on. There is no specificrule whether to use a two-points scale, three-points scale or scale with still more points. In practice,three to seven points scales are generally used for the simple reason that more points on a scaleprovide an opportunity for greater sensitivity of measurement.\\nRating scale may be either a graphic rating scale or an itemized rating scale.\\n(i)The graphic rating scale is quite simple and is commonly used in practice. Under it thevarious points are usually put along the line to form a continuum and the rater indicates hisrating by simply making a mark (such as ü) at the appropriate point on a line that runs from\\none extreme to the other. Scale-points with brief descriptions may be indicated along theline, their function being to assist the rater in performing his job. The following is an exampleof five-points graphic rating scale when we wish to ascertain people’s liking or disliking anyproduct:Measurement and Scaling Techniques 79\\nFig. 5.1\\nThis type of scale has several limitations. The respondents may check at almost any\\nposition along the line which fact may increase the difficulty of analysis. The meanings of\\nthe terms like “very much” and “some what” may depend upon respondent’s frame ofreference so much so that the statement might be challenged in terms of its equivalency.Several other rating scale variants (e.g., boxes replacing line) may also be used.\\n(ii)The itemized rating scale (also known as numerical scale) presents a series of statements\\nfrom which a respondent selects one as best reflecting his evaluation. These statementsare ordered progressively in terms of more or less of some property. An example of itemizedscale can be given to illustrate it.\\nSuppose we wish to inquire as to how well does a worker get along with his fellow workers? In\\nsuch a situation we may ask the respondent to select one, to express his opinion, from the following:\\nnHe is almost always involved in some friction with a fellow worker.\\nnHe is often at odds with one or more of his fellow workers.\\nnHe sometimes gets involved in friction.\\nnHe infrequently becomes involved in friction with others.\\nnHe almost never gets involved in friction with fellow workers.\\nThe chief merit of this type of scale is that it provides more information and meaning to the rater,\\nand thereby increases reliability. This form is relatively difficult to develop and the statements maynot say exactly what the respondent would like to express.\\nRating scales have certain good points. The results obtained from their use compare favourably\\nwith alternative methods. They require less time, are interesting to use and have a wide range ofapplications. Besides, they may also be used with a large number of properties or variables. But theirvalue for measurement purposes depends upon the assumption that the respondents can and domake good judgements. If the respondents are not very careful while rating, errors may occur. Threetypes of errors are common viz., the error of leniency, the error of central tendency and the error ofhallo effect. The error of leniency occurs when certain respondents are either easy raters or hardraters. When raters are reluctant to give extreme judgements, the result is the error of centraltendency. The error of hallo effect or the systematic bias occurs when the rater carries over ageneralised impression of the subject from one rating to another. This sort of error takes place whenwe conclude for example, that a particular report is good because we like its form or that someone isintelligent because he agrees with us or has a pleasing personality. In other words, hallo effect islikely to appear when the rater is asked to rate many factors, on a number of which he has noevidence for judgement.Like very\\nmuchLike some\\nwhatNeutralHow do you like the product?\\n(Please check)\\nDislike some\\nwhatDislike very\\nmuch80 Research Methodology\\nRanking scales: Under ranking scales (or comparative scales) we make relative judgements\\nagainst other similar objects. The respondents under this method directly compare two or more\\nobjects and make choices among them. There are two generally used approaches of ranking scales viz.\\n(a) Method of paired comparisons: Under it the respondent can express his attitude by making a\\nchoice between two objects, say between a new flavour of soft drink and an established brand ofdrink. But when there are more than two stimuli to judge, the number of judgements required in apaired comparison is given by the formula:\\nNnn=−1\\n2bg\\nwhereN = number of judgements\\nn = number of stimuli or objects to be judged.\\nFor instance, if there are ten suggestions for bargaining proposals available to a workers union, thereare 45 paired comparisons that can be made with them. When N happens to be a big figure, there is\\nthe risk of respondents giving ill considered answers or they may even refuse to answer. We canreduce the number of comparisons per respondent either by presenting to each one of them only asample of stimuli or by choosing a few objects which cover the range of attractiveness at about equalintervals and then comparing all other stimuli to these few standard objects. Thus, paired-comparisondata may be treated in several ways. If there is substantial consistency, we will find that if X is\\npreferred to Y, and Y to Z, then X will consistently be preferred to Z. If this is true, we may take the\\ntotal number of preferences among the comparisons as the score for that stimulus.\\nIt should be remembered that paired comparison provides ordinal data, but the same may be\\nconverted into an interval scale by the method of the Law of Comparative Judgement developed by\\nL.L. Thurstone. This technique involves the conversion of frequencies of preferences into a table ofproportions which are then transformed into Z matrix by referring to the table of area under the\\nnormal curve. J.P. Guilford in his book “Psychometric Methods” has given a procedure which isrelatively easier. The method is known as the Composite Standard Method and can be illustrated as\\nunder:\\nSuppose there are four proposals which some union bargaining committee is considering. Thecommittee wants to know how the union membership ranks these proposals. For this purposea sample of 100 members might express the views as shown in the following table:\\nTable 5.1:\\nResponse Patterns of 100 Members\\x92 Paired Comparisons of\\n4 Suggestions for Union Bargaining Proposal Priorities\\nSuggestion\\nAB C D\\nA –6 5*32 20\\nB 40 – 38 42\\nC 45 50 – 70\\nD 80 20 98 –\\n                     TOTAL: 165 135 168 132\\n*Read as 65 members preferred suggestion B to suggestion A.Contd.Measurement and Scaling Techniques 81\\nRank order 2 3 1 4\\nMp0.5375 0.4625 0.5450 0.4550\\nZj0.09 (–).09 0.11 (–).11\\nRj0.20 0.02 0.22 0.00\\nComparing the total number of preferences for each of the four proposals, we find that C is the\\nmost popular, followed by A, B and D respectively in popularity. The rank order shown in the above\\ntable explains all this.\\nBy following the composite standard method, we can develop an interval scale from the paired-\\ncomparison ordinal data given in the above table for which purpose we have to adopt the following\\nsteps in order:\\n(i) Using the data in the above table, we work out the column mean with the help of the\\nformula given below:\\nMCN\\nnNp=+=+=...5 165 5 100\\n4 1005375bg b gbg\\nwhere\\nMp = the mean proportion of the columns\\n  C = the total number of choices for a given suggestion\\n   n = number of stimuli (proposals in the given problem)\\n  N = number of items in the sample.\\nThe column means have been shown in the Mp row in the above table.\\n(ii)The Z values for the Mp are secured from the table giving the area under the normal curve.\\nWhen the Mp value is less than .5, the Z value is negative and for all Mp values higher than\\n.5, the Z values are positive.* These Z values are shown in Zj row in the above table.\\n(iii) As the Zj values represent an interval scale, zero is an arbitrary value. Hence we can\\neliminate negative scale values by giving the value of zero to the lowest scale value (this\\nbeing (–).11 in our example which we shall take equal to zero) and then adding the absolutevalue of this lowest scale value to all other scale items. This scale has been shown in R\\nj\\nrow in the above table.\\nGraphically we can show this interval scale that we have derived from the paired-comparison\\ndata using the composite standard method as follows:\\nFig. 5.2\\n* To use Normal curve area table for this sort of transformation, we must subtract 0.5 from all Mp values which exceed\\n.5 to secure the values with which to enter the normal curve area table for which Z values can be obtained. For all Mp values\\nof less than . 5 we must subtract all such values from 0.5 to secure the values with which to enter the normal curve area tablefor which Z values can be obtained but the Z values in this situation will be with negative sign.0.0 0.1 0.2 0.3 0.4D  B A C82 Research Methodology\\n(b) Method of rank order: Under this method of comparative scaling, the respondents are asked\\nto rank their choices. This method is easier and faster than the method of paired comparisons stated\\nabove. For example, with 10 items it takes 45 pair comparisons to complete the task, whereas themethod of rank order simply requires ranking of 10 items only. The problem of transitivity (such as A\\nprefers to B, B to C, but C prefers to A) is also not there in case we adopt method of rank order.\\nMoreover, a complete ranking at times is not needed in which case the respondents may be asked torank only their first, say, four choices while the number of overall items involved may be more thanfour, say, it may be 15 or 20 or more. To secure a simple ranking of all items involved we simply totalrank values received by each item. There are methods through which we can as well develop aninterval scale of these data. But then there are limitations of this method. The first one is that dataobtained through this method are ordinal data and hence rank ordering is an ordinal scale with all itslimitations. Then there may be the problem of respondents becoming careless in assigning ranksparticularly when there are many (usually more than 10) items.\\nScale Construction Techniques\\nIn social science studies, while measuring attitudes of the people we generally follow the techniqueof preparing the opinionnaire\\n* (or attitude scale) in such a way that the score of the individual\\nresponses assigns him a place on a scale. Under this approach, the respondent expresses hisagreement or disagreement with a number of statements relevant to the issue. While developingsuch statements, the researcher must note the following two points:\\n(i) That the statements must elicit responses which are psychologically related to the attitude\\nbeing measured;\\n(ii)That the statements need be such that they discriminate not merely between extremes ofattitude but also among individuals who differ slightly.\\nResearchers must as well be aware that inferring attitude from what has been recorded in\\nopinionnaires has several limitations. People may conceal their attitudes and express socially acceptableopinions. They may not really know how they feel about a social issue. People may be unaware oftheir attitude about an abstract situation; until confronted with a real situation, they may be unable topredict their reaction. Even behaviour itself is at times not a true indication of attitude. For instance,when politicians kiss babies, their behaviour may not be a true expression of affection toward infants.Thus, there is no sure method of measuring attitude; we only try to measure the expressed opinionand then draw inferences from it about people’s real feelings or attitudes.\\nWith all these limitations in mind, psychologists and sociologists have developed several scale\\nconstruction techniques for the purpose. The researcher should know these techniques so as todevelop an appropriate scale for his own study. Some of the important approaches, along with thecorresponding scales developed under each approach to measure attitude are as follows:\\n* An information form that attempts to measure the attitude or belief of an individual is known as opinionnaire.Measurement and Scaling Techniques 83\\nTable 5.2 :Different Scales for Measuring Attitudes of People\\nName of the scale construction approach Name of the scale developed\\n1. Arbitrary approach Arbitrary scales\\n2. Consensus scale approach Differential scales (such as Thurstone\\nDifferential scale)\\n3. Item analysis approach Summated scales (such as Likert Scale)4. Cumulative scale approach Cumulative scales (such as Guttman’s Scalogram)\\n5. Factor analysis approach Factor scales (such as Osgood’s Semantic\\nDifferential, Multi-dimensional Scaling, etc.)\\nA brief description of each of the above listed scales will be helpful.\\nArbitrary Scales\\nArbitrary scales are developed on ad hoc basis and are designed largely through the researcher’s\\nown subjective selection of items. The researcher first collects few statements or items which he\\nbelieves are unambiguous and appropriate to a given topic. Some of these are selected for inclusionin the measuring instrument and then people are asked to check in a list the statements with whichthey agree.\\nThe chief merit of such scales is that they can be developed very easily, quickly and with relatively\\nless expense. They can also be designed to be highly specific and adequate. Because of thesebenefits, such scales are widely used in practice.\\nAt the same time there are some limitations of these scales. The most important one is that we\\ndo not have objective evidence that such scales measure the concepts for which they have beendeveloped. We have simply to rely on researcher’s insight and competence.\\nDifferential Scales (or Thurstone-type Scales)\\nThe name of L.L. Thurstone is associated with differential scales which have been developed using\\nconsensus scale approach. Under such an approach the selection of items is made by a panel ofjudges who evaluate the items in terms of whether they are relevant to the topic area and unambiguousin implication. The detailed procedure is as under:\\n(a) The researcher gathers a large number of statements, usually twenty or more, that express\\nvarious points of view toward a group, institution, idea, or practice (i.e., statements belongingto the topic area).\\n(b) These statements are then submitted to a panel of judges, each of whom arranges them in\\neleven groups or piles ranging from one extreme to another in position. Each of the judgesis requested to place generally in the first pile the statements which he thinks are mostunfavourable to the issue, in the second pile to place those statements which he thinks arenext most unfavourable and he goes on doing so in this manner till in the eleventh pile heputs the statements which he considers to be the most favourable.\\n(c) This sorting by each judge yields a composite position for each of the items. In case of marked\\ndisagreement between the judges in assigning a position to an item, that item is discarded.84 Research Methodology\\n(d) For items that are retained, each is given its median scale value between one and eleven as\\nestablished by the panel. In other words, the scale value of any one statement is computed\\nas the ‘median’ position to which it is assigned by the group of judges.\\n(e) A final selection of statements is then made. For this purpose a sample of statements,\\nwhose median scores are spread evenly from one extreme to the other is taken. Thestatements so selected, constitute the final scale to be administered to respondents. Theposition of each statement on the scale is the same as determined by the judges.\\nAfter developing the scale as stated above, the respondents are asked during the administration\\nof the scale to check the statements with which they agree. The median value of the statements thatthey check is worked out and this establishes their score or quantifies their opinion. It may be notedthat in the actual instrument the statements are arranged in random order of scale value. If the valuesare valid and if the opinionnaire deals with only one attitude dimension, the typical respondent willchoose one or several contiguous items (in terms of scale values) to reflect his views. However, attimes divergence may occur when a statement appears to tap a different attitude dimension.\\nThe Thurstone method has been widely used for developing differential scales which are utilised\\nto measure attitudes towards varied issues like war, religion, etc. Such scales are considered mostappropriate and reliable when used for measuring a single attitude. But an important deterrent totheir use is the cost and effort required to develop them. Another weakness of such scales is that thevalues assigned to various statements by the judges may reflect their own attitudes. The method isnot completely objective; it involves ultimately subjective decision process. Critics of this method alsoopine that some other scale designs give more information about the respondent’s attitude in comparisonto differential scales.\\nSummated Scales (or Likert-type Scales)\\nSummated scales (or Likert-type scales) are developed by utilizing the item analysis approach wherein\\na particular item is evaluated on the basis of how well it discriminates between those persons whosetotal score is high and those whose score is low. Those items or statements that best meet this sort ofdiscrimination test are included in the final instrument.\\nThus, summated scales consist of a number of statements which express either a favourable or\\nunfavourable attitude towards the given object to which the respondent is asked to react. The respondentindicates his agreement or disagreement with each statement in the instrument. Each response isgiven a numerical score, indicating its favourableness or unfavourableness, and the scores are totalledto measure the respondent’s attitude. In other words, the overall score represents the respondent’sposition on the continuum of favourable-unfavourableness towards an issue.\\nMost frequently used summated scales in the study of social attitudes follow the pattern devised\\nby Likert. For this reason they are often referred to as Likert-type scales. In a Likert scale, therespondent is asked to respond to each of the statements in terms of several degrees, usually fivedegrees (but at times 3 or 7 may also be used) of agreement or disagreement. For example, whenasked to express opinion whether one considers his job quite pleasant, the respondent may respond inany one of the following ways: (i) strongly agree, (ii) agree, (iii) undecided, (iv) disagree, (v) stronglydisagree.Measurement and Scaling Techniques 85\\nWe find that these five points constitute the scale. At one extreme of the scale there is strong\\nagreement with the given statement and at the other, strong disagreement, and between them lie\\nintermediate points. We may illustrate this as under:\\nFig. 5.3\\nEach point on the scale carries a score. Response indicating the least favourable degree of job\\nsatisfaction is given the least score (say 1) and the most favourable is given the highest score (say 5).These score—values are normally not printed on the instrument but are shown here just to indicatethe scoring pattern. The Likert scaling technique, thus, assigns a scale value to each of the fiveresponses. The same thing is done in respect of each and every statement in the instrument. Thisway the instrument yields a total score for each respondent, which would then measure the respondent’sfavourableness toward the given point of view. If the instrument consists of, say 30 statements, thefollowing score values would be revealing.\\n30 × 5 = 150 Most favourable response possible\\n30 × 3 = 90 A neutral attitude\\n30 × 1 = 30 Most unfavourable attitude.\\nThe scores for any individual would fall between 30 and 150. If the score happens to be above\\n90, it shows favourable opinion to the given point of view, a score of below 90 would mean unfavourable\\nopinion and a score of exactly 90 would be suggestive of a neutral attitude.\\nProcedure:  The procedure for developing a Likert-type scale is as follows:\\n(i) As a first step, the researcher collects a large number of statements which are relevant to\\nthe attitude being studied and each of the statements expresses definite favourableness or\\nunfavourableness to a particular point of view or the attitude and that the number offavourable and unfavourable statements is approximately equal.\\n(ii)After the statements have been gathered, a trial test should be administered to a number ofsubjects. In other words, a small group of people, from those who are going to be studiedfinally, are asked to indicate their response to each statement by checking one of thecategories of agreement or disagreement using a five point scale as stated above.\\n(iii)The response to various statements are scored in such a way that a response indicative ofthe most favourable attitude is given the highest score of 5 and that with the most unfavourableattitude is given the lowest score, say, of 1.\\n(iv)Then the total score of each respondent is obtained by adding his scores that he receivedfor separate statements.\\n(v) The next step is to array these total scores and find out those statements which have a high\\ndiscriminatory power. For this purpose, the researcher may select some part of the highestand the lowest total scores, say the top 25 per cent and the bottom 25 per cent. These twoextreme groups are interpreted to represent the most favourable and the least favourableattitudes and are used as criterion groups by which to evaluate individual statements. ThisStrongly\\nagree (1)Agree\\n(2)Undecided\\n(3)Disagree\\n(4)Strongly\\ndisagree (5)86 Research Methodology\\nway we determine which statements consistently correlate with low favourability and which\\nwith high favourability.\\n(vi)Only those statements that correlate with the total test should be retained in the finalinstrument and all others must be discarded from it.\\nAdvantages:  The Likert-type scale has several advantages. Mention may be made of the important\\nones.\\n(a) It is relatively easy to construct the Likert-type scale in comparison to Thurstone-type\\nscale because Likert-type scale can be performed without a panel of judges.\\n(b) Likert-type scale is considered more reliable because under it respondents answer each\\nstatement included in the instrument. As such it also provides more information and datathan does the Thurstone-type scale.\\n(c) Each statement, included in the Likert-type scale, is given an empirical test for discriminating\\nability and as such, unlike Thurstone-type scale, the Likert-type scale permits the use ofstatements that are not manifestly related (to have a direct relationship) to the attitudebeing studied.\\n(d) Likert-type scale can easily be used in respondent-centred and stimulus-centred studies\\ni.e., through it we can study how responses differ between people and how responsesdiffer between stimuli.\\n(e) Likert-type scale takes much less time to construct, it is frequently used by the students of\\nopinion research. Moreover, it has been reported in various research studies\\n* that there is\\nhigh degree of correlation between Likert-type scale and Thurstone-type scale.\\nLimitations:  There are several limitations of the Likert-type scale as well. One important limitation\\nis that, with this scale, we can simply examine whether respondents are more or less favourable to atopic, but we cannot tell how much more or less they are. There is no basis for belief that the fivepositions indicated on the scale are equally spaced. The interval between ‘strongly agree’ and ‘agree’,may not be equal to the interval between “agree” and “undecided”. This means that Likert scaledoes not rise to a stature more than that of an ordinal scale, whereas the designers of Thurstonescale claim the Thurstone scale to be an interval scale. One further disadvantage is that often thetotal score of an individual respondent has little clear meaning since a given total score can besecured by a variety of answer patterns. It is unlikely that the respondent can validly react to a shortstatement on a printed form in the absence of real-life qualifying situations. Moreover, there “remainsa possibility that people may answer according to what they think they should feel rather than howthey do feel.”\\n4 This particular weakness of the Likert-type scale is met by using a cumulative scale\\nwhich we shall take up later in this chapter.\\nIn spite of all the limitations, the Likert-type summated scales are regarded as the most useful in\\na situation wherein it is possible to compare the respondent’s score with a distribution of scores fromsome well defined group. They are equally useful when we are concerned with a programme of\\n*A.L. Edwards and K.C. Kenney, “A comparison of the Thurstone and Likert techniques of attitude scale construction”,\\nJournal of Applied Psychology , 30, 72–83, 1946.\\n4 John W. Best and James V. Kahn, “Research in Education”, 5 ed., Prentice-Hall of India Pvt. Ltd., New Delhi, 1986,\\np. 183.Measurement and Scaling Techniques 87\\nchange or improvement in which case we can use the scales to measure attitudes before and after\\nthe programme of change or improvement in order to assess whether our efforts have had thedesired effects. We can as well correlate scores on the scale to other measures without any concernfor the absolute value of what is favourable and what is unfavourable. All this accounts for thepopularity of Likert-type scales in social studies relating to measuring of attitudes.\\nCumulative scales: Cumulative scales or Louis Guttman’s scalogram analysis, like other scales,\\nconsist of series of statements to which a respondent expresses his agreement or disagreement. The\\nspecial feature of this type of scale is that statements in it form a cumulative series. This, in otherwords, means that the statements are related to one another in such a way that an individual, whoreplies favourably to say item No. 3, also replies favourably to items No. 2 and 1, and one who repliesfavourably to item No. 4 also replies favourably to items No. 3, 2 and 1, and so on. This being so anindividual whose attitude is at a certain point in a cumulative scale will answer favourably all theitems on one side of this point, and answer unfavourably all the items on the other side of this point.The individual’s score is worked out by counting the number of points concerning the number ofstatements he answers favourably. If one knows this total score, one can estimate as to how arespondent has answered individual statements constituting cumulative scales. The major scale ofthis type of cumulative scales is the Guttman’s scalogram. We attempt a brief description of thesame below.\\nThe technique developed by Louis Guttman is known as scalogram analysis, or at times simply\\n‘scale analysis’. Scalogram analysis refers to the procedure for determining whether a set of itemsforms a unidimensional scale. A scale is said to be unidimensional if the responses fall into a patternin which endorsement of the item reflecting the extreme position results also in endorsing all itemswhich are less extreme. Under this technique, the respondents are asked to indicate in respect ofeach item whether they agree or disagree with it, and if these items form a unidimensional scale, theresponse pattern will be as under:\\nTable 5.3\\n:Response Pattern in Scalogram Analysis\\nItem Number Respondent Score\\n432 1\\nXXX X 4\\n–XX X 3\\n––X X 2\\n––– X 1\\n––– – 0\\nX = Agree\\n– = Disagree\\nA score of 4 means that the respondent is in agreement with all the statements which is indicative\\nof the most favourable attitude. But a score of 3 would mean that the respondent is not agreeable to\\nitem 4, but he agrees with all others. In the same way one can interpret other values of the respondents’scores. This pattern reveals that the universe of content is scalable.88 Research Methodology\\nProcedure: The procedure for developing a scalogram can be outlined as under:\\n(a) The universe of content must be defined first of all. In other words, we must lay down in\\nclear terms the issue we want to deal within our study.\\n(b) The next step is to develop a number of items relating the issue and to eliminate by inspection\\nthe items that are ambiguous, irrelevant or those that happen to be too extreme items.\\n(c) The third step consists in pre-testing the items to determine whether the issue at hand is\\nscalable (The pretest, as suggested by Guttman, should include 12 or more items, while the\\nfinal scale may have only 4 to 6 items. Similarly, the number of respondents in a pretestmay be small, say 20 or 25 but final scale should involve relatively more respondents, say100 or more).\\nIn a pretest the respondents are asked to record their opinions on all selected items using\\na Likert-type 5-point scale, ranging from ‘strongly agree’ to ‘strongly disagree’. The strongestfavourable response is scored as 5, whereas the strongest unfavourable response as 1. Thetotal score can thus range, if there are 15 items in all, from 75 for most favourable to 15 forthe least favourable.\\nRespondent opinionnaires are then arrayed according to total score for analysis and\\nevaluation. If the responses of an item form a cumulative scale, its response categoryscores should decrease in an orderly fashion as indicated in the above table. Failure toshow the said decreasing pattern means that there is overlapping which shows that theitem concerned is not a good cumulative scale item i.e., the item has more than one meaning.\\nSometimes the overlapping in category responses can be reduced by combining categories.\\nAfter analysing the pretest results, a few items, say 5 items, may be chosen.\\n(d) The next step is again to total the scores for the various opinionnaires, and to rearray them\\nto reflect any shift in order, resulting from reducing the items, say, from 15 in pretest to, say,5 for the final scale. The final pretest results may be tabulated in the form of a table givenin Table 5.4.\\nTable 5.4\\n:The Final Pretest Results in a Scalogram Analysis*\\nScale type Item Errors Number of Number of\\n5 12 3 10 7 per case cases errors\\n5 (perfect) XXXXX 0 7 0\\n4 (perfect) – XXXX 0 3 0\\n   (nonscale) –X–XX 1 1 1\\n   (nonscale) –XX–X 1 2 2\\n3 (perfect) – – X X X 0 5 0\\n2 (perfect) – – – X X 0 2 0\\n1 (perfect) ––––X 0 1 0\\n   (nonscale) – – X – – 2 1 2\\n   (nonscale) – – X – – 2 1 2\\n0 (perfect) ––––– 0 2 0\\nn = 5 N = 25 e = 7\\n* (Figures in the table are arbitrary and have been used to explain the tabulation process only.)Measurement and Scaling Techniques 89\\nThe table shows that five items (numbering 5, 12, 3, 10 and 7) have been selected for the\\nfinal scale. The number of respondents is 25 whose responses to various items have been\\ntabulated along with the number of errors. Perfect scale types are those in which therespondent’s answers fit the pattern that would be reproduced by using the person’s totalscore as a guide. Non-scale types are those in which the category pattern differs from that\\nexpected from the respondent’s total score i.e., non-scale cases have deviations fromunidimensionality or errors. Whether the items (or series of statements) selected for finalscale may be regarded a perfect cumulative (or a unidimensional scale), we have to examineon the basis of the coefficient of reproducibility. Guttman has set 0.9 as the level of minimumreproducibility in order to say that the scale meets the test of unidimensionality. He hasgiven the following formula for measuring the level of reproducibility:\\nGuttman’s Coefficient of Reproducibility = 1 –  e/n(N)\\nwheree = number of errors\\nn = number of items\\n N = number of cases\\nFor the above table figures,\\nCoefficient of Reproducibility = 1 – 7/5(25) = .94\\nThis shows that items number 5, 12, 3, 10 and 7 in this order constitute the cumulative or\\nunidimensional scale, and with this we can reproduce the responses to each item, knowing\\nonly the total score of the respondent concerned.\\nScalogram, analysis, like any other scaling technique, has several advantages as well as\\nlimitations. One advantage is that it assures that only a single dimension of attitude is beingmeasured. Researcher’s subjective judgement is not allowed to creep in the developmentof scale since the scale is determined by the replies of respondents. Then, we require onlya small number of items that make such a scale easy to administer. Scalogram analysis canappropriately be used for personal, telephone or mail surveys. The main difficulty in usingthis scaling technique is that in practice perfect cumulative or unidimensional scales arevery rarely found and we have only to use its approximation testing it through coefficient ofreproducibility or examining it on the basis of some other criteria. This method is not afrequently used method for the simple reason that its development procedure is tedious andcomplex. Such scales hardly constitute a reliable basis for assessing attitudes of personstowards complex objects for predicting the behavioural responses of individuals towardssuch objects. Conceptually, this analysis is a bit more difficult in comparison to other scalingmethods.\\nFactor Scales\\n*\\nFactor scales are developed through factor analysis or on the basis of intercorrelations of itemswhich indicate that a common factor accounts for the relationships between items. Factor scales areparticularly “useful in uncovering latent attitude dimensions and approach scaling through the conceptof multiple-dimension attribute space.”\\n5 More specifically the two problems viz., how to deal\\n* A detailed study of the factor scales and particularly the statistical procedures involved in developing factor scales is\\nbeyond the scope of this book. As such only an introductory idea of factor scales is presented here.\\n5 C. William Emory, Business Research Methods, p. 264–65.90 Research Methodology\\nappropriately with the universe of content which is multi-dimensional and how to uncover underlying\\n(latent) dimensions which have not been identified, are dealt with through factor scales. An importantfactor scale based on factor analysis is Semantic Differential (S.D.) and the other one is\\nMultidimensional Scaling . We give below a brief account of these factor scales.\\nSemantic differential scale: Semantic differential scale or the S.D. scale developed by Charles\\nE. Osgood, G.J. Suci and P.H. Tannenbaum (1957), is an attempt to measure the psychologicalmeanings of an object to an individual. This scale is based on the presumption that an object can havedifferent dimensions of connotative meanings which can be located in multidimensional propertyspace, or what can be called the semantic space in the context of S.D. scale. This scaling consists ofa set of bipolar rating scales, usually of 7 points, by which one or more respondents rate one or moreconcepts on each scale item. For instance, the S.D. scale items for analysing candidates for leadershipposition may be shown as under:\\nFig. 5.4\\nCandidates for leadership position (along with the concept—the ‘ideal’ candidate) may be\\ncompared and we may score them from +3 to –3 on the basis of the above stated scales. (Theletters, E, P, A showing the relevant factor viz., evaluation, potency and activity respectively, written\\nalong the left side are not written in actual scale. Similarly the numeric values shown are also notwritten in actual scale.)\\nOsgood and others did produce a list of some adjective pairs for attitude research purposes and\\nconcluded that semantic space is multidimensional rather than unidimensional. They made sincereefforts and ultimately found that three factors, viz., evaluation, potency and activity, contributed mostto meaningful judgements by respondents. The evaluation dimension generally accounts for 1/2 and3/4 of the extractable variance and the other two factors account for the balance.\\nProcedure:  Various steps involved in developing S.D. scale are as follows:\\n(a) First of all the concepts to be studied are selected. The concepts are usually chosen by\\npersonal judgement, keeping in view the nature of the problem.( )   Successful\\n( )   Severe( )   Heavy( )   Hot( )   Progressive( )   Strong( )   Active( )   Fast()T r u e( )   SociableE\\nP\\nP\\nA\\nE\\nP\\nA\\nA\\nE\\nEUnsuccessfulLenientLightColdRegressiveWeakPassiveSlowFalseUnsociable\\n3          2          1           0         –1        –2        –3Measurement and Scaling Techniques 91\\n(b) The next step is to select the scales bearing in mind the criterion of factor composition and\\nthe criterion of scale’s relevance to the concepts being judged (it is common practice to use\\nat least three scales for each factor with the help of which an average factor score has tobe worked out). One more criterion to be kept in view is that scales should be stable acrosssubjects and concepts.\\n(c) Then a panel of judges are used to rate the various stimuli (or objects) on the various\\nselected scales and the responses of all judges would then be combined to determine thecomposite scaling.\\nTo conclude, “the S.D. has a number of specific advantages. It is an efficient and easy\\nway to secure attitudes from a large sample. These attitudes may be measured in bothdirection and intensity. The total set of responses provides a comprehensive picture of themeaning of an object, as well as a measure of the subject doing the rating. It is a standardisedtechnique that is easily repeated, but escapes many of the problems of response distortionfound with more direct methods.”\\n6\\nMultidimensional scaling: Multidimensional scaling (MDS) is relatively more complicated scaling\\ndevice, but with this sort of scaling one can scale objects, individuals or both with a minimum ofinformation. Multidimensional scaling (or MDS) can be characterized as a set of procedures forportraying perceptual or affective dimensions of substantive interest. It “provides useful methodologyfor portraying subjective judgements of diverse kinds.”\\n7 MDS is used when all the variables (whether\\nmetric or non-metric) in a study are to be analyzed simultaneously and all such variables happen to beindependent. The underlying assumption in MDS is that people (respondents) “perceive a set ofobjects as being more or less similar to one another on a number of dimensions (usually uncorrelatedwith one another) instead of only one.”\\n8 Through MDS techniques one can represent geometrically\\nthe locations and interrelationships among a set of points. In fact, these techniques attempt to locatethe points, given the information about a set of interpoint distances, in space of one or more dimensionssuch as to best summarise the information contained in the interpoint distances. The distances in thesolution space then optimally reflect the distances contained in the input data. For instance, if objects,say X and Y, are thought of by the respondent as being most similar as compared to all other possible\\npairs of objects, MDS techniques will position objects X and Y in such a way that the distance\\nbetween them in multidimensional space is shorter than that between any two other objects.\\nTwo approaches, viz., the metric approach and the non-metric approach, are usually talked about\\nin the context of MDS, while attempting to construct a space containing m points such that\\nm(m – 1)/2 interpoint distances reflect the input data. The metric approach to MDS treats the input\\ndata as interval scale data and solves applying statistical methods for the additive constant\\n* which\\n6 Ibid., p. 260.\\n7 Paul E. Green, “ Analyzing Multivariate Data ”, p. 421.\\n8 Jagdish N. Sheth, “The Multivariate Revolution in Marketing Research”, quoted in “ Marketing Research ” by Danny\\nN. Bellenger and Barnett A. Greenberg, p. 255.\\n* Additive constant refers to that constant with which one can, either by subtracting or adding, convert interval scale to\\na ratio scale. For instance, suppose we know that distances, say a—b, b—c, c—d among stimuli on a ratio scale are 7, 6 and\\n3 respectively. If one were to subtract 3 from each of these distances, they would be 4, 3 and 0 respectively. The converteddistances would be on an interval scale of measurement, but not on a ratio scale. Obviously, one can add 3 to all theconverted distances and reachieve the ratio scale of distances. Thus 3 will be taken as the additive constant in this case. Welldefined iterative approach is employed in practice for estimating appropriate additive constant.92 Research Methodology\\nminimises the dimensionality of the solution space. This approach utilises all the information in the\\ndata in obtaining a solution. The data (i.e., the metric similarities of the objects) are often obtained ona bipolar similarity scale on which pairs of objects are rated one at a time. If the data reflect exactdistances between real objects in an r-dimensional space, their solution will reproduce the set of\\ninterpoint distances. But as the true and real data are rarely available, we require random andsystematic procedures for obtaining a solution. Generally, the judged similarities among a set ofobjects are statistically transformed into distances by placing those objects in a multidimensionalspace of some dimensionality.\\nThe non-metric approach first gathers the non-metric similarities by asking respondents to rank\\norder all possible pairs that can be obtained from a set of objects. Such non-metric data is thentransformed into some arbitrary metric space and then the solution is obtained by reducing thedimensionality. In other words, this non-metric approach seeks “a representation of points in a spaceof minimum dimensionality such that the rank order of the interpoint distances in the solution spacemaximally corresponds to that of the data. This is achieved by requiring only that the distances in thesolution be monotone with the input data.”\\n9 The non-metric approach has come into prominence\\nduring the sixties with the coming into existence of high speed computers to generate metric solutionsfor ordinal input data.\\nThe significance of MDS lies in the fact that it enables the researcher to study “the perceptual\\nstructure of a set of stimuli and the cognitive processes underlying the development of this structure.Psychologists, for example, employ multidimensional scaling techniques in an effort to scalepsychophysical stimuli and to determine appropriate labels for the dimensions along which thesestimuli vary.”\\n10 The MDS techniques, infact, do away with the need in the data collection process to\\nspecify the attribute(s) along which the several brands, say of a particular product, may be comparedas ultimately the MDS analysis itself reveals such attribute(s) that presumably underlie the expressedrelative similarities among objects. Thus, MDS is an important tool in attitude measurement and thetechniques falling under MDS promise “a great advance from a series of unidimensional measurements(e.g., a distribution of intensities of feeling towards single attribute such as colour, taste or a preferenceranking with indeterminate intervals), to a perceptual mapping in multidimensional space of objects ...company images, advertisement brands, etc.”\\n11\\nIn spite of all the merits stated above, the MDS is not widely used because of the computation\\ncomplications involved under it. Many of its methods are quite laborious in terms of both the collectionof data and the subsequent analyses. However, some progress has been achieved (due to the pioneeringefforts of Paul Green and his associates) during the last few years in the use of non-metric MDS inthe context of market research problems. The techniques have been specifically applied in “findingout the perceptual dimensions, and the spacing of stimuli along these dimensions, that people, use inmaking judgements about the relative similarity of pairs of Stimuli.”\\n12 But, “in the long run, the worth\\nof MDS will be determined by the extent to which it advances the behavioral sciences.”13\\n9 Robert Ferber (ed.), Handbook of Marketing Research, p. 3–51.\\n10 Ibid., p. 3–52.\\n11 G.B. Giles, Marketing , p. 43.\\n12 Paul E. Green, Analyzing Multivariate Data , p. 421.\\n13 Jum C. Nunnally, Psychometric Theory , p. 496.Measurement and Scaling Techniques 93\\nQuestions\\n1.What is the meaning of measurement in research? What difference does it make whether we measure in\\nterms of a nominal, ordinal, interval or ratio scale? Explain giving examples.\\n2.Are you in agreement with the following statements? If so, give reasons:\\n(1) Validity is more critical to measurement than reliability.\\n(2) Stability and equivalence aspects of reliability essentially mean the same thing.\\n(3) Content validity is the most difficult type of validity to determine.\\n(4) There is no difference between concept development and concept specification.(5) Reliable measurement is necessarily a valid measurement.\\n3.Point out the possible sources of error in measurement. Describe the tests of sound measurement.\\n4.Are the following nominal, ordinal, interval or ratio data? Explain your answers.\\n(a) Temperatures measured on the Kelvin scale.\\n(b) Military ranks.\\n(c) Social security numbers.\\n(d) Number of passengers on buses from Delhi to Mumbai.\\n(e) Code numbers given to the religion of persons attempting suicide.\\n5.Discuss the relative merits and demerits of:\\n(a) Rating vs. Ranking scales.\\n(b) Summated vs. Cumulative scales.\\n(c) Scalogram analysis vs. Factor analysis.\\n6.The following table shows the results of a paired-comparison preference test of four cold drinks from a\\nsample of 200 persons:\\nName Coca Cola Limca Goldspot Thumps up\\nCoca Cola – 60\\n*105 45\\nLimca 160 – 150 70\\nGoldspot 75 40 – 65\\nThumps up 165 120 145 –\\n       * To be read as 60 persons preferred Limca over Coca Cola.\\n(a) How do these brands rank in overall preference in the given sample.\\n(b) Develop an interval scale for the four varieties of cold drinks.\\n7.(1)Narrate the procedure for developing a scalogram and illustrate the same by an example.\\n(2)Workout Guttman’s coefficient of reproducibility from the following information:\\nNumber of cases ( N) = 30\\nNumber of items ( n)  = 6\\nNumber of errors ( e) = 10\\nInterpret the meaning of coefficient you work out in this example.\\n8.Write short notes on:\\n(a) Semantic differential scale;\\n(b) Scalogram analysis;94 Research Methodology\\n(c) Likert-type scale;\\n(d) Arbitrary scales;\\n(e) Multidimensional scaling (MDS).\\n9.Describe the different methods of scale construction, pointing out the merits and demerits of each.\\n10.“Scaling describes the procedures by which numbers are assigned to various degrees of opinion, attitude\\nand other concepts.” Discuss. Also point out the bases for scale classification.Methods of Data Collection 95\\n6\\nMethods of Data Collection\\nThe task of data collection begins after a research problem has been defined and research design/\\nplan chalked out. While deciding about the method of data collection to be used for the study, theresearcher should keep in mind two types of data viz., primary and secondary. The primary data are\\nthose which are collected afresh and for the first time, and thus happen to be original in character.The secondary data, on the other hand, are those which have already been collected by someone\\nelse and which have already been passed through the statistical process. The researcher would haveto decide which sort of data he would be using (thus collecting) for his study and accordingly he willhave to select one or the other method of data collection. The methods of collecting primary andsecondary data differ since primary data are to be originally collected, while in case of secondarydata the nature of data collection work is merely that of compilation. We describe the differentmethods of data collection, with the pros and cons of each method.\\nCOLLECTION OF PRIMARY DATA\\nWe collect primary data during the course of doing experiments in an experimental research but incase we do research of the descriptive type and perform surveys, whether sample surveys or censussurveys, then we can obtain primary data either through observation or through direct communicationwith respondents in one form or another or through personal interviews.\\n* This, in other words, means\\n* An experiment refers to an investigation in which a factor or variable under test is isolated and its effect(s) measured.\\nIn an experiment the investigator measures the effects of an experiment which he conducts intentionally. Survey refers tothe method of securing information concerning a phenomena under study from all or a selected number of respondents ofthe concerned universe. In a survey, the investigator examines those phenomena which exist in the universe independent ofhis action. The difference between an experiment and a survey can be depicted as under:\\nSurveys Experiments\\ncan be studied throughdetermine\\nPossible relationships between the data and the unknowns in the universe\\nEconomic Psychological Others96 Research Methodology\\nthat there are several methods of collecting primary data, particularly in surveys and descriptive\\nresearches. Important ones are: (i) observation method, (ii) interview method, (iii) through questionnaires,\\n(iv) through schedules, and (v) other methods which include (a) warranty cards; (b) distributoraudits; (c) pantry audits; (d) consumer panels; (e) using mechanical devices; (f) through projectivetechniques; (g) depth interviews, and (h) content analysis. We briefly take up each method separately.\\nObservation Method\\nThe observation method is the most commonly used method specially in studies relating to behaviouralsciences. In a way we all observe things around us, but this sort of observation is not scientificobservation. Observation becomes a scientific tool and the method of data collection for the researcher,when it serves a formulated research purpose, is systematically planned and recorded and is subjectedto checks and controls on validity and reliability. Under the observation method, the information issought by way of investigator’s own direct observation without asking from the respondent. Forinstance, in a study relating to consumer behaviour, the investigator instead of asking the brand ofwrist watch used by the respondent, may himself look at the watch. The main advantage of thismethod is that subjective bias is eliminated, if observation is done accurately. Secondly, the informationobtained under this method relates to what is currently happening; it is not complicated by either thepast behaviour or future intentions or attitudes. Thirdly, this method is independent of respondents’willingness to respond and as such is relatively less demanding of active cooperation on the part ofrespondents as happens to be the case in the interview or the questionnaire method. This method isparticularly suitable in studies which deal with subjects (i.e., respondents) who are not capable ofgiving verbal reports of their feelings for one reason or the other\\nHowever, observation method has various limitations. Firstly, it is an expensive method. Secondly,\\nthe information provided by this method is very limited. Thirdly, sometimes unforeseen factors mayinterfere with the observational task. At times, the fact that some people are rarely accessible todirect observation creates obstacle for this method to collect data effectively.\\nWhile using this method, the researcher should keep in mind things like: What should be observed?\\nHow the observations should be recorded? Or how the accuracy of observation can be ensured? Incase the observation is characterised by a careful definition of the units to be observed, the style ofrecording the observed information, standardised conditions of observation and the selection of pertinentdata of observation, then the observation is called as structured observation. But when observation\\nis to take place without these characteristics to be thought of in advance, the same is termed as\\nunstructured observation. Structured observation is considered appropriate in descriptive studies,\\nwhereas in an exploratory study the observational procedure is most likely to be relatively unstructured.\\nWe often talk about participant and non-participant types of observation in the context of studies,\\nparticularly of social sciences. This distinction depends upon the observer’s sharing or not sharingthe life of the group he is observing. If the observer observes by making himself, more or less, amember of the group he is observing so that he can experience what the members of the groupexperience, the observation is called as the participant observation. But when the observer observes\\nas a detached emissary without any attempt on his part to experience through participation whatothers feel, the observation of this type is often termed as non-participant observation. (When the\\nobserver is observing in such a manner that his presence may be unknown to the people he isobserving, such an observation is described as disguised observation. )Methods of Data Collection 97\\nThere are several merits of the participant type of observation: (i) The researcher is enabled to\\nrecord the natural behaviour of the group. (ii) The researcher can even gather information which\\ncould not easily be obtained if he observes in a disinterested fashion. (iii) The researcher can evenverify the truth of statements made by informants in the context of a questionnaire or a schedule. Butthere are also certain demerits of this type of observation viz., the observer may lose the objectivityto the extent he participates emotionally; the problem of observation-control is not solved; and it maynarrow-down the researcher’s range of experience.\\nSometimes we talk of controlled and uncontrolled observation. If the observation takes place\\nin the natural setting, it may be termed as uncontrolled observation, but when observation takes placeaccording to definite pre-arranged plans, involving experimental procedure, the same is then termedcontrolled observation. In non-controlled observation, no attempt is made to use precision instruments.The major aim of this type of observation is to get a spontaneous picture of life and persons. It has atendency to supply naturalness and completeness of behaviour, allowing sufficient time for observingit. But in controlled observation, we use mechanical (or precision) instruments as aids to accuracyand standardisation. Such observation has a tendency to supply formalised data upon whichgeneralisations can be built with some degree of assurance. The main pitfall of non-controlledobservation is that of subjective interpretation. There is also the danger of having the feeling that weknow more about the observed phenomena than we actually do. Generally, controlled observationtakes place in various experiments that are carried out in a laboratory or under controlled conditions,whereas uncontrolled observation is resorted to in case of exploratory researches.\\nInterview Method\\nThe interview method of collecting data involves presentation of oral-verbal stimuli and reply interms of oral-verbal responses. This method can be used through personal interviews and, if possible,through telephone interviews.\\n(a) Personal interviews: Personal interview method requires a person known as the interviewer\\nasking questions generally in a face-to-face contact to the other person or persons. (At times the\\ninterviewee may also ask certain questions and the interviewer responds to these, but usually theinterviewer initiates the interview and collects the information.) This sort of interview may be in theform of direct personal investigation or it may be indirect oral investigation. In the case of directpersonal investigation the interviewer has to collect the information personally from the sourcesconcerned. He has to be on the spot and has to meet people from whom data have to be collected.This method is particularly suitable for intensive investigations. But in certain cases it may not bepossible or worthwhile to contact directly the persons concerned or on account of the extensivescope of enquiry, the direct personal investigation technique may not be used. In such cases anindirect oral examination can be conducted under which the interviewer has to cross-examine otherpersons who are supposed to have knowledge about the problem under investigation and theinformation, obtained is recorded. Most of the commissions and committees appointed by governmentto carry on investigations make use of this method.\\nThe method of collecting information through personal interviews is usually carried out in a\\nstructured way. As such we call the interviews as structured interviews. Such interviews involve\\nthe use of a set of predetermined questions and of highly standardised techniques of recording. Thus,98 Research Methodology\\nthe interviewer in a structured interview follows a rigid procedure laid down, asking questions in a\\nform and order prescribed. As against it, the unstructured interviews are characterised by a flexibility\\nof approach to questioning. Unstructured interviews do not follow a system of pre-determinedquestions and standardised techniques of recording information. In a non-structured interview, theinterviewer is allowed much greater freedom to ask, in case of need, supplementary questions or attimes he may omit certain questions if the situation so requires. He may even change the sequenceof questions. He has relatively greater freedom while recording the responses to include some aspectsand exclude others. But this sort of flexibility results in lack of comparability of one interview withanother and the analysis of unstructured responses becomes much more difficult and time-consumingthan that of the structured responses obtained in case of structured interviews. Unstructured interviewsalso demand deep knowledge and greater skill on the part of the interviewer. Unstructured interview,however, happens to be the central technique of collecting information in case of exploratory orformulative research studies. But in case of descriptive studies, we quite often use the technique ofstructured interview because of its being more economical, providing a safe basis for generalisationand requiring relatively lesser skill on the part of the interviewer.\\nWe may as well talk about focussed interview, clinical interview and the non-directive interview.\\nFocussed interview is meant to focus attention on the given experience of the respondent and its\\neffects. Under it the interviewer has the freedom to decide the manner and sequence in which thequestions would be asked and has also the freedom to explore reasons and motives. The main task ofthe interviewer in case of a focussed interview is to confine the respondent to a discussion of issueswith which he seeks conversance. Such interviews are used generally in the development ofhypotheses and constitute a major type of unstructured interviews. The clinical interview is concerned\\nwith broad underlying feelings or motivations or with the course of individual’s life experience. Themethod of eliciting information under it is generally left to the interviewer’s discretion. In case ofnon-directive interview , the interviewer’s function is simply to encourage the respondent to talk\\nabout the given topic with a bare minimum of direct questioning. The interviewer often acts as acatalyst to a comprehensive expression of the respondents’ feelings and beliefs and of the frame ofreference within which such feelings and beliefs take on personal significance.\\nDespite the variations in interview-techniques, the major advantages and weaknesses of personal\\ninterviews can be enumerated in a general way. The chief merits of the interview method are asfollows:\\n(i) More information and that too in greater depth can be obtained.\\n(ii)Interviewer by his own skill can overcome the resistance, if any, of the respondents; theinterview method can be made to yield an almost perfect sample of the general population.\\n(iii)There is greater flexibility under this method as the opportunity to restructure questions isalways there, specially in case of unstructured interviews.\\n(iv)Observation method can as well be applied to recording verbal answers to various questions.\\n(v) Personal information can as well be obtained easily under this method.\\n(vi)Samples can be controlled more effectively as there arises no difficulty of the missingreturns; non-response generally remains very low.\\n(vii)The interviewer can usually control which person(s) will answer the questions. This is notpossible in mailed questionnaire approach. If so desired, group discussions may also beheld.Methods of Data Collection 99\\n(viii)The interviewer may catch the informant off-guard and thus may secure the most spontaneous\\nreactions than would be the case if mailed questionnaire is used.\\n(ix)The language of the interview can be adopted to the ability or educational level of theperson interviewed and as such misinterpretations concerning questions can be avoided.\\n(x) The interviewer can collect supplementary information about the respondent’s personal\\ncharacteristics and environment which is often of great value in interpreting results.\\nBut there are also certain weaknesses of the interview method. Among the important weaknesses,\\nmention may be made of the following:\\n(i) It is a very expensive method, specially when large and widely spread geographical sample\\nis taken.\\n(ii)There remains the possibility of the bias of interviewer as well as that of the respondent;there also remains the headache of supervision and control of interviewers.\\n(iii)Certain types of respondents such as important officials or executives or people in highincome groups may not be easily approachable under this method and to that extent thedata may prove inadequate.\\n(iv)This method is relatively more-time-consuming, specially when the sample is large and re-calls upon the respondents are necessary.\\n(v) The presence of the interviewer on the spot may over-stimulate the respondent, sometimes\\neven to the extent that he may give imaginary information just to make the interviewinteresting.\\n(vi)Under the interview method the organisation required for selecting, training and supervisingthe field-staff is more complex with formidable problems.\\n(vii)Interviewing at times may also introduce systematic errors.\\n(viii)Effective interview presupposes proper rapport with respondents that would facilitate freeand frank responses. This is often a very difficult requirement.\\nPre-requisites and basic tenets of interviewing: For successful implementation of the interview\\nmethod, interviewers should be carefully selected, trained and briefed. They should be honest, sincere,hardworking, impartial and must possess the technical competence and necessary practical experience.Occasional field checks should be made to ensure that interviewers are neither cheating, nor deviatingfrom instructions given to them for performing their job efficiently. In addition, some provision shouldalso be made in advance so that appropriate action may be taken if some of the selected respondentsrefuse to cooperate or are not available when an interviewer calls upon them.\\nIn fact, interviewing is an art governed by certain scientific principles. Every effort should be\\nmade to create friendly atmosphere of trust and confidence, so that respondents may feel at easewhile talking to and discussing with the interviewer. The interviewer must ask questions properly andintelligently and must record the responses accurately and completely. At the same time, the interviewermust answer legitimate question(s), if any, asked by the respondent and must clear any doubt that thelatter has. The interviewers approach must be friendly, courteous, conversational and unbiased. Theinterviewer should not show surprise or disapproval of a respondent’s answer but he must keep thedirection of interview in his own hand, discouraging irrelevant conversation and must make all possibleeffort to keep the respondent on the track.100 Research Methodology\\n(b) Telephone interviews: This method of collecting information consists in contacting respondents\\non telephone itself. It is not a very widely used method, but plays important part in industrial surveys,\\nparticularly in developed regions. The chief merits of such a system are:\\n1. It is more flexible in comparison to mailing method.\\n2. It is faster than other methods i.e., a quick way of obtaining information.3. It is cheaper than personal interviewing method; here the cost per response is relatively low.\\n4. Recall is easy; callbacks are simple and economical.\\n5. There is a higher rate of response than what we have in mailing method; the non-response\\nis generally very low.\\n6. Replies can be recorded without causing embarrassment to respondents.\\n7. Interviewer can explain requirements more easily.\\n8. At times, access can be gained to respondents who otherwise cannot be contacted for one\\nreason or the other.\\n9. No field staff is required.\\n10. Representative and wider distribution of sample is possible.\\nBut this system of collecting information is not free from demerits. Some of these may be\\nhighlighted.\\n1. Little time is given to respondents for considered answers; interview period is not likely to\\nexceed five minutes in most cases.\\n2. Surveys are restricted to respondents who have telephone facilities.\\n3. Extensive geographical coverage may get restricted by cost considerations.\\n4. It is not suitable for intensive surveys where comprehensive answers are required to various\\nquestions.\\n5. Possibility of the bias of the interviewer is relatively more.\\n6. Questions have to be short and to the point; probes are difficult to handle.\\nCOLLECTION OF DATA THROUGH QUESTIONNAIRES\\nThis method of data collection is quite popular, particularly in case of big enquiries. It is being adopted\\nby private individuals, research workers, private and public organisations and even by governments.In this method a questionnaire is sent (usually by post) to the persons concerned with a request toanswer the questions and return the questionnaire. A questionnaire consists of a number of questionsprinted or typed in a definite order on a form or set of forms. The questionnaire is mailed to respondentswho are expected to read and understand the questions and write down the reply in the space meantfor the purpose in the questionnaire itself. The respondents have to answer the questions on theirown.\\nThe method of collecting data by mailing the questionnaires to respondents is most extensively\\nemployed in various economic and business surveys. The merits claimed on behalf of this method areas follows:\\n1. There is low cost even when the universe is large and is widely spread geographically.Methods of Data Collection 101\\n2. It is free from the bias of the interviewer; answers are in respondents’ own words.\\n3. Respondents have adequate time to give well thought out answers.4. Respondents, who are not easily approachable, can also be reached conveniently.\\n5 Large samples can be made use of and thus the results can be made more dependable and\\nreliable.\\nThe main demerits of this system can also be listed here:\\n1. Low rate of return of the duly filled in questionnaires; bias due to no-response is often\\nindeterminate.\\n2. It can be used only when respondents are educated and cooperating.\\n3. The control over questionnaire may be lost once it is sent.\\n4. There is inbuilt inflexibility because of the difficulty of amending the approach once\\nquestionnaires have been despatched.\\n5. There is also the possibility of ambiguous replies or omission of replies altogether to certain\\nquestions; interpretation of omissions is difficult.\\n6. It is difficult to know whether willing respondents are truly representative.7. This method is likely to be the slowest of all.\\nBefore using this method, it is always advisable to conduct ‘pilot study’ (Pilot Survey) for testing\\nthe questionnaires. In a big enquiry the significance of pilot survey is felt very much. Pilot survey is\\ninfact the replica and rehearsal of the main survey. Such a survey, being conducted by experts, bringsto the light the weaknesses (if any) of the questionnaires and also of the survey techniques. From theexperience gained in this way, improvement can be effected.\\nMain aspects of a questionnaire: Quite often questionnaire is considered as the heart of a\\nsurvey operation. Hence it should be very carefully constructed. If it is not properly set up, then thesurvey is bound to fail. This fact requires us to study the main aspects of a questionnaire viz., thegeneral form, question sequence and question formulation and wording. Researcher should note thefollowing with regard to these three main aspects of a questionnaire:\\n1. General form: So far as the general form of a questionnaire is concerned, it can either be\\nstructured or unstructured questionnaire. Structured questionnaires are those questionnaires in which\\nthere are definite, concrete and pre-determined questions. The questions are presented with exactlythe same wording and in the same order to all respondents. Resort is taken to this sort of standardisationto ensure that all respondents reply to the same set of questions. The form of the question may beeither closed (i.e., of the type ‘yes’ or ‘no’) or open (i.e., inviting free response) but should be statedin advance and not constructed during questioning. Structured questionnaires may also have fixedalternative questions in which responses of the informants are limited to the stated alternatives. Thusa highly structured questionnaire is one in which all questions and answers are specified and commentsin the respondent’s own words are held to the minimum. When these characteristics are not presentin a questionnaire, it can be termed as unstructured or non-structured questionnaire. More specifically,we can say that in an unstructured questionnaire, the interviewer is provided with a general guide onthe type of information to be obtained, but the exact question formulation is largely his own responsibilityand the replies are to be taken down in the respondent’s own words to the extent possible; in somesituations tape recorders may be used to achieve this goal.102 Research Methodology\\nStructured questionnaires are simple to administer and relatively inexpensive to analyse. The\\nprovision of alternative replies, at times, helps to understand the meaning of the question clearly. But\\nsuch questionnaires have limitations too. For instance, wide range of data and that too in respondent’sown words cannot be obtained with structured questionnaires. They are usually considered inappropriatein investigations where the aim happens to be to probe for attitudes and reasons for certain actions orfeelings. They are equally not suitable when a problem is being first explored and working hypothesessought. In such situations, unstructured questionnaires may be used effectively. Then on the basis ofthe results obtained in pretest (testing before final use) operations from the use of unstructuredquestionnaires, one can construct a structured questionnaire for use in the main study.\\n2. Question sequence: In order to make the questionnaire effective and to ensure quality to the\\nreplies received, a researcher should pay attention to the question-sequence in preparing the\\nquestionnaire. A proper sequence of questions reduces considerably the chances of individual questionsbeing misunderstood. The question-sequence must be clear and smoothly-moving, meaning therebythat the relation of one question to another should be readily apparent to the respondent, with questionsthat are easiest to answer being put in the beginning. The first few questions are particularly importantbecause they are likely to influence the attitude of the respondent and in seeking his desiredcooperation. The opening questions should be such as to arouse human interest. The following typeof questions should generally be avoided as opening questions in a questionnaire:\\n1. questions that put too great a strain on the memory or intellect of the respondent;\\n2. questions of a personal character;\\n3. questions related to personal wealth, etc.\\nFollowing the opening questions, we should have questions that are really vital to the research\\nproblem and a connecting thread should run through successive questions. Ideally, the question-\\nsequence should conform to the respondent’s way of thinking. Knowing what information is desired,the researcher can rearrange the order of the questions (this is possible in case of unstructuredquestionnaire) to fit the discussion in each particular case. But in a structured questionnaire the bestthat can be done is to determine the question-sequence with the help of a Pilot Survey which is likelyto produce good rapport with most respondents. Relatively difficult questions must be relegatedtowards the end so that even if the respondent decides not to answer such questions, considerableinformation would have already been obtained. Thus, question-sequence should usually go from thegeneral to the more specific and the researcher must always remember that the answer to a givenquestion is a function not only of the question itself, but of all previous questions as well. For instance,if one question deals with the price usually paid for coffee and the next with reason for preferringthat particular brand, the answer to this latter question may be couched largely in terms of price-differences.\\n3. Question formulation and wording: With regard to this aspect of questionnaire, the researcher\\nshould note that each question must be very clear for any sort of misunderstanding can do irreparable\\nharm to a survey. Question should also be impartial in order not to give a biased picture of the truestate of affairs. Questions should be constructed with a view to their forming a logical part of a wellthought out tabulation plan. In general, all questions should meet the following standards—(a) shouldbe easily understood; (b) should be simple i.e., should convey only one thought at a time; (c) shouldbe concrete and should conform as much as possible to the respondent’s way of thinking. (ForMethods of Data Collection 103\\ninstance, instead of asking. “How many razor blades do you use annually?” The more realistic\\nquestion would be to ask, “How many razor blades did you use last week?”\\nConcerning the form of questions, we can talk about two principal forms, viz., multiple choice\\nquestion and the open-end question. In the former the respondent selects one of the alternativepossible answers put to him, whereas in the latter he has to supply the answer in his own words. Thequestion with only two possible answers (usually ‘Yes’ or ‘No’) can be taken as a special case of themultiple choice question, or can be named as a ‘closed question.’ There are some advantages anddisadvantages of each possible form of question. Multiple choice or closed questions have theadvantages of easy handling, simple to answer, quick and relatively inexpensive to analyse. They aremost amenable to statistical analysis. Sometimes, the provision of alternative replies helps to makeclear the meaning of the question. But the main drawback of fixed alternative questions is that of“putting answers in people’s mouths” i.e., they may force a statement of opinion on an issue aboutwhich the respondent does not infact have any opinion. They are not appropriate when the issueunder consideration happens to be a complex one and also when the interest of the researcher is inthe exploration of a process. In such situations, open-ended questions which are designed to permita free response from the respondent rather than one limited to certain stated alternatives are consideredappropriate. Such questions give the respondent considerable latitude in phrasing a reply. Getting thereplies in respondent’s own words is, thus, the major advantage of open-ended questions. But oneshould not forget that, from an analytical point of view, open-ended questions are more difficult tohandle, raising problems of interpretation, comparability and interviewer bias.\\n*\\nIn practice, one rarely comes across a case when one questionnaire relies on one form of\\nquestions alone. The various forms complement each other. As such questions of different forms areincluded in one single questionnaire. For instance, multiple-choice questions constitute the basis of astructured questionnaire, particularly in a mail survey. But even there, various open-ended questionsare generally inserted to provide a more complete picture of the respondent’s feelings and attitudes.\\nResearcher must pay proper attention to the wordings of questions since reliable and meaningful\\nreturns depend on it to a large extent. Since words are likely to affect responses, they should beproperly chosen. Simple words, which are familiar to all respondents should be employed. Wordswith ambiguous meanings must be avoided. Similarly, danger words, catch-words or words withemotional connotations should be avoided. Caution must also be exercised in the use of phraseswhich reflect upon the prestige of the respondent. Question wording, in no case, should bias theanswer. In fact, question wording and formulation is an art and can only be learnt by practice.\\nEssentials of a good questionnaire: To be successful, questionnaire should be comparatively\\nshort and simple i.e., the size of the questionnaire should be kept to the minimum. Questions shouldproceed in logical sequence moving from easy to more difficult questions. Personal and intimatequestions should be left to the end. Technical terms and vague expressions capable of differentinterpretations should be avoided in a questionnaire. Questions may be dichotomous (yes or noanswers), multiple choice (alternative answers listed) or open-ended. The latter type of questions areoften difficult to analyse and hence should be avoided in a questionnaire to the extent possible. Thereshould be some control questions in the questionnaire which indicate the reliability of the respondent.For instance, a question designed to determine the consumption of particular material may be asked\\n* Interviewer bias refers to the extent to which an answer is altered in meaning by some action or attitude on the part of\\nthe interviewer.104 Research Methodology\\nfirst in terms of financial expenditure and later in terms of weight. The control questions, thus,\\nintroduce a cross-check to see whether the information collected is correct or not. Questions affectingthe sentiments of respondents should be avoided. Adequate space for answers should be provided inthe questionnaire to help editing and tabulation. There should always be provision for indications ofuncertainty, e.g., “do not know,” “no preference” and so on. Brief directions with regard to filling upthe questionnaire should invariably be given in the questionnaire itself. Finally, the physical appearanceof the questionnaire affects the cooperation the researcher receives from the recipients and as suchan attractive looking questionnaire, particularly in mail surveys, is a plus point for enlisting cooperation.The quality of the paper, along with its colour, must be good so that it may attract the attention ofrecipients.\\nCOLLECTION OF DATA THROUGH SCHEDULES\\nThis method of data collection is very much like the collection of data through questionnaire, withlittle difference which lies in the fact that schedules (proforma containing a set of questions) arebeing filled in by the enumerators who are specially appointed for the purpose. These enumeratorsalong with schedules, go to respondents, put to them the questions from the proforma in the order thequestions are listed and record the replies in the space meant for the same in the proforma. In certainsituations, schedules may be handed over to respondents and enumerators may help them in recordingtheir answers to various questions in the said schedules. Enumerators explain the aims and objects ofthe investigation and also remove the difficulties which any respondent may feel in understanding theimplications of a particular question or the definition or concept of difficult terms.\\nThis method requires the selection of enumerators for filling up schedules or assisting respondents\\nto fill up schedules and as such enumerators should be very carefully selected. The enumeratorsshould be trained to perform their job well and the nature and scope of the investigation should beexplained to them thoroughly so that they may well understand the implications of different questionsput in the schedule. Enumerators should be intelligent and must possess the capacity of cross-examination in order to find out the truth. Above all, they should be honest, sincere, hardworking andshould have patience and perseverance.\\nThis method of data collection is very useful in extensive enquiries and can lead to fairly reliable\\nresults. It is, however, very expensive and is usually adopted in investigations conducted by governmentalagencies or by some big organisations. Population census all over the world is conducted through thismethod.\\nDIFFERENCE BETWEEN QUESTIONNAIRES AND SCHEDULES\\nBoth questionnaire and schedule are popularly used methods of collecting data in research surveys.There is much resemblance in the nature of these two methods and this fact has made many peopleto remark that from a practical point of view, the two methods can be taken to be the same. But fromthe technical point of view there is difference between the two. The important points of differenceare as under:\\n1. The questionnaire is generally sent through mail to informants to be answered as specified\\nin a covering letter, but otherwise without further assistance from the sender. The scheduleMethods of Data Collection 105\\nis generally filled out by the research worker or the enumerator, who can interpret questions\\nwhen necessary.\\n2. To collect data through questionnaire is relatively cheap and economical since we have to\\nspend money only in preparing the questionnaire and in mailing the same to respondents.Here no field staff required. To collect data through schedules is relatively more expensivesince considerable amount of money has to be spent in appointing enumerators and inimporting training to them. Money is also spent in preparing schedules.\\n3. Non-response is usually high in case of questionnaire as many people do not respond and\\nmany return the questionnaire without answering all questions. Bias due to non-responseoften remains indeterminate. As against this, non-response is generally very low in case ofschedules because these are filled by enumerators who are able to get answers to allquestions. But there remains the danger of interviewer bias and cheating.\\n4. In case of questionnaire, it is not always clear as to who replies, but in case of schedule the\\nidentity of respondent is known.\\n5. The questionnaire method is likely to be very slow since many respondents do not return\\nthe questionnaire in time despite several reminders, but in case of schedules the informationis collected well in time as they are filled in by enumerators.\\n6. Personal contact is generally not possible in case of the questionnaire method as\\nquestionnaires are sent to respondents by post who also in turn return the same by post.But in case of schedules direct personal contact is established with respondents.\\n7. Questionnaire method can be used only when respondents are literate and cooperative, but\\nin case of schedules the information can be gathered even when the respondents happen tobe illiterate.\\n8. Wider and more representative distribution of sample is possible under the questionnaire\\nmethod, but in respect of schedules there usually remains the difficulty in sendingenumerators over a relatively wider area.\\n9. Risk of collecting incomplete and wrong information is relatively more under the questionnaire\\nmethod, particularly when people are unable to understand questions properly. But in caseof schedules, the information collected is generally complete and accurate as enumeratorscan remove the difficulties, if any, faced by respondents in correctly understanding thequestions. As a result, the information collected through schedules is relatively more accuratethan that obtained through questionnaires.\\n10. The success of questionnaire method lies more on the quality of the questionnaire itself, but\\nin the case of schedules much depends upon the honesty and competence of enumerators.\\n11. In order to attract the attention of respondents, the physical appearance of questionnaire\\nmust be quite attractive, but this may not be so in case of schedules as they are to be filledin by enumerators and not by respondents.\\n12. Along with schedules, observation method can also be used but such a thing is not possible\\nwhile collecting data through questionnaires.106 Research Methodology\\nSOME OTHER METHODS OF DATA COLLECTION\\nLet us consider some other methods of data collection, particularly used by big business houses in\\nmodern times.\\n1. Warranty cards: Warranty cards are usually postal sized cards which are used by dealers of\\nconsumer durables to collect information regarding their products. The information sought is printed\\nin the form of questions on the ‘warranty cards’ which is placed inside the package along with theproduct with a request to the consumer to fill in the card and post it back to the dealer.\\n2. Distributor or store audits: Distributor or store audits are performed by distributors as well as\\nmanufactures through their salesmen at regular intervals. Distributors get the retail stores audited\\nthrough salesmen and use such information to estimate market size, market share, seasonal purchasingpattern and so on. The data are obtained in such audits not by questioning but by observation. Forinstance, in case of a grocery store audit, a sample of stores is visited periodically and data arerecorded on inventories on hand either by observation or copying from store records. Store audits areinvariably panel operations, for the derivation of sales estimates and compilation of sales trends bystores are their principal ‘ raison detre ’. The principal advantage of this method is that it offers the\\nmost efficient way of evaluating the effect on sales of variations of different techniques of in-storepromotion.\\n3. Pantry audits: Pantry audit technique is used to estimate consumption of the basket of goods at\\nthe consumer level. In this type of audit, the investigator collects an inventory of types, quantities and\\nprices of commodities consumed. Thus in pantry audit data are recorded from the examination ofconsumer’s pantry. The usual objective in a pantry audit is to find out what types of consumers buycertain products and certain brands, the assumption being that the contents of the pantry accuratelyportray consumer’s preferences. Quite often, pantry audits are supplemented by direct questioningrelating to reasons and circumstances under which particular products were purchased in an attemptto relate these factors to purchasing habits. A pantry audit may or may not be set up as a paneloperation, since a single visit is often considered sufficient to yield an accurate picture of consumers’preferences. An important limitation of pantry audit approach is that, at times, it may not be possibleto identify consumers’ preferences from the audit data alone, particularly when promotion devicesproduce a marked rise in sales.\\n4. Consumer panels: An extension of the pantry audit approach on a regular basis is known as\\n‘consumer panel’, where a set of consumers are arranged to come to an understanding to maintain\\ndetailed daily records of their consumption and the same is made available to investigator on demands.In other words, a consumer panel is essentially a sample of consumers who are interviewed repeatedlyover a period of time. Mostly consume panels are of two types viz., the transitory consumer paneland the continuing consumer panel. A transitory consumer panel is set up to measure the effect of\\na particular phenomenon. Usually such a panel is conducted on a before-and-after-basis. Initial interviews\\nare conducted before the phenomenon takes place to record the attitude of the consumer. A secondset of interviews is carried out after the phenomenon has taken place to find out the consequentchanges that might have occurred in the consumer’s attitude. It is a favourite tool of advertising andof social research. A continuing consumer panel is often set up for an indefinite period with a view\\nto collect data on a particular aspect of consumer behaviour over time, generally at periodic intervalsor may be meant to serve as a general purpose panel for researchers on a variety of subjects. Suchpanels have been used in the area of consumer expenditure, public opinion and radio and TV listenershipMethods of Data Collection 107\\namong others. Most of these panels operate by mail. The representativeness of the panel relative to\\nthe population and the effect of panel membership on the information obtained after the two majorproblems associated with the use of this method of data collection.\\n5. Use of mechanical devices: The use of mechanical devices has been widely made to collect\\ninformation by way of indirect means. Eye camera, Pupilometric camera, Psychogalvanometer,\\nMotion picture camera and Audiometer are the principal devices so far developed and commonlyused by modern big business houses, mostly in the developed world for the purpose of collecting therequired information.\\nEye cameras are designed to record the focus of eyes of a respondent on a specific portion of a\\nsketch or diagram or written material. Such an information is useful in designing advertising material.Pupilometric cameras record dilation of the pupil as a result of a visual stimulus. The extent ofdilation shows the degree of interest aroused by the stimulus. Psychogalvanometer is used for measuringthe extent of body excitement as a result of the visual stimulus. Motion picture cameras can be usedto record movement of body of a buyer while deciding to buy a consumer good from a shop or bigstore. Influence of packaging or the information given on the label would stimulate a buyer to performcertain physical movements which can easily be recorded by a hidden motion picture camera in theshop’s four walls. Audiometers are used by some TV concerns to find out the type of programmesas well as stations preferred by people. A device is fitted in the television instrument itself to recordthese changes. Such data may be used to find out the market share of competing television stations.\\n6. Projective techniques: Projective techniques (or what are sometimes called as indirect\\ninterviewing techniques) for the collection of data have been developed by psychologists to use\\nprojections of respondents for inferring about underlying motives, urges, or intentions which are such\\nthat the respondent either resists to reveal them or is unable to figure out himself. In projectivetechniques the respondent in supplying information tends unconsciously to project his own attitudesor feelings on the subject under study. Projective techniques play an important role in motivationalresearches or in attitude surveys.\\nThe use of these techniques requires intensive specialised training. In such techniques, the\\nindividual’s responses to the stimulus-situation are not taken at their face value. The stimuli mayarouse many different kinds of reactions. The nature of the stimuli and the way in which they arepresented under these techniques do not clearly indicate the way in which the response is to beinterpreted. The stimulus may be a photograph, a picture, an inkblot and so on. Responses to thesestimuli are interpreted as indicating the individual’s own view, his personality structure, his needs,tensions, etc. in the context of some pre-established psychological conceptualisation of what theindividual’s responses to the stimulus mean.\\nWe may now briefly deal with the important projective techniques.\\n(i) Word association tests: These tests are used to extract information regarding such words which\\nhave maximum association. In this sort of test the respondent is asked to mention the first word thatcomes to mind, ostensibly without thinking, as the interviewer reads out each word from a list. If theinterviewer says cold, the respondent may say hot and the like ones. The general technique is to use\\na list of as many as 50 to 100 words. Analysis of the matching words supplied by the respondentsindicates whether the given word should be used for the contemplated purpose. The same idea isexploited in marketing research to find out the quality that is mostly associated to a brand of aproduct. A number of qualities of a product may be listed and informants may be asked to write108 Research Methodology\\nbrand names possessing one or more of these. This technique is quick and easy to use, but yields\\nreliable results when applied to words that are widely known and which possess essentially one typeof meaning. This technique is frequently used in advertising research.\\n(ii) Sentence completion tests: These tests happen to be an extension of the technique of word\\nassociation tests. Under this, informant may be asked to complete a sentence (such as: persons who\\nwear Khadi are...) to find association of Khadi clothes with certain personality characteristics. Severalsentences of this type might be put to the informant on the same subject. Analysis of replies from thesame informant reveals his attitude toward that subject, and the combination of these attitudes of allthe sample members is then taken to reflect the views of the population. This technique permits thetesting not only of words (as in case of word association tests), but of ideas as well and thus, helps indeveloping hypotheses and in the construction of questionnaires. This technique is also quick andeasy to use, but it often leads to analytical problems, particularly when the response happens to bemultidimensional.\\n(iii) Story completion tests: Such tests are a step further wherein the researcher may contrive\\nstories instead of sentences and ask the informants to complete them. The respondent is given just\\nenough of story to focus his attention on a given subject and he is asked to supply a conclusion to thestory.\\n(iv) Verbal projection tests: These are the tests wherein the respondent is asked to comment on or\\nto explain what other people do. For example, why do people smoke? Answers may reveal the\\nrespondent’s own motivations.\\n(v) Pictorial techniques: There are several pictorial techniques. The important ones are as follows:\\n(a)Thematic apperception test (T.A.T.): The TAT consists of a set of pictures (some of the\\npictures deal with the ordinary day-to-day events while others may be ambiguous pictures\\nof unusual situations) that are shown to respondents who are asked to describe what theythink the pictures represent. The replies of respondents constitute the basis for the investigatorto draw inferences about their personality structure, attitudes, etc.\\n(b)Rosenzweig test: This test uses a cartoon format wherein we have a series of cartoons\\nwith words inserted in ‘balloons’ above. The respondent is asked to put his own words inan empty balloon space provided for the purpose in the picture. From what the respondentswrite in this fashion, the study of their attitudes can be made.\\n(c)Rorschach test: This test consists of ten cards having prints of inkblots. The design happens\\nto be symmetrical but meaningless. The respondents are asked to describe what theyperceive in such symmetrical inkblots and the responses are interpreted on the basis ofsome pre-determined psychological framework. This test is frequently used but the problemof validity still remains a major problem of this test.\\n(d)Holtzman Inkblot Test (HIT): This test from W.H. Holtzman is a modification of the\\nRorschach Test explained above. This test consists of 45 inkblot cards (and not 10 inkblotsas we find in case of Rorschach Test) which are based on colour, movement, shading andother factors involved in inkblot perception. Only one response per card is obtained fromthe subject (or the respondent) and the responses of a subject are interpreted at three levels of\\nform appropriateness. Form responses are interpreted for knowing the accuracy (F) orinaccuracy (F–) of respondent’s percepts; shading and colour for ascertaining his affectionaland emotional needs; and movement responses for assessing the dynamic aspects of his life.Methods of Data Collection 109\\nHoltzman Inkblot Test or H.I.T. has several special features or advantages. For example, it\\nelicits relatively constant number of responses per respondent. Secondly, it facilitates studyingthe responses of a respondent to different cards in the light of norms of each card instead oflumping them together. Thirdly, it elicits much more information from the respondent then ispossible with merely 10 cards in Rorschach test; the 45 cards used in this test provide avariety of stimuli to the respondent and as such the range of responses elicited by the test iscomparatively wider.\\nThere are some limitations of this test as well. One difficulty that remains in using this test is\\nthat most of the respondents do not know the determinants of their perceptions, but for theresearcher, who has to interpret the protocols of a subject and understand his personality (orattitude) through them, knowing the determinant of each of his response is a must. This factemphasises that the test must be administered individually and a post-test inquiry must as wellbe conducted for knowing the nature and sources of responses and this limits the scope ofHIT as a group test of personality. Not only this, “the usefulness of HIT for purposes ofpersonal selection, vocational guidance, etc. is still to be established.”\\n1\\nIn view of these limitations, some people have made certain changes in applying this test. Forinstance, Fisher and Cleveland in their approach for obtaining Barrier score of an individual’spersonality have developed a series of multiple choice items for 40 of HIT cards. Each ofthese cards is presented to the subject along with three acceptable choices [such as ‘Knightin armour’ (Barrier response), ‘X-Ray’ (Penetrating response) and ‘Flower’ (Neutralresponse)]. Subject taking the test is to check the choice he likes most, make a different markagainst the one he likes least and leave the third choice blank. The number of barrier responseschecked by him determines his barrier score on the test.\\n(e)Tomkins-Horn picture arrangement test: This test is designed for group administration.\\nIt consists of twenty-five plates, each containing three sketches that may be arranged indifferent ways to portray sequence of events. The respondent is asked to arrange them ina sequence which he considers as reasonable. The responses are interpreted as providingevidence confirming certain norms, respondent’s attitudes, etc.\\n(vi) Play techniques: Under play techniques subjects are asked to improvise or act out a situation\\nin which they have been assigned various roles. The researcher may observe such traits as hostility,dominance, sympathy, prejudice or the absence of such traits. These techniques have been used forknowing the attitudes of younger ones through manipulation of dolls. Dolls representing differentracial groups are usually given to children who are allowed to play with them freely. The manner inwhich children organise dolls would indicate their attitude towards the class of persons representedby dolls. This is also known as doll-play test , and is used frequently in studies pertaining to sociology.\\nThe choice of colour, form, words, the sense of orderliness and other reactions may provide opportunitiesto infer deep-seated feelings.\\n(vii) Quizzes, tests and examinations: This is also a technique of extracting information regarding\\nspecific ability of candidates indirectly. In this procedure both long and short questions are framed to\\ntest through them the memorising and analytical ability of candidates.\\n(viii) Sociometry: Sociometry is a technique for describing the social relationships among individuals\\nin a group. In an indirect way, sociometry attempts to describe attractions or repulsions between\\n1 S.L. Dass, “ Personality Assessment Through Projective Movie Pictures ”, p. 17.110 Research Methodology\\nindividuals by asking them to indicate whom they would choose or reject in various situations. Thus,\\nsociometry is a new technique of studying the underlying motives of respondents. “Under this anattempt is made to trace the flow of information amongst groups and then examine the ways in whichnew ideas are diffused. Sociograms are constructed to identify leaders and followers.”\\n2 Sociograms\\nare charts that depict the sociometric choices. There are many versions of the sociogram pattern andthe reader is suggested to consult specialised references on sociometry for the purpose. This approachhas been applied to the diffusion of ideas on drugs amongst medical practitioners.\\n7. Depth interviews: Depth interviews are those interviews that are designed to discover underlying\\nmotives and desires and are often used in motivational research. Such interviews are held to explore\\nneeds, desires and feelings of respondents. In other words, they aim to elicit unconscious as alsoother types of material relating especially to personality dynamics and motivations. As such, depthinterviews require great skill on the part of the interviewer and at the same time involve considerabletime. Unless the researcher has specialised training, depth interviewing should not be attempted.\\nDepth interview may be projective in nature or it may be a non-projective interview. The difference\\nlies in the nature of the questions asked. Indirect questions on seemingly irrelevant subjects provideinformation that can be related to the informant’s behaviour or attitude towards the subject understudy. Thus, for instance, the informant may be asked on his frequency of air travel and he mightagain be asked at a later stage to narrate his opinion concerning the feelings of relatives of someother man who gets killed in an airplane accident. Reluctance to fly can then be related to replies toquestions of the latter nature. If the depth interview involves questions of such type, the same may betreated as projective depth interview. But in order to be useful, depth interviews do not necessarilyhave to be projective in nature; even non-projective depth interviews can reveal important aspects ofpsycho-social situation for understanding the attitudes of people.\\n8. Content-analysis: Content-analysis consists of analysing the contents of documentary materials\\nsuch as books, magazines, newspapers and the contents of all other verbal materials which can beeither spoken or printed. Content-analysis prior to 1940’s was mostly quantitative analysis ofdocumentary materials concerning certain characteristics that can be identified and counted. Butsince 1950’s content-analysis is mostly qualitative analysis concerning the general import or messageof the existing documents. “The difference is somewhat like that between a casual interview anddepth interviewing.”\\n3 Bernard Berelson’s name is often associated with. the latter type of content-\\nanalysis. “Content-analysis is measurement through proportion…. Content analysis measurespervasiveness and that is sometimes an index of the intensity of the force.”\\n4\\nThe analysis of content is a central activity whenever one is concerned with the study of the\\nnature of the verbal materials. A review of research in any area, for instance, involves the analysisof the contents of research articles that have been published. The analysis may be at a relativelysimple level or may be a subtle one. It is at a simple level when we pursue it on the basis of certaincharacteristics of the document or verbal materials that can be identified and counted (such as on thebasis of major scientific concepts in a book). It is at a subtle level when researcher makes a study ofthe attitude, say of the press towards education by feature writers.\\n2 G.B. Giles, Marketing, p. 40–41.\\n3 Carter V. Good and Douglas E. Scates, Methods of Research, p. 670.\\n4 Ibid., p. 670.Methods of Data Collection 111\\nCOLLECTION OF SECONDARY DATA\\nSecondary data means data that are already available i.e., they refer to the data which have already\\nbeen collected and analysed by someone else. When the researcher utilises secondary data, then hehas to look into various sources from where he can obtain them. In this case he is certainly notconfronted with the problems that are usually associated with the collection of original data. Secondarydata may either be published data or unpublished data. Usually published data are available in: (a)various publications of the central, state are local governments; (b) various publications of foreigngovernments or of international bodies and their subsidiary organisations; (c) technical and tradejournals; (d) books, magazines and newspapers; (e) reports and publications of various associationsconnected with business and industry, banks, stock exchanges, etc.; (f) reports prepared by researchscholars, universities, economists, etc. in different fields; and (g) public records and statistics, historicaldocuments, and other sources of published information. The sources of unpublished data are many;they may be found in diaries, letters, unpublished biographies and autobiographies and also may beavailable with scholars and research workers, trade associations, labour bureaus and other public/private individuals and organisations.\\nResearcher must be very careful in using secondary data. He must make a minute scrutiny\\nbecause it is just possible that the secondary data may be unsuitable or may be inadequate in thecontext of the problem which the researcher wants to study. In this connection Dr. A.L. Bowleyvery aptly observes that it is never safe to take published statistics at their face value without knowingtheir meaning and limitations and it is always necessary to criticise arguments that can be based on\\nthem.\\nBy way of caution, the researcher, before using secondary data, must see that they possess\\nfollowing characteristics:\\n1. Reliability of data: The reliability can be tested by finding out such things about the said data:\\n(a)Who collected the data? (b) What were the sources of data? (c) Were they collected by using\\nproper methods (d) At what time were they collected?(e) Was there any bias of the compiler?(t) What level of accuracy was desired? Was it achieved ?\\n2. Suitability of data: The data that are suitable for one enquiry may not necessarily be found\\nsuitable in another enquiry. Hence, if the available data are found to be unsuitable, they should not be\\nused by the researcher. In this context, the researcher must very carefully scrutinise the definition ofvarious terms and units of collection used at the time of collecting the data from the primary sourceoriginally. Similarly, the object, scope and nature of the original enquiry must also be studied. If theresearcher finds differences in these, the data will remain unsuitable for the present enquiry andshould not be used.\\n3. Adequacy of data: If the level of accuracy achieved in data is found inadequate for the purpose\\nof the present enquiry, they will be considered as inadequate and should not be used by the researcher.\\nThe data will also be considered inadequate, if they are related to an area which may be eithernarrower or wider than the area of the present enquiry.\\nFrom all this we can say that it is very risky to use the already available data. The already\\navailable data should be used by the researcher only when he finds them reliable, suitable andadequate. But he should not blindly discard the use of such data if they are readily available fromauthentic sources and are also suitable and adequate for in that case it will not be economical to112 Research Methodology\\nspend time and energy in field surveys for collecting information. At times, there may be wealth of\\nusable information in the already available data which must be used by an intelligent researcher butwith due precaution.\\nSELECTION OF APPROPRIATE METHOD FOR DATA COLLECTION\\nThus, there are various methods of data collection. As such the researcher must judiciously selectthe method/methods for his own study, keeping in view the following factors:\\n1. Nature, scope and object of enquiry: This constitutes the most important factor affecting the\\nchoice of a particular method. The method selected should be such that it suits the type of enquiry\\nthat is to be conducted by the researcher. This factor is also important in deciding whether the dataalready available (secondary data) are to be used or the data not yet available (primary data) are tobe collected.\\n2. Availability of funds: Availability of funds for the research project determines to a large extent\\nthe method to be used for the collection of data. When funds at the disposal of the researcher are\\nvery limited, he will have to select a comparatively cheaper method which may not be as efficientand effective as some other costly method. Finance, in fact, is a big constraint in practice and theresearcher has to act within this limitation.\\n3. Time factor: Availability of time has also to be taken into account in deciding a particular method\\nof data collection. Some methods take relatively more time, whereas with others the data can be\\ncollected in a comparatively shorter duration. The time at the disposal of the researcher, thus, affectsthe selection of the method by which the data are to be collected.\\n4. Precision required: Precision required is yet another important factor to be considered at the\\ntime of selecting the method of collection of data.\\nBut one must always remember that each method of data collection has its uses and none is\\nsuperior in all situations. For instance, telephone interview method may be considered appropriate\\n(assuming telephone population) if funds are restricted, time is also restricted and the data is to becollected in respect of few items with or without a certain degree of precision. In case funds permitand more information is desired, personal interview method may be said to be relatively better. Incase time is ample, funds are limited and much information is to be gathered with no precision, thenmail-questionnaire method can be regarded more reasonable. When funds are ample, time is alsoample and much information with no precision is to be collected, then either personal interview or themail-questionnaire or the joint use of these two methods may be taken as an appropriate method ofcollecting data. Where a wide geographic area is to be covered, the use of mail-questionnairessupplemented by personal interviews will yield more reliable results per rupee spent than eithermethod alone. The secondary data may be used in case the researcher finds them reliable, adequateand appropriate for his research. While studying motivating influences in market researches or studyingpeople’s attitudes in psychological/social surveys, we can resort to the use of one or more of theprojective techniques stated earlier. Such techniques are of immense value in case the reason isobtainable from the respondent who knows the reason but does not want to admit it or the reasonrelates to some underlying psychological attitude and the respondent is not aware of it. But when therespondent knows the reason and can tell the same if asked, than a non-projective questionnaire,Methods of Data Collection 113\\nusing direct questions, may yield satisfactory results even in case of attitude surveys. Since projective\\ntechniques are as yet in an early stage of development and with the validity of many of them remainingan open question, it is usually considered better to rely on the straight forward statistical methodswith only supplementary use of projective techniques. Nevertheless, in pre-testing and in searchingfor hypotheses they can be highly valuable.\\nThus, the most desirable approach with regard to the selection of the method depends on the\\nnature of the particular problem and on the time and resources (money and personnel) availablealong with the desired degree of accuracy. But, over and above all this, much depends upon theability and experience of the researcher. Dr. A.L. Bowley’s remark in this context is very appropriatewhen he says that “in collection of statistical data common sense is the chief requisite and experiencethe chief teacher.”\\nCASE STUDY METHOD\\nMeaning : The case study method is a very popular form of qualitative analysis and involves a\\ncareful and complete observation of a social unit, be that unit a person, a family, an institution, acultural group or even the entire community. It is a method of study in depth rather than breadth. Thecase study places more emphasis on the full analysis of a limited number of events or conditions andtheir interrelations. The case study deals with the processes that take place and their interrelationship.Thus, case study is essentially an intensive investigation of the particular unit under consideration.The object of the case study method is to locate the factors that account for the behaviour-patternsof the given unit as an integrated totality.\\nAccording to H. Odum, “The case study method is a technique by which individual factor whether\\nit be an institution or just an episode in the life of an individual or a group is analysed in its relationshipto any other in the group.”\\n5 Thus, a fairly exhaustive study of a person (as to what he does and has\\ndone, what he thinks he does and had done and what he expects to do and says he ought to do) orgroup is called a life or case history. Burgess has used the words “the social microscope” for thecase study method.”\\n6 Pauline V. Young describes case study as “a comprehensive study of a social\\nunit be that unit a person, a group, a social institution, a district or a community.”7 In brief, we can say\\nthat case study method is a form of qualitative analysis where in careful and complete observation ofan individual or a situation or an institution is done; efforts are made to study each and every aspectof the concerning unit in minute details and then from case data generalisations and inferences aredrawn.\\nCharacteristics: The important characteristics of the case study method are as under:\\n1. Under this method the researcher can take one single social unit or more of such units for\\nhis study purpose; he may even take a situation to study the same comprehensively.\\n2. Here the selected unit is studied intensively i.e., it is studied in minute details. Generally, the\\nstudy extends over a long period of time to ascertain the natural history of the unit so as to\\nobtain enough information for drawing correct inferences.\\n5 H. Odum, An Introduction to Social Research, p. 229.\\n6 Burgess, Research Methods in Sociology, p. 26 in Georges Gurvitch and W.E. Moore (Eds.) Twentieth Century\\nSociology .\\n7 Pauline V. Young, Scientific Social Surveys and Research, p. 247.114 Research Methodology\\n3. In the context of this method we make complete study of the social unit covering all facets.\\nThrough this method we try to understand the complex of factors that are operative within\\na social unit as an integrated totality.\\n4 Under this method the approach happens to be qualitative and not quantitative. Mere\\nquantitative information is not collected. Every possible effort is made to collect informationconcerning all aspects of life. As such, case study deepens our perception and gives us aclear insight into life. For instance, under this method we not only study how many crimesa man has done but shall peep into the factors that forced him to commit crimes when weare making a case study of a man as a criminal. The objective of the study may be tosuggest ways to reform the criminal.\\n5. In respect of the case study method an effort is made to know the mutual inter-relationship\\nof causal factors.\\n6. Under case study method the behaviour pattern of the concerning unit is studied directly\\nand not by an indirect and abstract approach.\\n7. Case study method results in fruitful hypotheses along with the data which may be helpful\\nin testing them, and thus it enables the generalised knowledge to get richer and richer. In itsabsence, generalised social science may get handicapped.\\nEvolution and scope: The case study method is a widely used systematic field research technique\\nin sociology these days. The credit for introducing this method to the field of social investigation goesto Frederic Le Play who used it as a hand-maiden to statistics in his studies of family budgets.Herbert Spencer was the first to use case material in his comparative study of different cultures. Dr.William Healy resorted to this method in his study of juvenile delinquency, and considered it as abetter method over and above the mere use of statistical data. Similarly, anthropologists, historians,novelists and dramatists have used this method concerning problems pertaining to their areas ofinterests. Even management experts use case study methods for getting clues to several managementproblems. In brief, case study method is being used in several disciplines. Not only this, its use isincreasing day by day.\\nAssumptions: The case study method is based on several assumptions. The important assumptions\\nmay be listed as follows:\\n(i) The assumption of uniformity in the basic human nature in spite of the fact that human\\nbehaviour may vary according to situations.\\n(ii)The assumption of studying the natural history of the unit concerned.\\n(iii)The assumption of comprehensive study of the unit concerned.\\nMajor phases involved: Major phases involved in case study are as follows:\\n(i) Recognition and determination of the status of the phenomenon to be investigated or the\\nunit of attention.\\n(ii)Collection of data, examination and history of the given phenomenon.\\n(iii)Diagnosis and identification of causal factors as a basis for remedial or developmentaltreatment.\\n(iv)Application of remedial measures i.e., treatment and therapy (this phase is often characterisedas case work).Methods of Data Collection 115\\n(v) Follow-up programme to determine effectiveness of the treatment applied.\\nAdvantages: There are several advantages of the case study method that follow from the various\\ncharacteristics outlined above. Mention may be made here of the important advantages.\\n(i) Being an exhaustive study of a social unit, the case study method enables us to understand\\nfully the behaviour pattern of the concerned unit. In the words of Charles Horton Cooley,\\n“case study deepens our perception and gives us a clearer insight into life…. It gets atbehaviour directly and not by an indirect and abstract approach.”\\n(ii)Through case study a researcher can obtain a real and enlightened record of personalexperiences which would reveal man’s inner strivings, tensions and motivations that drivehim to action along with the forces that direct him to adopt a certain pattern of behaviour.\\n(iii)This method enables the researcher to trace out the natural history of the social unit and itsrelationship with the social factors and the forces involved in its surrounding environment.\\n(iv) It helps in formulating relevant hypotheses along with the data which may be helpful in\\ntesting them. Case studies, thus, enable the generalised knowledge to get richer and richer.\\n(v) The method facilitates intensive study of social units which is generally not possible if we\\nuse either the observation method or the method of collecting information through schedules.This is the reason why case study method is being frequently used, particularly in socialresearches.\\n(vi)Information collected under the case study method helps a lot to the researcher in the task\\nof constructing the appropriate questionnaire or schedule for the said task requires thorough\\nknowledge of the concerning universe.\\n(vii)The researcher can use one or more of the several research methods under the case studymethod depending upon the prevalent circumstances. In other words, the use of differentmethods such as depth interviews, questionnaires, documents, study reports of individuals,letters, and the like is possible under case study method.\\n(viii)Case study method has proved beneficial in determining the nature of units to be studiedalong with the nature of the universe. This is the reason why at times the case studymethod is alternatively known as “mode of organising data”.\\n(ix)This method is a means to well understand the past of a social unit because of its emphasisof historical analysis. Besides, it is also a technique to suggest measures for improvementin the context of the present environment of the concerned social units.\\n(x) Case studies constitute the perfect type of sociological material as they represent a real\\nrecord of personal experiences which very often escape the attention of most of the skilledresearchers using other techniques.\\n(xi)Case study method enhances the experience of the researcher and this in turn increaseshis analysing ability and skill.\\n(xii)This method makes possible the study of social changes. On account of the minute study ofthe different facets of a social unit, the researcher can well understand the social changethen and now. This also facilitates the drawing of inferences and helps in maintaining thecontinuity of the research process. In fact, it may be considered the gateway to and at thesame time the final destination of abstract knowledge.116 Research Methodology\\n(xiii)Case study techniques are indispensable for therapeutic and administrative purposes. They\\nare also of immense value in taking decisions regarding several management problems.Case data are quite useful for diagnosis, therapy and other practical case problems.\\nLimitations: Important limitations of the case study method may as well be highlighted.\\n(i) Case situations are seldom comparable and as such the information gathered in case studies\\nis often not comparable. Since the subject under case study tells history in his own words,logical concepts and units of scientific classification have to be read into it or out of it by theinvestigator.\\n(ii)Read Bain does not consider the case data as significant scientific data since they do notprovide knowledge of the “impersonal, universal, non-ethical, non-practical, repetitive aspectsof phenomena.”\\n8 Real information is often not collected because the subjectivity of the\\nresearcher does enter in the collection of information in a case study.\\n(iii)The danger of false generalisation is always there in view of the fact that no set rules arefollowed in collection of the information and only few units are studied.\\n(iv) It consumes more time and requires lot of expenditure. More time is needed under case\\nstudy method since one studies the natural history cycles of social units and that too minutely.\\n(v) The case data are often vitiated because the subject, according to Read Bain, may write\\nwhat he thinks the investigator wants; and the greater the rapport, the more subjective thewhole process is.\\n(vi)Case study method is based on several assumptions which may not be very realistic attimes, and as such the usefulness of case data is always subject to doubt.\\n(vii)Case study method can be used only in a limited sphere., it is not possible to use it in caseof a big society. Sampling is also not possible under a case study method.\\n(viii)Response of the investigator is an important limitation of the case study method. He oftenthinks that he has full knowledge of the unit and can himself answer about it. In case thesame is not true, then consequences follow. In fact, this is more the fault of the researcherrather than that of the case method.\\nConclusion: Despite the above stated limitations, we find that case studies are being undertaken in\\nseveral disciplines, particularly in sociology, as a tool of scientific research in view of the severaladvantages indicated earlier. Most of the limitations can be removed if researchers are alwaysconscious of these and are well trained in the modern methods of collecting case data and in thescientific techniques of assembling, classifying and processing the same. Besides, case studies, inmodern times, can be conducted in such a manner that the data are amenable to quantification andstatistical treatment. Possibly, this is also the reason why case studies are becoming popular day by day.\\nQuestion\\n1.Enumerate the different methods of collecting data. Which one is the most suitable for conductingenquiry regarding family welfare programme in India? Explain its merits and demerits.\\n8 Pauline V. Young, Scientific social surveys and research, p. 262.Methods of Data Collection 117\\n2.“It is never safe to take published statistics at their face value without knowing their meaning and\\nlimitations.” Elucidate this statement by enumerating and explaining the various points which you wouldconsider before using any published data. Illustrate your answer by examples wherever possible.\\n3.Examine the merits and limitations of the observation method in collecting material. Illustrate your answerwith suitable examples.\\n4.Describe some of the major projective techniques and evaluate their significance as tools of scientificsocial research.\\n5.How does the case study method differ from the survey method? Analyse the merits and limitations ofcase study method in sociological research.\\n6.Clearly explain the difference between collection of data through questionnaires and schedules.\\n7.Discuss interview as a technique of data collection.\\n8.Write short notes on:\\n(a) Depth interviews;\\n(b) Important aspects of a questionnaire;\\n(c) Pantry and store audits;\\n(d) Thematic Apperception Test;\\n(e) Holtzman Inkbolt Test.\\n9.What are the guiding considerations in the construction of questionnaire? Explain.\\n10.Critically examine the following:\\n(i) Interviews introduce more bias than does the use of questionnaire.\\n(ii)Data collection through projective techniques is considered relatively more reliable.\\n(iii) In collection of statistical data commonsense is the chief requisite and experience the chief teacher.\\n11.Distinguish between an experiment and survey. Explain fully the survey method of research.\\n[M. Phi. (EAFM) Exam. 1987 Raj. Uni. ]\\n12.“Experimental method of research is not suitable in management field.” Discuss, what are the problems inthe introduction of this research design in business organisation?\\n[M.B.A. (Part I) Exam. 1985 Raj. Uni. ]118Research Methodology\\nAppendix (i)\\nGuidelines for Constructing\\nQuestionnaire/Schedule\\nThe researcher must pay attention to the following points in constructing an appropriate and effective\\nquestionnaire or a schedule:\\n1. The researcher must keep in view the problem he is to study for it provides the starting\\npoint for developing the Questionnaire/Schedule. He must be clear about the various aspectsof his research problem to be dealt with in the course of his research project.\\n2. Appropriate form of questions depends on the nature of information sought, the sampled\\nrespondents and the kind of analysis intended. The researcher must decide whether to useclosed or open-ended question. Questions should be simple and must be constructed with aview to their forming a logical part of a well thought out tabulation plan. The units ofenumeration should also be defined precisely so that they can ensure accurate and fullinformation.\\n3. Rough draft of the Questionnaire/Schedule be prepared, giving due thought to the appropriate\\nsequence of putting questions. Questionnaires or schedules previously drafted (if available)may as well be looked into at this stage.\\n4. Researcher must invariably re-examine, and in case of need may revise the rough draft for\\na better one. Technical defects must be minutely scrutinised and removed.\\n5. Pilot study should be undertaken for pre-testing the questionnaire. The questionnaire may\\nbe edited in the light of the results of the pilot study.\\n6. Questionnaire must contain simple but straight forward directions for the respondents so\\nthat they may not feel any difficulty in answering the questions.Appendix (ii): Guidelines for Successful Interviewing 119\\nAppendix (ii)\\nGuidelines for Successful\\nInterviewing\\nInterviewing is an art and one learns it by experience. However, the following points may be kept in\\nview by an interviewer for eliciting the desired information:\\n1. Interviewer must plan in advance and should fully know the problem under consideration.\\nHe must choose a suitable time and place so that the interviewee may be at ease during theinterview period. For this purpose some knowledge of the daily routine of the intervieweeis essential.\\n2. Interviewer’s approach must be friendly and informal. Initially friendly greetings in\\naccordance with the cultural pattern of the interviewee should be exchanged and then thepurpose of the interview should be explained.\\n3. All possible effort should be made to establish proper rapport with the interviewee; people\\nare motivated to communicate when the atmosphere is favourable.\\n4. Interviewer must know that ability to listen with understanding, respect and curiosity is the\\ngateway to communication, and hence must act accordingly during the interview. For allthis, the interviewer must be intelligent and must be a man with self-restraint and self-discipline.\\n5. To the extent possible there should be a free-flowing interview and the questions must be\\nwell phrased in order to have full cooperation of the interviewee. But the interviewer mustcontrol the course of the interview in accordance with the objective of the study.\\n6. In case of big enquiries, where the task of collecting information is to be accomplished by\\nseveral interviewers, there should be an interview guide to be observed by all so as toensure reasonable uniformity in respect of all salient points in the study.120 Research Methodology\\nAppendix (iii)\\nDifference Between\\nSurvey and Experiment\\nThe following points are noteworthy so far as difference between survey and experiment is concerned:\\n(i) Surveys are conducted in case of descriptive research studies where as experiments are a\\npart of experimental research studies.\\n(ii)Survey-type research studies usually have larger samples because the percentage of\\nresponses generally happens to be low, as low as 20 to 30%, especially in mailed questionnaire\\nstudies. Thus, the survey method gathers data from a relatively large number of cases at aparticular time; it is essentially cross-sectional. As against this, experimental studies generallyneed small samples.\\n(iii)Surveys are concerned with describing, recording, analysing and interpreting conditionsthat either exist or existed. The researcher does not manipulate the variable or arrange forevents to happen. Surveys are only concerned with conditions or relationships that exist,opinions that are held, processes that are going on, effects that are evident or trends thatare developing. They are primarily concerned with the present but at times do considerpast events and influences as they relate to current conditions. Thus, in surveys, variablesthat exist or have already occurred are selected and observed.\\nExperimental research provides a systematic and logical method for answering the question,\\n“What will happen if this is done when certain variables are carefully controlled ormanipulated?” In fact, deliberate manipulation is a part of the experimental method. In anexperiment, the researcher measures the effects of an experiment which he conductsintentionally.\\n(iv)Surveys are usually appropriate in case of social and behavioural sciences (because manytypes of behaviour that interest the researcher cannot be arranged in a realistic setting)where as experiments are mostly an essential feature of physical and natural sciences.\\n(v) Surveys are an example of field research where as experiments generally constitute an\\nexample of laboratory research.Appendix (iii): Difference Between Survey and Experiment 121\\n(vi)Surveys are concerned with hypothesis formulation and testing the analysis of the relationship\\nbetween non-manipulated variables. Experimentation provides a method of hypothesis testing.After experimenters define a problem, they propose a hypothesis. They then test thehypothesis and confirm or disconfirm it in the light of the controlled variable relationshipthat they have observed. The confirmation or rejection is always stated in terms of probabilityrather than certainty. Experimentation, thus, is the most sophisticated, exacting and powerfulmethod for discovering and developing an organised body of knowledge. The ultimatepurpose of experimentation is to generalise the variable relationships so that they may beapplied outside the laboratory to a wider population of interest.\\n*\\n(vii)Surveys may either be census or sample surveys. They may also be classified as socialsurveys, economic surveys or public opinion surveys. Whatever be their type, the methodof data collection happens to be either observation, or interview or questionnaire/opinionnaireor some projective technique(s). Case study method can as well be used. But in case ofexperiments, data are collected from several readings of experiments.\\n(viii) In case of surveys, research design must be rigid, must make enough provision for protection\\nagainst bias and must maximise reliability as the aim happens to be to obtain complete andaccurate information. Research design in case of experimental studies, apart reducing biasand ensuring reliability, must permit drawing inferences about causality.\\n(ix)Possible relationships between the data and the unknowns in the universe can be studiedthrough surveys where as experiments are meant to determine such relationships.\\n(x) Causal analysis is considered relatively more important in experiments where as in most\\nsocial and business surveys our interest lies in understanding and controlling relationshipsbetween variables and as such correlation analysis is relatively more important in surveys.\\n* John W. Best and James V. Kahn, “ Research in Education ”, 5th ed., Prentice-Hall of India Pvt. Ltd., New Delhi, 1986,\\np.111.122 Research Methodology\\n7\\nProcessing and Analysis of Data\\nThe data, after collection, has to be processed and analysed in accordance with the outline laid down\\nfor the purpose at the time of developing the research plan. This is essential for a scientific study andfor ensuring that we have all relevant data for making contemplated comparisons and analysis.Technically speaking, processing implies editing, coding, classification and tabulation of collecteddata so that they are amenable to analysis. The term analysis refers to the computation of certainmeasures along with searching for patterns of relationship that exist among data-groups. Thus, “inthe process of analysis, relationships or differences supporting or conflicting with original or newhypotheses should be subjected to statistical tests of significance to determine with what validity datacan be said to indicate any conclusions”.\\n1 But there are persons (Selltiz, Jahoda and others) who do\\nnot like to make difference between processing and analysis. They opine that analysis of data in ageneral way involves a number of closely related operations which are performed with the purposeof summarising the collected data and organising these in such a manner that they answer theresearch question(s). We, however, shall prefer to observe the difference between the two terms asstated here in order to understand their implications more clearly.\\nPROCESSING OPERATIONS\\nWith this brief introduction concerning the concepts of processing and analysis, we can now proceedwith the explanation of all the processing operations.\\n1. Editing: Editing of data is a process of examining the collected raw data (specially in surveys) to\\ndetect errors and omissions and to correct these when possible. As a matter of fact, editing involves\\na careful scrutiny of the completed questionnaires and/or schedules. Editing is done to assure that thedata are accurate, consistent with other facts gathered, uniformly entered, as completed as possibleand have been well arranged to facilitate coding and tabulation.\\nWith regard to points or stages at which editing should be done, one can talk of field editing and\\ncentral editing. Field editing  consists in the review of the reporting forms by the investigator for\\ncompleting (translating or rewriting) what the latter has written in abbreviated and/or in illegible form\\n1 G.B. Giles, Marketing,  p. 44.Processing and Analysis of Data 123\\nat the time of recording the respondents’ responses. This type of editing is necessary in view of the\\nfact that individual writing styles often can be difficult for others to decipher. This sort of editingshould be done as soon as possible after the interview, preferably on the very day or on the next day.While doing field editing, the investigator must restrain himself and must not correct errors of omissionby simply guessing what the informant would have said if the question had been asked.\\nCentral editing  should take place when all forms or schedules have been completed and returned\\nto the office. This type of editing implies that all forms should get a thorough editing by a single editorin a small study and by a team of editors in case of a large inquiry. Editor(s) may correct the obviouserrors such as an entry in the wrong place, entry recorded in months when it should have beenrecorded in weeks, and the like. In case of inappropriate on missing replies, the editor can sometimesdetermine the proper answer by reviewing the other information in the schedule. At times, therespondent can be contacted for clarification. The editor must strike out the answer if the same isinappropriate and he has no basis for determining the correct answer or the response. In such a casean editing entry of ‘no answer’ is called for. All the wrong replies, which are quite obvious, must bedropped from the final results, especially in the context of mail surveys.\\nEditors must keep in view several points while performing their work: (a) They should be familiar\\nwith instructions given to the interviewers and coders as well as with the editing instructions suppliedto them for the purpose. (b) While crossing out an original entry for one reason or another, theyshould just draw a single line on it so that the same may remain legible. (c) They must make entries(if any) on the form in some distinctive colur and that too in a standardised form. (d) They shouldinitial all answers which they change or supply. (e) Editor’s initials and the date of editing should beplaced on each completed form or schedule.\\n2. Coding: Coding refers to the process of assigning numerals or other symbols to answers so that\\nresponses can be put into a limited number of categories or classes. Such classes should be appropriate\\nto the research problem under consideration. They must also possess the characteristic ofexhaustiveness (i.e., there must be a class for every data item) and also that of mutual exclusivelywhich means that a specific answer can be placed in one and only one cell in a given category set.Another rule to be observed is that of unidimensionality by which is meant that every class is definedin terms of only one concept.\\nCoding is necessary for efficient analysis and through it the several replies may be reduced to a\\nsmall number of classes which contain the critical information required for analysis. Coding decisionsshould usually be taken at the designing stage of the questionnaire. This makes it possible to precodethe questionnaire choices and which in turn is helpful for computer tabulation as one can straightforward key punch from the original questionnaires. But in case of hand coding some standardmethod may be used. One such standard method is to code in the margin with a coloured pencil. Theother method can be to transcribe the data from the questionnaire to a coding sheet. Whatevermethod is adopted, one should see that coding errors are altogether eliminated or reduced to theminimum level.\\n3. Classification: Most research studies result in a large volume of raw data which must be reduced\\ninto homogeneous groups if we are to get meaningful relationships. This fact necessitates classification\\nof data which happens to be the process of arranging data in groups or classes on the basis ofcommon characteristics. Data having a common characteristic are placed in one class and in this124 Research Methodology\\nway the entire data get divided into a number of groups or classes. Classification can be one of the\\nfollowing two types, depending upon the nature of the phenomenon involved:\\n(a)Classification according to attributes: As stated above, data are classified on the basis\\nof common characteristics which can either be descriptive (such as literacy, sex, honesty,etc.) or numerical (such as weight, height, income, etc.). Descriptive characteristics referto qualitative phenomenon which cannot be measured quantitatively; only their presence orabsence in an individual item can be noticed. Data obtained this way on the basis of certainattributes are known as statistics of attributes  and their classification is said to be\\nclassification according to attributes.\\nSuch classification can be simple classification or manifold classification. In simple\\nclassification we consider only one attribute and divide the universe into two classes—oneclass consisting of items possessing the given attribute and the other class consisting ofitems which do not possess the given attribute. But in manifold classification we considertwo or more attributes simultaneously, and divide that data into a number of classes (totalnumber of classes of final order is given by 2\\nn, where n = number of attributes considered).*\\nWhenever data are classified according to attributes, the researcher must see that theattributes are defined in such a manner that there is least possibility of any doubt/ambiguityconcerning the said attributes.\\n(b)Classification according to class-intervals: Unlike descriptive characteristics, the\\nnumerical characteristics refer to quantitative phenomenon which can be measured throughsome statistical units. Data relating to income, production, age, weight, etc. come under thiscategory. Such data are known as statistics of variables  and are classified on the basis of\\nclass intervals. For instance, persons whose incomes, say, are within Rs 201 to Rs 400 canform one group, those whose incomes are within Rs 401 to Rs 600 can form another groupand so on. In this way the entire data may be divided into a number of groups or classes orwhat are usually called, ‘class-intervals.’ Each group of class-interval, thus, has an upperlimit as well as a lower limit which are known as class limits. The difference between thetwo class limits is known as class magnitude. We may have classes with equal classmagnitudes or with unequal class magnitudes. The number of items which fall in a givenclass is known as the frequency of the given class. All the classes or groups, with theirrespective frequencies taken together and put in the form of a table, are described as groupfrequency distribution or simply frequency distribution. Classification according to classintervals usually involves the following three main problems:\\n(i) How may classes should be there? What should be their magnitudes?\\nThere can be no specific answer with regard to the number of classes. The decisionabout this calls for skill and experience of the researcher. However, the objectiveshould be to display the data in such a way as to make it meaningful for the analyst.Typically, we may have 5 to 15 classes. With regard to the second part of the question,we can say that, to the extent possible, class-intervals should be of equal magnitudes,but in some cases unequal magnitudes may result in better classification. Hence the\\n* Classes of the final order are those classes developed on the basis of ‘ n’ attributes considered. For example, if attributes\\nA and B are studied and their presence is denoted by A and B respectively and absence by a and b respectively, then we have\\nfour classes of final order viz., class AB, class Ab, class aB, and class ab.Processing and Analysis of Data 125\\nresearcher’s objective judgement plays an important part in this connection. Multiples\\nof 2, 5 and 10 are generally preferred while determining class magnitudes. Somestatisticians adopt the following formula, suggested by H.A. Sturges, determining thesize of class interval:\\ni = R/(1 + 3.3 log N)\\nwhere\\n i = size of class interval;\\nR = Range (i.e., difference between the values of the largest item and smallest item\\n  among the given items);\\nN = Number of items to be grouped.\\nIt should also be kept in mind that in case one or two or very few items have very high or very\\nlow values, one may use what are known as open-ended intervals in the overall frequency distribution.Such intervals may be expressed like under Rs 500 or Rs 10001 and over. Such intervals are generallynot desirable, but often cannot be avoided. The researcher must always remain conscious of this factwhile deciding the issue of the total number of class intervals in which the data are to be classified.\\n(ii)How to choose class limits?\\nWhile choosing class limits, the researcher must take into consideration the criterion\\nthat the mid-point (generally worked out first by taking the sum of the upper limit andlower limit of a class and then divide this sum by 2) of a class-interval and the actualaverage of items of that class interval should remain as close to each other as possible.Consistent with this, the class limits should be located at multiples of 2, 5, 10, 20, 100and such other figures. Class limits may generally be stated in any of the followingforms:\\nExclusive type class intervals:  They are usually stated as follows:\\n10–20\\n20–30\\n30–4040–50\\nThe above intervals should be read as under:\\n10 and under 2020 and under 30\\n30 and under 40\\n40 and under 50\\nThus, under the exclusive type class intervals, the items whose values are equal to the\\nupper limit of a class are grouped in the next higher class. For example, an item whosevalue is exactly 30 would be put in 30–40 class interval and not in 20–30 class interval.In simple words, we can say that under exclusive type class intervals, the upper limit ofa class interval is excluded and items with values less than the upper limit (but not lessthan the lower limit) are put in the given class interval.126 Research Methodology\\nInclusive type class intervals:  They are usually stated as follows:\\n11–20\\n21–30\\n31–40\\n41–50\\nIn inclusive type class intervals the upper limit of a class interval is also included in the\\nconcerning class interval. Thus, an item whose value is 20 will be put in 11–20 classinterval. The stated upper limit of the class interval 11–20 is 20 but the real limit is20.99999 and as such 11–20 class interval really means 11 and under 21.\\nWhen the phenomenon under consideration happens to be a discrete one (i.e., can be measured\\nand stated only in integers), then we should adopt inclusive type classification. But when thephenomenon happens to be a continuous one capable of being measured in fractions as well, we canuse exclusive type class intervals.\\n*\\n(iii)How to determine the frequency of each class?\\nThis can be done either by tally sheets or by mechanical aids. Under the technique of\\ntally sheet, the class-groups are written on a sheet of paper (commonly known as thetally sheet) and for each item a stroke (usually a small vertical line) is marked againstthe class group in which it falls. The general practice is that after every four smallvertical lines in a class group, the fifth line for the item falling in the same group, isindicated as horizontal line through the said four lines and the resulting flower (IIII)represents five items. All this facilitates the counting of items in each one of the classgroups. An illustrative tally sheet can be shown as under:\\nTable 7.1\\n:An Illustrative Tally Sheet for Determining the Number\\nof 70 Families in Different Income Groups\\nIncome groups Tally mark Number of families or\\n(Rupees) (Class frequency)\\nBelow 400 IIII     IIII     III 13\\n401–800 IIII     IIII     IIII     IIII 20\\n801–1200 IIII     IIII     II 12\\n1201–1600 IIII     IIII     IIII     III 18\\n1601 and\\nabove IIII     II 7\\nTotal 70\\nAlternatively, class frequencies can be determined, specially in case of large inquires and surveys,\\nby mechanical aids i.e., with the help of machines viz., sorting machines that are available for the\\npurpose. Some machines are hand operated, whereas other work with electricity. There are machines\\n* The stated limits of class intervals are different than true limits. We should use true or real limits keeping in view the\\nnature of the given phenomenon.Processing and Analysis of Data 127\\nwhich can sort out cards at a speed of something like 25000 cards per hour. This method is fast but\\nexpensive.\\n4. Tabulation: When a mass of data has been assembled, it becomes necessary for the researcher\\nto arrange the same in some kind of concise and logical order. This procedure is referred to as\\ntabulation. Thus, tabulation is the process of summarising raw data and displaying the same in compactform (i.e., in the form of statistical tables) for further analysis. In a broader sense, tabulation is anorderly arrangement of data in columns and rows.\\nTabulation is essential because of the following reasons.\\n1. It conserves space and reduces explanatory and descriptive statement to a minimum.\\n2. It facilitates the process of comparison.\\n3. It facilitates the summation of items and the detection of errors and omissions.4. It provides a basis for various statistical computations.\\nTabulation can be done by hand or by mechanical or electronic devices. The choice depends on\\nthe size and type of study, cost considerations, time pressures and the availaibility of tabulating\\nmachines or computers. In relatively large inquiries, we may use mechanical or computer tabulationif other factors are favourable and necessary facilities are available. Hand tabulation is usuallypreferred in case of small inquiries where the number of questionnaires is small and they are ofrelatively short length. Hand tabulation may be done using the direct tally, the list and tally or the cardsort and count methods. When there are simple codes, it is feasible to tally directly from thequestionnaire. Under this method, the codes are written on a sheet of paper, called tally sheet, and foreach response a stroke is marked against the code in which it falls. Usually after every four strokesagainst a particular code, the fifth response is indicated by drawing a diagonal or horizontal linethrough the strokes. These groups of five are easy to count and the data are sorted against each codeconveniently. In the listing method, the code responses may be transcribed onto a large work-sheet,allowing a line for each questionnaire. This way a large number of questionnaires can be listed onone work sheet. Tallies are then made for each question. The card sorting method is the most flexiblehand tabulation. In this method the data are recorded on special cards of convenient size and shapewith a series of holes. Each hole stands for a code and when cards are stacked, a needle passesthrough particular hole representing a particular code. These cards are then separated and counted.In this way frequencies of various codes can be found out by the repetition of this technique. We canas well use the mechanical devices or the computer facility for tabulation purpose in case we wantquick results, our budget permits their use and we have a large volume of straight forward tabulationinvolving a number of cross-breaks.\\nTabulation may also be classified as simple and complex tabulation. The former type of tabulation\\ngives information about one or more groups of independent questions, whereas the latter type oftabulation shows the division of data in two or more categories and as such is deigned to giveinformation concerning one or more sets of inter-related questions. Simple tabulation generally resultsin one-way tables which supply answers to questions about one characteristic of data only. Asagainst this, complex tabulation usually results in two-way tables (which give information about twointer-related characteristics of data), three-way tables (giving information about three interrelatedcharacteristics of data) or still higher order tables, also known as manifold tables, which supply128 Research Methodology\\ninformation about several interrelated characteristics of data. Two-way tables, three-way tables or\\nmanifold tables are all examples of what is sometimes described as cross tabulation.\\nGenerally accepted principles of tabulation:  Such principles of tabulation, particularly of\\nconstructing statistical tables, can be briefly states as follows:*\\n1. Every table should have a clear, concise and adequate title so as to make the table intelligible\\nwithout reference to the text and this title should always be placed just above the body of\\nthe table.\\n2. Every table should be given a distinct number to facilitate easy reference.\\n3. The column headings (captions) and the row headings (stubs) of the table should be clear\\nand brief.\\n4. The units of measurement under each heading or sub-heading must always be indicated.\\n5. Explanatory footnotes, if any, concerning the table should be placed directly beneath the\\ntable, along with the reference symbols used in the table.\\n6. Source or sources from where the data in the table have been obtained must be indicated\\njust below the table.\\n7. Usually the columns are separated from one another by lines which make the table more\\nreadable and attractive. Lines are always drawn at the top and bottom of the table and\\nbelow the captions.\\n8. There should be thick lines to separate the data under one class from the data under\\nanother class and the lines separating the sub-divisions of the classes should be comparativelythin lines.\\n9. The columns may be numbered to facilitate reference.\\n10. Those columns whose data are to be compared should be kept side by side. Similarly,\\npercentages and/or averages must also be kept close to the data.\\n11. It is generally considered better to approximate figures before tabulation as the same would\\nreduce unnecessary details in the table itself.\\n12. In order to emphasise the relative significance of certain categories, different kinds of type,\\nspacing and indentations may be used.\\n13. It is important that all column figures be properly aligned. Decimal points and (+) or (–)\\nsigns should be in perfect alignment.\\n14. Abbreviations should be avoided to the extent possible and ditto marks should not be used\\nin the table.\\n15. Miscellaneous and exceptional items, if any, should be usually placed in the last row of the\\ntable.\\n16. Table should be made as logical, clear, accurate and simple as possible. If the data happen\\nto be very large, they should not be crowded in a single table for that would make the tableunwieldy and inconvenient.\\n17. Total of rows should normally be placed in the extreme right column and that of columns\\nshould be placed at the bottom.\\n* All these points constitute the characteristics of a good table.Processing and Analysis of Data 129\\n18. The arrangement of the categories in a table may be chronological, geographical, alphabetical\\nor according to magnitude to facilitate comparison. Above all, the table must suit the needs\\nand requirements of an investigation.\\nSOME PROBLEMS IN PROCESSING\\nWe can take up the following two problems of processing the data for analytical purposes:\\n(a) The problem concerning “Don’t know” (or DK) responses: While processing the data, the\\nresearcher often comes across some responses that are difficult to handle. One category of such\\nresponses may be ‘Don’t Know Response’ or simply DK response. When the DK response groupis small, it is of little significance. But when it is relatively big, it becomes a matter of major concernin which case the question arises: Is the question which elicited DK response useless? The answerdepends on two points viz., the respondent actually may not know the answer or the researcher mayfail in obtaining the appropriate information. In the first case the concerned question is said to bealright and DK response is taken as legitimate DK response. But in the second case, DK responseis more likely to be a failure of the questioning process.\\nHow DK responses are to be dealt with by researchers? The best way is to design better type of\\nquestions. Good rapport of interviewers with respondents will result in minimising DK responses.But what about the DK responses that have already taken place? One way to tackle this issue is toestimate the allocation of DK answers from other data in the questionnaire. The other way is to keepDK responses as a separate category in tabulation where we can consider it as a separate replycategory if DK responses happen to be legitimate, otherwise we should let the reader make his owndecision. Yet another way is to assume that DK responses occur more or less randomly and as suchwe may distribute them among the other answers in the ratio in which the latter have occurred.Similar results will be achieved if all DK replies are excluded from tabulation and that too withoutinflating the actual number of other responses.\\n(b) Use or percentages: Percentages are often used in data presentation for they simplify numbers,\\nreducing all of them to a 0 to 100 range. Through the use of percentages, the data are reduced in the\\nstandard form with base equal to 100 which fact facilitates relative comparisons. While usingpercentages, the following rules should be kept in view by researchers:\\n1. Two or more percentages must not be averaged unless each is weighted by the group size\\nfrom which it has been derived.\\n2. Use of too large percentages should be avoided, since a large percentage is difficult to\\nunderstand and tends to confuse, defeating the very purpose for which percentages areused.\\n3. Percentages hide the base from which they have been computed. If this is not kept in view,\\nthe real differences may not be correctly read.\\n4. Percentage decreases can never exceed 100 per cent and as such for calculating the\\npercentage of decrease, the higher figure should invariably be taken as the base.\\n5. Percentages should generally be worked out in the direction of the causal-factor in case of\\ntwo-dimension tables and for this purpose we must select the more significant factor out ofthe two given factors as the causal factor.130 Research Methodology\\nELEMENTS/TYPES OF ANALYSIS\\nAs stated earlier, by analysis we mean the computation of certain indices or measures along with\\nsearching for patterns of relationship that exist among the data groups. Analysis, particularly in caseof survey or experimental data, involves estimating the values of unknown parameters of the populationand testing of hypotheses for drawing inferences. Analysis may, therefore, be categorised as descriptiveanalysis and inferential analysis (Inferential analysis is often known as statistical analysis). “ Descriptive\\nanalysis is largely the study of distributions of one variable. This study provides us with profiles of\\ncompanies, work groups, persons and other subjects on any of a multiple of characteristics such assize. Composition, efficiency, preferences, etc.”\\n2. this sort of analysis may be in respect of one\\nvariable (described as unidimensional analysis), or in respect of two variables (described as bivariateanalysis) or in respect of more than two variables (described as multivariate analysis). In this contextwe work out various measures that show the size and shape of a distribution(s) along with the studyof measuring relationships between two or more variables.\\nWe may as well talk of correlation analysis and causal analysis. Correlation analysis  studies\\nthe joint variation of two or more variables for determining the amount of correlation between two ormore variables. Causal analysis  is concerned with the study of how one or more variables affect\\nchanges in another variable. It is thus a study of functional relationships existing between two ormore variables. This analysis can be termed as regression analysis. Causal analysis is consideredrelatively more important in experimental researches, whereas in most social and business researchesour interest lies in understanding and controlling relationships between variables then with determiningcauses per se and as such we consider correlation analysis as relatively more important.\\nIn modern times, with the availability of computer facilities, there has been a rapid development\\nof multivariate analysis  which may be defined as “all statistical methods which simultaneously\\nanalyse more than two variables on a sample of observations”\\n3. Usually the following analyses* are\\ninvolved when we make a reference of multivariate analysis:\\n(a) Multiple regression analysis: This analysis is adopted when the researcher has one dependent\\nvariable which is presumed to be a function of two or more independent variables. The objective of\\nthis analysis is to make a prediction about the dependent variable based on its covariance with all theconcerned independent variables.\\n(b) Multiple discriminant analysis: This analysis is appropriate when the researcher has a single\\ndependent variable that cannot be measured, but can be classified into two or more groups on the\\nbasis of some attribute. The object of this analysis happens to be to predict an entity’s possibility ofbelonging to a particular group based on several predictor variables.\\n(c) Multivariate analysis of variance  (or multi-ANOVA ): This analysis is an extension of two-\\nway ANOVA, wherein the ratio of among group variance to within group variance is worked out on\\na set of variables.\\n(d) Canonical analysis: This analysis can be used in case of both measurable and non-measurable\\nvariables for the purpose of simultaneously predicting a set of dependent variables from their jointcovariance with a set of independent variables.\\n2 C. William Emory, Business Research Methods,  p. 356.\\n3 Jagdish N. Sheth, “The Multivariate Revolution in Marketing Research”, Journal of Marketing,  Vol. 35, No. 1\\n(Jan.1971), pp. 13–19.\\n* Readers are referred to standard texts for more details about these analyses.Processing and Analysis of Data 131\\nInferential analysis  is concerned with the various tests of significance for testing hypotheses in\\norder to determine with what validity data can be said to indicate some conclusion or conclusions. It\\nis also concerned with the estimation of population values. It is mainly on the basis of inferentialanalysis that the task of interpretation (i.e., the task of drawing inferences and conclusions) isperformed.\\nSTATISTICS IN RESEARCH\\nThe role of statistics in research is to function as a tool in designing research, analysing its data anddrawing conclusions therefrom. Most research studies result in a large volume of raw data whichmust be suitably reduced so that the same can be read easily and can be used for further analysis.Clearly the science of statistics cannot be ignored by any research worker, even though he may nothave occasion to use statistical methods in all their details and ramifications. Classification andtabulation, as stated earlier, achieve this objective to some extent, but we have to go a step furtherand develop certain indices or measures to summarise the collected/classified data. Only after thiswe can adopt the process of generalisation from small groups (i.e., samples) to population. If fact,there are two major areas of statistics viz., descriptive statistics and inferential statistics. Descriptive\\nstatistics concern the development of certain indices from the raw data, whereas inferential statistics\\nconcern with the process of generalisation. Inferential statistics  are also known as sampling statistics\\nand are mainly concerned with two major type of problems: (i) the estimation of population parameters,and (ii) the testing of statistical hypotheses.\\nThe important statistical measures\\n* that are used to summarise the survey/research data are:\\n(1) measures of central tendency or statistical averages; (2) measures of dispersion; (3) measures\\nof asymmetry (skewness); (4) measures of relationship; and (5) other measures.\\nAmongst the measures of central tendency, the three most important ones are the arithmetic\\naverage or mean, median and mode. Geometric mean and harmonic mean are also sometimes used.\\nFrom among the measures of dispersion, variance, and its square root—the standard deviation\\nare the most often used measures. Other measures such as mean deviation, range, etc. are alsoused. For comparison purpose, we use mostly the coefficient of standard deviation or the coefficientof variation.\\nIn respect of the measures of skewness and kurtosis, we mostly use the first measure of skewness\\nbased on mean and mode or on mean and median. Other measures of skewness, based on quartilesor on the methods of moments, are also used sometimes. Kurtosis is also used to measure thepeakedness of the curve of the frequency distribution.\\nAmongst the measures of relationship, Karl Pearson’s coefficient of correlation is the frequently\\nused measure in case of statistics of variables, whereas Yule’s coefficient of association is used incase of statistics of attributes. Multiple correlation coefficient, partial correlation coefficient, regressionanalysis, etc., are other important measures often used by a researcher.\\nIndex numbers, analysis of time series, coefficient of contingency, etc., are other measures that\\nmay as well be used by a researcher, depending upon the nature of the problem under study.\\nWe give below a brief outline of some important measures (our of the above listed measures)\\noften used in the context of research studies.\\n* One may read any standard text book on statistical methods for details about these measures.132 Research Methodology\\nMEASURES OF CENTRAL TENDENCY\\nMeasures of central tendency (or statistical averages) tell us the point about which items have a\\ntendency to cluster. Such a measure is considered as the most representative figure for the entiremass of data. Measure of central tendency is also known as statistical average. Mean, median andmode are the most popular averages. Mean, also known as arithmetic average, is the most common\\nmeasure of central tendency and may be defined as the value which we get by dividing the total ofthe values of various given items in a series by the total number of items. we can work it out as under:\\nMean (or )*XX\\nnXX X\\nnin=∑=++ +12 ...\\nwhereX = The symbol we use for mean (pronounced as X bar)\\n ∑ = Symbol for summation\\n  Xi = Value of the ith item X, i = 1, 2, …, n\\n   n = total number of items\\nIn case of a frequency distribution, we can work out mean in this way:\\nXfX\\nffX fX fX\\nff fnii\\ninn\\nn=∑\\n∑=++ +\\n++ +=11 22\\n12...\\n...\\nSometimes, instead of calculating the simple mean, as stated above, we may workout the weighted\\nmean for a realistic average. The weighted mean can be worked out as follows:\\nXwX\\nwwii\\ni=∑\\n∑\\nwhereXw = Weighted item\\n   wi = weight of ith item X\\n   Xi = value of the ith item X\\nMean is the simplest measurement of central tendency and is a widely used measure. Its chief\\nuse consists in summarising the essential features of a series and in enabling data to be compared. Itis amenable to algebraic treatment and is used in further statistical calculations. It is a relativelystable measure of central tendency. But it suffers from some limitations viz., it is unduly affected byextreme items; it may not coincide with the actual value of an item in a series, and it may lead towrong impressions, particularly when the item values are not given with the average. However,mean is better than other averages, specially in economic and social studies where direct quantitativemeasurements are possible.\\nMedian is the value of the middle item of series when it is arranged in ascending or descending\\norder of magnitude. It divides the series into two halves; in one half all items are less than median,whereas in the other half all items have values higher than median. If the values of the items arrangedin the ascending order are: 60, 74, 80, 90, 95, 100, then the value of the 4th item viz., 88 is the valueof median. We can also write thus:\\n* If we use assumed average A, then mean would be worked out as under:\\n XAXA\\nni=+∑−bg or  XAfX A\\nfii\\ni=+∑−\\n∑bg, in case of frequency distribution. This is also known as short cut\\nmethod of finding X.Processing and Analysis of Data 133\\nMedian Value of n+1\\n2th item Mbg= FHGIKJ\\nMedian is a positional average and is used only in the context of qualitative phenomena, for\\nexample, in estimating intelligence, etc., which are often encountered in sociological fields. Median is\\nnot useful where items need to be assigned relative importance and weights. It is not frequently usedin sampling statistics.\\nMode is the most commonly or frequently occurring value in a series. The mode in a distribution\\nis that item around which there is maximum concentration. In general, mode is the size of the itemwhich has the maximum frequency, but at items such an item may not be mode on account of theeffect of the frequencies of the neighbouring items. Like median, mode is a positional average and isnot affected by the values of extreme items. it is, therefore, useful in all situations where we want toeliminate the effect of extreme variations. Mode is particularly useful in the study of popular sizes.For example, a manufacturer of shoes is usually interested in finding out the size most in demand sothat he may manufacture a larger quantity of that size. In other words, he wants a modal size to bedetermined for median or mean size would not serve his purpose. but there are certain limitations ofmode as well. For example, it is not amenable to algebraic treatment and sometimes remainsindeterminate when we have two or more model values in a series. It is considered unsuitable incases where we want to give relative importance to items under consideration.\\nGeometric mean  is also useful under certain conditions. It is defined as the nth root of the\\nproduct of the values of n times in a given series. Symbolically, we can put it thus:\\nGeometric mean (or G.M.) = \\nπXin\\n          =⋅ ⋅XXX Xnn123 ...\\nwhere\\nG.M. = geometric mean,\\n      n = number of items.\\n     Xi = ith value of the variable X\\n     π = conventional product notation\\nFor instance, the geometric mean of the numbers, 4, 6, and 9 is worked out as\\nG.M. = 4693..\\n           = 6\\nThe most frequently used application of this average is in the determination of average per cent\\nof change i.e., it is often used in the preparation of index numbers or when we deal in ratios.\\nHarmonic mean  is defined as the reciprocal of the average of reciprocals of the values of items\\nof a series. Symbolically, we can express it as under:\\nHarmonic mean (H.M.) = Rec.Rec∑X\\nni\\n    =R e c .Rec. Rec. Rec.XX X\\nnn 12++ + ...134 Research Methodology\\nwhere\\nH.M. = Harmonic mean\\n Rec. = Reciprocal\\n     Xi = ith value of the variable X\\n      n = number of items\\nFor instance, the harmonic mean of the numbers 4, 5, and 10 is worked out as\\nH.M.= Rec Rec15+12 +614 15 11 0\\n3360 ///++=\\n   =R e c33\\n60× FHGIKJ==1\\n360\\n11545.\\nHarmonic mean is of limited application, particularly in cases where time and rate are involved.\\nThe harmonic mean gives largest weight to the smallest item and smallest weight to the largest item.\\nAs such it is used in cases like time and motion study where time is variable and distance constant.\\nFrom what has been stated above, we can say that there are several types of statistical averages.\\nResearcher has to make a choice for some average. There are no hard and fast rules for theselection of a particular average in statistical analysis for the selection of an average mostly dependson the nature, type of objectives of the research study. One particular type of average cannot betaken as appropriate for all types of studies. The chief characteristics and the limitations of thevarious averages must be kept in view; discriminate use of average is very essential for soundstatistical analysis.\\nMEASURES OF DISPERSION\\nAn averages can represent a series only as best as a single figure can, but it certainly cannot revealthe entire story of any phenomenon under study. Specially it fails to give any idea about the scatter ofthe values of items of a variable in the series around the true value of average. In order to measurethis scatter, statistical devices called measures of dispersion are calculated. Important measures ofdispersion are (a) range, (b) mean deviation, and (c) standard deviation.\\n(a) Range is the simplest possible measure of dispersion and is defined as the difference between\\nthe values of the extreme items of a series. Thus,\\nRange =Highest  value of an\\nitem in a seriesLowest  value of an\\nitem in a seriesFHIK−FHIK\\nThe utility of range is that it gives an idea of the variability very quickly, but the drawback is that\\nrange is affected very greatly by fluctuations of sampling. Its value is never stable, being based ononly two values of the variable. As such, range is mostly used as a rough measure of variability andis not considered as an appropriate measure in serious research studies.\\n(b) Mean deviation  is the average of difference of the values of items from some average of the\\nseries. Such a difference is technically described as deviation. In calculating mean deviation we\\nignore the minus sign of deviations while taking their total for obtaining the mean deviation. Meandeviation is, thus, obtained as under:Processing and Analysis of Data 135\\nMean deviation from mean δXiXX\\nnch=∑−,     if deviations, XXi−, are obtained from\\nor           arithmetic average.\\nMean deviation from median δmiXM\\nnbg=∑−,    if deviations, XMi−, are obtained\\nor  from median\\nMean deviation from mode δziXZ\\nnbg=∑−,    if deviations, XZi−, are obtained from\\n          mode.\\nwhere   δ = Symbol for mean deviation (pronounced as delta);\\n  Xi = ith values of the variable X;\\n  n  = number of items;\\nX = Arithmetic average;\\n  M = Median;\\n   Z = Mode.\\nWhen mean deviation is divided by the average used in finding out the mean deviation itself, the\\nresulting quantity is described as the coefficient of mean deviation . Coefficient of mean deviation\\nis a relative measure of dispersion and is comparable to similar measure of other series. Meandeviation and its coefficient are used in statistical studies for judging the variability, and therebyrender the study of central tendency of a series more precise by throwing light on the typicalness ofan average. It is a better measure of variability than range as it takes into consideration the values ofall items of a series. Even then it is not a frequently used measure as it is not amenable to algebraicprocess.\\n(c) Standard deviation  is most widely used measure of dispersion of a series and is commonly\\ndenoted by the symbol ‘\\nσ’ (pronounced as sigma). Standard deviation is defined as the square-root\\nof the average of squares of deviations, when such deviations for the values of individual items in a\\nseries are obtained from the arithmetic average. It is worked out as under:\\nStandard deviation*σbgdi=∑−XX\\nni2\\n* If we use assumed average, A, in place of X while finding deviations, then standard deviation would be worked out as\\nunder:\\nσ=∑−−∑−F\\nHGI\\nKJXA\\nnXA\\nniibgbg2 2\\n    Or\\nσ=∑−\\n∑−∑−\\n∑F\\nHGI\\nKJfX A\\nffX A\\nfii\\niii\\nibg bg2 2\\n, in case of frequency distribution.\\nThis is also known as the short-cut method of finding σ.136 Research Methodology\\nOr\\nStandard deviation σbgdi=∑−\\n∑fX X\\nfii\\ni2\\n, in case of frequency distribution\\nwhere fi means the frequency of the ith item.\\nWhen we divide the standard deviation by the arithmetic average of the series, the resulting quantity\\nis known as coefficient of standard deviation which  happens to be a relative measure and is often\\nused for comparing with similar measure of other series. When this coefficient of standard deviationis multiplied by 100, the resulting figure is known as coefficient of variation . Sometimes, we work\\nout the square of standard deviation, known as variance, which is frequently used in the context of\\nanalysis of variation.\\nThe standard deviation (along with several related measures like variance, coefficient of variation,\\netc.) is used mostly in research studies and is regarded as a very satisfactory measure of dispersionin a series. It is amenable to mathematical manipulation because the algebraic signs are not ignoredin its calculation (as we ignore in case of mean deviation). It is less affected by fluctuations ofsampling. These advantages make standard deviation and its coefficient a very popular measure ofthe scatteredness of a series. It is popularly used in the context of estimation and testing of hypotheses.\\nMEASURES OF ASYMMETRY (SKEWNESS)\\nWhen the distribution of item in a series happens to be perfectly symmetrical, we then have thefollowing type of curve for the distribution:\\nFig. 7.1\\nSuch a curve is technically described as a normal curve  and the relating distribution as normal\\ndistribution. Such a curve is perfectly bell shaped curve in which case the value of X or M or Z is\\njust the same and skewness is altogether absent. But if the curve is distorted (whether on the rightside or on the left side), we have asymmetrical distribution which indicates that there is skewness. Ifthe curve is distorted on the right side, we have positive skewness but when the curve is distortedtowards left, we have negative skewness as shown here under:(= =)XMZ\\nCurve showing no skewness in which case we have = = XMZProcessing and Analysis of Data 137\\nFig. 7.2\\nSkewness is, thus, a measure of asymmetry and shows the manner in which the items are clustered\\naround the average. In a symmetrical distribution, the items show a perfect balance on either side ofthe mode, but in a skew distribution the balance is thrown to one side. The amount by which thebalance exceeds on one side measures the skewness of the series. The difference between themean, median or the mode provides an easy way of expressing skewness in a series. In case of\\npositive skewness, we have Z < M < \\nX and in case of negative skewness we have X < M < Z.\\nUsually we measure skewness in this way:\\n Skewness = X – Z and its coefficient ( j) is worked\\nout as  jXZ=−\\nσ\\nIn case Z is not well defined, then we work out skewness as under:\\nSkewness = 3( X – M) and its coefficient ( j) is worked\\n         out as  jXM\\n=−3di\\nσ\\nThe significance of skewness lies in the fact that through it one can study the formation of series\\nand can have the idea about the shape of the curve, whether normal or otherwise, when the items of\\na given series are plotted on a graph.\\nKurtosis is the measure of flat-toppedness of a curve. A bell shaped curve or the normal curve\\nis Mesokurtic because it is kurtic in the centre; but if the curve is relatively more peaked than thenormal curve, it is called Leptokurtic whereas a curve is more flat than the normal curve, it is calledPlatykurtic. In brief, Kurtosis is the humpedness of the curve and points to the nature of distributionof items in the middle of a series.\\nIt may be pointed out here that knowing the shape of the distribution curve is crucial to the use of\\nstatistical methods in research analysis since most methods make specific assumptions about thenature of the distribution curve.X X\\nCurve showing positive skewness\\nIn case of positive skewness we have:\\n<<ZMXCurve showing negative skewness\\nIn case of negative skewness we have:\\n<<XMZZZM M138 Research Methodology\\nMEASURES OF RELATIONSHIP\\nSo far we have dealt with those statistical measures that we use in context of univariate population\\ni.e., the population consisting of measurement of only one variable. But if we have the data on twovariables, we are said to have a bivariate population and if the data happen to be on more than twovariables, the population is known as multivariate population. If for every measurement of a variable,X, we have corresponding value of a second variable, Y, the resulting pairs of values are called a\\nbivariate population. In addition, we may also have a corresponding value of the third variable, Z, or\\nthe forth variable, W, and so on, the resulting pairs of values are called a multivariate population. In\\ncase of bivariate or multivariate populations, we often wish to know the relation of the two and/ormore variables in the data to one another. We may like to know, for example, whether the number ofhours students devote for studies is somehow related to their family income, to age, to sex or tosimilar other factor. There are several methods of determining the relationship between variables,but no method can tell us for certain that a correlation is indicative of causal relationship. Thus wehave to answer two types of questions in bivariate or multivariate populations viz.,\\n(i) Does there exist association or correlation between the two (or more) variables? If yes, of\\nwhat degree?\\n(ii) Is there any cause and effect relationship between the two variables in case of the bivariate\\npopulation or between one variable on one side and two or more variables on the other sidein case of multivariate population? If yes, of what degree and in which direction?\\nThe first question is answered by the use of correlation technique and the second question by thetechnique of regression. There are several methods of applying the two techniques, but the importantones are as under:\\nIn case of bivariate population:  Correlation can be studied through (a) cross tabulation;\\n(b)Charles Spearman’s coefficient of correlation; (c) Karl Pearson’s coefficient of correlation;whereas cause and effect relationship can be studied through simple regression equations.\\nIn case of multivariate population:  Correlation can be studied through (a) coefficient of multiple\\ncorrelation; (b) coefficient of partial correlation; whereas cause and effect relationship can be studiedthrough multiple regression equations.\\nWe can now briefly take up the above methods one by one.\\nCross tabulation  approach is specially useful when the data are in nominal form. Under it we\\nclassify each variable into two or more categories and then cross classify the variables in these sub-\\ncategories. Then we look for interactions between them which may be symmetrical, reciprocal orasymmetrical. A symmetrical relationship is one in which the two variables vary together, but weassume that neither variable is due to the other. A reciprocal relationship exists when the two variablesmutually influence or reinforce each other. Asymmetrical relationship is said to exist if one variable(the independent variable) is responsible for another variable (the dependent variable). The crossclassification procedure begins with a two-way table which indicates whether there is or there is notan interrelationship between the variables. This sort of analysis can be further elaborated in whichcase a third factor is introduced into the association through cross-classifying the three variables. Bydoing so we find conditional relationship in which factor X appears to affect factor Y only when\\nfactor Z is held constant. The correlation, if any, found through this approach is not considered a veryProcessing and Analysis of Data 139\\npowerful form of statistical correlation and accordingly we use some other methods when data\\nhappen to be either ordinal or interval or ratio data.\\nCharles Spearman ’s coefficient of correlation (or rank correlation ) is the technique of\\ndetermining the degree of correlation between two variables in case of ordinal data where ranks aregiven to the different values of the variables. The main objective of this coefficient is to determinethe extent to which the two sets of ranking are similar or dissimilar. This coefficient is determined asunder:\\nSpearman\\'s coefficient of correlation (or r\\ns) = 16\\n12\\n2−∑\\n−L\\nNMMO\\nQPPd\\nnniej\\nwheredi = difference between ranks of ith pair of the two variables;\\nn = number of pairs of observations.\\nAs rank correlation is a non-parametric technique for measuring relationship between paired\\nobservations of two variables when data are in the ranked form, we have dealt with this technique ingreater details later on in the book in chapter entitled ‘Hypotheses Testing II (Non-parametric tests)’.\\nKarl Pearson ’s coefficient of correlation  (or simple correlation) is the most widely used method\\nof measuring the degree of relationship between two variables. This coefficient assumes the following:\\n(i) that there is linear relationship between the two variables;\\n(ii)that the two variables are casually related which means that one of the variables isindependent and the other one is dependent; and\\n(iii) a large number of independent causes are operating in both variables so as to produce a\\nnormal distribution.\\nKarl Pearson’s coefficient of correlation can be worked out thus.\\nKarl Pearson’s coefficient of correlation (or r)\\n* =∑− −\\n⋅⋅XX Y Y\\nnii\\nXYdi d i\\nσσ\\n* Alternatively, the formula can be written as:\\nrXX Y Y\\nXX Y Yii\\nii=∑− −\\n∑− ⋅ ∑ −di d i\\ndi d i22\\nOr\\nrXY XX Y Y n\\nxyii\\nxy=⋅=∑− −\\n⋅Covariance between  and \\nσσ σσdi d i /\\nOr\\nrXY n X Y\\nXn X Yn Yii\\nii=∑− ⋅ ⋅\\n∑− ∑ −2222\\n(This applies when we take zero as the assumed mean for both variables, X and Y.)140 Research Methodology\\nwhere   Xi = ith value of X variable\\n X = mean of X\\n   Yi  = ith value of Y variable\\n  Y = Mean of Y\\n    n = number of pairs of observations of X and Y\\nσX = Standard deviation of X\\n σY = Standard deviation of Y\\nIn case we use assumed means ( Ax and Ay for variables X and Y respectively) in place of true means,\\nthen Karl Person’s formula is reduced to:\\n∑⋅−∑⋅ ∑FHGIKJ\\n∑−∑FHGIKJ∑−∑FHGIKJdx dy\\nndx dy\\nn\\ndx\\nndx\\nndy\\nndy\\nnii i i\\nii ii2 2 2 2\\n∑⋅−∑⋅ ∑FHGIKJ\\n∑−∑FHGIKJ∑−∑FHGIKJdx dy\\nndx dy\\nn\\ndx\\nndx\\nndy\\nndy\\nnii i i\\niiii2 2 2 2\\nwhere         ∑= ∑−dx X Aii x bg\\n        ∑= ∑ −dy Y Aii y di\\n       ∑= ∑−dx X Aii x2 2bg\\n       ∑= ∑ −dy Y Aii y22di\\n∑⋅= ∑− −dx dy X A Y Ai i ix iy bg di\\n              n  = number of pairs of observations of X and Y.\\nThis is the short cut approach for finding ‘ r’ in case of ungrouped data. If the data happen to be\\ngrouped data (i.e., the case of bivariate frequency distribution), we shall have to write Karl Pearson’s\\ncoefficient of correlation as under:\\n∑⋅ ⋅\\n−∑⋅∑ FHGIKJ\\n∑−∑FHGIKJ∑\\n−∑FHGIKJfd x d y\\nnfd x\\nnfd y\\nn\\nfd x\\nnfd x\\nnfd y\\nnfd y\\nnij i j ii jj\\nii ii ij jj2 2 2\\nwhere fij is the frequency of a particular cell in the correlation table and all other values are defined\\nas earlier.Processing and Analysis of Data 141\\nKarl Pearson’s coefficient of correlation is also known as the product moment correlation\\ncoefficient. The value of ‘ r’ lies between ±1. Positive values of r indicate positive correlation\\nbetween the two variables (i.e., changes in both variables take place in the statement direction),\\nwhereas negative values of ‘ r’ indicate negative correlation i.e., changes in the two variables taking\\nplace in the opposite directions. A zero value of ‘ r’ indicates that there is no association between the\\ntwo variables. When r = (+) 1, it indicates perfect positive correlation and when it is (–)1, it indicates\\nperfect negative correlation, meaning thereby that variations in independent variable ( X) explain\\n100% of the variations in the dependent variable ( Y). We can also say that for a unit change in\\nindependent variable, if there happens to be a constant change in the dependent variable in the samedirection, then correlation will be termed as perfect positive. But if such change occurs in the oppositedirection, the correlation will be termed as perfect negative. The value of ‘ r’ nearer to +1 or –1\\nindicates high degree of correlation between the two variables.\\nSIMPLE REGRESSION ANALYSIS\\nRegression is the determination of a statistical relationship between two or more variables. In simpleregression, we have only two variables, one variable (defined as independent) is the cause of thebehaviour of another one (defined as dependent variable). Regression can only interpret what existsphysically i.e., there must be a physical way in which independent variable X can affect dependent\\nvariable Y. The basic relationship between X and Y is given by\\n$Yab X=+\\nwhere the symbol $Y denotes the estimated value of Y for a given value of X. This equation is known\\nas the regression equation of Y on X (also represents the regression line of Y on X when drawn on a\\ngraph) which means that each unit change in X produces a change of b in Y, which is positive for\\ndirect and negative for inverse relationships.\\nThen generally used method to find the ‘best’ fit that a straight line of this kind can give is the\\nleast-square method. To use it efficiently, we first determine\\n∑= ∑ −xX n Xii22 2\\n        ∑= ∑−yY n Yii22 2\\n      ∑= ∑− ⋅xy XY n X Yii ii\\nThen              bxy\\nxaYb Xii\\ni=∑\\n∑=−2,\\nThese measures define a and b which will give the best possible fit through the original X and Y\\npoints and the value of r can then be worked out as under:\\nrbx\\nyi\\ni=∑\\n∑2\\n2142 Research Methodology\\nThus, the regression analysis is a statistical method to deal with the formulation of mathematical\\nmodel depicting relationship amongst variables which can be used for the purpose of prediction of the\\nvalues of dependent variable, given the values of the independent variable.\\n[Alternatively, for fitting a regression equation of the type $Y = a + bX to the given values of X\\nand Y variables, we can find the values of the two constants viz., a  and b by using the following two\\nnormal equations:\\n∑= + ∑Yn ab Xii\\n     ∑= ∑ + ∑XY a X b Xii i i2\\nand then solving these equations for finding a and b values. Once these values are obtained and have\\nbeen put in the equation $Y = a + bX, we say that we have fitted the regression equation of Y on X\\nto the given data. In a similar fashion, we can develop the regression equation of X and Y viz., $X =\\na+ bX, presuming Y as an independent variable and X as dependent variable].\\nMULTIPLE CORRELATION AND REGRESSION\\nWhen there are two or more than two independent variables, the analysis concerning relationship isknown as multiple correlation and the equation describing such relationship as the multiple regressionequation. We here explain multiple correlation and regression taking only two independent variables\\nand one dependent variable (Convenient computer programs exist for dealing with a great number of\\nvariables). In this situation the results are interpreted as shown below:\\nMultiple regression equation assumes the form\\n$Y = a + b1X1 + b2X2\\nwhere X1 and X2 are two independent variables and Y being the dependent variable, and the constants\\na, b1 and b2 can be solved by solving the following three normal equations:\\n∑= +∑ + ∑Yn abX bXii i 1122\\n       ∑= ∑ + ∑ + ∑XY a X b X b XXii i i i i 11 1 12\\n21 2\\n       ∑= ∑ + ∑ + ∑XY a X b XX b Xii i i i i 22 1 1 2 2 22\\n(It may be noted that the number of normal equations would depend upon the number of\\nindependent variables. If there are 2 independent variables, then 3 equations, if there are 3 independentvariables then 4 equations and so on, are used.)\\nIn multiple regression analysis, the regression coefficients (viz., b\\n1 b2) become less reliable as\\nthe degree of correlation between the independent variables (viz., X1, X2) increases. If there is a high\\ndegree of correlation between independent variables, we have a problem of what is commonlydescribed as the problem of multicollinearity . In such a situation we should use only one set of the\\nindependent variable to make our estimate. In fact, adding a second variable, say X\\n2, that is correlated\\nwith the first variable, say X1, distorts the values of the regression coefficients. Nevertheless, the\\nprediction for the dependent variable can be made even when multicollinearity is present, but in sucha situation enough care should be taken in selecting the independent variables to estimate a dependentvariable so as to ensure that multi-collinearity is reduced to the minimum.Processing and Analysis of Data 143\\nWith more than one independent variable, we may make a difference between the collective\\neffect of the two independent variables and the individual effect of each of them taken separately.\\nThe collective effect is given by the coefficient of multiple correlation,\\nRyx x⋅12 defined as under:\\nRb YX n YX b YX n YX\\nYn Yyx xii ii\\ni⋅=∑− + ∑ −\\n∑−1211 1 22 2\\n22\\nAlternatively, we can write\\nRbx y bx y\\nYyx xii ii\\ni⋅=∑+ ∑\\n∑1211 22\\n2\\nwhere\\n x1i = (X1i – X1)\\n  x2i = (X2i – X2)\\nyi = (Yi – Y)\\nand b1 and b2 are the regression coefficients.\\nPARTIAL CORRELATION\\nPartial correlation measures separately the relationship between two variables in such a way that theeffects of other related variables are eliminated. In other words, in partial correlation analysis, weaim at measuring the relation between a dependent variable and a particular independent variable byholding all other variables constant. Thus, each partial coefficient of correlation measures the effectof its independent variable on the dependent variable. To obtain it, it is first necessary to compute thesimple coefficients of correlation between each set of pairs of variables as stated earlier. In the case\\nof two independent variables, we shall have two partial correlation coefficients denoted \\nryx x12⋅ and\\nryx x21⋅ which are worked out as under:\\nrRr\\nryx xyx x yx\\nyx12122\\n222\\n21⋅⋅=−\\n−\\nThis measures the effort of X1 on Y, more precisely, that proportion of the variation of Y not explained\\nby X2 which is explained by X1. Also,\\nrRr\\nryx xyx x y x\\nyx2112 1\\n122\\n21⋅⋅=−\\n−\\nin which X1 and X2 are simply interchanged, given the added effect of X2 on Y.144 Research Methodology\\nAlternatively , we can work out the partial correlation coefficients thus:\\nrrr r\\nrryx xyx yx x x\\nyx x x1212 1 2\\n21 21122⋅=−⋅\\n−−\\nand\\nrrr r\\nrryx xyx yx x x\\nyx x x2121 1 2\\n11 21122⋅=−⋅\\n−−\\nThese formulae of the alternative approach are based on simple coefficients of correlation (also\\nknown as zero order coefficients since no variable is held constant when simple correlation coefficientsare worked out). The partial correlation coefficients are called first order coefficients when onevariable is held constant as shown above; they are known as second order coefficients when twovariables are held constant and so on.\\nASSOCIATION IN CASE OF ATTRIBUTES\\nWhen data is collected on the basis of some attribute or attributes, we have statistics commonlytermed as statistics of attributes. It is not necessary that the objects may process only one attribute;rather it would be found that the objects possess more than one attribute. In such a situation ourinterest may remain in knowing whether the attributes are associated with each other or not. Forexample, among a group of people we may find that some of them are inoculated against small-poxand among the inoculated we may observe that some of them suffered from small-pox after inoculation.The important question which may arise for the observation is regarding the efficiency of inoculationfor its popularity will depend upon the immunity which it provides against small-pox. In other words,we may be interested in knowing whether inoculation and immunity from small-pox are associated.Technically, we say that the two attributes are associated if they appear together in a greater numberof cases than is to be expected if they are independent and not simply on the basis that they areappearing together in a number of cases as is done in ordinary life.\\nThe association may be positive or negative (negative association is also known as disassociation).\\nIf class frequency of AB, symbolically written as ( AB), is greater than the expectation of AB being\\ntogether if they are independent, then we say the two attributes are positively associated; but if theclass frequency of AB is less than this expectation, the two attributes are said to be negatively\\nassociated. In case the class frequency of AB is equal to expectation, the two attributes are considered\\nas independent i.e., are said to have no association. It can be put symbolically as shown hereunder:\\nIf \\nABA\\nNB\\nNN bgbg bg>×× , then AB are positively related/associated.\\nIf ABA\\nNB\\nNN bgbg bg<×× , then AB are negatively related/associated.\\nIf ABA\\nNB\\nNN bgbg bg=×× , then AB are independent i.e., have no association.Processing and Analysis of Data 145\\nWhere (AB) = frequency of class AB and\\nA\\nNB\\nNNbg bg××  = Expectation of AB, if A and B are independent, and N being the number of\\nitems\\nIn order to find out the degree or intensity of association between two or more sets of attributes, we\\nshould work out the coefficient of association. Professor Yule’s coefficient of association is mostpopular and is often used for the purpose. It can be mentioned as under:\\nQAB ab Ab aB\\nAB ab Ab aBAB=−+ bg b g b g b gbg b g b g b g\\nwhere,\\n QAB = Yule’s coefficient of association between attributes A and B.\\n(AB) = Frequency of class AB in which A and B are present.\\n(Ab) = Frequency of class Ab in which A is present but B is absent.\\n(aB) = Frequency of class aB in which A is absent but B is present.\\n(ab) = Frequency of class ab  in which both A and B are absent.\\nThe value of this coefficient will be somewhere between +1 and –1. If the attributes are completely\\nassociated (perfect positive association) with each other, the coefficient will be +1, and if they arecompletely disassociated (perfect negative association), the coefficient will be –1. If the attributesare completely independent of each other, the coefficient of association will be 0. The varying degreesof the coefficients of association are to be read and understood according to their positive andnegative nature between +1 and –1.\\nSometimes the association between two attributes, A and B, may be regarded as unwarranted\\nwhen we find that the observed association between A and B is due to the association of both A and\\nB with another attribute C. For example, we may observe positive association between inoculation\\nand exemption for small-pox, but such association may be the result of the fact that there is positiveassociation between inoculation and richer section of society and also that there is positive associationbetween exemption from small-pox and richer section of society. The sort of association between A\\nand B in the population of C is described as partial association as distinguished from total association\\nbetween A and B in the overall universe. We can workout the coefficient of partial association\\nbetween A and B in the population of C by just modifying the above stated formula for finding\\nassociation between A and B as shown below:\\nQABC abC AbC aBC\\nABC abC AbC aBCAB C .=−+ bg b g b g b gbg b g b g b g\\nwhere,\\nQAB.C = Coefficient of partial association between A and B in the population of C; and all other\\n     values are the class frequencies of the respective classes ( A, B, C denotes the presence\\n     of concerning attributes and a, b, c denotes the absence of concerning attributes).\\nAt times, we may come across cases of illusory association , wherein association between two\\nattributes does not correspond to any real relationship. This sort of association may be the result of146 Research Methodology\\nsome attribute, say C with which attributes A and B are associated (but in reality there is no association\\nbetween A and B). Such association may also be the result of the fact that the attributes A and B\\nmight not have been properly defined or might not have been correctly recorded. Researcher must\\nremain alert and must not conclude association between A and B when in fact there is no such\\nassociation in reality.\\nIn order to judge the significance of association between two attributes, we make use of Chi-\\nsquare test* by finding the value of Chi-square ( χ2) and using Chi-square distribution the value of\\nχ2 can be worked out as under:\\nχ22\\n=∑−OE\\nEij ij\\nijdi\\ni = 1, 2, 3 …\\nwhere j = 1, 2, 3 …\\nOij = observed frequencies\\nEij = expected frequencies.\\nAssociation between two attributes in case of manifold classification and the resulting contingencytable can be studied as explained below:\\nWe can have manifold classification of the two attributes in which case each of the two attributes\\nare first observed and then each one is classified into two or more subclasses, resulting into what iscalled as contingency table. The following is an example of 4 × 4 contingency table with two attributesA and B, each one of which has been further classified into four sub-categories.\\nTable 7.2\\n:4 × 4 Contingency Table\\nAttribute A\\nA1A2A3A4Total\\nB1(A1 B1)(A2 B1)(A3 B1)(A4 B1)(B1)\\nAttribute B B2(A1 B2)(A2 B2)(A3 B2)(A4 B2)(B2)\\nB3(A1 B3)(A2 B3)(A3 B3)(A4 B3)(B3)\\nB4(A1 B4)(A2 B4)(A3 B4)(A4 B4)(B4)\\nTotal ( A1)( A2)( A3)( A4) N\\nAssociation can be studied in a contingency table through Yule’s coefficient of association as\\nstated above, but for this purpose we have to reduce the contingency table into 2 × 2 table bycombining some classes. For instance, if we combine ( A\\n1) + (A2) to form ( A) and (A3) + (A4) to form\\n(a) and similarly if we combine ( B1) + (B2) to form (B) and ( B3) + (B4) to form (b) in the above\\ncontingency table, then we can write the table in the form of a 2 × 2 table as shown in Table 4.3\\n* See Chapter “Chi-square test” for all details.Processing and Analysis of Data 147\\nTable 7.3\\nAttribute\\nAa Total\\nAttribute B (AB)( aB)( B)\\nb (Ab)( ab)( b)\\nTotal ( A)( a) N\\nAfter reducing a contingency table in a two-by-two table through the process of combining some\\nclasses, we can work out the association as explained above. But the practice of combining classes\\nis not considered very correct and at times it is inconvenient also, Karl Pearson has suggested ameasure known as Coefficient of mean square contingency for studying association in contingency\\ntables. This can be obtained as under:\\nC\\nN=\\n+χ\\nχ2\\n2\\nwhere\\nC = Coefficient of contingency\\n    χ2\\n = Chi-square value which is =∑−OE\\nEij ij\\nijdi2\\nN = number of items.\\nThis is considered a satisfactory measure of studying association in contingency tables.\\nOTHER MEASURES\\n1. Index numbers: When series are expressed in same units, we can use averages for the purpose\\nof comparison, but when the units in which two or more series are expressed happen to be different,statistical averages cannot be used to compare them. In such situations we have to rely upon somerelative measurement which consists in reducing the figures to a common base. Once such methodis to convert the series into a series of index numbers. This is done when we express the givenfigures as percentages of some specific figure on a certain data. We can, thus, define an indexnumber as a number which is used to measure the level of a given phenomenon as compared to thelevel of the same phenomenon at some standard date. The use of index number weights more as aspecial type of average, meant to study the changes in the effect of such factors which are incapableof being measured directly. But one must always remember that index numbers measure only therelative changes.\\nChanges in various economic and social phenomena can be measured and compared through\\nindex numbers. Different indices serve different purposes. Specific commodity indices are to serveas a measure of changes in the phenomenon of that commodity only. Index numbers may measurecost of living of different classes of people. In economic sphere, index numbers are often termed as148 Research Methodology\\n‘economic barometers measuring the economic phenomenon in all its aspects either directly by\\nmeasuring the same phenomenon or indirectly by measuring something else which reflects upon themain phenomenon.\\nBut index numbers have their own limitations with which researcher must always keep himself\\naware. For instance, index numbers are only approximate indicators and as such give only a fair ideaof changes but cannot give an accurate idea. Chances of error also remain at one point or the otherwhile constructing an index number but this does not diminish the utility of index numbers for they stillcan indicate the trend of the phenomenon being measured. However, to avoid fallacious conclusions,index numbers prepared for one purpose should not be used for other purposes or for the samepurpose at other places.\\n2. Time series analysis: In the context of economic and business researches, we may obtain quite\\noften data relating to some time period concerning a given phenomenon. Such data is labelled as\\n‘Time Series’. More clearly it can be stated that series of successive observations of the givenphenomenon over a period of time are referred to as time series. Such series are usually the result ofthe effects of one or more of the following factors:\\n(i)Secular trend or long term trend that shows the direction of the series in a long period of\\ntime. The effect of trend (whether it happens to be a growth factor or a decline factor) isgradual, but extends more or less consistently throughout the entire period of time underconsideration. Sometimes, secular trend is simply stated as trend (or T).\\n(ii)Short time oscillations  i.e., changes taking place in the short period of time only and such\\nchanges can be the effect of the following factors:\\n(a)Cyclical fluctuations (or C) are the fluctuations as a result of business cycles and are\\ngenerally referred to as long term movements that represent consistently recurringrises and declines in an activity.\\n(b)Seasonal fluctuations (or S) are of short duration occurring in a regular sequence at\\nspecific intervals of time. Such fluctuations are the result of changing seasons. Usuallythese fluctuations involve patterns of change within a year that tend to be repeatedfrom year to year. Cyclical fluctuations and seasonal fluctuations taken togetherconstitute short-period regular fluctuations.\\n(c)Irregular fluctuations (or I), also known as Random fluctuations, are variations which\\ntake place in a completely unpredictable fashion.\\nAll these factors stated above are termed as components of time series and when we try to analysetime series, we try to isolate and measure the effects of various types of these factors on a series. Tostudy the effect of one type of factor, the other type of factor is eliminated from the series. The givenseries is, thus, left with the effects of one type of factor only.\\nFor analysing time series, we usually have two models; (1) multiplicative model; and (2) additive\\nmodel. Multiplicative model assumes that the various components interact in a multiplicative mannerto produce the given values of the overall time series and can be stated as under:\\nY = T × C × S × I\\nwhere\\nY = observed values of time series, T = Trend, C = Cyclical fluctuations, S = Seasonal fluctuations,\\nI = Irregular fluctuations.Processing and Analysis of Data 149\\nAdditive model considers the total of various components resulting in the given values of the\\noverall time series and can be stated as:\\nY = T + C + S + I\\nThere are various methods of isolating trend from the given series viz., the free hand method, semi-\\naverage method, method of moving averages, method of least squares and similarly there are methodsof measuring cyclical and seasonal variations and whatever variations are left over are considered asrandom or irregular fluctuations.\\nThe analysis of time series is done to understand the dynamic conditions for achieving the short-\\nterm and long-term goals of business firm(s). The past trends can be used to evaluate the success orfailure of management policy or policies practiced hitherto. On the basis of past trends, the futurepatterns can be predicted and policy or policies may accordingly be formulated. We can as well studyproperly the effects of factors causing changes in the short period of time only, once we haveeliminated the effects of trend. By studying cyclical variations, we can keep in view the impact ofcyclical changes while formulating various policies to make them as realistic as possible. Theknowledge of seasonal variations will be of great help to us in taking decisions regarding inventory,production, purchases and sales policies so as to optimize working results. Thus, analysis of timeseries is important in context of long term as well as short term forecasting and is considered a verypowerful tool in the hands of business analysts and researchers.\\nQuestions\\n1.“Processing of data implies editing, coding, classification and tabulation”. Describe in brief these fouroperations pointing out the significance of each in context of research study.\\n2.Classification according to class intervals involves three main problems viz., how many classes shouldbe there? How to choose class limits? How to determine class frequency? State how these problemsshould be tackled by a researcher.\\n3.Why tabulation is considered essential in a research study? Narrate the characteristics of a good table.\\n4.(a) How the problem of DK responses should be dealt with by a researcher? Explain.\\n(b) What points one should observe while using percentages in research studies?\\n5.Write a brief note on different types of analysis of data pointing out the significance of each.\\n6.What do you mean by multivariate analysis? Explain how it differs from bivariate analysis.\\n7.How will you differentiate between descriptive statistics and inferential statistics? Describe the important\\nstatistical measures often used to summarise the survey/research data.\\n8.What does a measure of central tendency indicate? Describe the important measures of central tendencypointing out the situation when one measure is considered relatively appropriate in comparison to othermeasures.\\n9.Describe the various measures of relationships often used in context of research studies. Explain themeaning of the following correlation coefficients:\\n(i) r\\nyx, (ii) ryx x12⋅, (iii) Ryxx⋅12\\n10.Write short notes on the following:\\n(i) Cross tabulation;\\n(ii)Discriminant analysis;150 Research Methodology\\n(iii)Coefficient of contingency;\\n(iv)Multicollinearity;\\n(v) Partial association between two attributes.\\n11.“The analysis of time series is done to understand the dynamic conditions for achieving the short-term\\nand long-term goals of business firms.” Discuss.\\n12.“Changes in various economic and social phenomena can be measured and compared through indexnumbers”. Explain this statement pointing out the utility of index numbers.\\n13.Distinguish between:\\n(i) Field editing and central editing;\\n(ii)Statistics of attributes and statistics of variables;\\n(iii)Exclusive type and inclusive type class intervals;\\n(iv)Simple and complex tabulation;\\n(v) Mechanical tabulation and cross tabulation.\\n14.“Discriminate use of average is very essential for sound statistical analysis”. Why? Answer givingexamples.\\n15.Explain how would you work out the following statistical measures often used by researchers?\\n(i) Coefficient of variation;\\n(ii)Arithmetic average;\\n(iii)Coefficient of skewness;\\n(iv)Regression equation of X on Y;\\n(v) Coefficient of \\nryx x21⋅.Appendix: Developing a Research Plan 151Appendix\\n(Summary chart concerning analysis of data)\\nAnalysis of Data\\n(in a broad general way can be categorised into)\\nProcessing of Data\\n(Preparing data for analysis)Analysis of Data\\n(Analysis proper)\\nEditing\\nCoding\\nClassification\\nTabulation\\nUsing percentagesDescriptive and Causal Analyses Inferential analysis/Statistical analysis\\nUni-dimensional\\nanalysisBivariateanalysis(Analysis oftwo variablesor attributesin a two-wayclassification)Multi-variateanalysis(simultaneousanalysis ofmore thantwo variables/attributes ina multiwayclassification)Estimation ofparameter valuesTestinghypotheses\\nPointestimateIntervalestimatePara-metrictestsNon-parametrictests orDistributionfree tests\\n(Calculation of several measuresmostly concerning one variable)\\n(i)  Measures of CentralTendency;\\n(ii)  Measures of dispersion;\\n(iii)  Measures of skewness;(iv)  One-way ANOVA, Index numbers,\\nTime series analysis;and\\n(v)   Others (including simple correlation\\nand regression in simple classificationof paired data)Simple regression* andsimple correlation (inrespect of variables)Association of attributes(through coefficient ofassociation and coefficientof contingency)Two-way ANOVAMultiple regression* and multiple correlation/partial correlation in respect of variablesMultiple discriminant analysis (in respect ofattributes)Multi-ANOVA (in respect of variables)Canonical analysis (in respect of both variablesand attributes)(Other types of analyses (such as factor analysis,cluster analysis)\\n* Regression analysis (whether simple or multiple) is ter med as Causal analysis whereas correlation analysis indicates simply c o-variation between two or\\nmore variables.152 Research Methodology\\n8\\nSampling Fundamentals\\nSampling may be defined as the selection of some part of an aggregate or totality on the basis of\\nwhich a judgement or inference about the aggregate or totality is made. In other words, it is theprocess of obtaining information about an entire population by examining only a part of it. In most ofthe research work and surveys, the usual approach happens to be to make generalisations or to drawinferences based on samples about the parameters of population from which the samples are taken.The researcher quite often selects only a few items from the universe for his study purposes. All thisis done on the assumption that the sample data will enable him to estimate the population parameters.The items so selected constitute what is technically called a sample, their selection process or techniqueis called sample design and the survey conducted on the basis of sample is described as samplesurvey. Sample should be truly representative of population characteristics without any bias so that itmay result in valid and reliable conclusions.\\nNEED FOR SAMPLING\\nSampling is used in practice for a variety of reasons such as:\\n1. Sampling can save time and money. A sample study is usually less expensive than a census\\nstudy and produces results at a relatively faster speed.\\n2. Sampling may enable more accurate measurements for a sample study is generally conducted\\nby trained and experienced investigators.\\n3. Sampling remains the only way when population contains infinitely many members.\\n4. Sampling remains the only choice when a test involves the destruction of the item under\\nstudy.\\n5. Sampling usually enables to estimate the sampling errors and, thus, assists in obtaining\\ninformation concerning some characteristic of the population.\\nSOME FUNDAMENTAL DEFINITIONS\\nBefore we talk about details and uses of sampling, it seems appropriate that we should be familiar\\nwith some fundamental definitions concerning sampling concepts and principles.Sampling Fundamentals 153\\n1. Universe/Population: From a statistical point of view, the term ‘Universe’refers to the total of\\nthe items or units in any field of inquiry, whereas the term ‘population’ refers to the total of items\\nabout which information is desired. The attributes that are the object of study are referred to ascharacteristics and the units possessing them are called as elementary units. The aggregate of suchunits is generally described as population. Thus, all units in any field of inquiry constitute universe andall elementary units (on the basis of one characteristic or more) constitute population. Quit often, wedo not find any difference between population and universe, and as such the two terms are taken asinterchangeable. However, a researcher must necessarily define these terms precisely.\\nThe population or universe can be finite or infinite. The population is said to be finite if it\\nconsists of a fixed number of elements so that it is possible to enumerate it in its totality. For instance,the population of a city, the number of workers in a factory are examples of finite populations. Thesymbol ‘N’ is generally used to indicate how many elements (or items) are there in case of a finite\\npopulation. An infinite population is that population in which it is theoretically impossible to observe allthe elements. Thus, in an infinite population the number of items is infinite i.e., we cannot have anyidea about the total number of items. The number of stars in a sky, possible rolls of a pair of dice areexamples of infinite population. One should remember that no truly infinite population of physicalobjects does actually exist in spite of the fact that many such populations appear to be very verylarge. From a practical consideration, we then use the term infinite population for  a population thatcannot be enumerated in a reasonable period of time. This way we use the theoretical concept ofinfinite population as an approximation of a very large finite population.\\n2. Sampling frame: The elementary units or the group or cluster of such units may form the basis\\nof sampling process in which case they are called as sampling units. A list containing all such sampling\\nunits is known as sampling frame. Thus sampling frame consists of a list of items from which thesample is to be drawn. If the population is finite and the time frame is in the present or past, then it ispossibe for the frame to be identical with the population. In most cases they are not identical becauseit is often impossible to draw a sample directly from population. As such this frame is either constructedby a researcher for the purpose of his study or may consist of some existing list of the population. Forinstance, one can use telephone directory as a frame for conducting opinion survey in a city. Whateverthe frame may be, it should be a good representative of the population.\\n3. Sampling design: A sample design is a definite plan for obtaining a sample from the sampling\\nframe. It refers to the technique or the procedure the researcher would adopt in selecting some\\nsampling units from which inferences about the population is drawn. Sampling design is determinedbefore any data are collected. Various sampling designs have already been explained earlier in thebook.\\n4. Statisitc(s) and parameter(s): A statistic is a characteristic of a sample, whereas a parameter is\\na characteristic of a population. Thus, when we work out certain measures such as mean, median,\\nmode or the like ones from samples, then they are called statistic(s) for they describe the characteristicsof a sample. But when such measures describe the characteristics of a population, they are knownas parameter(s). For instance, the population mean \\nµbg is a parameter,whereas the sample mean\\n(X) is a statistic. To obtain the estimate of a parameter from a statistic constitutes the prime\\nobjective of sampling analysis.\\n5. Sampling error: Sample surveys do imply the study of a small portion of the population and as\\nsuch there would naturally be a certain amount of inaccuracy in the information collected. This\\ninaccuracy may be termed as sampling error or error variance. In other words, sampling errors are154 Research Methodology\\nthose errors which arise on account of sampling and they generally happen to be random variations\\n(in case of random sampling) in the sample estimates around the true population values. The meaningof sampling error can be easily understood from the following diagram:\\nFig. 8.1\\nSampling error = Frame error + Chance error + Response error\\n(If we add measurement error or the non-sampling error to sampling error, we get total error).\\nSampling errors occur randomly and are equally likely to be in either direction. The magnitude of\\nthe sampling error depends upon the nature of the universe; the more homogeneous the universe, the\\nsmaller the sampling error. Sampling error is inversely related to the size of the sample i.e., samplingerror decreases as the sample size increases and vice-versa. A measure of the random samplingerror can be calculated for a given sample design and size and this measure is often called theprecision of the sampling plan. Sampling error is usually worked out as the product of the criticalvalue at a certain level of significance and the standard error.\\nAs opposed to sampling errors, we may have non-sampling errors which may creep in during the\\nprocess of collecting actual information and such errors occur in all surveys whether census orsample. We have no way to measure non-sampling errors.\\n6. Precision: Precision is the range within which the population average (or other parameter) will\\nlie in accordance with the reliability specified in the confidence level as a percentage of the estimate\\n± or as a numerical quantity. For instance, if the estimate is Rs 4000 and the precision desired is\\n±4%, then the true value will be no less than Rs 3840 and no more than Rs 4160. This is the range\\n(Rs 3840 to Rs 4160) within which the true answer should lie. But if we desire that the estimateResponse\\nResponse\\nerrorChanceerror\\nFrameerrorPopulation\\nSamplingframe\\nSample\\nSampling error = Frame error\\n+ chance error + response error.\\n(If we add measurement error or the non-sampling errorto sampling error, we get total error)Sampling Fundamentals 155\\nshould not deviate from the actual value by more than Rs 200 in either direction, in that case the\\nrange would be Rs 3800 to Rs 4200.\\n7. Confidence level and significance level: The confidence level or reliability is the expected\\npercentage of times that the actual value will fall within the stated precision limits. Thus, if we take\\na confidence level of 95%, then we mean that there are 95 chances in 100 (or .95 in 1) that thesample results represent the true condition of the population within a specified precision range against5 chances in 100 (or .05 in 1) that it does not. Precision is the range within which the answer mayvary and still be acceptable; confidence level indicates the likelihood that the answer will fall withinthat range, and the significance level indicates the likelihood that the answer will fall outside thatrange. We can always remember that if the confidence level is 95%, then the significance level willbe (100 – 95) i.e., 5%; if the confidence level is 99%, the significance level is (100 – 99) i.e., 1%, andso on. We should also remember that the area of normal curve within precision limits for the specifiedconfidence level constitute the acceptance region and the area of the curve outside these limits ineither direction constitutes the rejection regions.\\n*\\n8. Sampling distribution: We are often concerned with sampling distribution in sampling analysis.\\nIf we take certain number of samples and for each sample compute various statistical measuressuch as mean, standard deviation, etc., then we can find that each sample may give its own value forthe statistic under consideration. All such values of a particular statistic, say mean, together withtheir relative frequencies will constitute the sampling distribution of the particular statistic, say mean.Accordingly, we can have sampling distribution of mean, or the sampling distribution of standarddeviation or the sampling distribution of any other statistical measure. It may be noted that each itemin a sampling distribution is a particular statistic of a sample. The sampling distribution tends quitecloser to the normal distribution if the number of samples is large. The significance of samplingdistribution follows from the fact that the mean of a sampling distribution is the same as the mean ofthe universe. Thus, the mean of the sampling distribution can be taken as the mean of the universe.\\nIMPORTANT SAMPLING DISTRIBUTIONS\\nSome important sampling distributions, which are commonly used, are: (1) sampling distribution ofmean; (2) sampling distribution of proportion; (3) student’s ‘ t’ distribution; (4) F distribution; and\\n(5)Chi-square distribution. A brief mention of each one of these sampling distribution will be helpful.\\n1. Sampling distribution of mean:  Sampling distribution of mean refers to the probability distribution\\nof all the possible means of random samples of a given size that we take from a population. If\\nsamples are taken from a normal population, N \\nµσ,p di, the sampling distribution of mean would also\\nbe normal with mean µµx= and standard deviation =σpn, where µ is the mean of the population,\\nσp is the standard deviation of the population and n means the number of items in a sample. But\\nwhen sampling is from a population which is not normal (may be positively or negatively skewed),\\neven then, as per the central limit theorem, the sampling distribution of mean tends quite closer to thenormal distribution, provided the number of sample items is large i.e., more than 30. In case we wantto reduce the sampling distribution of mean to unit normal distribution i.e., N (0,1), we can write the\\n*See Chapter 9 Testing of Hypotheses I for details.156 Research Methodology\\nnormal variate zx\\nnp=−µ\\nσ for the sampling distribution of mean. This characteristic of the sampling\\ndistribution of mean is very useful in several decision situations for accepting or rejection of hypotheses.\\n2. Sampling distribution of proportion: Like sampling distribution of mean, we can as well have\\na sampling distribution of proportion. This happens in case of statistics of attributes. Assume that we\\nhave worked out the proportion of defective parts in large number of samples, each with say 100items,that have been taken from an infinite population and plot a probability distribution of the said proportions,we obtain what is known as the sampling distribution of the said proportions, we obtain what isknown as the sampling distribution of proportion. Usually the statistics of attributes correspond to theconditions of a binomial distribution that tends to become normal distribution as n becomes larger and\\nlarger. If p represents the proportion of defectives i.e., of successes and q the proportion of non-\\ndefectives i.e., of failures (or q = 1 – p) and if p is treated as a random variable, then the sampling\\ndistribution of proportion of successes has a mean = p with standard deviation \\n=⋅pq\\nn, where n\\nis the sample size. Presuming the binomial distribution approximating the normal distribution for large\\nn, the normal variate of the sampling distribution of proportion z=−\\n⋅$pp\\npq nbg, where $p (pronounced\\nas p-hat) is the sample proportion of successes, can be used for testing of  hypotheses.\\n3. Student’s t-distribution:  When population standard deviation σpdi is not known and the sample\\nis of a small size i.e.,n<30 bg , we use t distribution for the sampling distribution of mean and\\nworkout t variable as:\\ntX ns =− µσdi ej/\\nwhereσsiXX\\nn=−\\n−Σdi2\\n1\\ni.e., the sample standard deviation . t-distribution is also symmetrical and is very close to the distribution\\nof standard normal variate, z, except for small values of n. The variable t differs from z in the sense\\nthat we use sample standard deviation σsbg in the calculation of t, whereas we use standard deviation\\nof population σpdi in the calculation of z. There is a different t distribution for every possible sample\\nsize i.e., for different degrees of freedom. The degrees of freedom for a sample of size n is n – 1. As\\nthe sample size gets larger, the shape of the t distribution becomes apporximately equal to the normal\\ndistribution. In fact for sample sizes of more than 30, the t distribution is so close to the normal\\ndistribution that we can use the normal to approximate the t-distribution. But when n is small, the\\nt-distribution is far from normal but when n→α, t-distribution is identical with normal distribution.\\nThe t-distribution tables are available which give the critical values of t for different degrees of\\nfreedom at various levels of significance. The table value of t for given degrees of freedom at aSampling Fundamentals 157\\ncertain level of significance is compared with the calculated value of t from the sample data, and if\\nthe latter is either equal to or exceeds, we infer that the null hypothesis cannot be accepted.*\\n4. F distribution: If σs12bg and σs22bg are the variances of two independent samples of size n1\\nand n2 respectively taken from two independent normal populations, having the same variance,\\nσσpp12\\n22d idi= , the ratio Fss=σσ12\\n22bg b g /, where σsi XXn12\\n112\\n11 bg di=∑ − − / and\\nσsi XXn22\\n222\\n21 bg di=∑ − − / has an F distribution with n1 – 1 and n2 – 1 degrees of freedom.\\nF ratio is computed in a way that the larger variance is always in the numerator. Tables have been\\nprepared for F distribution that give critical values of F for various values of degrees of freedom for\\nlarger as well as smaller variances. The calculated value of F from the sample data is compared with\\nthe corresponding table value of F and if the former is equal to or exceeds the latter, then we infer\\nthat the null hypothesis of the variances being equal cannot be accepted. We shall make use of the F\\nratio in the context of hypothesis testing and also in the context of ANOVA technique.\\n5. Chi-square χ2ej distribution: Chi-square distribution is encountered when we deal with\\ncollections of values that involve adding up squares. Variances of samples require us to add a collection\\nof squared quantities and thus have distributions that are related to chi-square distribution. If we take\\neach one of a collection of sample variances, divide them by the known population variance andmultiply these quotients by ( n – 1), where n  means the number of items in the sample, we shall obtain\\na chi-square distribution. Thus, \\nσσspn221 / ej bg− would have the same distribution as chi-square\\ndistribution with ( n – 1) degrees of freedom. Chi-square distribution is not symmetrical and all the\\nvalues are positive. One must know the degrees of freedom for using chi-square distribution. Thisdistribution may also be used for judging the significance of difference between observed and expected\\nfrequencies and also as a test of goodness of fit. The generalised shape of \\nχ2distribution depends\\nupon the d.f. and the χ2 value is worked out as under:\\nχ22\\n1=−\\n=∑OE\\nEii\\ni ikbg\\nTables are there that give the value of χ2 for given d.f. which may be used with calculated value of\\nχ2 for relevant d.f. at a desired level of significance for testing hypotheses. We will take it up in\\ndetail in the chapter ‘Chi-square Test’.\\nCENTRAL LIMIT THEOREM\\nWhen sampling is from a normal population, the means of samples drawn from such a population are\\nthemselves normally distributed. But when sampling is not from a normal population, the size of the\\n* This aspect has been dealt with in details in the context of testing of hypotheses later in this book.158 Research Methodology\\nsample plays a critical role. When n is small, the shape of the distribution will depend largely on the\\nshape of the parent population, but as n gets large ( n > 30), the thape of the sampling distribution will\\nbecome more and more like a normal distribution, irrespective of the shape of the parent population.\\nThe theorem which explains this sort of relationship between the shape of the population distributionand the sampling distribution of the mean is known as the central limit theorem. This theorem is byfar the most important theorem in statistical inference. It assures that the sampling distribution of themean approaches normal distribtion as the sample size increases. In formal terms, we may say thatthe central limit theorem states that “the distribution of means of random samples taken from a\\npopulation having mean \\nµ and finite variance σ2 approaches the normal distribution with mean µ\\nand variance σ2/n as n goes to infinity.”1\\n“The significance of the central limit theorem lies in the fact that it permits us to use sample\\nstatistics to make inferences about population parameters without knowing anything about the shape\\nof the frequency distribution of that population other than what we can get from the sample.”2\\nSAMPLING THEORY\\nSampling theory is a study of relationships existing between a population and samples drawn fromthe population. Sampling theory is applicable only to random samples. For this purpose the populationor a universe may be defined as an aggregate of items possessing a common trait or traits. In otherwords, a universe is the complete group of items about which knowledge is sought. The universemay be finite or infinite. finite universe is one which has a definite and certain number of items, butwhen the number of items is uncertain and infinite, the universe is said to be an infinite universe.Similarly, the universe may be hypothetical or existent. In the former case the universe in fact doesnot exist and we can only imagin the items constituting it. Tossing of a coin or  throwing a dice areexamples of hypothetical universe. Existent universe is a universe of concrete objects i.e., the universewhere the items constituting it really exist. On the other hand, the term sample refers to that part ofthe universe which is selected for the purpose of investigation. The theory of sampling studies therelationships that exist between  the universe and the sample or samples drawn from it.\\nThe main problem of sampling theory is the problem of relationship between a parameter and a\\nstatistic. The theory of sampling is concerned with estimating the properties of the population fromthose of the sample and also with gauging the precision of the estimate. This sort of movement fromparticular (sample) towards general (universe) is what is known as statistical induction or statisticalinference. In more clear terms “from the sample we attempt to draw inference concerning theuniverse. In order to be able to follow this inductive method, we first follow a deductive argumentwhich is that we imagine a population or universe (finite or infinite) and investigate the behaviour ofthe samples drawn from this universe applying the laws of probability.”\\n3 The methodology dealing\\nwith all this is known as sampling theory.\\nSampling theory is designed to attain one or more of the following objectives:\\n1 Donald L. Harnett and James L. Murphy, Introductory Statistical Analysis,  p.223.\\n2 Richard I. Levin, Statistics for Management,  p. 199.\\n3 J.C. Chaturvedi: Mathematical Statistics,  p. 136.Sampling Fundamentals 159\\n(i) Statistical estimation: Sampling theory helps in estimating unknown population parameters from\\na knowledge of statistical measures based on sample studies. In other words, to obtain an estimate of\\nparameter from statistic is the main objective of the sampling theory. The estimate can either be apoint estimate or it may be an interval estimate. Point estimate is a single estimate expressed in theform of a single figure, but interval estimate has two limits viz., the upper limit and the lower limitwithin which the parameter value may lie. Interval estimates are often used in statistical induction.\\n(ii) Testing of hypotheses: The second objective of sampling theory is to enable us to decide\\nwhether to accept or reject hypothesis; the sampling theory helps in determining whether observed\\ndifferences are actually due to chance or whether they are really significant.\\n(iii) Statistical inference: Sampling theory helps in making generalisation about the population/\\nuniverse from the studies based  on samples drawn from it. It also helps in determining the accuracy\\nof such generalisations.\\nThe theory of sampling can be studied under two heads viz., the sampling of attributes and the\\nsampling of variables and that too in the context of large and small samples (By small sample iscommonly understood any sample that includes 30 or fewer items, whereas alarge sample is one inwhich the number of items is more than 30). When we study some qualitative characteristic of theitems in a population, we obtain statistics of attributes in the form of two classes; one class consistingof items wherein the attribute is present and the other class consisting of items wherein the attributeis absent. The presence of an attribute may be termed as a ‘success’ and its absence a ‘failure’.Thus, if out of 600 people selected randomly for the sample, 120 are found to possess a certainattribute and 480 are such people where the attribute is absent. In such a situation we would say that\\nsample consists of 600 items (i.e., n = 600) out of which 120 are successes and 480 failures. The\\nprobability of success would be taken as 120/600 = 0.2 (i.e., p = 0.2) and the probability of failure or\\nq = 480/600 = 0.8. With such data the sampling distribution generally takes the form of binomial\\nprobability distribution whose mean \\nµbg would be equal to np⋅ and standard deviation σpdi\\nwould be equal to npq⋅⋅. If n is large, the binomial distribution tends to become normal distribution\\nwhich may be used for sampling analysis. We generally consider the following three types of problems\\nin case of sampling of attributes:\\n(i) The parameter value may be given and it is only to be tested if an observed ‘statistic’ is its\\nestimate.\\n(ii) The parameter value is not known and we have to estimate it from the sample.\\n(iii) Examination of the reliability of the estimate i.e., the problem of finding out how far the\\nestimate is expected to deviate from the true value for the population.\\nAll the above stated problems are studied using the appropriate standard errors and the tests of\\nsignificance which have been explained and illustrated in the pages that follow.\\nThe theory of sampling can be applied in the context of statistics of variables (i.e., data relating\\nto some characteristic concerning population which can be measured or enumerated with the help ofsome well defined statistical unit) in which case the objective happens to be : ( i) to compare the\\nobserved and expected values and to find if the difference can be ascribed to the fluctuations ofsampling; ( ii) to estimate population parameters from the sample, and ( iii) to find out the degree of\\nreliability of the estimate.160 Research Methodology\\nThe tests of significance used for dealing with problems relating to large samples are different\\nfrom those used for small samples. This is so because the assumptions we make in case of large\\nsamples do not hold good for small samples. In case of large samples, we assume that the samplingdistribution tends to be normal and the sample values are approximately close to the populationvalues. As such we use the characteristics of normal distribution and apply what is known as z-test\\n*.\\nWhen n is large, the probability of a sample value of the statistic deviating from the parameter by\\nmore than 3 times its standard error is very small (it is 0.0027 as per the table giving area undernormal curve) and as such the z -test is applied to find out the degree of reliability of a statistic in case\\nof large samples. Appropriate standard errors have to be worked out which will enable us to give thelimits within which the parameter values would lie or would enable us to judge whether the difference\\nhappens to be significant or not at certain confidence levels. For instance, \\nXX±3σ would give us\\nthe range within which the parameter mean value is expected to vary with 99.73% confidence.\\nImportant standard errors generally used in case of large samples have been stated and applied in thecontext of real life problems in the pages that follow.\\nThe sampling theory for large samples is not applicable in small samples because when samples\\nare small, we cannot assume that the sampling distribution is approximately normal. As such werequire a new technique for handlng small samples, particularly when population parameters areunknown. Sir William S. Gosset (pen name Student) developed a significance test, known as Student’st-test, based on t distribution and through it made significant contribution in the theory of sampling\\napplicable in case of small samples. Student’s t-test is used when two conditions are fulfilled viz., the\\nsample size is 30 or less and the population variance is not known. While using t-test we assume that\\nthe population from which sample has been taken is normal or approximately normal, sample is arandom sample, observations are independent, there is no measurement error and that in the case oftwo samples when equality of the two population means is to be tested, we assume that the populationvariances are equal. For applying t-test, we work out the value of test statistic (i.e., ‘ t’) and then\\ncompare with the table value of t (based on ‘ t’ distribution) at certain level of significance for given\\ndegrees of freedom. If the calculated value of ‘ t’ is either equal to or exceeds the table value, we\\ninfer that the difference is significant, but if calculated value of t is less than the concerning table\\nvalue of t, the difference is not treated as significant. The following formulae are commonly used to\\ncalculate the t value:\\n(i) To test the significance of the mean of a random sample\\ntX\\nX=−µ\\nσdi\\nwhere X = Mean of the sample\\n  µ = Mean of the universe/population\\n σX = Standard error of mean worked out as under\\nσσ\\nXs\\nnXi X\\nnn ==∑−\\n−di2\\n1\\nand the degrees of freedom =  ( n – 1).\\n*The z-test may as well be applied in case of small sample provided we are given the variance of the population.Sampling Fundamentals 161\\n(ii) To test the difference between the means of two samples\\ntXX\\nXX=−\\n−12\\n12σ\\nwhere  X1 = Mean of sample one\\n  X2 = Mean of sample two\\nσXX12− = Standard error of difference between two sample means worked out as\\nσXXiiXX XX\\nnn n n12112\\n222\\n12 1 2 211\\n−=∑− + ∑−\\n+−×+di d i\\nand the d.f. = ( n1 + n2 – 2).\\n(iii) To test the significance of the coefficient of simple correlation\\ntr\\nrnt rn\\nr=\\n−×− =−\\n− 122\\n1 22or\\nwhere\\n      r = the coefficient of simple correlation\\nand the d.f. = ( n – 2).\\n(iv) To test the significance of the coefficient of partial correlation\\ntr\\nrnk trnk\\nrp\\npp\\np=\\n−×− =−\\n− 1 1 22orbg\\nwhererp is any partial coeficient of correlation\\nand the d.f. = ( n – k), n being the number of pairs of observations and k being the number\\nof variables involved.\\n(v) To test the difference in case of paired or correlated samples data (in which case t test is\\nofter described as difference test)\\ntDntDnD\\nDD=−=− µ\\nσσi.e.,0\\nwhere\\nHypothesised mean difference µDbg is taken as zero (0),\\n D = Mean of the differences of correlated sample items\\nσD = Standard deviation of differences worked out as under\\nσDiDD n\\nn=−\\n−Σ2\\n1\\n Di = Differences {i.e., Di = (Xi – Yi)}\\n  n = number of pairs in two samples and the d.f. = ( n – 1).162 Research Methodology\\nSANDLER\\x92S  A-TEST\\nJoseph Sandler has developed an alternate approach based on a simplification of t-test. His approach\\nis described as Sandler’s A-test that serves the same purpose as is accomplished by t-test relating to\\npaired data. Researchers can as well use A-test when correlated samples are employed and\\nhypothesised mean difference is taken as zero i.e., HD 0 0 :µ=. Psychologists generally use this\\ntest in case of two groups that are matched with respect to some extraneous variable(s). While using\\nA-test, we work out A-statistic that yields exactly the same results as Student’s t-test*. A-statistic is\\nfound as follows:\\nAD\\nDi\\ni==the sum of squares of the differences\\nthe squares of the sum of the differencesΣ\\nΣ2\\n2bg\\nThe number of degrees of freedom (d.f.) in A-test is the same as with Student’s t-test i.e.,\\nd.f.=n– 1, n being equal to the number of pairs. The critical value of A, at a given level of significance\\nfor given d.f., can be obtained from the table of A-statistic (given in appendix at the end of the book).\\nOne has to compare the computed value of A with its corresponding table value for drawing inference\\nconcerning acceptance or rejection of null hypothesis.** If the calculated value of A is equal to or less\\nthan the table value, in that case A-statistic is considered significant where upon we reject H0 and\\naccept Ha. But if the calculated value of A is more than its table value, then A-statistic is taken as\\ninsignificant and accordingly we accept H0. This is so because the two test statistics viz., t and A are\\ninversely related. We can write these two statistics in terms of one another in this way:\\n(i) ‘A’ in terms of  ‘ t’ can be expressed as\\nAn\\nnt n=−\\n⋅+11\\n2\\n(ii) ‘t’ in terms of ‘ A’ can be expressed as\\ntn\\nAn=−\\n⋅−1\\n1\\nComputational work concerning A-statistic is relatively simple. As such the use of A-statistic\\nresult in considerable saving of time and labour, specially when matched groups are to be comparedwith respect to a large number of variables. Accordingly researchers may replace Student’s t-test by\\nSandler’s A-test whenever correlated sets of scores are employed.\\nSandler’s A-statistic can as well be used “in the one sample case as a direct substitute for the\\nStudent t-ratio.”\\n4 This is so because Sandler’s A is an algebraically equivalent to the Student’s t.\\nWhen we use A-test in one sample case, the following steps are involved:\\n(i) Subtract the hypothesised mean of the population µHbg from each individual score ( Xi) to\\nobtain Di and then work out ΣDi.\\n* For proof, see the article, “ A test of the significance of the difference between the means of correlated measures based\\non a simplification of Student’s” by Joseph Sandler, published in the Brit. J Psych.,  1955, pp. 225–226.\\n** See illustrations 11 and 12 of Chapter 9 of this book for the purpose.\\n4 Richard P. Runyon, Inferential Statistics:  A Contemporary Approach,  p.28Sampling Fundamentals 163\\n(ii) Square each Di and then obtain the sum of such squares i.e., ΣDi2.\\n(iii) Find A-statistic as under:\\nAD Dii=Σ Σ2 2bg\\n(iv) Read the table of A-statistic for ( n – 1) degrees of freedom at a given level of significance\\n(using one-tailed or two-tailed values depending upon Ha) to find the critical value of A.\\n(v) Finally, draw the inference as under:\\nWhen calculated value of A is equal to or less than the table value, then reject H0 (or accept\\nHa) but when computed A is greater than its table value, then accept H0.\\nThe practical application/use of A-statistic in one sample case can be seen from Illustration\\nNo. 5 of Chapter IX of this book itself.\\nCONCEPT OF STANDARD ERROR\\nThe standard deviation of sampling distribution of a statistic is known as its standard error (S.E) and\\nis considered the key to sampling theory. The utility of the concept of standard error in statisticalinduction arises on account of the following reasons:\\n1. The standard error helps in testing whether the difference between observed and expected\\nfrequencies could arise due to chance. The criterion usually adopted is that if a difference is less than3 times the S.E., the difference is supposed to exist as a matter of chance and if the difference isequal to or more than 3 times the S.E., chance fails to account for it, and we conclude the differenceas significant difference. This criterion is based on the fact that at \\nX±3 (S.E.) the normal curve\\ncovers an area of 99.73 per cent. Sometimes the criterion of 2 S.E. is also used in place of 3 S.E.Thus the standard error is an important measure in significance tests or in examining hypotheses. Ifthe estimated parameter differs from the calculated statistic by more than 1.96 times the S.E., thedifference is taken as significant at 5 per cent level of significance. This, in other words, means thatthe difference is outside the limits i.e., it lies in the 5 per cent area (2.5 per cent on both sides) outsidethe 95 per cent area of the sampling distribution. Hence we can say with 95 per cent confidence thatthe said difference is not due to fluctuations of sampling. In such a situation our hypothesis that thereis no difference is rejected at 5 per cent level of significance. But if the difference is less than 1.96times the S.E., then it is considered not significant at 5 per cent level and we can say with 95 per centconfidence that it is because of the fluctuations of sampling. In such a situation our null hypothesisstands true. 1.96 is the critical value at 5 per cent level. The product of the critical value at a certainlevel of significance and the S.E. is often described as ‘Sampling Error’ at that particular level ofsignificance. We can test the difference at certain other levels of significance as well dependingupon our requirement. The following table gives some idea about the criteria at various levels forjudging the significance of the difference between observed and expected values:164 Research Methodology\\nTable 8.1 :Criteria for Judging Significance at Various Important Levels\\nSignificance Confidence Critical Sampling Confidence Difference Difference\\nlevel level value error limits Significant if Insignificant if\\n5.0% 95.0% 1.96 196.σ ±196.σ >196.σ <196.σ\\n1.0% 99.0% 2.5758 25758.σ±25758.σ>25758.σ<25758.σ\\n2.7% 99.73% 3 3σ ±3σ >3σ <3σ\\n4.55% 95.45% 2 2σ ±2σ >2σ <2σ\\nσ = Standard Error.\\n2. The standard error gives an idea about the reliability and precision of a sample. The smaller the\\nS.E., the greater the uniformity of sampling distribution and hence, greater is the reliability of sample.Conversely, the greater the S.E., the greater the difference between observed and expectedfrequencies. In such a situation the unreliability of the sample is greater.  The size of S.E., dependsupon the sample size to a great extent and it varies inversely with the size of the sample. If doublereliability is required i.e., reducing S.E. to 1/2 of its existing magnitude, the sample size should beincreased four-fold.\\n3. The standard error enables us to specify the limits within which the parameters of the population\\nare expected to lie with a specified degree of confidence. Such an interval is usually known asconfidence interval. The following table gives the percentage of samples having their mean values\\nwithin a range of population mean \\nµbg±S.E.\\nTable 8.2\\nRange Per cent Values\\nµ±1S .E . 68.27%\\nµ±2S . E . 95.45%\\nµ±3S . E . 99.73%\\nµ±196.S.E. 95.00%\\nµ±2 5758. S.E. 99.00%\\nImportant formulae  for computing the standard errors concerning various measures based on\\nsamples are as under:\\n(a)In case of sampling of attributes :\\n(i) Standard error of number of successes = npq⋅⋅\\nwhere n = number of events in each sample,\\np = probability of success in each event,\\nq = probability of failure in each event.Sampling Fundamentals 165\\n(ii)Standard error of proportion of successes pq\\nn⋅bg\\n(iii)Standard error of the difference between proportions of two samples:\\nσpp pqnn1211\\n12−=⋅ +FHGIKJ\\nwhere p = best estimate of proportion in the population and is worked out as under:\\npnp np\\nnn=+\\n+11 2 2\\n12\\n q = 1 – p\\nn1 = number of events in sample one\\nn2 = number of events in sample two\\nNote: Instead of the above formula, we use the following formula:\\nσpppq\\nnpq\\nn1211\\n122\\n2−=+\\nwhen samples are drawn from two heterogeneous populations where we cannot have the best\\nestimate of proportion in the universe on the basis of given sample data. Such a situation often arisesin study of association of attributes.\\n(b)In case of sampling of variables  (large samples ):\\n(i) Standard error of mean when population standard deviation is known:\\nσσ\\nXp\\nn=\\nwhere\\nσp = standard deviation of population\\nn = number of items in the sample\\n              Note:  This formula is used even when n is 30 or less.\\n(ii)Standard error of mean when population standard deviation is unknown:\\nσσ\\nXs\\nn=\\nwhere\\nσs = standard deviation of the sample and is worked out as under\\nσsiXX\\nn=−\\n−Σdi2\\n1\\nn = number of items in the sample.166 Research Methodology\\n(iii)Standard error of standard deviation when population standard deviation is known:\\nσσ\\nσsp\\nn=\\n2\\n(iv)Standard error of standard deviation when population standard deviation is unknown:\\nσσ\\nσss\\nn=\\n2\\nwhere     σsiXX\\nn=−\\n−Σdi2\\n1\\nn = number of items in the sample.\\n(v) Standard error of the coeficient of simple correlation:\\n   σrr\\nn=−12\\nwhere\\nr = coefficient of simple correlation\\nn = number of items in the sample.\\n(vi)Standard error of difference between means of two samples:\\n(a) When two samples are drawn from the same population:\\nσσXX pi nn−=+FHGIKJ22\\n1211\\n(If  σp is not known, sample standard deviation for combined samples σs12⋅ ej*\\n may be substituted.)\\n(b) When two samples are drawn from different populations:\\nσσσ\\nXXpp\\nnn12122\\n12\\n2−=+di di\\n(If σp1and σp2 are not known, then in their places σs1 and σs2 respectively may\\nbe substituted.)\\n(c)In case of sampling of variables  (small samples ):\\n(i) Standard error of mean when σp is unknown:Sampling Fundamentals 167\\nσσσ\\nsssnn n X X n X X\\nnn1212 12\\n22\\n11 1 22\\n22 1 22\\n12⋅=++ − + −\\n+⋅⋅ di di d i d i\\nwhere  XnX nX\\nnn1211 2 2\\n12⋅=+\\n+di d i\\nNote:    (1)   All these formulae apply in case of infinite population. But in case of finite population where sampling is done\\nwithout replacement and the sample is more than 5% of the population, we must as well use the finite\\npopulation multiplier in our standard error formulae. For instance, S.E.X in case of finite population will be as\\nunder:\\nSE\\nnNn\\nNXp=⋅−\\n−σ bgbg1\\nIt may be remembered that in cases in which the population is very large in relation to the size of the sample,\\nthe finite population multiplier is close to one and has little effect on the calculation of S.E. As such whensampling fraction is less than 0.5, the finite population multiplier is generally not used.\\n(2) The use of all the above stated formulae has been explained and illustrated in context of testing of hypotheses\\nin chapters that follow.\\nσσ\\nXsi\\nnXX\\nn\\nn==−\\n−Σdi2\\n1\\n(ii)Standard error of difference between two sample means when σp is unknown\\n        σXXiiXX XX\\nnn n n12112\\n222\\n12 1 2 211\\n−=−+ −\\n+−⋅+ΣΣdi d i\\nESTIMATION\\nIn most statistical research studies, population parameters are usually unknown and have to beestimated from a sample. As such the methods for estimating the population parameters assume animportant role in statistical anlysis.\\nThe random variables (such as \\nXs andσ2) used to estimate population parameters, such as\\nµσandp2 are conventionally called as ‘ estimators ’, while specific values of these (such as X=105\\nor σs22144=.) are referred to as ‘ estimates ’ of the population parameters. The estimate of a\\npopulation parameter may be one single value or it could be a range of values. In the former case itis referred as point estimate , whereas in the latter case it is termed as interval estimate . The168 Research Methodology\\nresearcher usually makes these two types of estimates through sampling analysis. While making\\nestimates of population parameters, the researcher can give only the best point estimate or else heshall have to speak in terms of  intervals and probabilities for he can never estimate with certainty theexact values of population parameters. Accordingly he must know the various properties of a goodestimator so that he can select appropriate estimators for his study. He must know that a goodestimator possesses the following properties:\\n(i) An estimator should on the average be equal to the value of the parameter being estimated.\\nThis is popularly known as the property of unbiasedness . An estimator is said to be\\nunbiased if the expected value of the estimator is equal to the parameter being estimated.\\nThe sample mean \\nXdi is he most widely used estimator because of the fact that it provides\\nan unbiased estimate of the population mean µbg.\\n(ii) An estimator should have a relatively small variance. This means that the most efficient\\nestimator, among a group of unbiased estimators, is one which has the smallest variance.\\nThis property is technically described as the property of efficiency .\\n(iii) An estimator should use as much as possible the information available from the sample.\\nThis property is known as the property of sufficiency .\\n(iv) An estimator should approach the value of population parameter as the sample size becomes\\nlarger and larger. This property is referred to as the property of consistency .\\nKeeping in view the above stated properties, the researcher must select appropriate\\nestimator(s) for his study. We may now explain the methods which will enable us to estimatewith reasonable accuracy the population mean and the population proportion, the two widelyused concepts.\\nESTIMATING THE POPULATION MEAN ()µ\\nSo far as the point estimate is concerned, the sample mean X is the best estimator of the population\\nmean, µ, and its sampling distribution, so long as the sample is sufficiently large, approximates the\\nnormal distribution. If we know the sampling distribution of X, we can make statements about any\\nestimate that we may make from the sampling information. Assume that we take a sample of 36\\nstudents and find that the sample yields an arithmetic mean of 6.2 i.e., X=62.. Replace these\\nstudent names on the population list and draw another sample of 36 randomly and let us assume that\\nwe get a mean of 7.5 this time. Similarly a third sample may yield a mean of 6.9; fourth a mean of 6.7,and so on. We go on drawing such samples till we accumulate a large number of means of samplesof 36. Each such sample mean is a separate point estimate of the population mean. When suchmeans are presented in the form of a distribution, the distribution happens to be quite close to normal.This is a characteristic of a distribution of sample means (and also of other sample statistics). Evenif the population is not normal, the sample means drawn from that population are dispersed aroundthe parameter in a distribution that is generally close to normal; the mean of the distribution of samplemeans is equal to the population mean.\\n5 This is true in case of large samples as per the dictates of the\\ncentral limit theorem. This relationship between a population distribution and a distribution of sample\\n5 C. William Emory, Business Research Methods,  p.145Sampling Fundamentals 169\\nmean is critical for drawing inferences about parameters. The relationship between the dispersion of\\na population distribution and that of the sample mean can be stated as under:\\nσσ\\nXp\\nn=\\nwhereσX = standard error of mean of a given sample size\\n σp = standard deviation of the population\\n     n = size of the sample.\\nHow to find σp when we have the sample data only for our analysis? The answer is that we must\\nuse some best estimate of σp and the best estimate can be the standard deviation of the sample,\\nσs. Thus, the standard error of mean can be worked out as under:6\\nσσ\\nXs\\nn=\\nwhere σsiXX\\nn=−\\n−Σdi2\\n1\\nWith the help of this, one may give interval estimates about the parameter in probabilistic terms(utilising the fundamental characteristics of the normal distribution). Suppose we take one sample of\\n36 items and work out its mean \\nXdi to be equal to 6.20 and its standard deviation σsbg to be equal\\nto 3.8, Then the best point estimate of population mean µbg is 6.20. The standard error of mean\\nσXch would be 38 36 38 6 0663.. / .== . If we take the interval estimate of µ to be\\nXX±196.σchor 62 0 12 4..±or from 4.96 to 7.44, it means that there is a 95 per cent chance that\\nthe population mean is within 4.96 to 7.44 interval. In other words, this means that if we were to take\\na complete census of all items in the population, the chances are 95 to 5 that we would find thepopulation mean lies between 4.96 to 7.44\\n*. In case we desire to have an estimate that will hold for\\na much smaller range, then we must either accept a smaller degree of confidence in the results ortake a sample large enough to provide this smaller interval with adequate confidence levels. Usuallywe think of increasing the sample size till we can secure the desired interval estimate and the degreeof confidence.\\nIllustration 1\\nFrom a random sample of 36 New Delhi civil service personnel, the mean age and the sample\\nstandard deviation were found to be 40 years and 4.5 years respectively. Construct a 95 per centconfidence interval for the mean age of civil servants in New Delhi.\\nSolution:  The given information can be written as under:\\n6 To make the sample standard deviation an unbiased estimate of the population, it is necessary to divide ΣXXi− di2\\nby (n – 1) and not by simply ( n).\\n* In case we want to change the degree of confidence in the interval estimate, the same can be done using the table of areas\\nunder the normal curve.170 Research Methodology\\nn = 36\\n     X=40 years\\n    σs=45. years\\nand the standard variate, z, for 95 per cent confidence is 1.96 (as per the normal curve area table).\\nThus, 95 per cent confidence inteval for the mean age of population is:\\nXz\\nns±σ\\nor      40 19645\\n36±..\\nor         40 196 0 75±..bg bg\\nor      40 147±. years\\nIllustration 2\\nIn a  random selection of 64 of the 2400 intersections in a small city, the mean number of scooter\\naccidents per year was 3.2 and the sample standard deviation was 0.8.\\n(1) Make an estimate of the standard deviation of the population from the sample standard\\ndeviation.\\n(2) Work out the standard error of mean for this finite population.\\n(3) If the desired confidence level is .90, what will be the upper and lower limits of the confidence\\ninterval for the mean number of accidents per intersection per year?\\nSolution:  The given information can be written as under:\\n   N = 2400 (This means that population is finite)\\n   n = 64\\n X=32.\\nσs=08.\\nand the standard variate ( z) for 90 per cent confidence is 1.645 (as per the normal curve area table).\\nNow we can answer the given questions thus:\\n(1) The best point estimate of the standard deviation of the population is the standard deviation\\nof the sample itself.\\nHence,\\n$ . σσp s== 08\\n(2) Standard error of mean for the given finite population is as follows:\\n          σσ\\nXs\\nnNn\\nN=×−\\n−1Sampling Fundamentals 171\\n=×−\\n−08\\n642400 64\\n2400 1.\\n       =×08\\n642336\\n2399.\\n       = (0.1) (.97)\\n       = .097\\n(3) 90 per cent confidence interval for the mean number of accidents per intersection per year\\nis as follows:\\nXz\\nnNn\\nNs±×−\\n−RS|\\nT|UV|\\nW|σ\\n1\\n=±3 2 1645 097... bg b g\\n                       =±32 1 6.. accidents per intersection.\\nWhen the sample size happens to be a large one or when the population standard deviation is\\nknown, we use normal distribution for detemining confidence intervals for population mean as stated\\nabove. But how to handle estimation problem when population standard deviation is not known and\\nthe sample size is small (i.e., when n<30)? In such a situation, normal distribution is not appropriate,\\nbut we can use t-distribution for our purpose. While using t-distribution, we assume that population is\\nnormal or approximately normal. There is a different t-distribution for each of the possible degrees of\\nfreedom. When we use t-distribution for estimating a population mean, we work out the degrees of\\nfreedom as equal to n – 1, where n means the size of the sample and then can look for cirtical value\\nof ‘t’ in the t-distribution table for appropriate degrees of freedom at a given level of significance. Let\\nus illustrate this by taking an example.\\nIllustration 3\\nThe foreman of ABC mining company has estimated the average quantity of iron ore extracted to be\\n36.8 tons per shift and the sample standard deviation to be 2.8 tons per shift, based upon a random\\nselection of 4 shifts. Construct a 90 per cent confidence interval around this estimate.\\nSolution:  As the standard deviation of population is not known and the size of the sample is small, we\\nshall use t-distribution for finding the required confidence interval about the population mean. The\\ngiven information can be written as under:\\n  X=36 8. tons per shift\\nσs=28. tons per shift\\n          n = 4\\ndegrees of freedom = n – 1 = 4 – 1 = 3 and the critical value of ‘ t’ for 90 per cent confidence interval\\nor at 10 per cent level of significance is 2.353 for 3 d.f. (as per the table of t-distribution).172 Research Methodology\\nThus, 90 per cent confidence interval for population mean is\\nXt\\nns±σ\\n=±36 8 2 35328\\n4...\\n=±368 2 353 14.. . bg b g\\n    =±36 8 3 294..  tons per shift.\\nESTIMATING POPULATION PROPORTION\\nSo far as the point estimate is concerned, the sample proportion ( p) of units that have a particular\\ncharacteristic is the best estimator of the population proportion $pbg and its sampling distribution, so\\nlong as the sample is sufficiently large, approximates the normal distribution. Thus, if we take a\\nrandom sample of 50 items and find that 10 per cent of these are defective i.e., p = .10, we can use\\nthis sample proportion ( p = .10) as best estimator of the population proportion  $ . pp== 10 bg . In\\ncase we want to construct confidence  interval to estimate a  population poportion, we should use the\\nbinomial distribution with the mean of population µbg=⋅np, where n = number of trials, p =\\nprobability of a success in any of the trials and population standard deviation =npq.  As the\\nsample size increases, the binomial distribution approaches normal distribution which we can use for\\nour purpose of estimating a population proportion. The mean of the sampling distribution of the\\nproportion of successes ()µp is taken as equal to p and the standard deviation for the proportion of\\nsuccesses, also known as the standard error of proportion, is taken as equal to pq n. But when\\npopulation proportion is unknown, then we can estimate the population parameters by substituting the\\ncorresponding sample statistics p and q in the formula for the standard error of proportion to obtain\\nthe estimated standard error of the proportion as shown below:\\nσppq\\nn=\\nUsing the above estimated standard error of proportion, we can work out the confidence interval\\nfor population proportion thus:\\npzpq\\nn±⋅\\nwhere\\np = sample proportion of successes;\\nq = 1 – p;\\nn = number of trials (size of the sample);\\nz = standard variate for given confidence level (as per normal curve area table).Sampling Fundamentals 173\\nWe now illustrate the use of this formula by an example.\\nIllustration 4\\nA market research survey in which 64 consumers were contacted states that 64 per cent of all\\nconsumers of a certain product were motivated by the product’s advertising. Find the confidencelimits for the proportion of consumers motivated by advertising in the population, given a confidencelevel equal to 0.95.\\nSolution:  The given information can be written as under:\\nn = 64\\np = 64% or .64\\nq = 1 – p = 1 – .64 = .36\\nand the standard variate (z ) for 95 per cent confidence is 1.96 (as per the normal curve area table).\\nThus, 95 per cent confidence interval for the proportion of consumers motivated by advertising in\\nthe population is:\\n  \\npzpq\\nn±⋅\\n            =±....64 19606 4 03 6\\n64bg bg\\n         =±.. .64 196 06 bg b g\\n         =±..64 1176\\nThus, lower confidence limit is 52.24%\\n   upper confidence limit is 75.76%\\nFor the sake of convenience, we can summarise the formulae which give confidence intevals\\nwhile estimating population mean µbg and the population proportion $pbg as shown in the following\\ntable.\\nTable 8.3 :Summarising Important Formulae Concerning Estimation\\nIn case of infinite In case of finite population*\\npopulation\\nEstimating population mean Xz\\nnp±⋅σXz\\nnNn\\nNp±⋅ ×−\\n−σ\\n1\\nµbg when we know σp\\nEstimating population mean Xz\\nns±⋅σXz\\nnNn\\nNs±⋅ ×−\\n−σ\\n1\\nµbg when we do not know σp\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○174 Research Methodology\\nIn case of infinite In case of finite population*\\npopulation\\nand use σs as the best estimate\\nof σp and sample is large (i.e.,\\nn > 30)\\nEstimating population mean Xt\\nns±⋅σXt\\nnNn\\nNs±⋅ ×−\\n−σ\\n1\\nµbg when we do not know σp\\nand use σs as the best estimate\\nof σp and sample is small (i.e.,\\nn<30)\\nEstimating the population pzpq\\nn±⋅ pzpq\\nnNn\\nN±⋅ ×−\\n−1\\nproportion $pbg when p is not\\nknown but the sample is large.\\n* In case of finite population, the standard error has to be multiplied by the finite population multiplier viz.,\\nNnN−− bg b g 1.\\nSAMPLE SIZE AND ITS DETERMINATION\\nIn sampling analysis the most ticklish question is: What should be the size of the sample or how large\\nor small should be ‘ n’? If the sample size (‘ n’) is too small, it may not serve to achieve the objectives\\nand if it is too large, we may incur huge cost and waste resources. As a general rule, one can say thatthe sample must be of an optimum size i.e., it should neither be excessively large nor too small.Technically, the sample size should be large enough to give a confidence inerval of desired width andas such the size of the sample must be chosen by some logical process before sample is taken fromthe universe. Size of the sample should be determined by a researcher keeping in view the followingpoints:\\n(i)Nature of universe: Universe may be either homogenous or heterogenous in nature. If\\nthe items of the universe are homogenous, a small sample can serve the purpose. But if theitems are heteogenous, a large sample would be required. Technically, this can be termedas the dispersion factor.\\n(ii)Number of classes proposed: If many class-groups (groups and sub-groups) are to be\\nformed, a large sample would be required because a small sample might not be able to givea reasonable number of items in each class-group.\\n(iii)Nature of study: If items are to be intensively and continuously studied, the sample should\\nbe small. For a general survey the size of the sample should be large, but a small sample isconsidered appropriate in technical surveys.\\n(iv)Type of sampling: Sampling technique plays an important part in determining the size of the\\nsample. A small random sample is apt to be much superior to a larger but badly selectedsample.Sampling Fundamentals 175\\n(v)Standard of accuracy and acceptable confidence level: If the standard of acuracy or\\nthe level of precision is to be kept high, we shall require relatively larger sample. For\\ndoubling the accuracy for a fixed significance level, the sample size has to be increasedfourfold.\\n(vi)Availability of finance: In prctice, size of the sample depends upon the amount of money\\navailable for the study purposes. This factor should be kept in view while determining thesize of sample for large samples result in increasing the cost of sampling estimates.\\n(vii)Other considerations: Nature of units, size of the population, size of questionnaire, availability\\nof trained investigators, the conditions under which the sample is being conducted, the timeavailable for completion of the study are a few other considerations to which a researchermust pay attention while selecting the size of the sample.\\nThere are two alternative approaches for determining the size of the sample. The first approach\\nis “to specify the precision of estimation desired and then to determine the sample size necessary toinsure it” and the second approach “uses Bayesian statistics to weigh the cost of additional informationagainst the expected value of the additional information.”\\n7 The first approach is capable of giving a\\nmathematical solution, and as such is a frequently used technique of determining ‘ n’. The limitation\\nof this technique is that it does not analyse the cost of gathering information vis-a-vis the expected\\nvalue of information. The second approach is theoretically optimal, but it is seldom used because ofthe difficulty involved in measuring the value of information. Hence, we shall mainly concentratehere on the first approach.\\nDETERMINATION OF SAMPLE SIZE THROUGH THE APPROACHBASED ON PRECISION RATE AND CONFIDENCE LEVEL\\nTo begin with, it can be stated that whenever a sample study is made, there arises some samplingerror which can be controlled by selecting a sample of adequate size. Researcher will have tospecify the precision that he wants in respect of his estimates concerning the population parameters.\\nFor instance, a researcher may like to estimate the mean of the universe within \\n±3 of the true mean\\nwith 95 per cent confidence. In this case we will say that the desired precision is ±3, i.e., if the\\nsample mean is Rs 100, the true value of the mean will be no less than Rs 97 and no more than\\nRs103. In other words, all this means that the acceptable error, e, is equal to 3. Keeping this in view,\\nwe can now explain the determination of sample size so that specified precision is ensured.\\n(a) Sample size when estimating a mean:  The confidence interval for the universe mean, µ, is\\ngiven by\\nXz\\nnp±σ\\nwhere X= sample mean;\\n  z = the value of the standard variate at a given confidence level (to be read from the table\\n      giving the areas under normal curve as shown in appendix) and it is 1.96 for a 95%\\n       confidence level;\\n  n = size of the sample;\\n7 Rodney D. Johnson and Bernard R. Siskih, Quantitative Techniques for Business Decisions,  p. 374–375.176 Research Methodology\\nσp= standard deviation of the popultion (to be estimated from past experience or on the basis of\\n  a trial sample). Suppose, we have σp=48. for our purpose.\\nIf the difference between µ and X or the acceptable error is to be kept with in ±3 of the sample\\nmean with 95% confidence, then we can express the acceptable error, ‘ e’ as equal to\\nez\\nnp=⋅σ\\n or 31 9 648=..\\nn\\nHence, n== ≅196 48\\n398 3 4 1 022\\n2...bg b g\\nbg.\\nIn a general way, if we want to estimate µ in a population with standard deviation σp  with an\\nerror no greater than ‘ e’ by calculating a confidence interval with confidence corresponding to z, the\\nnecessary sample size, n, equals as under:\\nnz\\ne=22\\n2σ\\nAll this is applicable whe the population happens to be infinite. Bu in case of finite population, the\\nabove stated formula for determining sample size will become\\nnzN\\nNe zp\\np=⋅⋅\\n−+22\\n22 21σ\\nσ*\\nbg\\n* In case of finite population the confidence interval for µ is given by\\nXz\\nnNn\\nNp±×−\\n−σ bgbg 1\\nwhere Nn N−− bg bg 1 is the finite population multiplier and all other terms mean the same thing as stated above.\\nIf the precision is taken as equal to ‘ e’ then we have\\nez\\nnNn\\nNp=×−\\n−σ bgbg\\n1\\nor               eznNn\\nNp 222\\n1=×−\\n−σ\\nor eNzN\\nnzn\\nnpp 222 22\\n1−= − bgσσ\\nor   eN zzN\\nnpp 22 222\\n1−+ = bg σσ\\nor nzN\\neN zp\\np=⋅⋅\\n−+22\\n22 21σ\\nσ bg\\nor nzN\\nNe zp\\np=⋅⋅\\n−+22\\n22 21σ\\nσ bg\\nThis is how we obtain the above stated formula for determining ‘ n’ in the case of infinite population given the precision\\nand confidence level.Sampling Fundamentals 177\\nwhere\\nN = size of population\\nn = size of sample\\ne = acceptable error (the precision)\\n  σp = standard deviation of population\\nz = standard variate at a given confidence level.\\nIllustration 5\\nDetermine the size of the sample for estimating the true weight of the cereal containers for the\\nuniverse with N = 5000 on the basis of the following information:\\n(1) the variance of weight = 4 ounces on the basis of past records.\\n(2) estimate should be within 0.8 ounces of the true average weight with 99% probability.\\nWill there be a change in the size of the sample if we assume infinite population in the given\\ncase? If so, explain by how much?\\nSolution:  In the given problem we have the following:\\nN = 5000;\\n   σp = 2 ounces (since the variance of weight = 4 ounces);\\ne = 0.8 ounces (since the estimate should be within 0.8 ounces of the true average weight);\\nz = 2.57 (as per the table of area under normal curve for the given confidence level of 99%).\\nHence, the confidence interval for µ is given by\\nXz\\nnNn\\nNp±⋅ ⋅−\\n−σ\\n1\\nand accordingly the sample size can be worked out as under:\\nnzN\\nNe zp\\np=⋅⋅\\n−+22\\n22 21σ\\nσ bg\\n        =⋅⋅\\n−+2 57 5000 2\\n5000 1 0 8 2 57 222\\n22 2.\\n..bg b g b g\\nb g b gbg b g\\n        =+== ≅132098\\n3199 36 26 4196132098\\n3225779640 95 41.. ..\\nHence, the sample size (or n) = 41 for the given precision and confidence level in the above\\nquestion with finite population. But if we take population to be infinite, the sample size will be worked\\nout as under:178 Research Methodology\\nnz\\nep=22\\n2σ\\n      == = −257 2\\n08264196\\n0644128 4122\\n2.\\n..\\n..~bg b g\\nbg\\nThus, in the given case the sample size remains the same even if we assume infinite population.\\nIn the above illustration, the standard deviation of the population was given, but in many cases\\nthe standard deviation of the population is not available. Since we have not yet taken the sample and\\nare in the stage of deciding how large to make it (sample), we cannot estimate the populaion standarddeviation. In such a situation, if we have an idea about the range (i.e., the difference between thehighest and lowest values) of the population, we can use that to get a crude estimate of the standarddeviation of the population for geting a working idea of the required sample size. We can get the saidestimate of standard deviation as follows:\\nSince 99.7 per cent of the area under normal curve lies within the range of \\n±3 standard deviations,\\nwe may say that these limits include almost all of the distribution. Accordingly,  we can say that the\\ngiven range equals 6 standard deviations because of ±3. Thus, a rough estimate of the population\\nstandard deviation would be:\\n6$σ= the given range\\nor     $σ=the given ran ge\\n6\\nIf the range happens to be, say Rs 12, then\\n          $σ= =12\\n6Rs 2.\\nand this estimate of standard deviation, $σ, can be used to determine the sample size in the formulae\\nstated above.\\n(b) Sample size when estimating a percentage or proportion: If we are to find the sample size for\\nestimating a proportion, our reasoning remains similar to what we have said in the context of estimating\\nthe mean. First of all, we shall have to specify the precision and the confidence level and then we willwork out the sample size as under:\\nSince the confidence interval for universe proportion, \\n$p is given by\\npzpq\\nn±⋅⋅\\nwherep = sample proportion, q = 1 – p;\\nz = the value of the standard variate at a given confidence level and to be worked out from\\n     table showing area under Normal Curve;\\nn = size of sample.Sampling Fundamentals 179\\nSince $p is actually what we are trying to estimate, then what value we should assign to it ? One\\nmethod may be to take the value of p = 0.5 in which case ‘ n’ will be the maximum and the sample\\nwill yield at least the desired precision. This will be the most conservative sample size. The other\\nmethod may be to take an initial estimate of p which may either be based on personal judgement or\\nmay be the result of a pilot study. In this context it has been suggested that a pilot study of somethinglike 225 or more items may result in a reasonable approximation of p value.\\nThen with the given precision rate, the acceptable error, ‘ e’, can be expressed as under:\\nezpq\\nn=⋅\\nor ezpq\\nn22=\\nor   nzp q\\ne=⋅⋅2\\n2\\nThe formula gives the size of the sample in case of infinite population when we are to estimate\\nthe proportion in the universe. But in case of finite population the above stated formula will bechanged as under:\\nnzp q N\\neN zp q=⋅⋅⋅\\n−+ ⋅⋅2\\n221 bg\\nIllustration 6\\nWhat should be the size of the sample if a simple random sample from a population of 4000 items is\\nto be drawn to estimate the per cent defective within 2 per cent of the true value with 95.5 per centprobability? What would be the size of the sample if the population is assumed to be infinite in thegiven case?\\nSolution:  In the given question we have the following:\\nN = 4000;\\ne = .02 (since the estimate should be within 2% of true value);\\nz = 2.005 (as per table of area under normal curve for the given confidence level of 95.5%).\\nAs we have not been given the p value being the proportion of defectives in the universe, let us\\nassume it to be p = .02 (This may be on the basis of our experience or on the basis of past data or\\nmay be the result of a pilot study).\\nNow we can determine the size of the sample using all this information for the given question as\\nfollows:\\nnzp q N\\neN zp q=⋅⋅⋅\\n−+ ⋅⋅2\\n221 bg180 Research Methodology\\n=−\\n−+ −2 005 02 1 02 4000\\n02 4000 1 2 005 02 1 022\\n22.. .\\n.. . .bg b g b g b g\\nbg b gb g bg b g\\n=+==3151699\\n15996 07883151699\\n1678418778 188.\\n...\\n..~\\nBut if the population happens to be infinite, then our sample size will be as under:\\nnzp q\\ne=⋅⋅2\\n2\\n    =⋅− 2 005 02 1 02\\n022\\n2...\\n.bg b g b g\\nbg\\n    ==.\\n..~0788\\n000419698 197\\nIllustration 7\\nSuppose a certain hotel management is interested in determining the percentage of the hotel’s guests\\nwho stay for more than 3 days. The reservation manager wants to be 95 per cent confident that the\\npercentage has been estimated to be within ±3% of the true value. What is the most conservative\\nsample size needed for this problem?\\nSolution:  We have been given the following:\\nPopulation is infinite;\\ne = .03 (since the estimate should be within 3% of the true value);\\nz = 1.96 (as per table of area under normal curve for the given confidence level of 95%).\\nAs we want the most conservative sample size we shall  take  the  value of  p = .5 and q = .5. Using\\nall this information, we can determine the sample size for the given problem as under:\\nnzp q\\ne=2\\n2\\n                                                              =⋅−==196 5 1 5\\n039604\\n0009106711 10672\\n2...\\n....~bg b g b g\\nbg\\nThus, the most conservative sample size needed for the problem is = 1067.\\nDETERMINATION OF SAMPLE SIZE THROUGH\\nTHE APPROACH BASED ON BAYESIAN STATISTICS\\nThis approach of determining ‘ n’utilises Bayesian statistics and as such is known as Bayesian approach.\\nThe procedure for finding the optimal value of ‘ n’ or the size of sample under this approach is as under:Sampling Fundamentals 181\\n(i) Find the expected value of the sample information (EVSI)* for every possible n;\\n(ii)Also workout reasonably approximated cost of taking a sample of every possible n;\\n(iii)Compare the EVSI and the cost of  the sample for every possible n. In other words,\\nworkout the expected net gain (ENG) for every possible n as stated below:\\nFor a given sample size ( n):\\n(EVSI) – (Cost of sample) = (ENG)\\n(iv)Form (iii) above the optimal sample size, that value of n which maximises the difference\\nbetween the EVSI and the cost of the sample, can be determined.\\nThe computation of EVSI for every possible n and then comparing the same with the respective\\ncost is often a very cumbersome task and is generally feasible with mechanised or computer help.\\nHence, this approach although being theoretically optimal is rarely used in practice.\\nQuestions\\n1.Explain the meaning and significance of the concept of “Standard Error’ in sampling analysis.\\n2.Describe briefly the commonly used sampling distributions.\\n3.State the reasons why sampling is used in the context of research studies.\\n4.Explain the meaning of the following sampling fundamentals:\\n(a) Sampling frame;\\n(b) Sampling error;\\n(c) Central limit theorem;\\n(d) Student’s t distribution;\\n(e) Finite population multiplier.\\n5.Distinguish between the following:\\n(a) Statistic and parameter;\\n(b) Confidence level and significance level;\\n(c) Random sampling and non-random sampling;\\n(d) Sampling of attributes and sampling of variables;\\n(e) Point estimate and interval estimation.\\n6.Write a brief essay on statistical estimation.\\n7.500 articles were selected at random out of a batch containing 10000 articles and 30 were found defective.How many defective articles would you reasonably expect to find in the whole batch?\\n8.In a sample of 400 people, 172 were males. Estimate the population proportion at 95% confidence level.\\n9.A smaple of 16 measurements of the diameter of a sphere gave a mean \\nX=45 8. inches and a standard\\ndeviation σs=00 8. inches. Find (a) 95%, and (b) 99% confidence limits for the actual diameter.\\n10.A random sample of 500 pineapples was taken from a large consignment and 65 were found to be bad.Show that the standard error of the population of bad ones in a sample of this size is 0.015 and also showthat the percentage of bad pineapples in the consignment almost certainly lies between 8.5 and 17.5.\\n* EVSI happens to be the difference between the expected value with sampling and the expected value without sampling.\\nFor finding EVSI we have to use Bayesian statistics for which one should have a thorough knowledge of Bayesianprobability analysis which can be looked into any standard text book on statistics.182 Research Methodology\\n11.From a packet containing iron nails, 1000 iron nails were taken at random and out of them 100 were found\\ndefective. Estimate the percentage of defective iron nails in the packet and assign limits within which thepercentage probably lies.\\n12.A random sample of 200 measurements from an infinite population gave a mean value of 50 and astandard deviation of 9. Determine the 95% confidence interval for the mean value of the population.\\n13.In a random sample of 64 mangoes taken from a large consignment, some were found to be bad. Deducethat the percentage of bad mangoes in the consignment almost certainly lies between 31.25 and 68.75given that the standard error of the proportion of bad mangoes in the sample 1/16.\\n14.A random sample of 900 members is found to have a mean of 4.45 cms. Can it be reasonably regarded asa sample from a large population whose mean is 5 cms and variance is 4 cms?\\n15.It is claimed that Americans are 16 pounds overweight on average. To test this claim, 9 randomly selectedindividuals were examined and the average excess weight was found to be 18 pounds. At the 5% level ofsignificance, is there reason to believe the claim of 16 pounds to be in error?\\n16.The foreman of a certain mining company has estimated the average quantity of ore extracted to be 34.6tons per shift and the sample standard deviation to be 2.8 tons per shift, based upon a random selectionof 6 shifts. Construct 95% as well as 98% confidence interval for the average quantity of ore extracted pershift.\\n17.A sample of 16 bottles has a mean of 122 ml. (Is the sample representative of a large consignment with amean of 130 ml.) and a standard deviation of 10 ml.? Mention the level of significance you use.\\n18.A sample of 900 days is taken from meteorological records of a certain district and 100 of them are foundto be foggy. What are the probable limits to the percentage of foggy days in the district?\\n19.Suppose the following ten values represent random observations from a normal parent population:\\n2, 6, 7, 9, 5, 1, 0, 3, 5, 4.\\nConstruct a 99 per cent confidence interval for the mean of the parent population.\\n20.A survey result of 1600 Playboy readers indicates that 44% finished at least three years of college. Set98% confidence limits on the true proportion of all Playboy readers with this background.\\n21.(a) What are the alternative approaches of determining a sample size? Explain.\\n(b) If we want to draw a simple random sample from a population of 4000 items, how large a sample do we\\nneed to draw if we desire to estimate the per cent  defective within 2 % of the true value with 95.45%probability. [M. Phil. Exam. (EAFM) RAJ. Uni. 1979 ]\\n22.(a) Given is the following information:\\n(i) Universe with  N =10,000.\\n(ii) Variance of weight of the cereal containers on the basis of past records = 8 kg. Determine the size of\\n the sample for estimating the true weight of the containers if the estimate should be within 0.4 kg. of\\n the true average weight with 95% probability.\\n(b)What would be the size of the sample if infinite universe is assumed in question number 22 (a) above?\\n23.Annual incomes of 900 salesmen employed by Hi-Fi Corporation is known to be approximately normallydistributed. If the Corporation wants to be 95% confident that the true mean of this year’s salesmen’sincome does not differ by more than 2% of the last year’s mean income of Rs 12,000, what sample sizewould be required assuming the population standard deviation to be Rs 1500?\\n[M. Phil. (EAFM) Special  Exam. RAJ. Uni. 1979 ]\\n24.Mr. Alok is a purchasing agent of electronic calculators. He is interested in determining at a confidencelevel of 95% what proportion (within plus or minus 4%), is defective. Conservatively, how many calculatorsshould be tested to find the proportion defective?\\n(Hint: If he tests conservatively, then p = .5 and q = .5).Sampling Fundamentals 183\\n25.A team of medico research experts feels confident that a new drug they have developed will cure about\\n80% of the patients. How large should the sample size be for the team to be 98% certain that the sampleproportion of cure is within plus and minus 2% of the proportion of all cases that the drug will cure?\\n26.Mr. Kishore wants to determine the average time required to complete a job with which he is concerned.As per the last studies, the population standard deviation is 8 days. How large should the sample be so\\nthat Mr. Kishore may be 99% confident that the sample average may remain within \\n±2 days of the\\naverage?184 Research Methodology\\n9\\nTesting of Hypotheses I\\n(Parametric or Standard Tests of Hypotheses)\\nHypothesis is usually considered as the principal instrument in research. Its main function is to\\nsuggest new experiments and observations. In fact, many experiments are carried out with thedeliberate object of testing hypotheses. Decision-makers often face situations wherein they areinterested in testing hypotheses on the basis of available information and then take decisions on thebasis of such testing. In social science, where direct knowledge of population parameter(s) is rare,hypothesis testing is the often used strategy for deciding whether a sample data offer such supportfor a hypothesis that generalisation can be made. Thus hypothesis testing enables us to make probabilitystatements about population parameter(s). The hypothesis may not be proved absolutely, but in practiceit is accepted if it has withstood a critical testing. Before we explain how hypotheses are testedthrough different tests meant for the purpose, it will be appropriate to explain clearly the meaning ofa hypothesis and the related concepts for better understanding of the hypothesis testing techniques.\\nWHAT IS A HYPOTHESIS?\\nOrdinarily, when one talks about hypothesis, one simply means a mere assumption or some suppositionto be proved or disproved. But for a researcher hypothesis is a formal question that he intends toresolve. Thus a hypothesis may be defined as a proposition or a set of proposition set forth as anexplanation for the occurrence of some specified group of phenomena either asserted merely as aprovisional conjecture to guide some investigation or accepted as highly probable in the light ofestablished facts. Quite often a research hypothesis is a predictive statement, capable of being testedby  scientific methods, that relates an independent variable to some dependent variable. For example,\\nconsider statements like the following ones:\\n“Students who receive counselling will show a greater increase in creativity than students not\\nreceiving counselling” Or\\n“the automobile A is performing as well as automobile B.”\\nThese are hypotheses capable of being objectively verified and tested. Thus, we may conclude thata hypothesis states what we are looking for and it is a proposition which can be put to a test todetermine its validity.Testing of Hypotheses I 185\\nCharacteristics of hypothesis: Hypothesis must possess the following characteristics:\\n(i) Hypothesis should be clear and precise. If the hypothesis is not clear and precise, the\\ninferences drawn on its basis cannot be taken as reliable.\\n(ii)Hypothesis should be capable of being tested. In a swamp of untestable hypotheses, many\\na time the research programmes have bogged down. Some prior study may be done byresearcher in order to make hypothesis a testable one. A hypothesis “is testable if otherdeductions can be made from it which, in turn, can be confirmed or disproved by observation.”\\n1\\n(iii)Hypothesis should state relationship between variables, if it happens to be a relationalhypothesis.\\n(iv)Hypothesis should be limited in scope and must be specific. A researcher must rememberthat narrower hypotheses are generally more testable and he should develop such hypotheses.\\n(v) Hypothesis should be stated as far as possible in most simple terms so that the same is\\neasily understandable by all concerned. But one must remember that simplicity of hypothesishas nothing to do with its significance.\\n(vi)Hypothesis should be consistent with most known facts i.e., it must be consistent with asubstantial body of established facts. In other words, it should be one which judges acceptas being the most likely.\\n(vii)Hypothesis should be amenable to testing within a reasonable time. One should not useeven an excellent hypothesis, if the same cannot be tested in reasonable time for onecannot spend a life-time collecting data to test it.\\n(viii)Hypothesis must explain the facts that gave rise to the need for explanation. This meansthat by using the hypothesis plus other known and accepted generalizations, one should beable to deduce the original problem condition. Thus hypothesis must actually explain whatit claims to explain; it should have empirical reference.\\nBASIC CONCEPTS CONCERNING TESTING OF HYPOTHESES\\nBasic concepts in the context of testing of hypotheses need to be explained.\\n(a) Null hypothesis and alternative hypothesis: In the context of statistical analysis, we often talk\\nabout null hypothesis and alternative hypothesis. If we are to compare method A with method B\\nabout its superiority and if we proceed on the assumption that both methods are equally good, then\\nthis assumption is termed as the null hypothesis. As against this, we may think that the method A is\\nsuperior or the method B is inferior, we are then stating what is termed as alternative hypothesis. The\\nnull hypothesis is generally symbolized as H0 and the alternative hypothesis as Ha. Suppose we want\\nto test the hypothesis that the population mean µbg is equal to the hypothesised  mean µH0100 di=.\\nThen we would say that the null hypothesis is that the population mean is equal to the hypothesised\\nmean 100 and symbolically we can express as:\\nH0 :µµ==H0100\\n1 C. William Emory, Business Research Methods,  p. 33.186 Research Methodology\\nIf our sample results do not support this null hypothesis, we should conclude that something else\\nis true. What we conclude rejecting the null hypothesis is known as alternative hypothesis. In other\\nwords, the set of alternatives to the null hypothesis is referred to as the alternative hypothesis. If weaccept H\\n0, then we are rejecting Ha and if we reject H0, then we are accepting Ha. For\\nH0:µµ==H0100, we may consider three possible alternative hypotheses as follows*:\\nTable 9.1\\nAlternative hypothesis To be read as follows\\nHaH:µµ≠\\n0 (The alternative hypothesis is that the population mean is not\\nequal to 100 i.e., it may be more or less than 100)\\nHaH:µµ>\\n0 (The alternative hypothesis is that the population mean is greater\\nthan 100)\\nHaH:µµ<\\n0 (The alternative hypothesis is that the population mean is less\\nthan 100)\\nThe null hypothesis and the alternative hypothesis are chosen before the sample is drawn (the researcher\\nmust avoid the error of deriving hypotheses from the data that he collects and then testing thehypotheses from the same data). In the choice of null hypothesis, the following considerations areusually kept in view:\\n(a) Alternative hypothesis is usually the one which one wishes to prove and the null hypothesis\\nis the one which one wishes to disprove. Thus, a null hypothesis represents the hypothesiswe are trying to reject, and alternative hypothesis represents all other possibilities.\\n(b) If the rejection of a certain hypothesis when it is actually true involves great risk, it is taken\\nas null hypothesis because then the probability of rejecting it when it is true is \\nα(the level\\nof significance) which is chosen very small.\\n(c) Null hypothesis should always be specific hypothesis i.e., it should not state about or\\napproximately a certain value.\\nGenerally, in hypothesis testing we proceed on the basis of null hypothesis, keeping the alternative\\nhypothesis in view. Why so? The answer is that on the assumption that null hypothesis is true, onecan assign the probabilities to different possible sample results, but this cannot be done if we proceedwith the alternative hypothesis. Hence the use of null hypothesis (at times also known as statisticalhypothesis) is quite frequent.\\n(b) The level of significance: This is a very important concept in the context of hypothesis testing.\\nIt is always some percentage (usually 5%) which should be chosen wit great care, thought and\\nreason. In case we take the significance level at 5 per cent, then this implies that H\\n0 will be rejected\\n*If a hypothesis is of the type µµ=H0, then we call such a hypothesis as simple (or specific) hypothesis but if it is\\nof the type µµ µµ µµ≠><HHH000or or , then we call it a composite (or nonspecific) hypothesis.Testing of Hypotheses I 187\\nwhen the sampling result (i.e., observed evidence) has a less than 0.05 probability of occurring if H0\\nis true. In other words, the 5 per cent level of significance means that researcher is willing to take as\\nmuch as a 5 per cent risk of rejecting the null hypothesis when it ( H0) happens to be true. Thus the\\nsignificance level is the maximum value of the probability of rejecting H0 when it is true and is usually\\ndetermined in advance before testing the hypothesis.\\n(c) Decision rule or test of hypothesis: Given a hypothesis H0 and an alternative hypothesis Ha,\\nwe make a rule which is known as decision rule according to which we accept H0 (i.e., reject Ha) or\\nreject H0 (i.e., accept Ha). For instance, if ( H0 is that a certain lot is good (there are very few\\ndefective items in it) against Ha) that the lot is not good (there are too many defective items in it),\\nthen we must decide the number of items to be tested and the criterion for accepting or rejecting the\\nhypothesis. We might test 10 items in the lot and plan our decision saying that if there are none or only1 defective item among the 10, we will accept H\\n0 otherwise we will reject H0 (or accept Ha). This\\nsort of basis is known as decision rule.\\n(d) Type I and Type II errors: In the context of testing of hypotheses, there are basically two types\\nof errors we can make. We may reject H0 when H0 is true and we may accept H0 when in fact H0 is\\nnot true. The former is known as Type I error and the latter as Type II error. In other words, Type I\\nerror means rejection of hypothesis which should have been accepted and Type II error meansaccepting the hypothesis which should have been rejected. Type I error is denoted by \\nα (alpha)\\nknown as α error, also called the level of significance of test; and Type II error is denoted by β\\n(beta) known as β error. In a tabular form the said two errors can be presented as follows:\\nTable 9.2\\nDecision\\nAccept H0Reject H0\\nH0 (true) Correct Type I error\\ndecision (α error)\\nH0 (false) Type II error Correct\\n(β error) decision\\nThe probability of Type I error is usually determined in advance and is understood as the level of\\nsignificance of testing the hypothesis. If type I error is fixed at 5 per cent, it means that there areabout 5 chances in 100 that we will reject H\\n0 when H0 is true. We can control Type I error just by\\nfixing it at a lower level. For instance, if we fix it at 1 per cent, we will say that the maximumprobability of committing Type I error would only be 0.01.\\nBut with a fixed sample size, n, when we try to reduce Type I error, the probability of committing\\nType II error increases. Both types of errors cannot be reduced simultaneously. There is a trade-offbetween two types of errors which means that the probability of making one type of error can onlybe reduced if we are willing to increase the probability of making the other type of error. To deal withthis trade-off in business situations, decision-makers decide the appropriate level of Type I error byexamining the costs or penalties attached to both types of errors. If Type I error involves the time andtrouble of reworking a batch of chemicals that should have been accepted, whereas Type II errormeans taking a chance that an entire group of users of this chemical compound will be poisoned, then188 Research Methodology\\nin such a situation one should prefer a Type I error to a Type II error. As a result one must set very\\nhigh level for Type I error in one’s testing technique of a given hypothesis.2 Hence, in the testing of\\nhypothesis, one must make all possible effort to strike an adequate balance between Type I and TypeII errors.\\n(e) Two-tailed and One-tailed tests: In the context of hypothesis testing, these two terms are quite\\nimportant and must be clearly understood. A two-tailed test rejects the null hypothesis if, say, the\\nsample mean is significantly higher or lower than the hypothesised value of the mean of the population.Such a test is appropriate when the null hypothesis is some specified value and the alternativehypothesis is a value not equal to the specified value of the null hypothesis. Symbolically, the two-\\ntailed test is appropriate when we have \\nHH 00:µµ= and HaH:µµ≠\\n0 which may mean µµ>H0\\nor µµ <H0. Thus, in a two-tailed test, there are two rejection regions*, one on each tail of the curve\\nwhich can be illustrated as under:\\nFig. 9.1\\n2 Richard I. Levin, Statistics for Management,  p. 247–248.\\n*Also known as critical regions.Acceptance and rejection regions\\nin case of a two-tailed test\\n(with 5% significance level)\\nAcceptance region\\n(Accept if the sample\\nmean ( ) falls in this region)H\\nX0Rejection region Rejection region\\n0.475\\nof area0.475\\nof area\\n0.025 of area 0.025 of area\\nLimit\\nLimit\\nZ= –1.96 Z= 1.96 /c109/c109H0/c61Both taken together equals\\n0.95 or 95% of area\\nReject if the sample mean\\n( ) falls in either of these\\ntwo regionsH\\nX0Testing of Hypotheses I 189\\nMathematically we can state:\\nAcceptance Region  AZ:<196.\\n    Rejection Region  RZ:>196.\\nIf the significance level is 5 per cent and the two-tailed test is to be applied, the probability of the\\nrejection area will be 0.05 (equally splitted on both tails of the curve as 0.025) and that of theacceptance region will be 0.95 as shown in the above curve. If we take \\nµ=100 and if our sample\\nmean deviates significantly from 100 in either direction, then we shall reject the null hypothesis; but\\nif the sample mean does not deviate significantly from µ, in that case we shall accept the null\\nhypothesis.\\nBut there are situations when only one-tailed test is considered appropriate. A one-tailed test\\nwould be used when we are to test, say, whether the population mean is either lower than or higher\\nthan some hypothesised value. For instance, if our HH 00:µµ= and HaH:µµ<\\n0, then we are\\ninterested in what is known as left-tailed test (wherein there is one rejection region only on the left\\ntail) which can be illustrated as below:\\nFig. 9.2\\nMathematically we can state:\\nAcceptance Region  AZ:>−1645.\\n    Rejection Region  RZ:<−1645.Acceptance and rejection regions\\nin case of one tailed test (left-tail)\\nwith 5% significance\\nAcceptance region\\n(Accept if the sample\\nmean falls in this region)H0Rejection region\\n0.45 of\\narea0.50 of\\narea\\n0.05 of area\\nLimit\\nZ= –1.645 /c109/c109H0/c61Both taken together equals\\n0.95 or 95% of area\\nReject if the sample mean\\n( falls in this regionH\\nX )0190 Research Methodology\\nIf our µ=100 and if our sample mean deviates significantly from100 in the lower direction, we\\nshall reject H0, otherwise we shall accept H0 at a certain level of significance. If the significance\\nlevel in the given case is kept at 5%, then the rejection region will be equal to 0.05 of area in the left\\ntail as has been shown in the above curve.\\nIn case our HH 00:µµ= and HaH:µµ>\\n0, we are then interested in what is known as one-\\ntailed test (right tail) and the rejection region will be on the right tail of the curve as shown below:\\nFig. 9.3\\nMathematically we can state:\\nAcceptance Region  AZ:<1645.\\n  Rejection Region  AZ:>1645.\\nIf our µ=100 and if our sample mean deviates significantly from 100 in the upward direction, we\\nshall reject H0, otherwise we shall accept the same. If in the given case the significance level is kept\\nat 5%, then the rejection region will be equal to 0.05 of area in the right-tail as has been shown in theabove curve.\\nIt should always be remembered that accepting H\\n0 on the basis of sample information does not\\nconstitute the proof that H0 is true. We only mean that there is no statistical evidence to reject it, but\\nwe are certainly not saying that H0 is true (although we behave as if H0 is true).Acceptance and rejection regions\\nin case of one-tailed test (right tail)\\nwith 5% significance level\\nAcceptance region\\n(Accept if the sample\\nmean falls in this region)H0Rejection region\\n0.05 of area 0.45 of area\\n0.05 of areaLimit\\nZ= –1.645 /c109/c109H0/c61Both taken together equals\\n0.95 or 95% of area\\nReject if the sample mean\\nfalls in this regionH0Testing of Hypotheses I 191\\nPROCEDURE FOR HYPOTHESIS TESTING\\nTo test a hypothesis means to tell (on the basis of the data the researcher has collected) whether or\\nnot the hypothesis seems to be valid. In hypothesis testing the main question is: whether to accept thenull hypothesis or not to accept the null hypothesis? Procedure for hypothesis testing refers to allthose steps that we undertake for making a choice between the two actions i.e., rejection andacceptance of a null hypothesis. The various steps involved in hypothesis testing are stated below:\\n(i) Making a formal statement: The step consists in making a formal statement of the null hypothesis\\n(H\\n0) and also of the alternative hypothesis ( Ha). This means that hypotheses should be clearly stated,\\nconsidering the nature of the research problem. For instance, Mr. Mohan of the Civil Engineering\\nDepartment wants to test the load bearing capacity of an old bridge which must be more than 10tons, in that case he can state his hypotheses as under:\\nNull hypothesis H\\n0 :t o n sµ=10\\nAlternative Hypothesis Ha:t o n sµ>10\\nTake another example. The average score in an aptitude test administered at the national level is 80.To evaluate a state’s education  system, the average score of 100 of the state’s students selected onrandom basis was 75. The state wants to know if there is a significant difference between the localscores and the national scores. In such a situation the hypotheses may be stated as under:\\nNull hypothesis \\nH0:8 0µ=\\nAlternative Hypothesis Ha:8 0µ≠\\nThe formulation of hypotheses is an important step which must be accomplished with due care in\\naccordance with the object and nature of the problem under consideration. It also indicates whetherwe should use a one-tailed test or a two-tailed test. If H\\na is of the type greater than (or of the type\\nlesser than), we use a one-tailed test, but when Ha is of the type “whether greater or smaller” then\\nwe use a two-tailed test.\\n(ii) Selecting a significance level: The hypotheses are tested on a pre-determined level of significance\\nand as such the same should be specified. Generally, in practice, either 5% level or 1% level is\\nadopted for the purpose. The factors that affect the level of significance are: (a) the magnitude of thedifference between sample means; (b) the size of the samples; (c) the variability of measurementswithin samples; and (d) whether the hypothesis is directional or non-directional (A directional hypothesisis one which predicts the direction of the difference between, say, means). In brief, the level ofsignificance must be adequate in the context of the purpose and nature of enquiry.\\n(iii) Deciding the distribution to use: After deciding the level of significance, the next step in\\nhypothesis testing is to determine the appropriate sampling distribution. The choice generally remains\\nbetween normal distribution and the t-distribution. The rules for selecting the correct distribution are\\nsimilar to those which we have stated earlier in the context of estimation.\\n(iv) Selecting a random sample and computing an appropriate value: Another step is to select\\na random sample(s) and compute an appropriate value from the sample data concerning the test\\nstatistic utilizing the relevant distribution. In other words, draw a sample to furnish empirical data.\\n(v) Calculation of the probability: One has then to calculate the probability that the sample result\\nwould diverge as widely as it has from expectations, if the null hypothesis were in fact true.192 Research Methodology\\n(vi) Comparing the probability: Yet another step consists in comparing the probability thus calculated\\nwith the specified value for α, the significance level. If the calculated probability is equal to or\\nsmaller than the α value in case of one-tailed test (and α/2 in case of two-tailed test), then reject\\nthe null hypothesis (i.e., accept the alternative hypothesis), but if the calculated probability is greater,\\nthen accept the null hypothesis. In case we reject H0, we run a risk of (at most the level of significance)\\ncommitting an error of Type I, but if we accept H0, then we run some risk (the size of which cannot\\nbe specified as long as the H0 happens to be vague rather than specific) of committing an error of\\nType II.\\nFLOW DIAGRAM FOR HYPOTHESIS TESTING\\nThe above stated general procedure for hypothesis testing can also be depicted in the from of a flow-chart for better understanding as shown in Fig. 9.4:\\n3\\nFig. 9.4\\n3 Based on the flow diagram in William A. Chance’s Statistical Methods for Decision Making, Richard D. Irwin INC.,\\nIllinois, 1969, p.48.FLOW DIAGRAM FOR HYPOTHESISTESTING\\nYes No\\nthereby run the risk\\nof committing\\nType I errorthereby run some\\nrisk of committing\\nType II errorState as well asHH0 a\\nSpecify the level of\\nsignificance (or the value) /c97\\nDecide the correct sampling\\ndistribution\\nSample a random sample(s)\\nand workout an appropriate\\nvalue from sample data\\nCalculate the probability that sample\\nresult would diverge as widely as it has\\nfrom expectations, if were true H0\\nIs this probability equal to or smaller than\\nvalue in case of one-tailed test and /2\\nin case of two-tailed test/c97/c97\\nRejectH0 AcceptH0Testing of Hypotheses I 193\\nMEASURING THE POWER OF A HYPOTHESIS TEST\\nAs stated above we may commit Type I and Type II errors while testing a hypothesis. The probability\\nof Type I error is denoted as α (the significance level of the test) and the probability of Type II error\\nis referred to as β. Usually the significance level of a test is assigned in advance and once we decide\\nit, there is nothing else we can do about α. But what can we say about β? We all know that\\nhypothesis test cannot be foolproof; sometimes the test does not reject H0 when it happens to be a\\nfalse one and this way a Type II error is made. But we would certainly like that β (the probability of\\naccepting H0 when H0 is not true) to be as small as possible. Alternatively, we would like that 1 – β\\n(the probability of rejecting H0 when H0 is not true) to be as large as possible. If  1 – β is very much\\nnearer to unity (i.e., nearer to 1.0), we can infer that the test is working quite well, meaning therebythat the test is rejecting H\\n0 when it is not true and if  1 – β is very much nearer to 0.0, then we infer\\nthat the test is poorly working, meaning thereby that it is not rejecting H0 when H0 is not true.\\nAccordingly 1 – β value is the measure of how well the test is working or what is technically\\ndescribed as the power of the test . In case we plot the values of 1 – β for each possible value of the\\npopulation parameter (say µ, the true population mean) for which the H0 is not true (alternatively the\\nHa is true), the resulting curve is known as the power curve associated with the given test. Thus\\npower curve of a hypothesis test is the curve that shows the conditional probability of rejecting H0 as\\na function of the population parameter and size of the sample.\\nThe function defining this curve is known as the power function . In other words, the power\\nfunction of a test is that function defined for all values of the parameter(s) which yields the probability\\nthat H0 is rejected and the value of the power function at a specific parameter point is called the\\npower of the test at that point. As the population parameter gets closer and closer to hypothesisedvalue of the population parameter, the power of the test (i.e., 1 – \\nβ) must get closer and closer to the\\nprobability of rejecting H0 when the population parameter is exactly equal to hypothesised value of\\nthe parameter. We know that this probability is simply the significance level of the test, and as suchthe power curve of a test terminates at a point that lies at a height of \\nα (the significance level)\\ndirectly over the population parameter.\\nClosely related to the power function, there is another function which is known as the operating\\ncharacteristic function  which shows the conditional probability of accepting H0 for all values of\\npopulation parameter(s) for a given sample size, whether or not the decision happens to be a correctone. If power function is represented as H and operating characteristic function as L, then we have\\nL = 1 – H. However, one needs only one of these two functions for any decision rule in the context\\nof testing hypotheses. How to compute the power of a test (i.e., 1 – \\nβ) can be explained through\\nexamples.\\nIllustration 1\\nA certain chemical process is said to have produced 15 or less pounds of waste material for every\\n60lbs. batch with a corresponding standard deviation of 5 lbs. A random sample of 100 batchesgives an average of 16 lbs. of waste per batch. Test at 10 per cent level whether the average quantity\\nof waste per batch has increased. Compute the power of the test for \\nµ = 16 lbs. If we raise the level\\nof significance to 20 per cent, then how the power of the test for µ = 16 lbs. would be affected?194 Research Methodology\\nSolution:  As we want to test the hypothesis that the average quantity of waste per batch of 60 lbs.\\nis 15 or less pounds against the hypothesis that the waste quantity is more than 15 lbs., we can write\\nas under:\\nH015 : lbs.µ<\\nHa:l b s .µ>15\\nAs Ha is one-sided, we shall use the one-tailed test (in the right tail because Ha is of more than type)\\nat 10% level for finding the value of standard deviate ( z), corresponding to .4000 area of normal\\ncurve which comes to 1.28 as per normal curve area table.* From this we can find the limit of µ for\\naccepting H0 as under:\\nAccept  HX np 015 128if ( ) <+./α\\nor           X<+15 128 5 100./ej\\nor            X<1564.\\nat 10% level of significance otherwise accept Ha.\\nBut the sample average is 16 lbs. which does not come in the acceptance region as above. We,\\ntherefore, reject H0 and conclude that average quantity of waste per batch has increased. For finding\\nthe power of the test, we first calculate β and then subtract it from one. Since β is a conditional\\nprobability which depends on the value of µ, we take it as 16 as given in the question. We can now\\nwrite β = p (Accept : ) H015 16µµ<= . Since we have already worked out that H0 is accepted\\nif X<1564. (at 10% level of significance), therefore βµ=< =pX()1564 16.  which can be\\ndepicted as follows:\\nFig. 9.5\\n* Table No. 1. given in appendix at the end of the book./c109/c6116 X/c6115 64./c98/c610 2358.Rejection region Acceptance\\nregion\\n1 0 7642/c45/c61 /c98bg .Testing of Hypotheses I 195\\nWe can find out the probability of the area that lies between 15.64 and 16 in the above curve first\\nby finding z and then using the area table for the purpose. In the given case zX n=−() ( )µσ//\\n=− = −() ( )1564 16 5 100 072./ / .  corresponding to which the area is 0.2642. Hence, β = 0.5000 –\\n0.2642 =0.2358 and the power of the test = (1 – β) = (1 – .2358) = 0.7642 for µ = 16.\\nIn case the significance level is raised to 20%, then we shall have the following criteria:\\nAccept HX0 15 84 5 100if<+.bg ej\\norX<1542., otherwise accept Ha\\n∴= < =βµpX1542 16. di\\nor β=.,1230, using normal curve area table as explained above.\\nHence, 1 1 1230 8770−= − =β bg b g ..\\nTESTS OF HYPOTHESES\\nAs has been stated above that hypothesis testing determines the validity of the assumption (technically\\ndescribed as null hypothesis) with a view to choose between two conflicting hypotheses about thevalue of a population parameter. Hypothesis testing helps to decide on the basis of a sample data,whether a hypothesis about the population is likely to be true or false. Statisticians have developedseveral tests of hypotheses (also known as the tests of significance) for the purpose of testing ofhypotheses which can be classified as: (a) Parametric tests or standard tests of hypotheses; and(b) Non-parametric tests or distribution-free test of hypotheses.\\nParametric tests usually assume certain properties of the parent population from which we draw\\nsamples. Assumptions like observations come from a normal population, sample size is large,assumptions about the population parameters like mean, variance, etc., must hold good beforeparametric tests can be used. But there are situations when the researcher cannot or does not wantto make such assumptions. In such situations we use statistical methods for testing hypotheses whichare called non-parametric tests because such tests do not depend on any assumption about theparameters of the parent population. Besides, most non-parametric tests assume only nominal orordinal data, whereas parametric tests require measurement equivalent to at least an interval scale.As a result, non-parametric tests need more observations than parametric tests to achieve the samesize of Type I and Type II errors.\\n4 We take up in the present chapter some of the important parametric\\ntests, whereas non-parametric tests will be dealt with in a separate chapter later in the book.\\nIMPORTANT PARAMETRIC TESTS\\nThe important parametric tests are: (1) z-test; (2) t-test; (*3) χ2-test, and (4) F-test. All these tests\\nare based on the assumption of normality i.e., the source of data is considered to be normally distributed.\\n4 Donald L. Harnett and James L. Murphy, Introductory Statistical Analysis,  p. 368.\\n* χ2- test is also used as a test of goodness of fit and also as a test of independence in which case it is a non-parametric\\ntest. This has been made clear in Chapter 10 entitled χ2-test.196 Research Methodology\\nIn some cases the population may not be normally distributed, yet the tests will be applicable on\\naccount of the fact that we mostly deal with samples and the sampling distributions closely approachnormal distributions.\\nz-test is based on the normal probability distribution and is used for judging the significance of\\nseveral statistical measures, particularly the mean. The relevant test statistic\\n*, z, is worked out and\\ncompared with its probable value (to be read from table showing area under normal curve) at aspecified level of significance for judging the significance of the measure concerned. This is a mostfrequently used test in research studies. This test is used even when binomial distribution ort-distribution is applicable on the presumption that such a distribution tends to approximate normal\\ndistribution as ‘ n’ becomes larger. z-test is generally used for comparing the mean of a sample to\\nsome hypothesised mean for the population in case of large sample, or when population variance isknown. z-test  is also used for judging he significance of difference between means of two independent\\nsamples in case of large samples, or when population variance is known. z-test is also used for comparing\\nthe sample proportion to a theoretical value of population proportion or for judging the difference inproportions of two independent samples when n happens to be large. Besides, this test may be used\\nfor judging the significance of median, mode, coefficient of correlation and several other measures.\\nt-test is based on t-distribution and is considered an appropriate test for judging the significance\\nof a sample mean or for judging the significance of  difference between the means of two samples incase of small sample(s) when population variance is not known (in which case we use variance ofthe sample as an estimate of the population variance). In case two samples are related, we usepaired t-test  (or what is known as difference test) for judging the significance of the mean of\\ndifference between the two related samples. It can also be used for judging the significance of thecoefficients of simple and partial correlations. The relevant test statistic, t, is calculated from the\\nsample data and then compared with its probable value based on t-distribution (to be read from the\\ntable that gives probable values of t for different levels of significance for different degrees of\\nfreedom) at a specified level of significance for concerning degrees of freedom for accepting orrejecting the null hypothesis. It may be noted that t-test applies only in case of small sample(s) when\\npopulation variance is unknown.\\nχ2-test is based on chi-square distribution and as a parametric test is used for comparing a\\nsample variance to a theoretical population variance.\\nF-test is based on F-distribution and is used to compare the variance of the two-independent\\nsamples. This test is also used in the context of analysis of variance (ANOVA) for judging thesignificance of more than two sample means at one and the same time. It is also used for judging thesignificance of multiple correlation coefficients. Test statistic, F, is calculated and compared with its\\nprobable value (to be seen in the F-ratio tables for different degrees of freedom for greater and\\nsmaller variances at specified level of significance) for accepting or rejecting the null hypothesis.\\nThe table on pages 198–201 summarises the important parametric tests along with test statistics\\nand test situations for testing hypotheses relating to important parameters (often used in researchstudies) in the context of one sample and also in the context of two samples.\\nWe can now explain and illustrate the use of the above stated test statistics in testing of hypotheses.\\n* The test statistic is the value obtained from the sample data that corresponds to the parameter under investigation.Testing of Hypotheses I 197\\nHYPOTHESIS TESTING OF MEANS\\nMean of the population can be tested presuming different situations such as the population may be\\nnormal or other than normal, it may be finite or infinite, sample size may be large or small, varianceof the population may be known or unknown and the alternative hypothesis may be two-sided or one-sided. Our testing technique will differ in different situations. We may consider some of the importantsituations.\\n1.Population normal, population infinite, sample size may be large or small but varianceof the population is known, H\\na may be one-sided or two-sided :\\nIn such a situation z-test is used for testing hypothesis of mean and the test statistic z is\\nworked our as under:\\nzX\\nnH\\np=−µ\\nσ0\\n2.Population normal, population finite, sample size may be large or small but varianceof the population is known, H\\na may be one-sided or two-sided :\\nIn such a situation z-test is used and the test statistic z is worked out as under (using\\nfinite population multiplier):\\nzX\\nnN n NH\\np=−\\n×− −µ\\nσ0\\n1 ej bg b g\\n3.Population normal, population infinite, sample size small and variance of thepopulation unknown, H\\na may be one-sided or two-sided:\\nIn such a situation t-test is used and the test statistic t is worked out as under:\\ntX\\nnH\\ns=−µ\\nσ0\\n/ with d.f. = ( n – 1)\\nand          σsiXX\\nn=∑−\\n−dibg2\\n1\\n4.Population normal, population finite, sample size small and variance of the populationunknown, and H\\na may be one-sided or two-sided:\\nIn such a situation t-test is used and the test statistic ‘ t’ is worked out as under (using\\nfinite population multiplier):\\ntX\\nnN n NH\\ns=−\\n×− −µ\\nσ0\\n1 //ej bg b g with d.f. = ( n – 1)198 Research MethodologyTable 9.3 : Names of Some Parametric Tests along with Test Situations and Test Statistics used in Context of Hypothesis Testing\\nUnknown Test situation (Population Name of the test and the test statistic to be used\\nparameter characteristics and other\\nconditions. Random One sample Two samples\\nsampling is assumed in all\\nsituations along  with Independent Related\\ninfinite population\\n12 3 4 5\\nMean ()µPopulation(s) normal or z -test and the z-test for difference in means and the test\\nSample size large (i.e., test statistic statistic\\nn > 30) or population\\nvariance(s) known\\nzX\\nnH\\np=−µ\\nσ0\\n        zX X\\nn np=−\\n+FHGIKJ1 2\\n2\\n1 21 1\\nσ\\nIn case σp is not is used when two samples are drawn from the\\nknown, we use same population. In case σp is not known, we use\\nσs in its placeσs12 in its place calculating\\ncalculatingσsiX X\\nn=−\\n−Σd i2\\n1        σσσ\\nss s n D n D\\nn n121 12\\n12\\n2 22\\n22\\n1 2=++ +\\n+e j e j\\nwhere D X X1 1 12 =− d i\\n           D X X2 2 12 =− d i\\n          XnX nX\\nn n121 1 2 2\\n1 2=+\\n+\\nContd.Testing of Hypotheses I 19912 3 4 5\\n             OR\\nzX X\\nn np p1 2\\n12\\n122\\n2−\\n+\\nσσ\\nis used when two samples are drawn from\\ndifferent populations. In case σp1and σp2are not\\nknown. We use σσs s1 2and respectively in their\\nplaces calculatingσs iX X n1 1 12\\n11 = − − Σd i\\nandσs iX X n2 2 22\\n21 = − − Σd i\\nMean ()µPopulations(s) normal t-test and the t-test for difference in means and the test statistic   Paired t-test or\\nand test statistic   difference test and\\nsample size small (i.e.,   the test statistic\\nn<30)\\ntX\\nnH\\ns=−µ\\nσ0tX X\\nX X X X\\nn nn n\\ni i=−\\n−+ −\\n+−×+1 2\\n1 12\\n2 22\\n1 21 2\\n21 1\\nΣ Σ d i d i\\n  tD\\nDDn\\nnni=−\\n−\\n−0\\n122Σ ,\\nwith with d.f. = ( n1 + n2 – 2)\\n  with d.f = ( n – 1) d.f. = (n – 1)\\n  where n = number of where\\nContd.and\\npopulation variance(s)unknown (but thepopulation variancesassumed equal in case oftest on difference betweenmeans)200 Research Methodology12 3 4 5\\nσsiX X\\nn=−\\n−Σd i2\\n1pairs in two samples.\\nAlternatively , t can be worked out as under:\\nX X\\nn n\\nn n\\nn n\\nn nD\\nD X Ys s\\ni\\ni i i1 2\\n1 12\\n2 22\\n1 2\\n1 2\\n1 21 1\\n2\\n1 1\\n2−\\n−+−\\n+−\\n×+\\n=+−R\\nS|||||\\nT|||||U\\nV|||||\\nW|||||=\\n=−b g b g\\nb gbg\\nσσ\\nwi th d.f.d ifference si.e.,\\nProportion Repeated independent z-test and the z-test for difference in proportions of two\\n(p) trials, sample size test statistic samples and the test statistic\\nlarge (presuming normal\\napproximation of binomialzpp\\npqn=−\\n⋅$\\n/zpp\\npq\\nnpq\\nn=−\\n+$$\\n$$ $$12\\n11\\n122\\n2distribution)\\nIf p and q are is used in case of heterogenous populations. But\\nnot  known, when populations are similar with respect to a\\nthen we use given attribute, we work out the best estimate of\\np and q in their the population proportion as under:\\nplaces\\npnpnp\\nnn01122\\n12=+\\n+$ $\\nContd.Testing of Hypotheses I 2011 2 3                  4 5\\n    and qp0 01=− in which case\\n    we calculate test statistic\\nzpp\\npqnn=−\\n+FHGIKJ$$12\\n00\\n1211\\nvariance Population(s) χ2-test and the test     F-test and the test statistic\\nσp2e jnormal, observations statistic\\nFXXn\\nXXns\\nsi\\ni==∑− −\\n∑− −σ\\nσ12\\n22112\\n2221\\n1d i\\nd i/\\n/are independent\\nχσ\\nσ22\\n21 = −s\\npnb gwhere σs12 is treated >σs22\\nwith d.f. = ( n – 1) with d.f. = v1 = (n1 –1) for\\ngreater variance and\\nd.f. = v2 = (n2 – 1) for smaller variance\\nIn the table the various symbols stand as under:\\nX = mean of the sample, X1 = mean of sample one, X2 = mean of sample two, n = No. of items in a sample, n1 = No. of items in sample one,\\nn2 = No. of items in sample two, µH0 = Hypothesised mean for population, σp = standard deviation of population, σs = standard deviation of\\nsample,   p = population proportion, qpp =−1,$ = sample proportion, $ $qp=−1.202 Research Methodology\\nand σsiXX\\nn=∑−\\n−dibg2\\n1\\n5.Population may not be normal but sample size is large, variance of the population\\nmay be known or unknown, and Ha may be one-sided or two-sided:\\nIn such a situation we use z-test and work out the test statistic z as under:\\nzX\\nnH\\np=−µ\\nσ0\\n/\\n(This applies in case of infinite population when variance of the population is known but\\nwhen variance is not known, we use σs in place of σp in this formula.)\\nOR\\nzX\\nnN n NH\\np=−\\n×− −µ\\nσ0\\n1 //ej bg b g\\n(This applies in case of finite population when variance of the population is known but\\nwhen variance is not known, we use σs in place of σp in this formula.)\\nIllustration 2\\nA sample of 400 male students is found to have a mean height 67.47 inches. Can it be reasonably\\nregarded as a sample from a large population with mean height 67.39 inches and standard deviation1.30 inches? Test at 5% level of significance.\\nSolution:  Taking the null hypothesis that the mean height of the population is equal to 67.39 inches,\\nwe can write:\\nHH006739:µ=.\"\\nHaH:µ\\n06739≠.\"\\nand the given information as Xp ==6747 130.\" , .\" ,σ  n = 400. Assuming the population to be\\nnormal, we can work out the test statistic z as under:\\nzX\\nnH\\np=−\\n=−==µ\\nσ06747 6739\\n130 400008\\n00651231\\n/..\\n./.\\n..\\nAs Ha is two-sided in the given question, we shall be applying a two-tailed test for determining the\\nrejection regions at 5% level of significance which comes to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is 1.231 which is in the acceptance region since R : | z | > 1.96 and thus\\nH0 is accepted. We may conclude that the given sample (with mean height = 67.47 \") can be regardedTesting of Hypotheses I 203\\nto have been taken from a population with mean height 67.39 \" and standard deviation 1.30 \" at 5%\\nlevel of significance.\\nIllustration 3\\nSuppose we are interested in a population of 20 industrial units of the same size, all of which are\\nexperiencing excessive labour turnover problems. The past records show that the mean of thedistribution of annual turnover is 320 employees, with a standard deviation of 75 employees. Asample of 5 of these industrial units is taken at random which gives a mean of annual turnover as 300employees. Is the sample mean consistent with the population mean? Test at 5% level.\\nSolution:  Taking the null hypothesis that the population mean is 320 employees, we can write:\\nHH00320: employeesµ=\\nHaH: employeesµ\\n0320≠\\nand the given information as under:\\nX = 300 employees, σp=75 employees\\n        n = 5; N = 20\\nAssuming the population to be normal, we can work out the test statistic z as under:\\nzX\\nnN n NH\\np*\\n//=−\\n×− −µ\\nσ0\\n1 bg b g\\n  =−\\n×− −=−300 320\\n75 5 20 5 20 120\\n3354 888 // .. bg bg bg b g\\n   = – 0.67\\nAs Ha is two-sided in the given question, we shall apply a two-tailed test for determining the\\nrejection regions at 5% level of significance which comes to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is –0.67 which is in the acceptance region since R : | z | > 1.96 and thus,\\nH0 is accepted and we may conclude that the sample mean is consistent with population mean i.e.,\\nthe population mean 320 is supported by sample results.\\nIllustration 4\\nThe mean of a certain production process is known to be 50 with a standard deviation of 2.5. The\\nproduction manager may welcome any change is mean value towards higher side but would like tosafeguard against decreasing values of mean. He takes a sample of 12 items that gives a mean valueof 48.5. What inference should the manager take for the production process on the basis of sampleresults? Use 5 per cent level of significance for the purpose.\\nSolution:  Taking the mean value of the population to be 50, we may write:\\nHH0050 :µ=\\n* Being a case of finite population.204 Research Methodology\\nHaH:µ\\n050< (Since the manager wants to safeguard against decreasing values of mean.)\\nand the given information as Xp ==485 25., .σ and n = 12. Assuming the population to be normal,\\nwe can work out the test statistic z as under:\\nzX\\nnH\\np=−\\n=−=− =−µ\\nσ0485 50\\n25 1215\\n25 346420784\\n/.\\n./.\\n./..bg b g\\nAs Ha is one-sided in the given question, we shall determine the rejection region applying one-\\ntailed test (in the left tail because Ha is of less than type) at 5 per cent level of significance and it\\ncomes to as under, using normal curve area table:\\nR : z < – 1.645\\nThe observed value of z  is – 2.0784 which is in the rejection region and thus, H0 is rejected at 5\\nper cent level of significance. We can conclude that the production process is showing mean which\\nis significantly less than the population mean and this calls for some corrective action concerning thesaid process.\\nIllustration 5\\nThe specimen of copper wires drawn form a large lot have the following breaking strength (in kg.\\nweight):\\n578, 572, 570, 568, 572, 578, 570, 572, 596, 544\\nTest (using Student’s t-statistic)whether the mean breaking strength of the lot may be taken to be\\n578 kg. weight (Test at 5 per cent level of significance). Verify the inference so drawn by usingSandler’s A-statistic as well.\\nSolution:  Taking the null hypothesis that the population mean is equal to hypothesised mean of\\n578kg., we can write:\\nHH 00578 :k g µµ== .\\n      HaH:µµ ≠\\n0\\nAs the sample size is mall (since n = 10) and the population standard deviation is not known, we\\nshall use t-test assuming normal population and shall work out the test statistic t as under:\\ntX\\nnH\\ns=−µ\\nσ0\\n/\\nTo find X and σs we make the following computations:\\nS. No. XiXXi− di XXi− di2\\n1 578 6 36\\n2 572 0 0\\n3 570 – 2 4\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Testing of Hypotheses I 205\\nS. No. XiXXi− di XXi− di2\\n4 568 – 4 16\\n5 572 0 0\\n6 578 6 36\\n7 570 – 2 4\\n8 572 0 0\\n9 596 24 576\\n10 544 – 28 784\\nn = 10 ∑=Xi5720 ∑− =XXidi21456\\n∴ XX\\nni=∑==5720\\n10572 kg.\\nand σsiXX\\nn=∑−\\n−=−=di2\\n11456\\n10 11272..kg\\n      Hence, t=−=−572 578\\n1272 101488\\n./.\\nDegree of freedom = ( n – 1) = (10 – 1) = 9\\nAs Ha is two-sided, we shall determine the rejection region applying two-tailed test at 5 per cent\\nlevel of significance, and it comes to as under, using table of t-distribution* for 9 d.f.:\\nR : | t | > 2.262\\nAs the observed value of t (i.e., – 1.488) is in the acceptance region, we accept H0 at 5 per cent\\nlevel and conclude that the mean breaking strength of copper wires lot may be taken as 578 kg.\\nweight.\\nThe same inference can be drawn using Sandler’s A-statistic as shown below:\\nTable 9.3 :Computations for A-Statistic\\nS. No. XiHypothesised mean DXii H=− µ\\n0 di Di2\\nm5 7 8 k g .H0=\\n1 578 578 0 0\\n2 572 578 –6 36\\n3 570 578 –8 64\\n4 568 578 –10 100\\n* Table No. 2 given in appendix at the end of the book.contd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○206 Research Methodology\\nS. No. XiHypothesised mean DXii H=− µ\\n0 di Di2\\nm5 7 8 k g .H0=\\n5 572 578 –6 36\\n6 578 578 0 0\\n7 570 578 –8 64\\n8 572 578 –6 36\\n9 596 578 18 324\\n10 544 578 –34 1156\\nn = 10 ∑= −Di60 ∑=Di21816\\n∴ ADDii=∑ ∑ = − =2 2 21816 60 05044 // .bg b g\\nNull hypothesis  HH00578:k gµ= .\\nAlternate hypothesis HaH:k gµ\\n0578≠.\\nAs Ha is two-sided, the critical value of A-statistic from the A-statistic table (Table No. 10 given\\nin appendix at the end of the book) for ( n – 1) i.e., 10 – 1 = 9 d.f. at 5% level is 0.276. Computed\\nvalue of A (0.5044), being greater than 0.276 shows that A-statistic is insignificant in the given case\\nand accordingly we accept H0 and conclude that the mean breaking strength of copper wire’ lot\\nmaybe taken as578 kg. weight. Thus, the inference on the basis of t-statistic stands verified by\\nA-statistic.\\nIllustration 6\\nRaju Restaurant near the railway station at Falna has been having average sales of 500 tea cups per\\nday. Because of the development of bus stand nearby, it expects to increase its sales. During the first12 days after the start of the bus stand, the daily sales were as under:\\n550, 570, 490, 615, 505, 580, 570, 460, 600, 580, 530, 526\\nOn the basis of this sample information, can one conclude that Raju Restaurant’s sales have increased?Use 5 per cent level of significance.\\nSolution:  Taking the null hypothesis that sales average 500 tea cups per day and they have not\\nincreased unless proved, we can write:\\nH\\n0 : µ = 500 cups per day\\nHa : µ > 500 (as we want to conclude that sales have increased).\\nAs the sample size is small and the population standard deviation is not known, we shall use t-test\\nassuming normal population and shall work out the test statistic t as:\\n tX\\nns=−µ\\nσ/\\n(To find X and σs we make the following computations:)Testing of Hypotheses I 207\\nTable 9.4\\nS. No. XiXXi− di XXi− di2\\n1 550 2 4\\n2 570 22 484\\n3 490 –58 3364\\n4 615 67 4489\\n5 505 –43 1849\\n6 580 32 1024\\n7 570 22 484\\n8 460 –88 7744\\n9 600 52 2704\\n10 580 32 1024\\n11 530 –18 324\\n12 526 –22 484\\nn = 10 ∑=Xi6576 ∑− =XXidi223978\\n∴ XX\\nni=∑==6576\\n12548\\nand     σsiXX\\nn=∑−\\n−=−=di2\\n123978\\n12 14668.\\nHence,       t=−==548 500\\n4668 1248\\n13493558\\n./ ..\\nDegree of freedom = n – 1 = 12 – 1 = 11\\nAs Ha is one-sided, we shall determine the rejection region applying one-tailed test (in the right\\ntail because Ha is of more than type) at 5 per cent level of significance and it comes to as under, using\\ntable of t-distribution for 11 degrees of freedom:\\nR : t > 1.796\\nThe observed value of t is 3.558 which is in the rejection region and thus H0 is rejected at 5 per\\ncent level of significance and we can conclude that the sample data indicate that Raju restaurant’s\\nsales have increased.\\nHYPOTHESIS TESTING FOR DIFFERENCES BETWEEN MEANS\\nIn many decision-situations, we may be interested in knowing whether the parameters of twopopulations are alike or different. For instance, we may be interested in testing whether femaleworkers earn less than male workers for the same job. We shall explain now the technique of208 Research Methodology\\nhypothesis testing for differences between means. The null hypothesis for testing of difference\\nbetween means is generally stated as H01 2:µµ =, where µ1 is population mean of one population\\nand µ2 is population mean of the second population, assuming both the populations to be normal\\npopulations. Alternative hypothesis may be of not equal to or less than or greater than type as statedearlier and accordingly we shall determine the acceptance or rejection regions for testing thehypotheses. There may be different situations when we are examining the significance of differencebetween two means, but the following may be taken as the usual situations:\\n1.Population variances are known or the samples happen to be large samples:\\nIn this situation we use z-test for difference in means and work out the test statistic z as\\nunder:\\nzXX\\nnnpp=−\\n+12\\n12\\n122\\n2σσ\\nIn case σp1 and σp2 are not known, we use σs1 and σs2 respectively in their places\\ncalculating\\nσσsi\\nsi XX\\nnXX\\nn12112\\n1222\\n2 11=∑−\\n−=∑−\\n−di d iand\\n2.Samples happen to be large but presumed to have been drawn from the same\\npopulation whose variance is known:\\nIn this situation we use z test for difference in means and work out the test statistic z as\\nunder:\\nzXX\\nnnp=−\\n+FHGIKJ12\\n2\\n1211σ\\nIn case σp is not known, we use σs12. (combined standard deviation of the two samples)\\nin its place calculating\\n    σσσ\\nsssnD nD\\nnn121212\\n12\\n22\\n22\\n12.=++ +\\n+ej ej\\nwhere DXX11 1 2=−. di\\n  DXX22 1 2=−. diTesting of Hypotheses I 209\\nXnX nX\\nnn1211 22\\n12.=+\\n+\\n3.Samples happen to be small samples and population variances not known but assumed\\nto be equal:\\nIn this situation we use t-test for difference in means and work out the test statistic t as\\nunder:\\ntXX\\nXX XX\\nnn n nii=−\\n∑− + ∑−\\n+−×+12\\n112\\n222\\n12 1 2 211 di d i\\nwith d.f. = ( n1 + n2 – 2)\\nAlternatively, we can also state\\ntXX\\nnn\\nnn n nss=−\\n−+ −\\n+−×+12\\n12\\n22\\n12 1 211\\n21112 bg b gσσ\\nwith d.f. = ( n1 + n2 – 2)\\nIllustration 7\\nThe mean produce of wheat of a sample of 100 fields in 200 lbs. per acre with a standard deviation\\nof 10 lbs. Another samples of 150 fields gives the mean of 220 lbs. with a standard deviation of12lbs. Can the two samples be considered to have been taken from the same population whosestandard deviation is 11 lbs? Use 5 per cent level of significance.\\nSolution:  Taking the null hypothesis that the means of two populations do not differ, we can write\\nH\\n0 : µµ =2\\nHa : µµ12≠\\nand the given information as n1 = 100; n2 = 150;\\nXX12200 220 ==lbs; lbs; ..\\nσσss1210 12 ==lbs; lbs; ..\\nand σp=11lbs.\\nAssuming the population to be normal, we can work out the test statistic z as under:\\nzXX\\nnnp=−\\n+FHGIKJ=−\\n+ FHGIKJ12\\n2\\n122 11200 220\\n111\\n1001\\n150σ bg210 Research Methodology\\n=− =−20\\n1421408..\\nAs Ha is two-sided, we shall apply a two-tailed test for determining the rejection regions at 5 per cent\\nlevel of significance which come to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is – 14.08 which falls in the rejection region and thus we reject H0 and\\nconclude that the two samples cannot be considered to have been taken at 5 per cent level of\\nsignificance from the same population whose standard deviation is 11 lbs. This means that the differencebetween means of two samples is statistically significant and not due to sampling fluctuations.\\nIllustration 8\\nA simple random sampling survey in respect of monthly earnings of semi-skilled workers in two\\ncities gives the following statistical information:\\nTable 9.5\\nCity Mean monthly Standard deviation of Size of\\nearnings (Rs) sample data of sample\\nmonthly earnings\\n(Rs)\\nA 695 40 200\\nB 710 60 175\\nTest the hypothesis at 5 per cent level that there is no difference between monthly earnings ofworkers in the two cities.\\nSolution:  Taking the null hypothesis that there is no difference in earnings of workers in the two\\ncities, we can write:\\nH\\n0 : µµ12=\\nHa : µµ12≠\\nand the given information as\\nSample 1  (City A) Sample 2  (City B)\\n X1695=Rs  X2710=Rs\\nσs140=Rs σs260=Rs\\n  n1 = 200   n2 = 175\\nAs the sample size is large, we shall use z-test for difference in means assuming the populations to be\\nnormal and shall work out the test statistic z as under:\\nzXX\\nnnss=−\\n+12\\n2\\n12\\n212σσTesting of Hypotheses I 211\\n(Since the population variances are not known, we have used the sample variances, considering\\nthe sample variances as the estimates of population variances.)\\nHence z=−\\n+=−\\n+=−695 710\\n40\\n2006017515\\n82 0 5 72809\\n22bg bg..\\nAs Ha is two-sided, we shall apply a two-tailed test for determining the rejection regions at 5 per\\ncent level of significance which come to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is – 2.809 which falls in the rejection region and thus we reject H0 at\\n5per cent level and conclude that earning of workers in the two cities differ significantly.\\nIllustration 9\\nSample of sales in similar shops in two towns are taken for a new product with the following results:\\nTown Mean sales Variance Size of sample\\nA 57 5.3 5\\nB 61 4.8 7\\nIs there any evidence of difference in sales in the two towns? Use 5 per cent level of significance\\nfor testing this difference between the means of two samples.\\nSolution:  Taking the null hypothesis that the means of two populations do not differ we can write:\\nH0 : µµ12=\\nHa : µµ12≠\\nand the given information as follows:\\nTable 9.6\\nSample from town A\\nas sample one X157= σs1253=. n1 = 5\\nSample from town B\\nAs sample two X261= σs2248=. n2 = 7\\nSince in the given question variances of the population are not known and the size of samples is\\nsmall, we shall use t-test for difference in means, assuming the populations to be normal and can\\nwork out the test statistic t as under:\\ntXX\\nnn\\nnn n nss=−\\n−+ −\\n+−×+12\\n12\\n22\\n12 1 211\\n21112 bg b gσσ\\nwith d.f. = ( n1 + n2 – 2)212 Research Methodology\\n=−\\n+\\n+−×+=−57 61\\n45 3 64 8\\n5721\\n51\\n73053\\n...bg bg\\nDegrees of freedom = ( n1 + n2 – 2) = 5 + 7 – 2 = 10\\nAs Ha is two-sided, we shall apply a two-tailed test for determining the rejection regions at 5 per\\ncent level which come to as under, using table of t-distribution for 10 degrees of freedom:\\nR : | t | > 2.228\\nThe observed value of t  is – 3.053 which falls in the rejection region and thus, we reject H0 and\\nconclude that the difference in sales in the two towns is significant at 5 per cent level.\\nIllustration 10\\nA group of seven-week old chickens reared on a high protein diet weigh 12, 15, 11, 16, 14, 14, and 16\\nounces; a second group of five chickens, similarly treated except that they receive a low protein diet,weigh 8, 10, 14, 10 and 13 ounces. Test at 5 per cent level whether there is significant evidence thatadditional protein has increased the weight of the chickens. Use assumed mean (or A\\n1) = 10 for the\\nsample of 7 and assumed mean (or A2) = 8 for the sample of 5 chickens in your calculations.\\nSolution: Taking the null hypothesis that additional protein has not increased the weight of the chickens\\nwe can write:\\nH0 : µµ12=\\nHa : µµ12> (as we want to conclude that additional protein has increased the weight of\\n         chickens)\\nSince in the given question variances of the populations are not known and the size of samples is\\nsmall, we shall use t-test for difference in means, assuming the populations to be normal and thus\\nwork out the test statistic t as under:\\ntXX\\nnn\\nnn n nss=−\\n−+ −\\n+−×+12\\n12\\n22\\n12 1 211\\n21112 bg b gσσ\\nwith d.f. = ( n1 + n2 – 2)\\nFrom the sample data we work out XXs 122\\n1,,σ and σs22 (taking high protein diet sample as\\nsample one and low protein diet sample as sample two) as shown below:Testing of Hypotheses I 213\\nTable 9.7\\nSample one Sample two\\nS.No. X1iX1i – A1XAi12\\n1− bg S.No. X2iX2i – A2XAi22\\n2− bg\\n(A1 = 10) (A2 = 8)\\n1. 12 2 4 1. 8 0 0\\n2. 15 5 25 2. 10 2 4\\n3. 11 1 1 3. 14 6 36\\n4. 16 6 36 4. 10 2 4\\n5. 14 4 16 5. 13 5 25\\n6. 14 4 16\\n7. 16 6 36\\nn1 = 7;      ∑−=XAi11 28 bg ;   ∑−XAi112bg n2 = 5;         ∑−=XAi22 15 bg ;     ∑−XAi222bg\\n= 134 = 69\\n∴ XAXA\\nni\\n1111\\n11028\\n714 =+∑−=+ =bgounces\\nXAXA\\nni\\n2222\\n2815\\n511 =+∑−=+ =bgounces\\nσsiiXA XAn\\nn12 112\\n112\\n1\\n11=∑− − ∑−\\n−bg bg\\nbg/\\n     =−\\n−=134 28 7\\n7136672bg/.ounces\\nσsiiXA XAn\\nn22 222\\n222\\n2\\n21=∑− − ∑−\\n−bg bg\\nbg/\\n     =−\\n−=69 15 5\\n5162bg/ounces\\nHence, t=−\\n−+ −\\n+−×+14 11\\n7 1 3667 5 1 6\\n7521\\n71\\n5bg bg b g b g.214 Research Methodology\\n=\\n×==3\\n46 3453\\n1262381\\n.. ..\\nDegrees of freedom = ( n1 + n2 – 2) = 10\\nAs Ha is one-sided, we shall apply a one-tailed test (in the right tail because Ha is of more than\\ntype) for determining the rejection region at 5 per cent level which comes to as under, using table of\\nt-distribution for 10 degrees of freedom:\\nR : t > 1.812\\nThe observed value of t is 2.381 which falls in the rejection region and thus, we reject H0 and\\nconclude that additional protein has increased the weight of chickens, at 5 per cent level of significance.\\nHYPOTHESIS TESTING FOR COMPARING TWO RELATED SAMPLES\\nPaired t-test is a way to test for comparing two related samples, involving small values of n that does\\nnot require the variances of the two populations to be equal, but the assumption that the two populationsare normal must continue to apply. For a paired t-test, it is necessary that the observations in the two\\nsamples be collected in the form of what is called matched pairs i.e., “each observation in the onesample must be paired with an observation in the other sample in such a manner that these observationsare somehow “matched” or related, in an attempt to eliminate extraneous factors which are not ofinterest in test.”\\n5 Such a test is generally considered appropriate in a before-and-after-treatment\\nstudy. For instance, we may test a group of certain students before and after training in order toknow whether the training is effective, in which situation we may use paired t-test. To apply this test,\\nwe first work out the difference score for each matched pair, and then find out the average of suchdifferences, \\nD, along with the sample variance of the difference score. If the values from the two\\nmatched samples are denoted as Xi and Yi and the differences by Di (Di = Xi – Yi), then the mean of\\nthe differences i.e.,\\nDD\\nni=∑\\nand the variance of the differences or\\nσdiffiDD n\\nn. didi 222\\n1=∑− ⋅\\n−\\nAssuming the said differences to be normally distributed and independent, we can apply the paired t-\\ntest for judging the significance of mean of differences and work out the test statistic t as under:\\n tD\\nndiff=−0\\nσ/ with (n – 1) degrees of freedom\\nwhere D = Mean of differences\\n5 Donald L. Harnett and James L. Murphy, “ Introductory Statistical Analysis ”, p. 364.Testing of Hypotheses I 215\\nσdiff . = Standard deviation of differences\\n      n = Number of matched pairs\\nThis calculated value of t is compared with its table value at a given level of significance as usual for\\ntesting purposes. We can also use Sandler’s A-test for this very purpose as stated earlier in\\nChapter 8.\\nIllustration 11\\nMemory capacity of 9 students was tested before and after training. State at 5 per cent level of\\nsignificance whether the training was effective from the following scores:\\nStudent 1 23456789\\nBefore 10 15 9 3 7 12 16 17 4\\nAfter 12 17 8 5 6 11 18 20 3\\nUse paired t-test as well as A-test for your answer.\\nSolution:  Take the score before training as X and the score after training as Y and then taking the null\\nhypothesis that the mean of difference is zero, we can write:\\nH0 : µµ12= which is equivalent to test H0 :D=0\\nHa : µµ12< (as we want to conclude that training has been effective)\\nAs we are having matched pairs, we use paired t-test and work out the test statistic t as under:\\ntD\\nndiff=−0\\nσ./\\nTo find the value of t, we shall first have to work out the mean and standard deviation of differences\\nas shown below:\\nTable 9.8\\nStudent Score before Score after Difference Difference\\ntraining training Squared\\nXiYi(Di = Xi – Yi ) Di2\\n11 0 1 2 –  2 4\\n21 5 1 7 –  2 4\\n39 8  1 1\\n43 5 –  2 4\\n57 6 1 1\\n61 2 1 1 1 1\\n71 6 1 8 –  2 4\\n81 7 2 0 –  3 9\\n94 3 1 1\\nn = 9 ∑= −Di7 ∑=Di229216 Research Methodology\\n∴ Mean of Differences or DD\\nni=∑=−=−7\\n90778.\\nand Standard deviation of differences or\\nσdiffiDD n\\nn.=∑− ⋅\\n−22\\n1di\\n           =−− ×\\n−29 778 9\\n912.bg\\n    ==2944 1715..\\nHence,                         t=−−=−=−0778 0\\n1715 9778\\n05721361.\\n./.\\n..\\nDegrees of freedom = n – 1 = 9 – 1 = 8.\\nAs Ha is one-sided, we shall apply a one-tailed test (in the left tail because Ha is of less than type)\\nfor determining the rejection region at 5 per cent level which comes to as under, using the table of\\nt-distribution for 8 degrees of freedom:\\nR : t < – 1.860\\nThe observed value of t is –1.361 which is in the acceptance region and thus, we accept H0 and\\nconclude that the difference in score before and after training is insignificant i.e., it is only due tosampling fluctuations. Hence we can infer that the training was not effective.\\nSolution using A-test: Using A-test, we workout the test statistic for the given problem thus:\\nAD\\nDi\\ni=∑\\n∑=\\n−=2\\n2229\\n70592bgb g.\\nSince Ha in the given problem is one-sided, we shall apply one-tailed test. Accordingly, at 5% level of\\nsignificance the table value of A-statistic for ( n – 1) or (9 – 1) = 8 d.f. in the given case is 0.368 (as\\nper table of A-statistic given in appendix). The computed value of A i.e., 0.592 is higher than this table\\nvalue and as such A-statistic is insignificant and accordingly H0 should be accepted. In other words,\\nwe should conclude that the training was not effective. (This inference is just the same as drawn\\nearlier using paired t-test.)\\nIllustration 12\\nThe sales data of an item in six shops before and after a special promotional campaign are:\\nShops A B C D E F\\nBefore the promotional campaign 53 28 31 48 50 42\\nAfter the campaign 58 29 30 55 56 45\\nCan the campaign be judged to be a success? Test at 5 per cent level of significance. Use paired\\nt-test as well as A-test.Testing of Hypotheses I 217\\nSolution:  Let the sales before campaign be represented as X and the sales after campaign as Y and\\nthen taking the null hypothesis that campaign does not bring any improvement in sales, we can write:\\nH0 : µµ12= which is equivalent to test HD00 :=\\nHa : µµ12< (as we want to conclude that campaign has been a success).\\nBecause of the matched pairs we use paired t-test and work out the test statistic ‘ t’ as under:\\ntD\\nndiff=−0\\nσ./\\nTo find the value of t, we first work out the mean and standard deviation of differences as under:\\nTable 9.9\\nShops Sales before Sales after Difference Difference\\ncampaign campaign squared\\nXiYi(Di = Xi – Yi ) Di2\\nA5 3 5 8 – 5 2 5\\nB2 8 2 9 – 1 1\\nC3 1 3 0 1 1\\nD4 8 5 5 – 7 4 9\\nE5 0 5 6 – 6 3 6\\nF4 2 4 5 – 3 9\\nn = 6 ∑= −Di21 ∑=Di2121\\n∴ DD\\nni=∑=− =−21\\n635.\\nσdiffiDD n\\nn... =∑− ⋅\\n−=−− ×\\n−=222\\n1121 35 6\\n61308di bg\\nHence,             t=−−=−=−35 0\\n308 635\\n12572784.\\n./.\\n..\\nDegrees of freedom = ( n – 1) = 6 – 1 = 5\\nAs Ha is one-sided, we shall apply a one-tailed test (in the left tail because Ha is of less than type)\\nfor determining the rejection region at 5 per cent level of significance which come to as under, using\\ntable of t-distribution for 5 degrees of freedom:\\nR : t < – 2.015\\nThe observed value of t  is – 2.784 which falls in the rejection region and thus, we reject H0 at 5\\nper cent level and conclude that sales promotional campaign has been a success.218 Research Methodology\\nSolution:  Using A-test:  Using A-test, we work out the test statistic for the given problem as under:\\nAD\\nDi\\ni=∑\\n∑=\\n−=2\\n22121\\n2102744bgb g.\\nSince Ha in the given problem is one-sided, we shall apply one-tailed test. Accordingly, at 5%\\nlevel of significance the table value of A-statistic for ( n –1) or (6 –1) = 5 d.f. in the given case is\\n0.372 (as per table of A-statistic given in appendix). The computed value of A, being 0.2744, is less\\nthan this table value and as such A-statistic is significant. This means we should reject H0 (alternately\\nwe should accept Ha ) and should infer that the sales promotional campaign has been a success.\\nHYPOTHESIS TESTING OF PROPORTIONS\\nIn case of qualitative phenomena, we have data on the basis of presence or absence of an attribute(s).\\nWith such data the sampling distribution may take the form of binomial probability distribution whose\\nmean would be equal to np⋅ and standard deviation equal to npq⋅⋅, where p represents the\\nprobability of success, q represents the probability of failure such that p + q = 1 and n, the size of the\\nsample. Instead of taking mean number of successes and standard deviation of the number of\\nsuccesses, we may record the proportion of successes in each sample in which case the mean andstandard deviation (or the standard error) of the sampling distribution may be obtained as follows:\\nMean proportion of successes \\n=⋅ =np n pbg/\\nand standard deviation of the proportion of successes =⋅pq\\nn.\\nIn n is large, the binomial distribution tends to become normal distribution, and as such for\\nproportion testing purposes we make use of the test statistic z as under:\\nzpp\\npq\\nn=−\\n⋅$\\nwhere $p is the sample proportion.\\nFor testing of proportion, we formulate H0 and Ha and construct rejection region, presuming\\nnormal approximation of the binomial distribution, for a predetermined level of significance and thenmay judge the significance of the observed sample result. The following examples make all this quiteclear.\\nIllustration 13\\nA sample survey indicates that out of 3232 births, 1705 were boys and the rest were girls. Do these\\nfigures confirm the hypothesis that the sex ratio is 50 : 50? Test at 5 per cent level of significance.\\nSolution:  Starting from the null hypothesis that the sex ratio is 50 : 50 we may write:Testing of Hypotheses I 219\\n       HppH 001\\n2:==\\nHppaH:≠\\n0\\nHence the probability of boy birth or p=1\\n2 and the probability of girl birth is also 1\\n2.\\nConsidering boy birth as success and the girl birth as failure, we can write as under:\\n the proportion success or p=1\\n2\\nthe proportion of failure or q=1\\n2\\nand n = 3232 (given).\\nThe standard error of proportion of success.\\n=⋅=×\\n=pq\\nn1\\n21\\n2\\n323200088.\\nObserved sample proportion of success, or\\n         $/.p==1705 3232 05275\\nand the test statistic\\n     zpp\\npq\\nn=−\\n⋅=−=$ ..\\n..05275 5000\\n00883125\\nAs Ha is two-sided in the given question, we shall be applying the two-tailed test for determining\\nthe rejection regions at 5 per cent level which come to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is 3.125 which comes in the rejection region since R : | z | > 1.96 and\\nthus, H0 is rejected in favour of Ha. Accordingly, we conclude that the given figures do not conform\\nthe hypothesis of sex ratio being 50 : 50.\\nIllustration 14\\nThe null hypothesis is that 20 per cent of the passengers go in first class, but management recognizes\\nthe possibility that this percentage could be more or less. A random sample of 400 passengersincludes 70 passengers holding first class tickets. Can the null hypothesis be rejected at 10 per centlevel of significance?\\nSolution:  The null hypothesis is\\n H\\n0 : p = 20% or 0.20\\nand  Ha : p ≠ 20%220 Research Methodology\\nHence, p = 0.20 and\\nq = 0.80\\nObserved sample  proportion $pbg = 70/400 = 0.175\\nand the test statistic zpp\\npq\\nn=−\\n⋅=−\\n×=−$ ..\\n...0175 20\\n20 80\\n400125\\nAs Ha is two-sided we shall determine the rejection regions applying two-tailed test at 10 per\\ncent level which come to as under, using normal curve area table:\\nR : | z | > 1.645\\nThe observed value of z is –1.25 which is in the acceptance region and as such H0 is accepted.\\nThus the null hypothesis cannot be rejected at 10 per cent level of significance.\\nIllustration 15\\nA certain process produces 10 per cent defective articles. A supplier of new raw material claims\\nthat the use of his material would reduce the proportion of defectives. A random sample of 400 unitsusing this new material was taken out of which 34 were defective units. Can the supplier’s claim beaccepted? Test at 1 per cent level of significance.\\nSolution:  The null hypothesis can be written as H\\n0 : p = 10% or 0.10 and the alternative hypothesis\\nHa : p < 0.10 (because the supplier claims that new material will reduce proportion of defectives).\\nHence,\\np = 0.10 and q = 0.90\\nObserved sample proportion $p = 34/400 = 0.085 and test statistic\\nzpp\\npq\\nn=−\\n⋅=−\\n×== −$ ..\\n...\\n..085 10\\n10 90\\n400015015100\\nAs Ha is one-sided, we shall determine the rejection region applying one-tailed test (in the left tail\\nbecause Ha is of less than type) at 1% level of significance and it comes to as under, using normal\\ncurve area table:\\nR : z < – 2.32\\nAs the computed value of z does not fall in the rejection region, H0 is accepted at 1% level of\\nsignificance and we can conclude that on the basis of sample information, the supplier’s claim cannot\\nbe accepted at 1% level.\\nHYPOTHESIS TESTING FOR DIFFERENCE BETWEEN PROPORTIONS\\nIf two samples are drawn from different populations, one may be interested in knowing whether thedifference between the proportion of successes is significant or not. In such a case, we start with the\\nhypothesis that the difference between the proportion of success in sample one \\n$p1bg and the proportionTesting of Hypotheses I 221\\nof success in sample two $p2bg is due to fluctuations of random sampling. In other words, we take\\nthe null hypothesis as Hp p01 2:$$= and for testing the significance of difference, we work out the\\ntest statistic as under:\\nzpp\\npq\\nnpq\\nn=−\\n⋅+⋅$$\\n$$ $$12\\n11\\n122\\n2\\nwhere $p1 = proportion of success in sample one\\n$p2 = proportion of success in sample two\\n  $$qp111=−\\n $$qp221=−\\n  n1 = size of sample one\\n  n2 = size of sample two\\nand\\n$$ $$pq\\nnpq\\nn11\\n122\\n2+ = the standard error of difference between two sample proportions.*\\nThen, we construct the rejection region(s) depending upon the Ha for a given level of significance\\nand on its basis we judge the significance of the sample result for accepting or rejecting H0. We can\\nnow illustrate all this by examples.\\nIllustration 6\\nA drug research experimental unit is testing two drugs newly developed to reduce blood pressure\\nlevels. The drugs are administered to two different sets of animals. In group one, 350 of 600 animalstested respond to drug one and in group two, 260 of 500 animals tested respond to drug two. Theresearch unit wants to test whether there is a difference between the efficacy of the said two drugsat 5 per cent level of significance. How will you deal with this problem?\\n* This formula is used when samples are drawn from two heterogeneous populations where we cannot have the best\\nestimate of the common value of the proportion of the attribute in the population from the given sample information. Buton the assumption that the populations are similar as regards the given attribute, we make use of the following formula forworking out the standard error of difference between proportions of the two samples:\\nS.E.Diff p ppq\\nnpq\\nn.1200\\n100\\n2−=⋅+⋅\\nwhere pnp np\\nnn011 22\\n12=⋅+⋅\\n+$$\\n = best estimate of proportion in the population\\n qp001=−222 Research Methodology\\nSolution:  We take the null hypothesis that there is no difference between the two drugs i.e.,\\nHp p01 2:$$=\\nThe alternative hypothesis can be taken as that there is a difference between the drugs i.e.,\\nHp pa:$$12≠ and the given information can be stated as:\\n$/.p1350 600 0583==\\n        $$ . qp111 0417=− =\\n        n1 = 600\\n       $/.p2260 500 0520==\\n       $$ . qp221 0480=− =\\n        n2 = 500\\nWe can work out the test statistic z thus:\\nzpp\\npq\\nnpq\\nn=−\\n+=−\\n+$$\\n$$ $$..\\n.. ..12\\n11\\n122\\n20583 0520\\n583 417\\n600520 480\\n500bg b g bg bg\\n= 2.093\\nAs Ha is two-sided, we shall determine the rejection regions applying two-tailed test at 5% level\\nwhich comes as under using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is 2.093 which is in the rejection region and thus, H0 is rejected in favour of\\nHa and as such we conclude that the difference between the efficacy of the two drugs is significant.\\nIllustration 17\\nAt a certain date in a large city 400 out of a random sample of 500 men were found to be smokers.\\nAfter the tax on tobacco had been heavily increased, another random sample of 600 men in the samecity included 400 smokers. Was the observed decrease in the proportion of smokers significant? Testat 5 per cent level of significance.\\nSolution:  We start with the null hypothesis that the proportion of smokers even after the heavy tax\\non tobacco remains unchanged i.e. \\nHp p01 2:$$= and the alternative hypothesis that proportion of\\nsmokers after tax has decreased i.e.,\\nHp pa:$$12>\\nOn the presumption that the given populations are similar as regards the given attribute, we work\\nout the best estimate of proportion of smokers ( p0) in the population as under, using the given information:\\npnp np\\nnn011 22\\n12500400\\n500600400600\\n500 600800\\n11008\\n117273 =+\\n+=FHGIKJ+ FHGIKJ\\n+== =$$.Testing of Hypotheses I 223\\nThus, q0 = 1 – p0 = .2727\\nThe test statistic z can be worked out as under:\\nzpp\\npq\\nnpq\\nn=−\\n+=−\\n+$$\\n.. ..12\\n00\\n100\\n2400\\n500400\\n600\\n7273 2727\\n5007273 2727\\n600bg bg bg bg\\n       ==0133\\n00274926.\\n..\\nAs the Ha is one-sided we shall determine the rejection region applying one-tailed test (in the right tail\\nbecause Ha is of greater than type) at 5 per cent level and the same works out to as under, using\\nnormal curve area table:\\nR : z > 1.645\\nThe observed value of z is 4.926 which is in the rejection region and so we reject H0 in favour of Ha\\nand conclude that the proportion of smokers after tax has decreased significantly.\\nTesting the difference between proportion based on the sample and the proportion given\\nfor the whole population:  In such a situation we work out the standard error of difference between\\nproportion of persons possessing an attribute in a sample and the proportion given for the population\\nas under:\\nStandard error of difference between sample proportion and\\npopulation proportion or S.E.diff p p pqNn\\nnN.$−=⋅−\\nwherep = population proportion\\nq = 1 – p\\nn = number of items in the sample\\nN = number of items in population\\nand the test statistic z can be worked out as under:\\nzpp\\npqNn\\nnN=−\\n⋅−$\\nAll other steps remain the same as explained above in the context of testing of proportions. We\\ntake an example to illustrate the same.\\nIllustration 18\\nThere are 100 students in a university college and in the whole university, inclusive of this college, the\\nnumber of students is 2000. In a random sample study 20 were found smokers in the college and theproportion of smokers in the university is 0.05. Is there a significant difference between the proportionof smokers in the college and university? Test at 5 per cent level.224 Research Methodology\\nSolution: Let Hpp0:$= (there is no difference between sample proportion and population proportion)\\nand        Hppa:$≠ (there is difference between the two proportions)\\nand on the basis of the given information, the test statistic z can be worked out as under:\\nzpp\\npqNn\\nnN=−\\n⋅−=−\\n−$.\\n..20\\n10005\\n05 952000 100\\n100 2000bg bgbg b g\\n    ==0150\\n00217143...\\nAs the Ha is two-sided, we shall determine the rejection regions applying two-tailed test at 5 per\\ncent level and the same works out to as under, using normal curve area table:\\nR : | z | > 1.96\\nThe observed value of z is 7.143 which is in the rejection region and as such we reject H0 and\\nconclude that there is a significant difference between the proportion of smokers in the college and\\nuniversity.\\nHYPOTHESIS TESTING FOR COMPARING A VARIANCETO SOME HYPOTHESISED POPULATION VARIANCE\\nThe test we use for comparing a sample variance to some theoretical or hypothesised variance ofpopulation is different than z-test or the t-test. The test we use for this purpose is known as chi-\\nsquare test and the test statistic symbolised as \\nχ2, known as the chi-square value, is worked out.\\nThe chi-square value to test the null hypothesis viz, Hsp022:σσ = worked out as under:\\nχσ\\nσ22\\n21 =−s\\npnbg\\nwhereσs2 = variance of the sample\\nσp2 = variance of the population\\n (n – 1) = degree of freedom, n being the number of items in the sample.\\nThen by comparing the calculated value of χ2 with its table value for ( n – 1) degrees of\\nfreedom at a given level of significance, we may either accept H0 or reject it. If the calculated value\\nof χ2 is equal to or less than the table value, the null hypothesis is accepted; otherwise the null\\nhypothesis is rejected. This test is based on chi-square distribution which is not symmetrical and allTesting of Hypotheses I 225\\nthe values happen to be positive; one must simply know the degrees of freedom for using such a\\ndistribution.*\\nTESTING THE EQUALITY OF VARIANCESOF TWO NORMAL POPULATIONS\\nWhen we want to test the equality of variances of two normal populations, we make use of F-test\\nbased on F-distribution. In such a situation, the null hypothesis happens to be Hpp p022 2\\n12 1:,σσ σ=\\nand σp22 representing the variances of two normal populations. This hypothesis is tested on the basis\\nof sample data and the test statistic F is found, using σs12 and σs22 the sample estimates for σp12 and\\nσp22 respectively, as stated below:\\nFs\\ns=σ\\nσ1\\n22\\n2\\nwhere σσsi\\nsi XX\\nnXX\\nn122 112\\n12 222\\n2 11=∑−\\n−=∑−\\n−dibgdibgand\\nWhile calculating F, σs12 is treated > σs22 which means that the numerator is always the greater\\nvariance. Tables for F-distribution** have been prepared by statisticians for different values of F at\\ndifferent levels of significance for different degrees of freedom for the greater and the smaller\\nvariances. By comparing the observed value of F with the corresponding table value, we can infer\\nwhether the difference between the variances of samples could have arisen due to samplingfluctuations. If the calculated value of F is greater than table value of F at a certain level of significance\\nfor (n\\n1 – 1) and ( n2 – 2) degrees of freedom, we regard the F-ratio as significant. Degrees of\\nfreedom for greater variance is represented as v1 and for smaller variance as v2. On the other hand,\\nif the calculated value of F is smaller than its table value, we conclude that F-ratio is not significant.\\nIf F-ratio is considered non-significant, we accept the null hypothesis, but if F-ratio is considered\\nsignificant, we then reject H0 (i.e., we accept Ha).\\nWhen we use the F-test, we presume that\\n(i) the populations are normal;\\n(ii)samples have been drawn randomly;\\n(iii)observations are independent; and\\n(iv)there is no measurement error.\\nThe object of F-test is to test the hypothesis whether the two samples are from the same normal\\npopulation with equal variance or from two normal populations with equal variances. F-test was\\ninitially used to verify the hypothesis of equality between two variances, but is now mostly used in the\\n*See Chapter 10 entitled Chi-square test for details.\\n** F-distribution tables [Table 4(a) and Table 4(b)] have been given in appendix at the end of the book.226 Research Methodology\\ncontext of analysis of variance. The following examples illustrate the use of F-test for testing the\\nequality of variances of two normal populations.\\nIllustration 19\\nTwo random samples drawn from two normal populations are:\\nSample 1 20 16 26 27 23 22 18 24 25 19\\nSample 2 27 33 42 35 32 34 38 28 41 43 30 37\\nTest using variance ratio at 5 per cent and 1 per cent level of significance whether the two\\npopulations have the same variances.\\nSolution:  We take the null hypothesis that the two populations from where the samples have been\\ndrawn have the same variances i.e., Hpp022\\n12:σσ = . From the sample data we work out σs12 and\\nσs22 as under:\\nTable 9.10\\nSample 1 Sample 2\\nX1iXXi11− di XXi112− di X2iXXi22− di XXi222− di\\n20 –2 4 27 –8 64\\n16 –6 36 33 –2 4\\n26 4 16 42 7 49\\n27 5 25 35 0 0\\n23 1 1 32 –3 9\\n22 0 0 34 –1 1\\n18 –4 16 38 3 9\\n24 2 4 28 –7 49\\n25 3 9 41 6 36\\n19 –3 9 43 8 64\\n30 –5 25\\n37 2 4\\n∑=Xi1220 ∑− =XXi112120 di ∑=Xi2420 ∑− =XXi222314 di\\nn1 = 10 n2 = 12\\nXX\\nnXX\\nnii\\n11\\n122\\n2220\\n1022420\\n1235 =∑== =∑== ;\\n∴  σsiXX\\nn12 112\\n11120\\n10 11333 =∑−\\n−=−=di.Testing of Hypotheses I 227\\nand σsiXX\\nn22 222\\n21314\\n12 12855 =∑−\\n−=−=di.\\nHence,         Fs\\nsss =>σ\\nσσσ2\\n1212\\n222Qej\\n==2855\\n1333214.\\n..\\nDegrees of freedom in sample 1 = ( n1 – 1) = 10 – 1 = 9\\nDegrees of freedom in sample 2 = ( n2 – 1) = 12 – 1 = 11\\nAs the variance of sample 2 is greater variance, hence\\nv1 = 11; v2 = 9\\nThe table value of F at 5 per cent level of significance for v1 = 11 and v2 = 9 is 3.11 and the table\\nvalue of F at 1 per cent level of significance for v1 = 11 and v2 = 9 is 5.20.\\nSince the calculated value of F = 2.14 which is less than 3.11 and also less than 5.20, the F ratio\\nis insignificant at 5 per cent as well as at 1 per cent level of significance and as such we accept the\\nnull hypothesis and conclude that samples have been drawn from two populations having the samevariances.\\nIllustration 20\\nGiven n\\n1 = 9; n2 = 8\\n∑− =XXi112184 di\\n       ∑− =XXi22238 di\\nApply F-test to judge whether this difference is significant at 5 per cent level.\\nSolution: We start with the hypothesis that the difference is not significant and hence, Hpp022\\n12:σσ = .\\nTo test this, we work out the F-ratio as under:\\nFXXn\\nXXns\\nsi\\ni==∑− −\\n∑− −σ\\nσ1\\n22\\n2112\\n1\\n222\\n21\\n1di bg\\ndi bg/\\n/\\n == =184 8\\n38 723\\n543425/\\n/..\\nv1 = 8 being the number of d.f. for greater variance\\nv2 = 7 being the number of d.f. for smaller variance.228 Research Methodology\\nThe table value of F at 5 per cent level for v1 = 8 and v2= 7 is 3.73. Since the calculated value of\\nF is greater than the table value, the F ratio is significant at 5 per cent level. Accordingly we reject\\nH0 and conclude that the difference is significant.\\nHYPOTHESIS TESTING OF CORRELATION COEFFICIENTS*\\nWe may be interested in knowing whether the correlation coefficient that we calculate on the basis\\nof sample data is indicative of significant correlation. For this purpose we may use (in the context ofsmall samples) normally either the t-test or the F-test depending upon the type of correlation coefficient.\\nWe use the following tests for the purpose:\\n(a) In case of simple correlation coefficient: We use t-test and calculate the test statistic as under:\\ntrn\\nryx\\nyx=−\\n−2\\n12\\nwith (n – 2) degrees of freedom ryx being coefficient of simple correlation between x and y.\\nThis calculated value of t is then compared with its table value and if the calculated value is less\\nthan the table value, we accept the null hypothesis at the given level of significance and may infer\\nthat there is no relationship of statistical significance between the two variables.\\n(b) In case of partial correlation coefficient: We use t-test and calculate the test statistic as under:\\ntrnk\\nrp\\np=−\\n−bg\\n12\\nwith (n – k) degrees of freedom, n being the number of paired observations and k being the number\\nof variables involved, rp happens to be the coefficient of partial correlation.\\nIf the value of t in the table is greater than the calculated value, we may accept null hypothesis\\nand infer that there is no correlation.\\n(c) In case of multiple correlation coefficient: We use F-test and work out the test statistic as\\nunder:\\nFRk\\nRn k=−\\n−−2\\n21\\n1/\\n/bg\\nej bg\\nwhere R is any multiple coefficient of correlation, k being the number of variables involved and n\\nbeing the number of paired observations. The test is performed by entering tables of the F-distribution\\nwith\\nv1 = k – 1 = degrees of freedom for variance in numerator.\\nv2 = n – k = degrees of freedom for variance in denominator.\\nIf the calculated value of F is less than the table value, then we may infer that there is no statistical\\nevidence of significant correlation.\\n*Only the outline of testing procedure has been given here. Readers may look into standard tests for further details.Testing of Hypotheses I 229\\nLIMITATIONS OF THE TESTS OF HYPOTHESES\\nWe have described above some important test often used for testing hypotheses on the basis of\\nwhich important decisions may be based. But there are several limitations of the said tests whichshould always be borne in mind by a researcher. Important limitations are as follows:\\n(i) The tests should not be used in a mechanical fashion. It should be kept in view that testing\\nis not decision-making itself; the tests are only useful aids for decision-making. Hence“proper interpretation of statistical evidence is important to intelligent decisions.”\\n6\\n(ii) Test do not explain the reasons as to why does the difference exist, say between the means\\nof the two samples. They simply indicate whether the difference is due to fluctuations ofsampling or because of other reasons but the tests do not tell us as to which is/are the otherreason(s) causing the difference.\\n(iii)Results of significance tests are based on probabilities and as such cannot be expressedwith full certainty. When a test shows that a difference is statistically significant, then itsimply suggests that the difference is probably not due to chance.\\n(iv)Statistical inferences based on the significance tests cannot be said to be entirely correctevidences concerning the truth of the hypotheses. This is specially so in case of smallsamples where the probability of drawing erring inferences happens to be generally higher.For greater reliability, the size of samples be sufficiently enlarged.\\nAll these limitations suggest that in problems of statistical significance, the inference techniques\\n(or the tests) must be combined with adequate knowledge of the subject-matter along with the abilityof good judgement.\\nQuestions\\n1.Distinguish between the following:\\n(i) Simple hypothesis and composite hypothesis;\\n(ii)Null hypothesis and alternative hypothesis;\\n(iii)One-tailed test and two-tailed test;\\n(iv) Type I error and Type II error;\\n(v) Acceptance region and rejection region;\\n(vi)Power function and operating characteristic function.\\n2.What is a hypothesis? What characteristics it must possess in order to be a good research hypothesis?A manufacturer considers his production process to be working properly if the mean length of the rodsthe manufactures is 8.5 \". The standard deviation of the rods always runs about 0.26 \". Suppose a sample\\nof 64 rods is taken and this gives a mean length of rods equal to 8.6 \". What are the null and alternative\\nhypotheses for this problem? Can you infer at 5% level of significance that the process is workingproperly?\\n3.The procedure of testing hypothesis requires a researcher to adopt several steps. Describe in brief allsuch steps.\\n6 Ya-Lun-Chou, “Applied Business and Economic Statistics”.230 Research Methodology\\n4.What do you mean by the power of a hypothesis test? How can it be measured? Describe and illustrate\\nby an example.\\n5.Briefly describe the important parametric tests used in context of testing hypotheses. How such testsdiffer from non-parametric tests? Explain.\\n6.Clearly explain how will you test the equality of variances of two normal populations.\\n7.(a) What is a t-test? When it is used and for what purpose(s)? Explain by means of examples.\\n(b) Write a brief note on “Sandler’s A-test” explaining its superiority over t-test.\\n8.Point out the important limitations of tests of hypotheses. What precaution the researcher must takewhile drawing inferences as per the results of the said tests?\\n9.A coin is tossed 10,000 times and head turns up 5,195 times. Is the coin unbiased?\\n10.In some dice throwing experiments, A threw dice 41952 times and of these 25145 yielded a 4 or 5 or 6. Is\\nthis consistent with the hypothesis that the dice were unbiased?\\n11. A machine puts out 16 imperfect articles in a sample of 500. After machine is overhauled, it puts out threeimperfect articles in a batch of 100. Has the machine improved? Test at 5% level of significance.\\n12.In two large populations, there are 35% and 30% respectively fair haired people. Is this difference likelyto be revealed by simple sample of 1500 and 1000 respectively from the two populations?\\n13.In a certain association table the following frequencies were obtained:\\n(AB) = 309, (Ab) = 214, (aB) = 132, (ab) = 119.\\nCan the association between AB as per the above data can be said to have arisen as a fluctuation of\\nsimple sampling?\\n14.A sample of 900 members is found to have a mean of 3.47 cm. Can it be reasonably regarded as a simple\\nsample from a large population with mean 3.23 cm. and standard deviation 2.31 cm.?\\n15.The means of the two random samples of 1000 and 2000 are 67.5 and 68.0 inches respectively. Can the\\nsamples be regarded to have been drawn from the same population of standard deviation 9.5 inches? Testat 5% level of significance.\\n16.A large corporation uses thousands of light bulbs every year. The brand that has been used in the pasthas an average life of 1000 hours with a standard deviation of 100 hours. A new brand is offered to thecorporation at a price far lower than one they are paying for the old brand. It is decided that they willswitch to the new brand unless it is proved with a level of significance of 5% that the new brand hassmaller average life than the old brand. A random sample of 100 new brand bulbs is tested yielding anobserved sample mean of 985 hours. Assuming that the standard deviation of the new brand is the sameas that of the old brand,\\n(a) What conclusion should be drawn and what decision should be made?\\n(b) What is the probability of accepting the new brand if it has the mean life of 950 hours?\\n17.Ten students are selected at random from a school and their heights are found to be, in inches, 50, 52, 52,53, 55, 56, 57, 58, 58 and 59. In the light of these data, discuss the suggestion that the mean height of thestudents of the school is 54 inches. You may use 5% level of significance (Apply t-test as well as A-test).\\n18.In a test given to two groups of students, the marks obtained were as follows:\\nFirst Group 18 20 36 50 49 36 34 49 41\\nSecond Group 29 28 26 35 30 44 46\\nExamine the significance of difference between mean marks obtained by students of the above two\\ngroups. Test at five per cent level of significance.\\n19.The heights of six randomly chosen sailors are, in inches, 63, 65, 58, 69, 71 and 72. The heights of 10randomly chosen soldiers are, in inches, 61, 62, 65, 66, 69, 69, 70, 71, 72 and 73. Do these figures indicatethat soldiers are on an average shorter than sailors? Test at 5% level of significance.Testing of Hypotheses I 231\\n20.Ten young recruits were put through a strenuous physical training programme by the army. Their weights\\n(in kg) were recorded before and after with the following results:\\nRecruit 1 2 3 4 567891 0\\nWeight before 127 195 162 170 143 205 168 175 197 136\\nWeight after 135 200 160 182 147 200 172 186 194 141\\nUsing 5% level of significance, should we conclude that the programme affects the average weight of\\nyoung recruits (Answer using t-test as well as A-test)?\\n21.Suppose a test on the hypotheses H0 : µ = 200 against Ha : µ > 200 is done with 1%  level of significance,\\nσp = 40 and n = 16.\\n(a) What is the probability that the null hypothesis might be accepted when the true mean is really 210?\\nWhat is the power of the test for µ = 210? How these values of β and 1 – β change if the test had\\nused 5% level of significance?\\n(b) Which is more serious, a Type I and Type II error?\\n22.The following nine observations were drawn from a normal population:\\n27  19  20  24  23  29  21  17  27\\n(i) Test the null hypothesis H0 : µ = 26 against the alternative hypothesis Ha : µ≠ 26. At what level of\\nsignificance can H0 be rejected?\\n(ii) At what level of significance can H0 : µ = 26 be rejected when tested against Ha : µ < 26?\\n23.Suppose that a public corporation has agreed to advertise through a local newspaper if it can be establishedthat the newspaper circulation reaches more than 60% of the corporation’s customers. What H\\n0 and Ha\\nshould be established for this problem while deciding on the basis of a sample of customers whether ornot the corporation should advertise in the local newspaper?  If a sample of size 100 is collected and 1%level of significance is taken, what is the critical value for making a decision whether or not to advertise?Would it make any difference if we take a sample of 25 in place of 100 for our purpose? If so, explain.\\n24.Answer using F-test whether the following two samples have come from the same population:\\nSample 1 17   27   18   25   27   29   27   23   17\\nSample 2 16   16   20   16   20   17   15   21\\n Use 5% level of significance.\\n25.The following table gives the number of units produced per day by two workers A and B for a number of\\ndays:\\nA  40  30  38  41  38  35\\n           B  39  38  41  33  32  49  49  34\\nShould these results be accepted as evidence that B is the more stable worker? Use F-test at 5% level.\\n26.A sample of 600 persons selected at random from a large city gives the result that males are 53%. Is therereason to doubt the hypothesis that males and females are in equal numbers in the city? Use 1% level ofsignificance.\\n27.12 students were given intensive coaching and 5 tests were conducted in a month. The scores of tests 1and 5 are given below. Does the score from Test 1 to Test 5 show an improvement? Use 5% level ofsignificance.\\nNo. of students 1234567891 0 1 1 1 2\\nMarks in 1st Test 50 42 51 26 35 42 60 41 70 55 62 38\\nMarks in 5th test 62 40 61 35 30 52 68 51 84 63 72 50232 Research Methodology\\n28.(i) A random sample from 200 villages was taken from Kanpur district and the average population per\\nvillage was found to be 420 with a standard deviation of 50. Another random sample of 200 villages fromthe same district gave an average population of 480 per village with a standard deviation of 60. Is thedifference between the averages of the two samples statistically significant? Take 1% level of significance.\\n(ii) The means of the random samples of sizes 9 and 7 are 196.42 and 198.42 respectively. The sums of he\\nsquares of the deviations from the mean are 26.94 and 18.73 respectively. Can the samples be constitutedto have been drawn from the same normal population? Use 5% level of significance.\\n29.A farmer grows crops on two fields A and B. On A he puts Rs. 10 worth of manure per acre and on B Rs 20\\nworth. The net returns per acre exclusive of the cost of manure on the two fields in the five years are:\\nYear 12345\\nField A, Rs per acre 34 28 42 37 44\\nField B, Rs per acre 36 33 48 38 50\\nOther things being equal, discuss the question whether it is likely to pay the farmer to continue the more\\nexpensive dressing. Test at 5% level of significance.\\n30.ABC Company is considering a site for locating their another plant. The company insists that any\\nlocation they choose must have an average auto traffic of more than 2000 trucks per day passing the site.They take a traffic sample of 20 days and find an average volume per day of 2140 with standard deviationequal to 100 trucks.\\nAnswer the following:\\n(i) If \\nα = .05, should they purchase the site?\\n(ii) If we assume the population mean to be 2140, what is the β error?Chi-square Test 233\\n10\\nChi-Square Test\\nThe chi-square test is an important test amongst the several tests of significance developed by\\nstatisticians. Chi-square, symbolically written as χ2 (Pronounced as Ki-square), is a statistical\\nmeasure used in the context of sampling analysis for comparing a variance to a theoretical variance.\\nAs a non-parametric* test, it “can be used to determine if categorical data shows dependency or the\\ntwo classifications are independent. It can also be used to make comparisons between theoreticalpopulations and actual data when categories are used.”\\n1 Thus, the chi-square test is applicable in\\nlarge number of problems. The test is, in fact, a technique through the use of which it is possible forall researchers to (i) test the goodness of fit; (ii) test the significance of association between twoattributes, and (iii) test the homogeneity or the significance of population variance.\\nCHI-SQUARE AS A TEST FOR COMPARING VARIANCE\\nThe chi-square value is often used to judge the significance of population variance i.e., we can use\\nthe test to judge if a random sample has been drawn from a normal population with mean ()µ and\\nwith a specified variance ( σp2). The test is based on χ2-distribution. Such a distribution we encounter\\nwhen we deal with collections of values that involve adding up squares. Variances of samples require\\nus to add a collection of squared quantities and, thus, have distributions that are related to\\nχ2-distribution. If we take each one of a collection of sample variances, divided them by the known\\npopulation variance and multiply these quotients by ( n – 1), where n means the number of items in\\nthe sample, we shall obtain a χ2-distribution. Thus, σ\\nσσ\\nσs\\nps\\npn2\\n22\\n21−=bg  (d.f.) would have the same\\ndistribution as χ2-distribution with ( n – 1) degrees of freedom.\\n* See Chapter 12 Testing of Hypotheses-II for more details.\\n1 Neil R. Ullman, Elementary Statistics—An Applied Approach , p. 234.234 Research Methodology\\nThe χ2-distribution is not symmetrical and all the values are positive. For making use of this\\ndistribution, one is required to know the degrees of freedom since for different degrees of freedom\\nwe have different curves. The smaller the number of degrees of freedom, the more skewed is thedistribution which is illustrated in Fig. 10.1:\\nFig. 10.1\\nTable given in the Appendix gives selected critical values of χ2 for the different degrees of\\nfreedom. χ2-values are the quantities indicated on the x-axis of the above diagram and in the table\\nare areas below that value.\\nIn brief, when we have to use chi-square as a test of population variance, we have to work out\\nthe value of χ2 to test the null hypothesis (viz., Hsp022:σσ =) as under:\\nχσ\\nσ22\\n21 =−s\\npnbg\\nwhere      σs2 = variance of the sample;\\n     σp2 = variance of the population;\\n(n – 1) = degrees of freedom, n being the number of items in the sample.\\nThen by comparing the calculated value with the table value of χ2 for (n – 1) degrees of\\nfreedom at a given level of significance, we may either accept or reject the null hypothesis. If the\\ncalculated value of χ2 is less than the table value, the null hypothesis is accepted, but if the calculated\\nvalue is equal or greater than the table value, the hypothesis is rejected. All this can be made clear by\\nan example.\\nIllustration 1\\nWeight of 10 students is as follows:/c992—distribution for different degrees of freedom\\n/c992—Values05 15 2010 25 30df = 1\\ndf = 3\\ndf = 5\\ndf = 10Chi-square Test 235\\nS. No. 1234567891 0\\nWeight (kg.) 38 40 45 53 47 43 55 48 52 49\\nCan we say that the variance of the distribution of weight of all students from which the above\\nsample of 10 students was drawn is equal to 20 kgs? Test this at 5 per cent and 1 per cent level of\\nsignificance.\\nSolution:  First of all we should work out the variance of the sample data or σs2 and the same has\\nbeen worked out as under:\\nTable 10.1\\nS. No. Xi (Weight in kgs.) (Xi – X)( Xi – X)2\\n13 8 – 9 8 1\\n24 0 – 7 4 9\\n34 5 – 2 0 4\\n45 3 + 6 3 6\\n54 7 + 0 0 0\\n64 3 – 4 1 6\\n75 5 + 8 6 4\\n84 8 + 1 0 1\\n95 2 + 5 2 5\\n10 49 +2 04\\nn = 10 ∑=Xi470 ∑− =XXidi2280\\nXX\\nni=∑==470\\n1047 kgs.\\n∴                     σsiXX\\nn=∑−\\n−=−=di2\\n1280\\n10 13111.\\nor   σs23111=..\\nLet the null hypothesis be Hps022:σσ =. In order to test this hypothesis we work out the χ2\\nvalue as under:\\nχσ\\nσ22\\n21 =−s\\npnbg236 Research Methodology\\n=−3111\\n2010 1.bg = 13.999.\\nDegrees of freedom in the given case is ( n – 1) = (10 – 1) = 9. At 5 per cent level of significance\\nthe table value of χ2 = 16.92 and at 1 per cent level of significance, it is 21.67 for 9 d.f. and both\\nthese values are greater than the calculated value of χ2 which is 13.999. Hence we accept the null\\nhypothesis and conclude that the variance of the given distribution can be taken as 20 kgs at 5 per\\ncent as also at 1 per cent level of significance. In other words, the sample can be said to have beentaken from a population with variance 20 kgs.\\nIllustration 2\\nA sample of 10 is drawn randomly from a certain population. The sum of the squared deviations from\\nthe mean of the given sample is 50. Test the hypothesis that the variance of the population is 5 at5 per cent level of significance.\\nSolution:  Given information is\\nn = 10\\n∑− =XXidi250\\n∴ σsiXX\\nn22\\n150\\n9=∑−\\n−=di\\nTake the null hypothesis as Hps022:σσ =. In order to test this hypothesis, we work out the χ2\\nvalue as under:\\nχσ\\nσ22\\n250\\n91510 150\\n91\\n59\\n110 =− =− = × × =s\\npnbg b g\\nDegrees of freedom = (10 – 1) = 9.\\nThe table value of χ2 at 5 per cent level for 9 d.f. is 16.92. The calculated value of χ2 is less\\nthan this table value, so we accept the null hypothesis and conclude that the variance of the population\\nis 5 as given in the question.\\nCHI-SQUARE AS A NON-PARAMETRIC TEST\\nChi-square is an important non-parametric test and as such no rigid assumptions are necessary inrespect of the type of population. We require only the degrees of freedom (implicitly of course thesize of the sample) for using this test. As a non-parametric test, chi-square can be used (i) as a testof goodness of fit and (ii) as a test of independence.Chi-square Test 237\\nAs a test of goodness of fit , χ2 test enables us to see how well does the assumed theoretical\\ndistribution (such as Binomial distribution, Poisson distribution or Normal distribution) fit to the observed\\ndata. When some theoretical distribution is fitted to the given data, we are always interested inknowing as to how well this distribution fits with the observed data. The chi-square test can give\\nanswer to this. If the calculated value of \\nχ2 is less than the table value at a certain level of significance,\\nthe fit is considered to be a good one which means that the divergence between the observed and\\nexpected frequencies is attributable to fluctuations of sampling. But if the calculated value of χ2 is\\ngreater than its table value, the fit is not considered to be a good one.\\nAs a test of independence , χ2 test enables us to explain whether or not two attributes are\\nassociated. For instance, we may be interested in knowing whether a new medicine is effective in\\ncontrolling fever or not, χ2 test will helps us in deciding this issue. In such a situation, we proceed\\nwith the null hypothesis that the two attributes (viz., new medicine and control of fever) are independent\\nwhich means that new medicine is not effective in controlling fever. On this basis we first calculate\\nthe expected frequencies and then work out the value of χ2. If the calculated value of χ2 is less\\nthan the table value at a certain level of significance for given degrees of freedom, we conclude that\\nnull hypothesis stands which means that the two attributes are independent or not associated (i.e., the\\nnew medicine is not effective in controlling the fever). But if the calculated value of χ2 is greater\\nthan its table value, our inference then would be that null hypothesis does not hold good which means\\nthe two attributes are associated and the association is not because of some chance factor but it\\nexists in reality (i.e., the new medicine is effective in controlling the fever and as such may be\\nprescribed). It may, however, be stated here that χ2 is not a measure of the degree of relationship\\nor the form of relationship between two attributes, but is simply a technique of judging the significance\\nof such association or relationship between two attributes.\\nIn order that we may apply the chi-square test either as a test of goodness of fit or as a test to\\njudge the significance of association between attributes, it is necessary that the observed as well as\\ntheoretical or expected frequencies must be grouped in the same way and the theoretical distribution\\nmust be adjusted to give the same total frequency as we find in case of observed distribution. χ2 is\\nthen calculated as follows:\\nχ22\\n=∑−OE\\nEij ij\\nijdi\\nwhere\\nOij = observed frequency of the cell in ith row and jth column.\\nEij = expected frequency of the cell in ith row and jth column.\\nIf two distributions (observed and theoretical) are exactly alike, χ2 = 0; but generally due to\\nsampling errors, χ2 is not equal to zero and as such we must know the sampling distribution of χ2\\nso that we may find the probability of an observed χ2 being given by a random sample from the\\nhypothetical universe. Instead of working out the probabilities, we can use ready table which givesprobabilities for given values of \\nχ2. Whether or not a calculated value of χ2 is significant can be238 Research Methodology\\nascertained by looking at the tabulated values of χ2 for given degrees of freedom at a certain level\\nof significance. If the calculated value of χ2 is equal to or exceeds the table value, the difference\\nbetween the observed and expected frequencies is taken as significant, but if the table value is more\\nthan the calculated value of χ2, then the difference is considered as insignificant i.e., considered to\\nhave arisen as a result of chance and as such can be ignored.\\nAs already stated, degrees of freedom* play an important part in using the chi-square distribution\\nand the test based on it, one must correctly determine the degrees of freedom. If there are 10\\nfrequency classes and there is one independent constraint, then there are (10 – 1) = 9 degrees offreedom. Thus, if ‘ n’ is the number of groups and one constraint is placed by making the totals of\\nobserved and expected frequencies equal, the d.f. would be equal to ( n – 1). In the case of a\\ncontingency table (i.e., a table with 2 columns and 2 rows or a table with two columns and more thantwo rows or a table with two rows but more than two columns or a table with more than two rowsand more than two columns), the d.f. is worked out as follows:\\nd.f. = (c – 1) (r – 1)\\nwhere ‘c’ means the number of columns and ‘ r’ means the number of rows.\\nCONDITIONS FOR THE APPLICATION OF χ2 TEST\\nThe following conditions should be satisfied before χ2 test can be applied:\\n(i) Observations recorded and used are collected on a random basis.\\n(ii)All the itmes in the sample must be independent.\\n(iii) No group should contain very few items, say less than 10. In case where the frequencies\\nare less than 10, regrouping is done by combining the frequencies of adjoining groups sothat the new frequencies become greater than 10. Some statisticians take this number as 5,but 10 is regarded as better by most of the statisticians.\\n(iv)The overall number of items must also be reasonably large. It should normally be at least50, howsoever small the number of groups may be.\\n(v) The constraints must be linear. Constraints which involve linear equations in the cell\\nfrequencies of a contingency table (i.e., equations containing no squares or higher powersof the frequencies) are known are know as linear constraints.\\nSTEPS INVOLVED IN APPLYING CHI-SQUARE TEST\\nThe various steps involved are as follows:\\n* For d.f. greater than 30, the distribution of 22χ approximates the normal distribution wherein the mean of 22χ\\ndistribution is 21d.f.− and the standard deviation = 1. Accordingly, when d.f. exceeds 30, the quantity\\n22 12χ− − LNMOQPd.f. may be used as a normal variate with unit variance, i.e.,\\nzαχ=−−22 12d.f.Chi-square Test 239\\n(i) First of all calculate the expected frequencies on the basis of given hypothesis or on the\\nbasis of null hypothesis. Usually in case of a 2 × 2 or any contingency table, the expected\\nfrequency for any given cell is worked out as under:\\nExpected frequency of any cell=(Row total for the row of that cell) \\n(Column total for the column of that cell)\\n(Grand total)× L\\nNMMMO\\nQPPP\\n(ii)Obtain the difference between observed and expected frequencies and find out the squares\\nof such differences i.e., calculate ( Oij – Eij)2.\\n(iii)Divide the quantity ( Oij – Eij)2 obtained as stated above by the corresponding expected\\nfrequency to get ( Oij – Eij)2/Eij and this should be done for all the cell frequencies or the\\ngroup frequencies.\\n(iv)Find the summation of ( Oij – Eij)2/Eij values or what we call ∑−OE\\nEij ij\\nijdi2\\n. This is the\\nrequired χ2 value.\\nThe χ2 value obtained as such should be compared with relevant table value of χ2 and then\\ninference be drawn as stated above.\\nWe now give few examples to illustrate the use of χ2 test.\\nIllustration 3\\nA die is thrown 132 times with following results:\\nNumber turned up 123456\\nFrequency 16 20 25 14 29 28\\nIs the die unbiased?\\nSolution:  Let us take the hypothesis that the die is unbiased. If that is so, the probability of obtaining\\nany one of the six numbers is 1/6 and as such the expected frequency of any one number coming\\nupward is 132 ×1/6 = 22. Now we can write the observed frequencies along with expected frequencies\\nand work out the value of χ2 as follows:\\nTable 10.2\\nNo. Observed Expected (Oi – Ei )( Oi – Ei )2(Oi – Ei )2/Ei\\nturned frequency frequency\\nup OiEi\\n1 16 22 –6 36 36/22\\n2 20 22 –2 4 4/22\\n3 25 22 3 9 9/22\\n4 14 22 –8 64 64/22\\n5 29 22 7 49 49/22\\n6 28 22 6 36 36/22240 Research Methodology\\n∴ ∑[(Oi – Ei)2/Ei] = 9.\\nHence, the calculated value of χ2 = 9.\\nQ Degrees of freedom in the given problem is\\n(n – 1) = (6 – 1) = 5.\\nThe table value* of χ2 for 5 degrees of freedom at 5 per cent level of significance is 11.071.\\nComparing calculated and table values of χ2, we find that calculated value is less than the table\\nvalue and as such could have arisen due to fluctuations of sampling. The result, thus, supports the\\nhypothesis and it can be concluded that the die is unbiased.\\nIllustration 4\\nFind the value of χ2 for the following information:\\nClass AB C D E\\nObserved frequency 8 29 44 15 4\\nTheoretical (or expected) frequency 7 24 38 24 7\\nSolution:  Since some of the frequencies less than 10, we shall first re-group the given data as\\nfollows and then will work out the value of χ2:\\nTable 10.3\\nClass Observed Expected Oi – Ei(Oi – Ei)2/Ei\\nfrequency Oifrequency Ei\\nA and B (8 + 29) = 37 (7 + 24) = 31 6 36/31\\nC 44 38 6 36/38\\nD and E (15 + 4) = 19 (24 + 7) = 31 –12 144/31\\n∴ χ22\\n=∑−OE\\nEii\\nibg\\n = 6.76 app.\\nIllustration 5\\nGenetic theory states that children having one parent of blood type A and the other of blood type B\\nwill always be of one of three types, A, AB, B and that the proportion of three types will on\\nan average be as 1 : 2 : 1. A report states that out of 300 children having one A parent and B parent,\\n30 per cent were found to be types A, 45 per cent per cent type AB and remainder type B. Test the\\nhypothesis by χ2 test.\\nSolution:  The observed frequencies of type A, AB and B is given in the question are 90, 135 and 75\\nrespectively.\\n*Table No. 3 showing some critical values of χ2for specified degrees of freedom has been given in Appendix at the end\\nof the book.Chi-square Test 241\\nThe expected frequencies of type A, AB and B (as per the genetic theory) should have been 75,\\n150 and 75 respectively.\\nWe now calculate the value of χ2 as follows:\\nTable 10.4\\nType Observed Expected (Oi – Ei)( Oi – Ei)2(Oi – Ei)2/Ei\\nfrequency frequency\\nOiEi\\nA 90 75 15 225 225/75 = 3\\nAB 135 150 –15 225 225/150 = 1.5\\nB 75 75 0 0 0/75 = 0\\n∴ χ22\\n=∑−OE\\nEii\\nibg\\n = 3 + 1.5 + 0 = 4.5\\nQ d.f. = (n – 1) = (3 – 1) = 2.\\nTable value of χ2 for 2 d.f. at 5 per cent level of significance is 5.991.\\nThe calculated value of χ2 is 4.5 which is less than the table value and hence can be ascribed\\nto have taken place because of chance. This supports the theoretical hypothesis of the genetic theory\\nthat on an average type A, AB and B stand in the proportion of 1 : 2 : 1.\\nIllustration 6\\nThe table given below shows the data obtained during outbreak of smallpox:\\nAttacked Not attacked Total\\nVaccinated 31 469 500\\nNot vaccinated 185 1315 1500\\nTotal 216 1784 2000\\nTest the effectiveness of vaccination in preventing the attack from smallpox. Test your result\\nwith the help of χ2 at 5 per cent level of significance.\\nSolution:  Let us take the hypothesis that vaccination is not effective in preventing the attack from\\nsmallpox i.e., vaccination and attack are independent. On the basis of this hypothesis, the expected\\nfrequency corresponding to the number of persons vaccinated and attacked would be:\\nExpectation of ( ) =() ()ABAB\\nN×\\nwhen A represents vaccination and B represents attack.242 Research Methodology\\n∴ (A) = 500\\n(B) = 216\\n  N = 2000\\nExpectation of ( ) = AB500 216\\n200054×=\\nNow using the expectation of ( AB), we can write the table of expected values as follows:\\nAttacked: B Not attacked: b Total\\nVaccinated: A (AB) = 54 (Ab) = 446 500\\nNot vaccinated: a (aB) = 162 (ab) = 1338 1500\\nTotal 216 1784 2000\\nTable 10.5 :Calculation of Chi-Square\\nGroup Observed Expected (Oij – Eij)( Oij – Eij)2(Oij – Eij)2/Eij\\nfrequency frequency\\nOijEij\\nAB 31 54 –23 529 529/54 = 9.796\\nAb 469 446 +23 529 529/44 = 1.186\\naB 158 162 +23 529 529/162 = 3.265\\nab 1315 1338 –23 529 529/1338 = 0.395\\nχ22\\n=∑−OE\\nEij ij\\nijdi\\n = 14.642\\nQ Degrees of freedom in this case = ( r – 1) (c – 1) = (2 – 1) (2 – 1) = 1.\\nThe table value of χ2 for 1 degree of freedom at 5 per cent level of significance is 3.841. The\\ncalculated value of χ2 is much higher than this table value and hence the result of the experiment\\ndoes not support the hypothesis. We can, thus, conclude that vaccination is effective in preventing\\nthe attack from smallpox.\\nIllustration 7\\nTwo research workers classified some people in income groups on the basis of sampling studies.\\nTheir results are as follows:\\nInvestigators Income groups Total\\nPoor Middle Rich\\nA 160 30 10 200\\nB 140 120 40 300\\nTotal 300 150 50 500Chi-square Test 243\\nShow that the sampling technique of at least one research worker is defective.\\nSolution:  Let us take the hypothesis that the sampling techniques adopted by research workers are\\nsimilar (i.e., there is no difference between the techniques adopted by research workers). This being\\nso, the expectation of A investigator classifying the people in\\n(i)Poor income group =200 300×=500120\\n(ii)Middle income group =200 150×=50060\\n(iii)Rich income group =200 50×=50020\\nSimilarly the expectation of B investigator classifying the people in\\n(i)Poor income group =300 300×=500180\\n(ii)Middle income group =300 150×=50090\\n(iii)Rich income group =300 50×=50030\\nWe can now calculate value of χ2 as follows:\\nTable 10.6\\nGroups Observed Expected Oij – Eij(Oij – Eij)2 Eij\\nfrequency frequency\\nOijEij\\nInvestigator A\\nclassifies people as poor 160 120 40 1600/120 = 13.33\\nclassifies people as\\n     middle class people 30 60 –30 900/60 = 15.00\\nclassifies people as rich 10 20 –10 100/20 = 5.00\\nInvestigator B\\nclassifies people as poor 140 180 –40 1600/180 = 8.88\\nclassifies people as\\n    middle class people 120 90 30 900/90 = 10.00\\nclassifies people as rich 40 30 10 100/30 = 3.33244 Research Methodology\\nHence, χ22\\n=∑−OE\\nEij ij\\nijdi\\n = 55.54\\nQDegrees of freedom = ( c – 1) (r – 1)\\n       = (3 – 1) (2 – 1) = 2.\\nThe table value of χ2 for two degrees of freedom at 5 per cent level of significance is 5.991.\\nThe calculated value of χ2 is much higher than this table value which means that the calculated\\nvalue cannot be said to have arisen just because of chance. It is significant. Hence, the hypothesis\\ndoes not hold good. This means that the sampling techniques adopted by two investigators differ andare not similar. Naturally, then the technique of one must be superior than that of the other.\\nIllustration 8\\nEight coins were tossed 256 times and the following results were obtained:\\nNumbers of heads 0 1 23 456 7 8\\nFrequency 2 6 30 52 67 56 32 10 1\\nAre the coins biased? Use χ2 test.\\nSolution:  Let us take the hypothesis that the coins are not biased. If that is so, the probability of any\\none coin falling with head upward is 1/2 and with tail upward is 1/2 and it remains the same whatever\\nbe the number of throws. In such a case the expected values of getting 0, 1, 2, … heads in a singlethrow in 256 throws of eight coins will be worked out as follows\\n*.\\nTable 10.7\\nEvents or Expected frequencies\\nNo. of heads\\n0 8\\n0081\\n21\\n2256 1 CFHGIKJFHGIKJ×=\\n1 8\\n1171\\n21\\n2256 8 CFHGIKJFHGIKJ×=\\n28\\n2261\\n21\\n2256 28 CFHGIKJFHGIKJ×=\\n* The probabilities of random variable i.e., various possible events have been worked out on the binomial principle viz.,\\nthrough the expansion of ( p + q)n where p = 1/2 and q = 1/2 and n = 8 in the given case. The expansion of the term\\nnCr pr qn–r has given the required probabilities which have been multiplied by 256 to obtain the expected frequencies.contd.\\n○ ○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Chi-square Test 245\\nEvents or Expected frequencies\\nNo. of heads\\n38\\n3351\\n21\\n2256 56 CFHGIKJFHGIKJ×=\\n48\\n4441\\n21\\n2256 70 CFHGIKJFHGIKJ×=\\n58\\n5531\\n21\\n2256 56 CFHGIKJFHGIKJ×=\\n68\\n6621\\n21\\n2256 28 CFHGIKJFHGIKJ×=\\n78\\n7711\\n21\\n2256 8 CFHGIKJFHGIKJ×=\\n88\\n8801\\n21\\n2256 1 CFHGIKJFHGIKJ×=\\nThe value of χ2 can be worked out as follows:\\nTable 10.8\\nNo. of heads Observed Expected Oi – Ei(Oi – Ei )2/Ei\\nfrequency frequency\\nOiEi\\n0 2 1 1 1/1 = 1.00\\n1 6 8 –2 4/8 = 0.50\\n2 30 28 2 4/28 = 0.14\\n3 52 56 –4 16/56 = 0.29\\n4 67 70 –3 9/70 = 0.13\\n5 56 56 0 0/56 = 0.00\\n6 32 28 4 16/28 = 0.57\\n7 10 8 2 4/8 = 0.50\\n8 1 1 0 0/1 = 0.00\\n∴ χ22\\n=∑−OE\\nEii\\nibg\\n = 3.13246 Research Methodology\\n∴Degrees of freedom = ( n – 1) = (9 – 1) = 8\\nThe table value of χ2 for eight degrees of freedom at 5 per cent level of significance is 15.507.\\nThe calculated value of χ2 is much less than this table and hence it is insignificant and can be\\nascribed due to fluctuations of sampling. The result, thus, supports the hypothesis and we may say\\nthat the coins are not biased.\\nALTERNATIVE FORMULA\\nThere is an alternative method of calculating the value of χ2 in the case of a (2 × 2) table. If we\\nwrite the cell frequencies and marginal totals in case of a (2 × 2) table thus,\\nthen the formula for calculating the value of χ2 will be stated as follows:\\nχ22\\n=−⋅\\n++++ad bc N\\nac bdab cdbgbg bg bg bg\\nwhere N means the total frequency, ad means the larger cross product, bc means the smaller cross\\nproduct and ( a + c), (b + d), (a + b), and (c + d) are the marginal totals. The alternative formula is\\nrarely used in finding out the value of chi-square as it is not applicable uniformly in all cases but can\\nbe used only in a (2 × 2) contingency table.\\nYATES\\x92 CORRECTION\\nF. Yates has suggested a correction for continuity in χ2 value calculated in connection with a (2 × 2)\\ntable, particularly when cell frequencies are small (since no cell frequency should be less than 5 in\\nany case, through 10 is better as stated earlier) and χ2 is just on the significance level. The correction\\nsuggested by Yates is popularly known as Yates’ correction. It involves the reduction of the deviationof observed from expected frequencies which of course reduces the value of \\nχ2. The rule for\\ncorrection is to adjust the observed frequency in each cell of a (2 × 2) table in such a way as to\\nreduce the deviation of the observed from the expected frequency for that cell by 0.5, but thisadjustment is made in all the cells without disturbing the marginal totals. The formula for finding the\\nvalue of \\nχ2 after applying Yates’ correction can be stated thus:( +  )  ( +  )acbd N( +  )\\n( +  )ab\\ncdab         \\ncd         Chi-square Test 247\\nχ2205\\n(corrected) =⋅− −\\n++++Na d b c N\\nabcdac bd. ch\\nbg bg bg bg\\nIn case we use the usual formula for calculating the value of chi-square viz.,\\nχ22\\n=∑−OE\\nEij ij\\nijdi\\n,\\nthen Yates’ correction can be applied as under:\\nχ2 112\\n1222\\n205 05\\n(corrected) =−−\\n+−−\\n+OE\\nEOE\\nE..\\n...\\nIt may again be emphasised that Yates’ correction is made only in case of (2 × 2) table and that\\ntoo when cell frequencies are small.\\nIllustration 9\\nThe following information is obtained concerning an investigation of 50 ordinary shops of small size:\\nShops Total\\nIn towns In villages\\nRun by men 17 18 35\\nRun by women 3 12 15\\nTotal 20 30 50\\nCan it be inferred that shops run by women are relatively more in villages than in towns? Use\\nχ2 test.\\nSolution:  Take the hypothesis that there is no difference so far as shops run by men and women in\\ntowns and villages. With this hypothesis the expectation of shops run by men in towns would be:\\nExpectation of ( ) =() ()ABAB\\nN×\\nwhereA = shops run by men\\nB = shops in towns\\n(A) = 35; ( B) = 20 and N = 50\\nThus, expectation of ( ) = AB35 20\\n5014×=\\nHence, table of expected frequencies would be248 Research Methodology\\nShops in towns Shops in villages T otal\\nRun by men 14 ( AB) 21 (Ab)3 5\\nRun by women 6 ( aB)9  (ab)1 5\\nTotal 20 30 50\\nCalculation of χ2 value:\\nTable 10.9\\nGroups Observed Expected (Oij – Eij)( Oij – Eij)2/Eij\\nfrequency frequency\\nOijEij\\n(AB) 17 14 3 9/14 = 0.64\\n(Ab) 18 21 –3 9/21 = 0.43\\n(aB) 3 6 –3 9/6 = 1.50\\n(ab) 12 9 3 9/9 = 1.00\\n∴ χ22\\n=∑−OE\\nEij ij\\nijdi\\n = 3.57\\nAs one cell frequency is only 3 in the given 2 × 2 table, we also work out χ2 value applying\\nYates’ correction and this is as under:\\nχ222 2 217 14 05\\n1418 21 05\\n21360 5\\n612 9 05\\n9(corrected) =−−\\n+−−\\n+−−\\n+−− .. . .\\n      =+++25\\n1425\\n2125\\n625\\n92222....bg bg bg bg\\n= 0.446 + 0.298 + 1.040 + 0.694\\n= 2.478\\nQDegrees of freedom = ( c – 1) (r – 1) = (2 – 1) (2 – 1) = 1\\nTable value of χ2 for one degree of freedom at 5 per cent level of significance is 3.841. The\\ncalculated value of χ2 by both methods (i.e., before correction and after Yates’ correction) is less\\nthan its table value. Hence the hypothesis stands. We can conclude that there is no difference\\nbetween shops run by men and women in villages and towns.\\nAdditive property: An important property of χ2 is its additive nature. This means that several\\nvalues of χ2 can be added together and if the degrees of freedom are also added, this number gives\\nthe degrees of freedom of the total value of χ2. Thus, if a number of χ2 values have been obtainedChi-square Test 249\\nfrom a number of samples of similar data, then because of the additive nature of χ2 we can combine\\nthe various values of χ2 by just simply adding them. Such addition of various values of χ2 gives one\\nvalue of χ2 which helps in forming a better idea about the significance of the problem under\\nconsideration. The following example illustrates the additive property of χ2.\\nIllustration 10\\nThe following values of χ2 from different investigations carried to examine the effectiveness of a\\nrecently invented medicine for checking malaria are obtained:\\nInvestigation χ2d.f.\\n1 2.5 1\\n2 3.2 1\\n3 4.1 1\\n4 3.7 1\\n5 4.5 1\\nWhat conclusion would you draw about the effectiveness of the new medicine on the basis of the\\nfive investigations taken together?\\nSolution:  By adding all the values of χ2, we obtain a value equal to 18.0. Also by adding the various\\nd.f., as given in the question, we obtain the value 5. We can now state that the value of χ2 for 5\\ndegrees of freedom (when all the five investigations are taken together) is 18.0.\\nLet us take the hypothesis that the new medicine is not effective. The table value of χ2 for 5\\ndegrees of freedom at 5 per cent level of significance is 11.070. But our calculated value is higher\\nthan this table value which means that the difference is significant and is not due to chance. As suchthe hypothesis is rejected and it can be concluded that the new medicine is effective in checkingmalaria.\\nCONVERSION OF CHI-SQUARE INTO PHI COEFFICIENT ()φ\\nSince χ2 does not by itself provide an estimate of the magnitude of association between two attributes,\\nany obtained χ2 value may be converted into Phi coefficient (symbolized as φ) for the purpose. In\\nother words, chi-square tells us about the significance of a relation between variables; it provides noanswer regarding the magnitude of the relation. This can be achieved by computing the Phi coefficient,which is a non-parametric measure of coefficient of correlation, as under:\\nφχ=2\\nN250 Research Methodology\\nCONVERSION OF CHI-SQUARE INTO COEFFICIENT OF CONTINGENCY ( C)\\nChi-square value may also be converted into coefficient of contingency, especially in case of a\\ncontingency table of higher order than 2 × 2 table to study the magnitude of the relation or the degreeof association between two attributes, as shown below:\\nC\\nN=\\n+χ\\nχ2\\n2\\nWhile finding out the value of C we proceed on the assumption of null hypothesis that the two\\nattributes are independent and exhibit no association. Coefficient of contingency is also known ascoefficient of Mean Square contingency. This measure also comes under the category of non-parametric measure of relationship.\\nIMPORTANT CHARACTERISTICS OF χ2 TEST\\n(i) This test (as a non-parametric test) is based on frequencies and not on the parameters like\\nmean and standard deviation.\\n(ii)The test is used for testing the hypothesis and is not useful for estimation.\\n(iii)This test possesses the additive property as has already been explained.\\n(iv)This test can also be applied to a complex contingency table with several classes and assuch is a very useful test in research work.\\n(v) This test is an important non-parametric test as no rigid assumptions are necessary in\\nregard to the type of population, no need of parameter values and relatively less mathematicaldetails are involved.\\nCAUTION IN USING χ2 TEST\\nThe chi-square test is no doubt a most frequently used test, but its correct application is equally anuphill task. It should be borne in mind that the test is to be applied only when the individual observationsof sample are independent which means that the occurrence of one individual observation (event)has no effect upon the occurrence of any other observation (event) in the sample under consideration.Small theoretical frequencies, if these occur in certain groups, should be dealt with under specialcare. The other possible reasons concerning the improper application or misuse of this test can be (i)neglect of frequencies of non-occurrence; (ii) failure to equalise the sum of observed and the sum ofthe expected frequencies; (iii) wrong determination of the degrees of freedom; (iv) wrong computations,and the like. The researcher while applying this test must remain careful about all these things andmust thoroughly understand the rationale of this important test before using it and drawing inferencesin respect of his hypothesis.Chi-square Test 251\\nQuestions\\n1.What is Chi-square text? Explain its significance in statistical analysis.\\n2.Write short notes on the following:\\n(i) Additive property of Chi-square;\\n(ii)Chi-square as a test of ‘goodness of fit’;\\n(iii)Precautions in applying Chi-square test;\\n(iv)Conditions for applying Chi-square test.\\n3.An experiment was conducted to test the efficacy of chloromycetin in checking typhoid. In a certain\\nhospital chloromycetin was given to 285 out of the 392 patients suffering from typhoid. The number oftyphoid cases were as follows:\\nTyphoid No T yphoid T otal\\nChloromycetin 35 250 285\\nNo chloromycetin 50 57 107\\nTotal 85 307 392\\nWith the help of \\nχ2, test the effectiveness of chloromycetin in checking typhoid.\\n(The χ2 value at 5 per cent level of significance for one degree of freedom is 3.841).\\n(M. Com., Rajasthan University, 1966 )\\n4.On the basis of information given below about the treatment of 200 patients suffering from a disease,state whether the new treatment is comparatively superior to the conventional treatment.\\nNo. of patients\\nTreatment Favourable No Response\\nResponse\\nNew 60 20\\nConventional 70 50\\nFor drawing your inference, use the value of \\nχ2 for one degree of freedom at the 5 per cent level of\\nsignificance, viz., 3.84.\\n5.200 digits were chosen at random from a set of tables. The frequencies of the digits were:\\nDigit 0123456789\\nFrequency 18 19 23 21 16 25 22 20 21 15\\nCalculate χ2.\\n6.Five dice were thrown 96 times and the number of times 4, 5, or 6 was thrown were\\nNumber of dice throwing4 ,  5  o r  6 543210\\nFrequency 8 18 35 24 10 1\\nFind the value of Chi-square.252 Research Methodology\\n7.Find Chi-square from the following information:\\nCondition of home\\nCondition of child Total\\nClean Dirty\\nClean 70 50 120\\nFairly clean 80 20 100\\nDirty 35 45 80\\nTotal 185 115 300\\nState whether the two attributes viz., condition of home and condition of child are independent (Use\\nChi-square test for the purpose).\\n8.In a certain cross the types represented by XY, Xy, xY and xy are expected to occur in a 9 : 5 : 4 : 2 ratio. The\\nactual frequencies were:\\nXY Xy xY xy\\n180 110 60 50\\nTest the goodness of fit of observation to theory.\\n9.The normal rate of infection for a certain disease in cattle is known to be 50 per cent. In an experiment withseven animals injected with a new vaccine it was found that none of the animals caught infection. Can theevidence be regarded as conclusive (at 1 per cent level of significance) to prove the value of the newvaccine?\\n10.Result of throwing die were recorded as follows:\\nNumber falling upwards 123456\\nFrequency 27 33 31 29 30 24\\nIs the die unbiased? Answer on the basis of Chi-square test.\\n11.The Theory predicts the proportion of beans, in the four groups A, B, C and D should be 9 : 3 : 3 : 1. In an\\nexperiment among 1600 beans, the number in the four groups were 882, 313, 287 and 118. Does the\\nexperimental result support the theory? Apply \\nχ2 test.\\n(M.B.A., Delhi University, 1975 )\\n12.You are given a sample of 150 observations classified by two attributes A and B as follows:\\nA1A2A3Total\\nB140 25 15 80\\nB211 26 8 45\\nB399 7 2 5\\nTotal 60 60 30 150\\nUse the χ2 test to examine whether A and B are associated.\\n(M.A. Eco., Patiala University, 1975 )\\n13.A survey of 320 families with five children each revealed the following distribution:Chi-square Test 253\\nNo. of boys 5 4 3 2 1 0\\nNo. of girls 0 1 2 3 4 5No. of families 14 56 110 88 40 12\\nIs this distribution consistent with the hypothesis that male and female births are equally probable?\\nApply Chi-square test.\\n14.What is Yates’ correction? Find the value of Chi-square applying Yates’ correction to the following data:\\nPassed Failed Total\\nDay classes 10 20 30\\nEvening classes 4 66 70\\nTotal 14 86 100\\nAlso state whether the association, if any, between passing in the examination and studying in dayclasses is significant using Chi-square test.\\n15.(a) 1000 babies were born during a certain week in a city of which 600 were boys and 400 girls. Use \\nχ2\\ntest to examine the correctness of the hypothesis that the sex-ratio is 1 : 1 in newly born babies.\\n(b) The percentage of smokers in a certain city was 90. A random sample of 100 persons was selected in\\nwhich 85 persons were found to be smokers. Is the sample proportion significantly different from theproportion of smokers in the city? Answer on the basis of Chi-square test.\\n16.A college is running post-graduate classes in five subjects with equal number of students. The totalnumber of absentees in these five classes is 75. Test the hypothesis that these classes are alike inabsenteeism if the actual absentees in each are as follows:\\nHistory =  19\\nPhilosophy =  18\\nEconomics =  15Commerce =  12\\nChemistry =  11\\n(M.Phil. (EAFM) Exam. Raj. Uni., 1978 )\\n17.The number of automobile accidents per week in a certain community were as follows:\\n12, 8, 20, 2, 14, 10, 15, 6, 9, 4\\nAre these frequencies in agreement with the belief that accident conditions were the same during the\\n10week period under consideration?\\n18.A certain chemical plant processes sea water to collect sodium chloride and magnesium. From scientificanalysis, sea water is known to contain sodium chloride, magnesium and other elements in the ratio of62: 4 : 34. A sample of 200 tons of sea water has resulted in 130 tons of sodium chloride and 6 tons ofmagnesium. Are these data consistent with the scientific model at 5 per cent level of significance?\\n19.An oil company has explored three different areas for possible oil reserves. The results of the test wereas given below:254 Research Methodology\\nArea Total\\nAB C\\nStrikes 7 10 8 25\\nDry holes 10 18 9 37\\nTotal number of test wells 17 28 17 62\\nDo the three areas have the same potential, at the 10 per cent level of significance?\\n20.While conducting an air traffic study, a record was made of the number of aircraft arrivals, at a certain\\nairport, during 250 half hour time intervals. The following tables gives the observed number of periods inwhich there were 0, 1, 2, 3, 4, or more arrivals as well as the expected number of such periods if arrivals per\\nhalf hour have a Poisson distribution \\nλ= 2. Does this Poisson distribution describe the observed\\narrivals at 5 per cent level of significance.\\nNumber of observed Number of periods Number of periods\\narrivals (per half hour) observed expected (Poisson, λ = 2)\\n04 7 3 4\\n15 6 6 8\\n27 1 6 8\\n34 4 4 5\\n4 or more 32 35\\n21.A marketing researcher interested in the business publication reading habits of purchasing agents has\\nassembled the following data:\\nBusiness Publication Preferences (First Choice Mentions)\\nBusiness Publication Frequency of first choice\\nA 35\\nB 30\\nC 45\\nD 55\\n(i) Test the null hypothesis ( α = 0.05) that there are no differences among frequencies of first choice of\\ntested publications.\\n(ii) If the choice of A and C and that of B and D are aggregated, test the null hypothesis at α = 0.05 that\\nthere are no differences.\\n22.A group of 150 College students were asked to indicate their most liked film star from among six differentwell known film actors viz., A, B, C, D, E and F in order to ascertain their relative popularity. The observed\\nfrequency data were as follows:\\nActors A B C D E F Total\\nFrequencies 24 20 32 25 28 21 150\\nTest at 5 per cent whether all actors are equally popular.Chi-square Test 255\\n23.For the data in question 12, find the coefficient of contingency to measure the magnitude of relationship\\nbetween A and B.\\n24.(a) What purpose is served by calculating the Phi coefficient ( φ)? Explain.\\n(b) If χ2 = 16 and N = 4, find the value of Phi coefficient.256 Research Methodology\\n11\\nAnalysis of Variance\\nand Co-variance\\nANALYSIS OF VARIANCE (ANOVA)\\nAnalysis of variance (abbreviated as ANOVA) is an extremely useful technique concerning researches\\nin the fields of economics, biology, education, psychology, sociology, business/industry and in researchesof several other disciplines. This technique is used when multiple sample cases are involved. As\\nstated earlier, the significance of the difference between the means of two samples can be judged\\nthrough either z-test or the t-test, but the difficulty arises when we happen to examine the significance\\nof the difference amongst more than two sample means at the same time. The ANOVA techniqueenables us to perform this simultaneous test and as such is considered to be an important tool ofanalysis in the hands of a researcher. Using this technique, one can draw inferences about whetherthe samples have been drawn from populations having the same mean.\\nThe ANOVA technique is important in the context of all those situations where we want to\\ncompare more than two populations such as in comparing the yield of crop from several varieties ofseeds, the gasoline mileage of four automobiles, the smoking habits of five groups of universitystudents and so on. In such circumstances one generally does not want to consider all possiblecombinations of two populations at a time for that would require a great number of tests before wewould be able to arrive at a decision. This would also consume lot of time and money, and even thencertain relationships may be left unidentified (particularly the interaction effects). Therefore, onequite often utilizes the ANOVA technique and through it investigates the differences among themeans of all the populations simultaneously.\\nWHAT IS ANOVA?\\nProfessor R.A. Fisher was the first man to use the term ‘Variance’* and, in fact, it was he who\\ndeveloped a very elaborate theory concerning ANOVA, explaining its usefulness in practical field.\\n* Variance is an important statistical measure and is described as the mean of the squares of deviations taken from the\\nmean of the given series of data. It is a frequently used measure of variation. Its squareroot is known as standard deviation,\\ni.e., Standard deviation = Variance.Analysis of Variance and Co-variance 257\\nLater on Professor Snedecor and many others contributed to the development of this technique.\\nANOVA is essentially a procedure for testing the difference among different groups of data forhomogeneity. “The essence of ANOVA is that the total amount of variation in a set of data is brokendown into two types, that amount which can be attributed to chance and that amount which can beattributed to specified causes.”\\n1 There may be variation between samples and also within sample\\nitems. ANOVA consists in splitting the variance for analytical purposes. Hence, it is a method ofanalysing the variance to which a response is subject into its various components corresponding tovarious sources of variation. Through this technique one can explain whether various varieties ofseeds or fertilizers or soils differ significantly so that a policy decision could be taken accordingly,concerning a particular variety in the context of agriculture researches. Similarly, the differences invarious types of feed prepared for a particular class of animal or various types of drugs manufacturedfor curing a specific disease may be studied and judged to be significant or not through the applicationof ANOVA technique. Likewise, a manager of a big concern can analyse the performance ofvarious salesmen of his concern in order to know whether their performances differ significantly.\\nThus, through ANOVA technique one can, in general, investigate any number of factors which\\nare hypothesized or said to influence the dependent variable. One may as well investigate thedifferences amongst various categories within each of these factors which may have a large numberof possible values. If we take only one factor and investigate the differences amongst its variouscategories having numerous possible values, we are said to use one-way ANOVA and in case weinvestigate two factors at the same time, then we use two-way ANOVA. In a two or more wayANOVA, the interaction (i.e., inter-relation between two independent variables/factors), if any, betweentwo independent variables affecting a dependent variable can as well be studied for better decisions.\\nTHE BASIC PRINCIPLE OF ANOVA\\nThe basic principle of ANOVA is to test for differences among the means of the populations byexamining the amount of variation within each of these samples, relative to the amount of variationbetween the samples. In terms of variation within the given population, it is assumed that the valuesof (X\\nij) differ from the mean of this population only because of random effects i.e., there are influences\\non (Xij) which are unexplainable, whereas in examining differences between populations we assume\\nthat the difference between the mean of the jth population and the grand mean is attributable to what\\nis called a ‘specific factor’ or what is technically described as treatment effect. Thus while usingANOVA, we assume that each of the samples is drawn from a normal population and that each ofthese populations has the same variance. We also assume that all factors other than the one or morebeing tested are effectively controlled. This, in other words, means that we assume the absence ofmany factors that might affect our conclusions concerning the factor(s) to be studied.\\nIn short, we have to make two estimates of population variance viz., one based on between\\nsamples variance and the other based on within samples variance. Then the said two estimates ofpopulation variance are compared with F-test, wherein we work out.\\nF=Estimate of population variance based on between samples variance\\nEstimate of population variance based on within samples variance\\n1 Donald L. Harnett and James L. Murphy, Introductory Statistical Analysis, p. 376.258 Research Methodology\\nThis value of F is to be compared to the F-limit for given degrees of freedom. If the F value we\\nwork out is equal or exceeds* the F-limit value (to be seen from F tables No. 4(a) and 4(b) given in\\nappendix), we may say that there are significant differences between the sample means.\\nANOVA TECHNIQUE\\nOne-way (or single factor ) ANOVA: Under the one-way ANOVA, we consider only one factor\\nand then observe that the reason for said factor to be important is that several possible types of\\nsamples can occur within that factor. We then determine if there are differences within that factor.The technique involves the following steps:\\n(i) Obtain the mean of each sample i.e., obtain\\nXXX Xk 123,,,,...\\nwhen there are k samples.\\n(ii) Work out the mean of the sample means as follows:\\nXXXX X\\nkk=+++ +123 ...\\nNo. of samples ( )\\n(iii) Take the deviations of the sample means from the mean of the sample means and calculate\\nthe square of such deviations which may be multiplied by the number of items in thecorresponding sample, and then obtain their total. This is known as the sum of squares forvariance between the samples (or SS between). Symbolically, this can be written:\\nSS n X X n X X n X Xkk between =1212\\n222\\n− FHIK+− FHIK\\n++ − FHIK\\n...\\n(iv)Divide the result of the (iii) step by the degrees of freedom between the samples to obtain\\nvariance or mean square ( MS) between samples. Symbolically, this can be written:\\nMSSS\\nkbetween =between\\n(– 1 )\\nwhere (k – 1) represents degrees of freedom (d.f.) between samples.\\n(v) Obtain the deviations of the values of the sample items for all the samples from corresponding\\nmeans of the samples and calculate the squares of such deviations and then obtain theirtotal. This total is known as the sum of squares for variance within samples (or SS within).\\nSymbolically this can be written:\\nSS X X X X X Xii k ik within = ∑ − +∑ − + +∑ −112\\n2222di d i d i ...\\ni = 1, 2, 3, …\\n(vi)Divide the result of (v) step by the degrees of freedom within samples to obtain the varianceor mean square ( MS) within samples. Symbolically, this can be written:\\n* It should be remembered that ANOVA test is always a one-tailed test, since a low calculated value of F from the sample\\ndata would mean that the fit of the sample means to the null hypothesis (viz., XX Xk 12==...) is a very good fit.Analysis of Variance and Co-variance 259\\nMSSS\\nnkwithin =within\\n(–)\\nwhere (n – k) represents degrees of freedom within samples,\\nn = total number of items in all the samples i.e., n1 + n2 + … + nk\\nk = number of samples.\\n(vii)For a check, the sum of squares of deviations for total variance can also be worked out by\\nadding the squares of deviations when the deviations for the individual items in all thesamples have been taken from the mean of the sample means. Symbolically, this can bewritten:\\nSS X Xij for total variance = ∑−FHIK2\\n          i = 1, 2, 3, …\\nj = 1, 2, 3, …\\nThis total should be equal to the total of the result of the (iii) and (v) steps explained above\\ni.e.,\\nSS for total variance = SS between + SS within.\\nThe degrees of freedom for total variance will be equal to the number of items in allsamples minus one i.e., ( n – 1). The degrees of freedom for between and within must add\\nup to the degrees of freedom for total variance i.e.,\\n(n – 1) = (k – 1) + (n – k)\\nThis fact explains the additive property of the ANOVA technique .\\n(viii)Finally, F-ratio may be worked out as under:\\nFMS\\nMS-ratio =between\\nwithin\\nThis ratio is used to judge whether the difference among several sample means is significantor is just a matter of sampling fluctuations. For this purpose we look into the table\\n*, giving\\nthe values of F for given degrees of freedom at different levels of significance. If the\\nworked out value of F, as stated above, is less than the table value of F, the difference is\\ntaken as insignificant i.e., due to chance and the null-hypothesis of no difference betweensample means stands. In case the calculated value of F happens to be either equal or more\\nthan its table value, the difference is considered as significant (which means the samplescould not have come from the same universe) and accordingly the conclusion may bedrawn. The higher the calculated value of F is above the table value, the more definite and\\nsure one can be about his conclusions.\\nSETTING UP ANALYSIS OF VARIANCE TABLE\\nFor the sake of convenience the information obtained through various steps stated above can be putas under:\\n* An extract of table giving F-values has been given in Appendix at the end of the book in Tables 4 (a) and 4 (b).260 Research Methodology\\nTable 11.1 :Analysis of Variance Table for One-way Anova\\n(There are k samples having in all n items)\\nSource of Sum of squares Degrees of Mean Square (MS) F-ratio\\nvariation (SS) freedom (d.f.) (This is SS divided\\nby d.f.) and is an\\nestimation of variance\\nto be used in\\nF-ratio\\nBetween\\nsamples or\\ncategoriesnX X112\\n− FHIK+... (k – 1)SS\\nk between\\n(– 1 )MS\\nMS between\\n within\\n+− FHIK\\nnX Xkk2\\nWithin\\nsamples orcategories ∑− +XXi112di ... (n – k)SS\\nnk within\\n(–)\\n+∑ −XXki kdi2\\ni = 1, 2, 3, …\\nTotal ∑−FHIKXXij2\\n(n –1)\\ni = 1, 2, …\\nj = 1, 2, …\\nSHORT-CUT METHOD FOR ONE-WAY ANOVA\\nANOVA can be performed by following the short-cut method which is usually used in practice since\\nthe same happens to be a very convenient method, particularly when means of the samples and/ormean of the sample means happen to be non-integer values. The various steps involved in the short-cut method are as under:\\n(i) Take the total of the values of individual items in all the samples i.e., work out \\n∑Xij\\ni = 1, 2, 3, …\\nj = 1, 2, 3, …\\nand call it as T .\\n(ii) Work out the correction factor as under:\\nCorrection factor =  T\\nnbg2Analysis of Variance and Co-variance 261\\n(iii)Find out the square of all the item values one by one and then take its total. Subtract the\\ncorrection factor from this total and the result is the sum of squares for total variance.Symbolically, we can write:\\nTotal \\nSS XT\\nnij=∑ −22bg      i = 1, 2, 3, …\\nj = 1, 2, 3, …\\n(iv)Obtain the square of each sample total ( Tj)2 and divide such square value of each sample\\nby the number of items in the concerning sample and take the total of the result thusobtained. Subtract the correction factor from this total and the result is the sum of squaresfor variance between the samples. Symbolically, we can write:\\nSST\\nnT\\nnj\\nj between = ∑−di bg22\\n     j = 1, 2, 3, …\\nwhere subscript j represents different samples or categories.\\n(v) The sum of squares within the samples can be found out by subtracting the result of (iv)\\nstep from the result of (iii) step stated above and can be written as under:\\nSS XT\\nnT\\nnT\\nnijj\\nj within = ∑−RS|\\nT|UV|\\nW|−∑ −RS|\\nT|UV|\\nW|2222bg di bg\\n  =∑ −∑XT\\nnijj\\nj22di\\nAfter doing all this, the table of ANOVA can be set up in the same way as explained\\nearlier.\\nCODING METHOD\\nCoding method is furtherance of the short-cut method. This is based on an important property ofF-ratio that its value does not change if all the n item values are either multiplied or divided by a\\ncommon figure or if a common figure is either added or subtracted from each of the given n item\\nvalues. Through this method big figures are reduced in magnitude by division or subtraction andcomputation work is simplified without any disturbance on the F-ratio. This method should be usedspecially when given figures are big or otherwise inconvenient. Once the given figures are convertedwith the help of some common figure, then all the steps of the short-cut method stated above can beadopted for obtaining and interpreting F-ratio.\\nIllustration 1\\nSet up an analysis of variance table for the following per acre production data for three varieties of\\nwheat, each grown on 4 plots and state if the variety differences are significant.262 Research Methodology\\nPer acre production data\\nPlot of land Variety of wheat\\nAB C\\n16 5 5\\n27 5 4\\n33 3 3\\n48 7 4\\nSolution:  We can solve the problem by the direct method or by short-cut method, but in each case\\nwe shall get the same result. We try below both the methods.\\nSolution through direct method:  First we calculate the mean of each of these samples:\\nX16738\\n46 =+++=\\nX25537\\n45 =+++=\\nX35434\\n44 =+++=\\nMean of the sample means or     XXXX\\nk=++123\\n=++=654\\n35\\nNow we work out SS between and SS within samples:\\nSS n X X n X X n X Xbetween =12312\\n22\\n32\\n− FHIK+− FHIK\\n+− FHIK\\n  = 4(6 – 5)2 + 4(5 – 5)2 + 4(4 – 5)2\\n= 4 + 0 + 4\\n= 8\\nSS X X X X X Xiii within = ∑− + ∑− + ∑−112\\n222\\n332di d i d i ,i = 1, 2, 3, 4\\n          = {(6 – 6)2 + (7 – 6)2 + (3 – 6)2 + (8 – 6)2}\\n   + {(5 – 5)2 + (5 – 5)2 + (3 – 5)2 + (7 – 5)2}\\n   + {(5 – 4)2 + (4 – 4)2 + (3 – 4)2 + (4 – 4)2}\\n          = {0 + 1 + 9 + 4} + {0 + 0 + 4 + 4} + {1 + 0 + 1 + 0}          = 14 + 8 + 2\\n          = 24Analysis of Variance and Co-variance 263\\nSS X Xij for total variance = ∑−FHIK2\\n      i = 1, 2, 3…\\nj = 1, 2, 3…\\n= (6 – 5)2 + (7 – 5)2 + (3 – 5)2 + (8 – 5)2\\n+ (5 – 5)2 + (5 – 5)2 + (3 – 5)2\\n+ (7 – 5)2 + (5 – 5)2 + (4 – 5)2\\n+ (3 – 5)2 + (4 – 5)2\\n        = 1 + 4 + 4 + 9 + 0 + 0 + 4 + 4 + 0 + 1 + 4 + 1\\n      = 32\\nAlternatively, it ( SS for total variance) can also be worked out thus:\\nSS for total = SS between + SS within\\n= 8 + 24\\n      = 32\\nWe can now set up the ANOVA table for this problem:\\nTable 11.2\\nSource of SS d.f. MS F-ratio 5% F-limit\\nvariation (from the F-table)\\nBetween sample   8   (3 – 1) = 2    8/2 = 4.00 4.00/2.67 = 1.5 F(2, 9) = 4.26\\nWithin sample 24  (12 – 3) = 9 24/9 = 2.67\\nTotal 32(12 – 1) = 11\\nThe above table shows that the calculated value of F is 1.5 which is less than the table value of\\n4.26 at 5% level with d.f. being v1 = 2 and v2 = 9 and hence could have arisen due to chance. This\\nanalysis supports the null-hypothesis of no difference is sample means. We may, therefore, conclude\\nthat the difference in wheat output due to varieties is insignificant and is just a matter of chance.\\nSolution through short-cut method:  In this case we first take the total of all the individual\\nvalues of n  items and call it as T.\\nT in the given case = 60\\nand n = 12\\nHence, the correction factor = ( T)2/n = 60 × 60/12 = 300. Now total SS, SS between and SS\\nwithin can be worked out as under:\\nTotal SS XT\\nnij=∑ −22bg     i = 1, 2, 3, …\\nj = 1, 2, 3, …264 Research Methodology\\n= (6)2 + (7)2 + (3)2 + (8)2 + (5)2 + (5)2 + (3)2\\n+ (7)2 + (5)2 + (4)2 + (3)2 + (4)2 – 60 60\\n12× FHGIKJ\\n   = 332 – 300 = 32\\nSST\\nnT\\nnj\\nj between = ∑−di bg22\\n               =× FHGIKJ+× FHGIKJ+× FHGIKJ−× FHGIKJ24 24\\n420 20\\n416 16\\n460 60\\n12\\n   = 144 + 100 + 64 – 300\\n   = 8\\nSS within =∑ −∑XT\\nnijj\\nj22di\\n      = 332 – 308\\n      = 24\\nIt may be noted that we get exactly the same result as we had obtained in the case of direct\\nmethod. From now onwards we can set up ANOVA table and interpret F-ratio in the same manner\\nas we have already done under the direct method.\\nTWO-WAY ANOVA\\nTwo-way ANOVA technique is used when the data are classified on the basis of two factors. For\\nexample, the agricultural output may be classified on the basis of different varieties of seeds and alsoon the basis of different varieties of fertilizers used. A business firm may have its sales data classifiedon the basis of different salesmen and also on the basis of sales in different regions. In a factory, thevarious units of a product produced during a certain period may be classified on the basis of differentvarieties of machines used and also on the basis of different grades of labour. Such a two-way designmay have repeated measurements of each factor or may not have repeated values. The ANOVAtechnique is little different in case of repeated measurements where we also compute the interactionvariation. We shall now explain the two-way ANOVA technique in the context of both the saiddesigns with the help of examples.\\n(a) ANOVA technique in context of two-way design when repeated values are not there: As we\\ndo not have repeated values, we cannot directly compute the sum of squares within samples as we\\nhad done in the case of one-way ANOVA. Therefore, we have to calculate this residual or errorvariation by subtraction, once we have calculated (just on the same lines as we did in the case of one-way ANOVA) the sum of squares for total variance and for variance between varieties of onetreatment as also for variance between varieties of the other treatment.Analysis of Variance and Co-variance 265\\nThe various steps involved are as follows:\\n(i) Use the coding device, if the same simplifies the task.\\n(ii) Take the total of the values of individual items (or their coded values as the case may be)\\nin all the samples and call it T.\\n(iii) Work out the correction factor as under:\\nCorrection factor =  T\\nnbg2\\n(iv)Find out the square of all the item values (or their coded values as the case may be) one by\\none and then take its total. Subtract the correction factor from this total to obtain the sum ofsquares of deviations for total variance. Symbolically, we can write it as:\\nSum of squares of deviations for total variance or total SS\\n=∑ −XT\\nnij22bg\\n(v) Take the total of different columns and then obtain the square of each column total and\\ndivide such squared values of each column by the number of items in the concerning\\ncolumn and take the total of the result thus obtained. Finally, subtract the correction factorfrom this total to obtain the sum of squares of deviations for variance between columns or(SS between columns).\\n(vi) Take the total of different rows and then obtain the square of each row total and divide\\nsuch squared values of each row by the number of items in the corresponding row and takethe total of the result thus obtained. Finally, subtract the correction factor from this total toobtain the sum of squares of deviations for variance between rows (or SS between rows).\\n(vii)Sum of squares of deviations for residual or error variance can be worked out by subtractingthe result of the sum of (v)th and (vi)th steps from the result of (iv)th step stated above. Inother words,\\nTotal SS – (SS between columns + SS between rows)\\n= SS for residual or error variance.\\n(viii)Degrees of freedom (d.f.) can be worked out as under:\\nd.f. for total variance = (c . r – 1)\\nd.f. for variance between columns = ( c – 1)\\nd.f. for variance between rows = ( r – 1)\\nd.f. for residual variance = ( c – 1) (r – 1)\\nwherec = number of columns\\nr = number of rows\\n(ix)ANOVA table can be set up in the usual fashion as shown below:266 Research Methodology\\nTable 11.3 :Analysis of Variance Table for Two-way Anova\\nSource of Sum of squares Degrees of Mean square F-ratio\\nvariation (SS) freedom (d.f.) (MS)\\nBetween\\ncolumns\\ntreatment∑−T\\nnT\\nnj\\njdi bg22\\n(c – 1)SS\\nc between columns\\n(– 1 )MS\\nMS between columns\\n residual\\nBetween\\nrows\\ntreatment∑−T\\nnT\\nni\\nibg bg2 2\\n(r – 1)SS\\nr between rows\\n(– 1 )MS\\nMS between rows\\n residual\\nResidual\\nor errorTotal  – (\\nbetween columns\\n+ between rows)SS SS\\nSS(c – 1) (r – 1)SS\\ncr residual\\n(– 1 ) (– 1 )\\nTotal ∑−XT\\nnij22bg(c.r – 1)\\nIn the table c = number of columns\\nr = number of rows\\n   SS residual = Total SS – (SS between columns + SS between rows).\\nThus, MS residual or the residual variance provides the basis for the F-ratios concerning\\nvariation between columns treatment and between rows treatment. MS residual is always\\ndue to the fluctuations of sampling, and hence serves as the basis for the significance test.\\nBoth the F-ratios are compared with their corresponding table values, for given degrees of\\nfreedom at a specified level of significance, as usual and if it is found that the calculatedF-ratio concerning variation between columns is equal to or greater than its table value,then the difference among columns means is considered significant. Similarly, the F-ratio\\nconcerning variation between rows can be interpreted.\\nIllustration 2\\nSet up an analysis of variance table for the following two-way design results:\\nPer Acre Production Data of Wheat\\n(in metric tonnes )\\nVarieties of seeds A B C\\nVarieties of fertilizers\\nW 655\\nX 754\\nY 333\\nZ 874\\nAlso state whether variety differences are significant at 5% level.Analysis of Variance and Co-variance 267\\nSolution:  As the given problem is a two-way design of experiment without repeated values, we shall\\nadopt all the above stated steps while setting up the ANOVA table as is illustrated on the following\\npage.\\nANOVA table can be set up for the given problem as shown in Table  11.5.\\nFrom the said ANOVA table, we find that differences concerning varieties of seeds are insignificant\\nat 5% level as the calculated F-ratio of 4 is less than the table value of 5.14, but the variety differences\\nconcerning fertilizers are significant as the calculated F-ratio of 6 is more than its table value of 4.76.\\n(b) ANOVA technique in context of two-way design when repeated values are there: In case of\\na two-way design with repeated measurements for all of the categories, we can obtain a separate\\nindependent measure of inherent or smallest variations. For this measure we can calculate the sumof squares and degrees of freedom in the same way as we had worked out the sum of squares forvariance within samples in the case of one-way ANOVA. Total SS, SS between columns and SS\\nbetween rows can also be worked out as stated above. We then find left-over sums of squares andleft-over degrees of freedom which are used for what is known as ‘ interaction variation ’ (Interaction\\nis the measure of inter relationship among the two different classifications). After making all thesecomputations, ANOVA table can be set up for drawing inferences. We illustrate the same with anexample.\\nTable 11.4\\n:Computations for Two-way Anova (in a design without repeated values)\\nStep (i) T = 60, n = 12, ∴=×= Correction factor =  T\\nnbg260 60\\n12300\\nStep (ii) Total SS = (36 + 25 + 25 + 49 + 25 + 16 + 9 + 9 + 9 + 64 + 49 + 16) – 60 60\\n12× FHGIKJ\\n= 332 – 300\\n= 32\\nStep (iii) SS between columns treatment =×+×+× LNMOQP−× LNMOQP24 24\\n420 20\\n416 16\\n460 60\\n12\\n           = 144 + 100 + 64 – 300\\n          = 8\\nStep (iv) SS between rows treatment =×+×+×+× LNMOQP−× LNMOQP16 16\\n316 16\\n399\\n319 19\\n360 60\\n12\\n   = 85.33 + 85.33 + 27.00 + 120.33 – 300\\n   = 18\\nStep (v) SS residual or error = Total SS – (SS between columns + SS between rows)\\n    = 32 – (8 + 18)    = 6268 Research Methodology\\nTable 11.5 :The Anova Table\\nSource of variation SS d.f. MS F-ratio 5% F-limit (or the\\ntables values)\\nBetween columns 8 (3 – 1) = 2 8/2 = 4 4/1 = 4 F(2, 6) = 5.14\\n(i.e., between varieties\\nof seeds)\\nBetween rows 18 (4 – 1) = 3 18/3 = 6 6/1 = 6 F(3, 6) = 4.76\\n(i.e., between varieties\\nof fertilizers)\\nResidual or error 6 (3 – 1) × 6/6=1\\n(4 – 1) = 6\\nTotal 32 (3 × 4) – 1 = 11\\nIllustration 3\\nSet up ANOVA table for the following information relating to three drugs testing to judge the\\neffectiveness in reducing blood pressure for three different groups of people:\\nAmount of Blood Pressure Reduction in Millimeters of Mercury\\nDrug\\nXY Z\\nGroup of People A 14 10 11\\n15 9 11\\nB 12 7 10\\n11 8 11\\nC 10 11 8\\n11 11 7\\nDo the drugs act differently?\\nAre the different groups of people affected differently?Is the interaction term significant?\\nAnswer the above questions taking a significant level of 5%.\\nSolution:  We first make all the required computations as shown below:\\nWe can set up ANOVA table shown in Table 11.7 (Page 269).Analysis of Variance and Co-variance 269\\nTable 11.6 :Computations for Two-way Anova (in design with repeated values)\\nStep (i) T = 187, n = 18, thus, the correction factor =×=187 187\\n18194272.\\nStep (ii) Total SS = [(14)2 + (15)2 + (12)2 + (11)2 + (10)2 + (11)2 + (10)2 +(9)2 + (7)2 + (8)2 + (11)2 + (11)2 + (11)2\\n+ (11)2 + (10)2 + (11)2 + (8)2 + (7)2] – 187\\n182bgL\\nNMMO\\nQPP\\n            = (2019 – 1942.72)\\n           = 76.28\\nStep (iii) SS between columns (i.e., between drugs) =×+×+× LNMOQP−L\\nNMMO\\nQPP73 73\\n656 56\\n658 58\\n6187\\n182bg\\n        = 888.16 + 522.66 + 560.67 – 1942.72\\n       = 28.77\\n       Step (iv) SS between rows (i.e., between people) =×+×+× LNMOQP−L\\nNMMO\\nQPP70 70\\n659 59\\n658 58\\n6187\\n182bg\\n        = 816.67 + 580.16 + 560.67 – 1942.72\\n        = 14.78\\n       Step (v) SS within samples = (14 – 14.5)2 + (15 – 14.5)2 + (10 – 9.5)2 + (9 – 9.5)2 + (11 – 11)2 + (11 – 11)2\\n+ (12 – 11.5)2 + (11 – 11.5)2 + (7 – 7.5)2 + (8 – 7.5)2\\n+ (10 – 10.5)2 + (11 – 10.5)2 + (10 – 10.5)2 + (11 – 10.5)2\\n+ (11 – 11)2 + (11 – 11)2 + (8 – 7.5)2 + (7 – 7.5)2\\n   = 3.50\\n       Step (vi) SS for interaction variation = 76.28 – [28.77 + 14.78 + 3.50]\\n                = 29.23\\nTable 11.7 :The Anova Table\\nSource of variation SS d.f. MS F -ratio 5% F-limit\\nBetween\\ncolumns (i.e.,\\nbetween drugs)28.77 (3 – 1) = 22877\\n2.14385\\n0389.\\n.F (2, 9) = 4.26\\n= 14.385 = 36.9\\nBetween rows\\n(i.e.,between\\npeople)14.78 (3 – 1) = 21478\\n2. 7390\\n0389.\\n.F (2, 9) = 4.26\\n= 7.390 = 19.0\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○270 Research Methodology\\nSource of variation SS d.f. MS F -ratio 5% F-limit\\nInteraction 29.23*4* 2923\\n4. 7308\\n0389.\\n.F (4, 9) = 3.63\\nWithin\\nsamples\\n(Error)3.50(18 – 9) = 9350\\n9.\\n= 0.389\\nTotal 76.28(18 – 1) = 17\\n* These figures are left-over figures and have been obtained by subtracting from the column total the total of all other\\nvalue in the said column. Thus, interaction SS = (76.28) – (28.77 + 14.78 + 3.50) = 29.23 and interaction degrees of freedom\\n= (17) – (2 + 2 + 9) = 4.\\nThe above table shows that all the three F-ratios are significant of 5% level which means that\\nthe drugs act differently, different groups of people are affected differently and the interaction term\\nis significant. In fact, if the interaction term happens to be significant, it is pointless to talk about thedifferences between various treatments i.e., differences between drugs or differences betweengroups of people in the given case.\\nGraphic method of studying interaction in a two-way design: Interaction can be studied in a\\ntwo-way design with repeated measurements through graphic method also. For such a graph we\\nshall select one of the factors to be used as the X-axis. Then we plot the averages for all the samples\\non the graph and connect the averages for each variety of the other factor by a distinct mark (or acoloured line). If the connecting lines do not cross over each other, then the graph indicates that thereis no interaction, but if the lines do cross, they indicate definite interaction or inter-relation betweenthe two factors. Let us draw such a graph for the data of illustration 3 of this chapter to see whetherthere is any interaction between the two factors viz., the drugs and the groups of people.\\nFig. 11.1\\n* Alternatively, the graph can be drawn by taking different group of people on X-axis and drawing lines for various drugs\\nthrough the averages.X YZ\\nDrugsX-axis 579111315171921(Blood pressure reduction\\nin millimeters of mercury)Y-axis Groups of\\nPeople\\nA\\nB\\nCGraph of the averages for amount of blood pressure reduction in millimeters of\\nmercury for different drugs and different groups of people.*Analysis of Variance and Co-variance 271\\nThe graph indicates that there is a significant interaction because the different connecting lines\\nfor groups of people do cross over each other. We find that A and B are affected very similarly, but\\nC is affected differently. The highest reduction in blood pressure in case of C is with drug Y and the\\nlowest reduction is with drug Z, whereas the highest reduction in blood pressure in case of A and B\\nis with drug X and the lowest reduction is with drug Y. Thus, there is definite inter-relation between\\nthe drugs and the groups of people and one cannot make any strong statements about drugs unless he\\nalso qualifies his conclusions by stating which group of people he is dealing with. In such a situation,performing F-tests is meaningless. But if the lines do not cross over each other (and remain more or\\nless identical), then there is no interaction or the interaction is not considered a significantly largevalue, in which case the researcher should proceed to test the main effects, drugs and people in thegiven case, as stated earlier.\\nANOVA IN LATIN-SQUARE DESIGN\\nLatin-square design is an experimental design used frequently in agricultural research. In such adesign the treatments are so allocated among the plots that no treatment occurs, more than once inany one row or any one column. The ANOVA technique in case of Latin-square design remainsmore or less the same as we have already stated in case of a two-way design, excepting the fact thatthe variance is splitted into four parts as under:\\n(i) variance between columns;\\n(ii)variance between rows;\\n(iii)variance between varieties;\\n(iv)residual variance.\\nAll these above stated variances are worked out as under:\\nTable 11.8\\nVariance between\\ncolumns or \\nbetween columnsMS\\n=∑−\\n−=T\\nnT\\nn\\ncSSj\\njdi bg\\nbg22\\n1 between columns\\nd.f.\\nVariance between\\nrows or \\nbetween rowsMS\\n=∑−\\n−=T\\nnT\\nn\\nrSSi\\nibg bg\\nbg2 2\\n1 between rows\\nd.f.\\nVariance between\\nvarieties or \\nbetween varietiesMS\\n=∑−\\n−=T\\nnT\\nn\\nvSSv\\nvbg bg\\nbg2 2\\n1 between varieties\\nd.f.\\nResidual or error\\nvariance or residualMS Total  – (  between columns + \\nbetween rows +  between varieties)\\n( – 1) ( – 2)  *SS SS SS\\nSS\\ncc=\\nContd.\\n* In place of c we can as well write r or v since in Latin-square design c = r = v.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○272 Research Methodology\\nwhere total SS xT\\nnij=∑ − dibg22\\nc = number of columns\\nr = number of rows\\nv = number of varieties\\nIllustration 4\\nAnalyse and interpret the following statistics concerning output of wheat per field obtained as a\\nresult of experiment conducted to test four varieties of wheat viz., A, B, C and D under a Latin-\\nsquare design.\\nSolution:  Using the coding method, we subtract 20 from the figures given in each of the small\\nsquares and obtain the coded figures as under:\\nFig. 11.2 (a)\\nSquaring these coded figures in various columns and rows we have:C\\nA\\nB\\nDB\\nD\\nA\\nCA\\nC\\nD\\nBD\\nB\\nC\\nA25\\n19\\n19\\n1723\\n19\\n14\\n2020\\n21\\n17\\n2120\\n18\\n20\\n15\\nColumns Row totals\\n1 2 3 4\\nC\\nA\\nB\\nDB\\nD\\nA\\nCA\\nC\\nD\\nBD\\nB\\nC\\nA5\\n–1\\n–1\\n–3\\n03\\n–1\\n–6\\n0\\n–40\\n1\\n–3\\n1\\n–10\\n–2\\n0\\n–5\\n–71\\n2348\\n–2\\n–10\\n–7\\nT= –12Rows\\nColumn\\ntotalsAnalysis of Variance and Co-variance 273\\nFig. 11.2 (b)\\nCorrection factor =  T\\nnbg b g b g212 12\\n169 =−−=\\n        SS XT\\nnij  for total variance =  ∑−= − =dibg22\\n122 9 113\\n  SST\\nnT\\nnj\\nj for variance between columns =  ∑−di bg22\\n           =+−+−+− RS|\\nT|UV|\\nW|−0\\n44\\n41\\n47\\n4922 22b g bg b g bg\\n         =− =66\\n497 5.\\nSS for variance between rows\\n=∑ − +−+−+− RS|\\nT|UV|\\nW|−T\\nnT\\nni\\nibg bg b g b g b g b g2 22 2 2 28\\n43\\n410\\n47\\n49\\n     =− =222\\n494 6 5.\\nSS for variance between varieties would be worked out as under:ColumnsSum of\\nsquares\\n1 2 3 4\\nC\\nA\\nB\\nDB\\nD\\nA\\nCA\\nC\\nD\\nBD\\nB\\nC\\nA25\\n1\\n1\\n9\\n369\\n1\\n36\\n0\\n460\\n1\\n9\\n1\\n110\\n4\\n0\\n25\\n291\\n23434\\n7\\n46\\n35\\nT= 122Rows\\nSum of\\nsquaresSquares of\\ncoded figures274 Research Methodology\\nFor finding SS for variance between varieties, we would first rearrange the coded data in the\\nfollowing form:\\nTable 11. 9\\nVarieties of Yield in different parts of field Total (Tv)\\nwheat\\nI II III IV\\nA –1 –6 0 –5 –12\\nB –1 3 1 –2 1\\nC 50 1 0 6\\nD –3 –1 –3 0 –7\\nNow we can work out SS for variance between varieties as under:\\nSS for variance between varieties =∑ −T\\nnT\\nnv\\nvbg bg2 2\\n=−+++− RS|\\nT|UV|\\nW|−12\\n41\\n46\\n47\\n49222 2bg b g b g b g\\n=− =230\\n494 8 5.\\n∴ Sum of squares for residual variance will work out to\\n113 – (7.5 + 46.5 + 48.5) = 10.50\\nd.f. for variance between columns  = ( c – 1) = (4 – 1) = 3\\nd.f. for variance between rows  = ( r – 1) = (4 – 1) = 3\\nd.f. for variance between varieties  = (v  – 1) = (4 – 1) = 3\\nd.f. for total variance  = (n – 1) = (16 – 1) = 15\\nd.f. for residual variance  = ( c – 1) (c – 2) = (4 – 1) (4 – 2) = 6\\nANOVA table can now be set up as shown below:\\nTable 11. 10 :The Anova Table in Latin-square Design\\nSource of SS d.f. MS F-ratio 5% F-limit\\nvariation\\nBetween\\ncolumns7.50 3750\\n3250..=250\\n175143.\\n..= F (3, 6) = 4.76\\nBetween\\nrows46.50 34650\\n31550..=1550\\n175885.\\n..= F (3, 6) = 4.76\\ncontd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Analysis of Variance and Co-variance 275\\nSource of SS d.f. MS F-ratio 5% F-limit\\nvariation\\nBetween\\nvarieties48.50 34850\\n31617..=1617\\n175924.\\n..= F (3, 6) = 4.76\\nResidual\\nor error10.50 61050\\n6175..=\\nTotal 113.00 15\\nThe above table shows that variance between rows and variance between varieties are significant\\nand not due to chance factor at 5% level of significance as the calculated values of the said two\\nvariances are 8.85 and 9.24 respectively which are greater than the table value of 4.76. But variancebetween columns is insignificant and is due to chance because the calculated value of 1.43 is lessthan the table value of 4.76.\\nANALYSIS OF CO-VARIANCE (ANOCOVA)WHY ANOCOVA?\\nThe object of experimental design in general happens to be to ensure that the results observed maybe attributed to the treatment variable and to no other causal circumstances. For instance, theresearcher studying one independent variable, X, may wish to control the influence of some uncontrolled\\nvariable (sometimes called the covariate or the concomitant variables), Z, which is known to be\\ncorrelated with the dependent variable, Y, then he should use the technique of analysis of covariance\\nfor a valid evaluation of the outcome of the experiment. “In psychology and education primaryinterest in the analysis of covariance rests in its use as a procedure for the statistical control of anuncontrolled variable.”\\n2\\nANOCOVA TECHNIQUE\\nWhile applying the ANOCOVA technique, the influence of uncontrolled variable is usually removedby simple linear regression method and the residual sums of squares are used to provide varianceestimates which in turn are used to make tests of significance. In other words, covariance analysisconsists in subtracting from each individual score ( Y\\ni) that portion of it Yi´ that is predictable from\\nuncontrolled variable ( Zi) and then computing the usual analysis of variance on the resulting\\n(Y – Y´)’s, of course making the due adjustment to the degrees of freedom because of the fact that\\nestimation using regression method required loss of degrees of freedom.*\\n2 George A-Ferguson, Statistical Analysis in Psychology and Education , 4th ed., p. 347.\\n* Degrees of freedom associated with adjusted sums of squares will be as under:\\nBetween      k – 1\\nwithin      N – k – 1\\nTotal      N – 2276 Research Methodology\\nASSUMPTIONS IN ANOCOVA\\nThe ANOCOVA technique requires one to assume that there is some sort of relationship between\\nthe dependent variable and the uncontrolled variable. We also assume that this form of relationship isthe same in the various treatment groups. Other assumptions are:\\n(i) Various treatment groups are selected at random from the population.\\n(ii)The groups are homogeneous in variability.\\n(iii)The regression is linear and is same from group to group.\\nThe short-cut method for ANOCOVA  can be explained by means of an example as shown\\nbelow:\\nIllustration 5\\nThe following are paired observations for three experimental groups:\\nGroup I Group II Group III\\nXY X Y X Y\\n72 1 5 8 3 0 1 5\\n6 5 24 12 35 16\\n9 7 25 15 32 20\\n15 9 19 18 38 24\\n12 10 31 19 40 30\\nY is the covariate (or concomitant) variable. Calculate the adjusted total, within groups and\\nbetween groups, sums of squares on X and test the significance of differences between the adjusted\\nmeans on X by using the appropriate F-ratio. Also calculate the adjusted means on X.\\nSolution:  We apply the technique of analysis of covariance and work out the related measures as\\nunder:\\nTable 11.11\\nGroup I Group II Group III\\nXY X Y X Y\\n72 1 5 8 3 0 1 5\\n6 5 24 12 35 16\\n9 7 25 15 32 20\\n15 9 19 18 38 24\\n12 10 31 19 40 30\\nTotal 49 33 114 72 175 105\\nMean 9.80 6.60 22.80 14.40 35.00 21.00\\n∑= + + =X49 114 175 338Analysis of Variance and Co-variance 277\\nCorrection factor for = XX\\nN∑=bg2\\n761627.\\n          ∑= + + =Y33 72 105 210\\n   Correction factor for = YY\\nN∑=bg2\\n2940\\n       ∑=X29476  ∑=Y23734  ∑=XY5838\\n Correction factor for = XYXY\\nN∑⋅ ∑=4732\\n    Hence, total SS  for X = ∑X2 – correction factor for X\\n       = 9476 – 7616.27 = 1859.73\\nSS X X between for =49 114 175correction factor for bg b g b glq222\\n555++RS|\\nT|UV|\\nW|−\\n       = (480.2 + 2599.2 + 6125) – (7616.27)\\n       = 1588.13\\nSS within for X = (total SS for X) – (SS between for X)\\n                  = (1859.73) – (1588.13) = 271.60\\nSimilarly we work out the following values in respect of Y\\ntotal SS for Y = ∑Y2 – correction factor for Y\\n   = 3734 – 2940 = 794\\nSS Y Y between for =33 72 105correction factor for bg bg b glq22 2\\n555++RS|\\nT|UV|\\nW|−\\n          = (217.8 + 1036.8 + 2205) – (2940) = 519.6\\n        SS within for Y = (total SS for Y) – (SS between for Y)\\n         = (794) – (519.6) = 274.4\\nThen, we work out the following values in respect of both X and Y\\nTotal sum of product of XY XY=∑ – correction factor for XY\\n      = 5838 – 4732 = 1106\\nSS XY XY between for =33 72 105correction factor for 49\\n5114\\n5175\\n5bg bg b g bg b g b g++RSTUVW−\\n   = (323.4 + 1641.6 + 3675) – (4732) = 908\\n SS within for XY = (Total sum of product) – ( SS between for XY )\\n   = (1106) – (908) = 198278 Research Methodology\\nANOVA table for X, Y and XY can now be set up as shown below:\\nAnova Table for X, Y and XY\\nSource d.f. SS for X SS for Y Sum of product XY\\nBetween groups 2 1588.13 519.60 908\\nWithin groups 12 EXX 271.60 EYY 274.40 EXY 198\\nTotal 14 TXX 1859.73 TYY 794.00 TXY 1106\\n           Adjusted total  SS TT\\nTXXXY\\nYY=−bg2\\n  =−1859731106\\n7942\\n.bg\\n  = (1859.73) – (1540.60)\\n  = 319.13\\nAdjusted SS within group =−EE\\nEXXXY\\nYYbg2\\n        =−27160198\\n274402\\n..bg\\n   = (271.60) – (142.87)) = 128.73\\n          Adjusted SS between groups = (adjusted total SS) – (Adjusted SS within group)\\n         = (319.13 – 128.73)\\n              = 190.40\\nAnova Table for Adjusted X\\nSource d.f. SS MS F-ratio\\nBetween groups 2 190.40 95.2 8.14\\nWithin group 11 128.73 11.7\\nTotal 13 319.13\\nAt 5% level, the table value of F for v1 = 2 and v2 = 11 is 3.98 and at 1% level the table value of\\nF is 7.21. Both these values are less than the calculated value (i.e., calculated value of 8.14 is greater\\nthan table values) and accordingly we infer that F-ratio is significant at both levels which means the\\ndifference in group means is significant.\\nAdjusted means on X will be worked out as follows :\\nRegression coefficient for X on Y i.e., bY=Sum of product within group\\nSum of squares within groups for Analysis of Variance and Co-variance 279\\n==198\\n2744007216..\\nDeviation of initial group means from Final means of groups in X (unadjusted)\\ngeneral mean (= 14) in case of Y\\nGroup I –7.40 9.80\\nGroup II 0.40 22.80\\nGroup III 7.00 35.00\\nAdjusted means of groups in X = (Final mean) – b (deviation of initial mean from general mean\\nin case of Y)\\nHence,\\nAdjusted mean for Group I  = (9.80) – 0.7216 (–7.4) = 15.14\\nAdjusted mean for Group II  = (22.80) – 0.7216 (0.40) = 22.51\\nAdjusted mean for Group III = (35.00) – 0.7216 (7.00) = 29.95\\nQuestions\\n1.(a)Explain the meaning of analysis of variance. Describe briefly the technique of analysis of variance for\\none-way and two-way classifications.\\n(b)State the basic assumptions of the analysis of variance.\\n2.What do you mean by the additive property of the technique of the analysis of variance? Explain how\\nthis technique is superior in comparison to sampling.\\n3.Write short notes on the following:\\n(i) Latin-square design.\\n(ii)Coding in context of analysis of variance.\\n(iii)F-ratio and its interpretation.\\n(iv)Significance of the analysis of variance.\\n4.Below are given the yields per acre of wheat for six plots entering a crop competition, there of the plotsbeing sown with wheat of variety A and three with B.\\nVariety Yields in fields per acre\\n12 3\\nA 30 32 22\\nB 20 18 16\\nSet up a table of analysis of variance and calculate F. State whether the difference between the yields of\\ntwo varieties is significant taking 7.71 as the table value of F at 5% level for v\\n1 = 1 and v2 = 4.\\n(M.Com. II Semester EAFM Exam., Rajasthan University, 1976 )\\n5.A certain manure was used on four plots of land A, B, C and D. Four beds were prepared in each plot and\\nthe manure used. The output of the crop in the beds of plots A, B, C and D is given below:280 Research Methodology\\nOutput on Plots\\nABC D\\n893 3\\n12 4 8 7\\n172 8\\n315 2\\nFind out whether the difference in the means of the production of crops of the plots is significant or not.\\n6.Present your conclusions after doing analysis of variance to the following results of the Latin-square\\ndesign experiment conducted in respect of five fertilizers which were used on plots of different fertility.\\nABCDE\\n16 10 11 09 09\\nECABD\\n10 09 14 12 11\\nBDECA\\n15 08 08 10 18\\nDEBAC\\n12 06 13 13 12\\nCADEB\\n13 11 10 07 14\\n7.Test the hypothesis at the 0.05 level of significance that µµµ123==  for the following data:\\nSamples\\nNo. one No. two No. three\\n(1) (2) (3)\\n62 6\\n74 8\\n65 9\\n–3 5\\n–4 –\\nTotal 19 18 28\\n8.Three varieties of wheat W1, W2 and W3 are treated with four different fertilizers viz., f1, f2, f3 and f4. The\\nyields of wheat per acre were as under:Analysis of Variance and Co-variance 281\\nFertilizer treatment Varieties of wheat Total\\nW1W2W3\\nf155 72 47 174\\nf264 66 53 183\\nf358 57 74 189\\nf459 57 58 174\\nTotal 236 252 232 720\\nSet up a table for the analysis of variance and work out the F-ratios in respect of the above. Are the\\nF-ratios significant?\\n9.The following table gives the monthly sales (in thousand rupees) of a certain firm in three states by its\\nfour salesmen:\\nStates Salesmen Total\\nAB CD\\nX 54 4 7 2 0\\nY 78 5 4 2 4\\nZ 96 6 7 2 8\\nTotal 21 18 15 18 72\\nSet up an analysis of variance table for the above information. Calculate F-coefficients and state whether\\nthe difference between sales affected by the four salesmen and difference between sales affected in threeStates are significant.\\n10.The following table illustrates the sample psychological health ratings of corporate executives in the fieldof Banking. Manufacturing and Fashion retailing:\\nBanking 41 53 54 55 43\\nManufacturing 45 51 48 43 39\\nFashion retailing 34 44 46 45 51\\nCan we consider the psychological health of corporate executives in the given three fields to be equal at5% level of significance?\\n11.The following table shows the lives in hours of randomly selected electric lamps from four batches:\\nBatch Lives in hours\\n1 1600 1610 1650 1680 1700 1720 1800\\n2 1580 1640 1640 1700 17503 1450 1550 1600 1620 1640 1660 1740 1820\\n4 1510 1520 1530 1570 1600 1680\\nPerform an analysis of variance of these data and show that a significance test does not reject their\\nhomogeneity. (M.Phil. (EAFM) Exam., Raj. University, 1979 )\\n12.Is the interaction variation significant in case of the following information concerning mileage based ondifferent brands of gasoline and cars?282 Research Methodology\\n                            Brands of gasoline\\nWXY Z\\nA 13 12 12 11\\n11 10 11 13\\nCars B 12 10 11 9\\n13 11 12 10\\nC 14 11 13 10\\n13 10 14 8\\n13.The following are paired observations for three experimental groups concerning an experimental involving\\nthree methods of teaching performed on a single class.\\nMethod A to Group I Method B to Group II Method C to Group III\\nXY X Y X Y\\n33 20 35 31 15 15\\n40 32 50 45 10 20\\n40 22 10 5 5 10\\n32 24 50 33 35 15\\nX represents initial measurement of achievement in a subject and Y the final measurement after subject\\nhas been taught. 12 pupils were assigned at random to 3 groups of 4 pupils each, one group from onemethod as shown in the table.\\nApply the technique of analysis of covariance for analyzing the experimental results and then state\\nwhether the teaching methods differ significantly at 5% level. Also calculate the adjusted means on Y.\\n[Ans: F-ratio is not significant and hence there is no difference due to teaching methods.\\nAdjusted means on Y will be as under:\\nFor Group I 20.70\\nFor Group II 24.70\\nFor Group III 22.60]Testing of Hypotheses-II 283\\n12\\nTesting of Hypotheses-II\\n(Nonparametric or Distribution-free Tests)\\nIt has already been stated in earlier chapters that a statistical test is a formal technique, based on\\nsome probability distribution, for arriving at a decision about the reasonableness of an assertion orhypothesis. The test technique makes use of one or more values obtained from sample data [oftencalled test statistic(s)] to arrive at a probability statement about the hypothesis. But such a testtechnique also makes use of some more assertions about the population from which the sample isdrawn. For instance, it may assume that population is normally distributed, sample drawn is a randomsample and similar other assumptions. The normality of the population distribution forms the basis formaking statistical inferences about the sample drawn from the population. But no such assumptionsare made in case of non-parametric tests.\\nIn a statistical test, two kinds of assertions are involved viz., an assertion directly related to the\\npurpose of investigation and other assertions to make a probability statement. The former is anassertion to be tested and is technically called a hypothesis, whereas the set of all other assertions iscalled the model. When we apply a test (to test the hypothesis) without a model, it is known asdistribution-free test, or the nonparametric test. Non-parametric tests do not make an assumptionabout the parameters of the population and thus do not make use of the parameters of the distribution.In other words, under non-parametric or distribution-free tests we do not assume that a particulardistribution is applicable, or that a certain value is attached to a parameter of the population. Forinstance, while testing the two training methods, say A and B, for determining the superiority of one\\nover the other, if we do not assume that the scores of the trainees are normally distributed or that themean score of all trainees taking method A would be a certain value, then the testing method is\\nknown as a distribution-free or nonparametric method. In fact, there is a growing use of such tests insituations when the normality assumption is open to doubt. As a result many distribution-free testshave been developed that do not depend on the shape of the distribution or deal with the parametersof the underlying population. The present chapter discusses few such tests.284 Research Methodology\\nIMPORTANT NONPARAMETRIC OR DISTRIBUTION-FREE TESTS\\nTests of hypotheses with ‘order statistics’ or ‘nonparametric statistics’ or ‘distribution-free’ statistics\\nare known as nonparametric or distribution-free tests. The following distribution-free tests are importantand generally used:\\n(i) Test of a hypothesis concerning some single value for the given data (such as one-sample\\nsign test).\\n(ii) Test of a hypothesis concerning no difference among two or more sets of data (such as\\ntwo-sample sign test, Fisher-Irwin test, Rank sum test, etc.).\\n(iii) Test of a hypothesis of a relationship between variables (such as Rank correlation,  Kendall’s\\ncoefficient of concordance and other tests for dependence.\\n(iv) Test of a hypothesis concerning variation in the given data i.e., test analogous to ANOVA\\nviz., Kruskal-Wallis test.\\n(v) Tests of randomness of a sample based on the theory of runs viz., one sample runs test.\\n(vi) Test of hypothesis to determine if categorical data shows dependency or if two classifications\\nare independent viz., the chi-square test. (The chi-square test has already been dealt within Chapter 10.) The chi-square test can as well be used to make comparison betweentheoretical populations and actual data when categories are used.\\nLet us explain and illustrate some of the above stated tests which are often used in practice.\\n1. Sign Tests\\nThe sign test is one of the easiest parametric tests. Its name comes from the fact that it is based onthe direction of the plus or minus signs of observations in a sample and not on their numericalmagnitudes. The sign test may be one of the following two types:\\n(a) One sample sign test;\\n(b) Two sample sign test.\\n(a) One sample sign test: The one sample sign test is a very simple non-parametric test applicable\\nwhen we sample a continuous symmetrical population in which case the probability of getting a\\nsample value less than mean is 1/2 and the probability of getting a sample value greater than mean is\\nalso 1/2. To test the null hypothesis \\nµµ =H0 against an appropriate alternative on the basis of a\\nrandom sample of size ‘ n’, we replace the value of each and every item of the sample with a plus (+)\\nsign if it is greater than µH0, and with a minus (–) sign if it is less than µH0. But if the value happens\\nto be equal to µH0, then we simply discard it. After doing this, we test the null hypothesis that these\\n+ and – signs are values of a random variable, having a binomial distribution with p = 1/2*. For\\nperforming one sample sign test when the sample is small, we can use tables of binomial probabilities,\\nbut when sample happens to be large, we use normal approximation to binomial distribution. Let ustake an illustration to apply one sample sign test.\\n*If it is not possible for one reason or another to assume a symmetrical population, even then we can use the one sample\\nsign test, but we shall then be testing the null hypothesis ~~µµ =H0, where ~µ is the population median.Testing of Hypotheses-II 285\\nIllustration 1\\nSuppose playing four rounds of golf at the City Club 11 professionals totalled 280, 282, 290, 273, 283,\\n283, 275, 284, 282, 279, and 281. Use the sign test at 5% level of significance to test the null hypothesis\\nthat professional golfers average µH0 = 284 for four rounds against the alternative hypothesis\\nµH0<284.\\nSolution: To test the null hypothesis µH0 = 284 against the alternative hypothesis µH0 < 284 at 5%\\n(or 0.05) level of significance, we first replace each value greater than 284 with a plus sign and each\\nvalue less than 284 with a minus sign and discard the one value which actually equals 284. If we dothis we get\\n–,–,+,–,–,–,–,–,–,–.\\nNow we can examine whether the one plus sign observed in 10 trials support the null hypothesisp= 1/2 or the alternative hypothesis p < 1/2. The probability of one or fewer successes with n = 10\\nand p = 1/2 can be worked out as under:\\n10\\n119 1 0\\n001 019 01 0\\n101\\n21\\n21121\\n2Cpq Cpq+=FHGIKJFHGIKJ+FHGIKJFHGIKJ\\n           = 0.010 + 0.001\\n(These values can also be seen from the table of binomial probabilities* when p = 1/2 and n=10)\\n= 0.011\\nSince this value is less than α = 0.05, the null hypothesis must be rejected. In other words, we\\nconclude that professional golfers’ average is less than 284 for four rounds of golf.\\nAlternatively, we can as well use normal approximation to the binomial distribution. If we do that,\\nwe find the observed proportion of success, on the basis of signs that we obtain, is 1/10 and that of\\nfailure is 9/10. The. standard error of proportion assuming null hypothesis p = 1/2 is as under:\\nσprop.=⋅=×=pq\\nn1\\n212\\n1001581.\\nFor testing the null hypothesis i.e., p = 1/2 against the alternative hypothesis p < 1/2, a one-tailed test\\nis appropriate which can be indicated as shown in the Fig. 12.1.\\nBy using table of area under normal curve, we find the appropriate z value for 0.45 of the area\\nunder normal curve and it is 1.64. Using this, we now work out the limit (on the lower side as the\\nalternative hypothesis is of < type) of the acceptance region as under:\\npz−⋅ σprop.bg\\nor p – (1.64) (0.1581)\\nor1\\n202593−.\\nor 0.2407\\n* Table No. 8 given in appendix at the end of the book.286 Research Methodology\\nFig. 12.1\\nAs the observed proportion of success is only 1/10 or 0.1 which comes in the rejection region, we\\nreject the null hypothesis at 5% level of significance and accept the alternative hypothesis. Thus, we\\nconclude that professional golfers’ average is less than 284 for four rounds of golf.\\n(b) Two sample sign test (or the sign test for paired data) :The sign test has important applications\\nin problems where we deal with paired data. In such problems, each pair of values can be replaced\\nwith a plus (+) sign if the first value of the first sample (say X) is greater than the first value of the\\nsecond sample (say Y) and we take minus (–) sign if the first value of X is less than the first value of\\nY. In case the two values are equal, the concerning pair is discarded. (In case the two samples are\\nnot of equal size, then some of the values of the larger sample left over after the random pairing willhave to be discarded.) The testing technique remains the same as started in case of one sample signtest. An example can be taken to explain and illustrate the two sample sign test.\\nIllustration 2\\nThe following are the numbers of artifacts dug up by two archaeologists at an ancient cliff dwelling\\non 30 days.\\nBy X 1  0  2  3  1  0  2  2  3  0  1  1  4  1  2  1  3  5  2  1  3  2  4  1  3  2  0  2  4  2\\nBy Y 0  0  1  0  2  0  0  1  1  2  0  1  2  1  1  0  2  2  6  0  2  3  0  2  1  0  1  0  1  0\\nUse the sign test at 1% level of significance to test the null hypothesis that the two archaeologists,\\nX and Y, are equally good at finding artifacts against the alternative hypothesis that X is better.\\nSolution:  First of all the given paired values are changed into signs (+ or –) as under:(0.45 of area)0.05 of area\\nLimit\\n0.2407 p= 1/2p– (1.64) ( ) /c115prop\\n(Shaded portion indicates rejection region)Testing of Hypotheses-II 287\\nTable 12.1\\nBy X 1   0   2   3   1   0   2   2   3   0   1   1   4   1   2   1   3   5   2   1   3   2   4   1   3   2   0   2   4   2\\nBy Y 0   0   1   0   2   0   0   1   1   2   0   1   2   1   1   0   2   2   6   0   2   3   0   2   1   0   1   0   1   0\\nSign +   0  +   +   –   0   +   +   +   –  +   0  +   0   +   +  +   +  –   +   +   –  +   –  +   +   –  +   +  +\\n(X – Y)\\nTotal Number of + signs = 20\\nTotal Number of – signs = 6\\nHence, sample size = 26(Since there are 4 zeros in the sign row and as such four pairs are discarded, we are left with\\n30 – 4 = 26.)\\nThus the observed proportion of pluses (or successes) in the sample is = 20/26 = 0.7692 and the\\nobserved proportion of minuses (or failures) in the sample is = 6/26 = 0.2308.\\nAs we are to test the null hypothesis that the two archaeologists X and Y are equally good and if\\nthat is so, the number of pluses and minuses should be equal and as such p = 1/2 and q = 1/2. Hence,\\nthe standard error of proportion of successes, given the null hypothesis and the size of the sample, we\\nhave:\\nσprop.=⋅=×=pq\\nn1\\n21\\n2\\n2600981.\\nSince the alternative hypothesis is that the archaeologists X is better (or p > 1/2), we find one\\ntailed test is appropriate. This can be indicated as under, applying normal approximation to binomialdistribution in the given case:\\nFig. 12.20.01 of area 0.49 of area\\nLimit\\n0.7276 p= 1/2p+ 2.32 ( )/c115prop\\n(Shaded area represents\\nrejection region)288 Research Methodology\\nBy using the table of area under normal curve, we find the appropriate z value for 0.49 of the\\narea under normal curve and it is 2.32. Using this, we now work out the limit (on the upper side as the\\nalternative hypothesis is of > type) of the acceptance region as under:\\np+= +232 05 232 00981.. . ..σprop bg\\n                           = 0.5 + 0.2276 = 0.7276\\nand we now find the observed proportion of successes is 0.7692 and this comes in the rejectionregion and as such we reject the null hypothesis, at 1% level of significance, that two archaeologistsX and Y are equally good. In other words, we accept the alternative hypothesis, and thus conclude\\nthat archaeologist X is better.\\nSign tests, as explained above, are quite simple and they can be applied in the context of both\\none-tailed and two-tailed tests. They are generally based on binomial distribution, but when the\\nsample size happens to be large enough (such that \\nnp⋅ and nq⋅ both happen to be greater than 5),\\nwe can as well make use of normal approximation to binomial distribution.\\n2. Fisher-Irwin Test\\nFisher-Irwin test is a distribution-free test used in testing a hypothesis concerning no difference\\namong two sets of data. It is employed to determine whether one can reasonably assume, for example,that two supposedly different treatments are in fact different in terms of the results they produce.Suppose the management of a business unit has designed a new training programme which is nowready and as such it wishes to test its performance against that of the old training programme. Forthis purpose a test is performed as follows:\\nTwelve newly selected workers are chosen for an experiment through a standard selection\\nprocedure so that we presume that they are of equal ability prior to the experiment. This group oftwelve is then divided into two groups of six each, one group for each training programme. Workersare randomly assigned to the two groups. After the training is completed, all workers are given thesame examination and the result is as under:\\nTable 12.2\\nNo. passed No. failed T otal\\nNew Training ( A)5 1   6\\nOld Training ( B)3 3   6\\nTotal 8 4 12\\nA casual look of the above result shows that the new training programme is superior. But the\\nquestion arises: Is it really so? It is just possible that the difference in the result of the two groups maybe due to chance factor. Such a result may occur even though the two training programmes wereequally good. Then how can a decision be made? We may test the hypothesis for the purpose. Thehypothesis is that the two programmes are equally good. Prior to testing, the significance level (or the\\nα value) must be specified and supposing the management fixes 5% level for the purpose, which\\nmust invariably be respected following the test to guard against bias entering into the result and toavoid the possibility of vacillation oil the part of the decision maker. The required probability that theparticular result or a better one for A Group would occur if the two training programmes were, inTesting of Hypotheses-II 289\\nfact, equally good, (alternatively the probability that the particular result or worse for B group would\\noccur) be worked out. This should be done keeping in view the probability principles. For the given\\ncase, the probability that Group A has the particular result or a better one, given the null hypothesis\\nthat the two programmes are equally good, is as follows:\\nPr. of Group A doing as well or better\\n= Pr. (5 passing and 1 failing) + Pr. (6 passing and 0 failing)\\n    =×+×8\\n54\\n1\\n12\\n68\\n64\\n0\\n12\\n6CC\\nCCC\\nC\\n    =+=+=224\\n92428\\n924024 003 027...\\nAlternatively, we can work out as under:\\nPr. of Group B doing as well or worse\\n= Pr. (3 passing and 3 failing) + Pr. (2 passing and 4 failing)\\n    =×+×8\\n34\\n3\\n12\\n68\\n24\\n4\\n12\\n6CC\\nCCC\\nC\\n    =+=+=224\\n92428\\n924024 003 027...\\nNow we have to compare this calculated probability with the significance level of 5% or 0.05\\nalready specified by the management. If we do so, we notice that the calculated value is greater than\\n0.05 and hence, we must accept the null hypothesis. This means that at a significance level of 5% theresult obtained in the above table is not significant. Hence, we can infer that both training programmesare equally good.\\nThis test (Fisher-Irwin test), illustrated above, is applicable for those situations where the observed\\nresult for each item in the sample can be classified into one of the two mutually exclusive categories.For instance, in the given example the worker’s performance was classified as fail or pass andaccordingly numbers failed and passed in each group were obtained. But supposing the score ofeach worker is also given and we only apply the Fisher-Irwin test as above, then certainly we arediscarding the useful information concerning how well a worker scored. This in fact is the limitationof the Fisher-Irwin test which can be removed if we apply some other test, say, Wilcoxon test asstated in the pages that follow.\\n3. McNemer Test\\nMcNemer test is one of the important nonparametric tests often used when the data happen to be\\nnominal and relate to two related samples. As such this test is specially useful with before-aftermeasurement of the same subjects. The experiment is designed for the use of this test in such a waythat the subjects initially are divided into equal groups as to their favourable and unfavourable viewsabout, say, any system. After some treatment, the same number of subjects are asked to expresstheir views about the given system whether they favour it or do not favour it. Through McNemer testwe in fact try to judge the significance of any observed change in views of the same subjects before290 Research Methodology\\nand after the treatment by setting up a table in the following form in respect of the first and second\\nset of responses:\\nTable 12.3\\nBefore treatment After treatment\\nDo not favour Favour\\nFavour AB\\nDo not favour CD\\nSince A + D indicates change in people’s responses ( B + C shows no change in responses), the\\nexpectation under null hypothesis H0 is that (A + D)/2 cases change in one direction and the same\\nproportion in other direction. The test statistic under McNemer Test is worked out as under (as ituses the under-mentioned transformation of Chi-square test):\\nχ221\\n=−−\\n+AD\\nADch\\nbg with d.f. =1\\nThe minus 1 in the above equation is a correction for continuity as the Chi-square test happens to bea continuous distribution, whereas the observed data represent a discrete distribution. We illustrate\\nthis test by an example given below:\\nIllustration 3\\nIn a certain before-after experiment the responses obtained from 1000 respondents, when classified,\\ngave the following information:\\nBefore treatment After treatment\\nUnfavourable Favourable\\nResponse Response\\nFavourable response 200 =A 300 =B\\nUnfavourable response 400 = C 100 = D\\nTest at 5% level of significance, whether there has been a significant change in people’s attitude\\nbefore and after the concerning experiment.\\nSolution:  In the given question we have nominal data and the study involves before-after\\nmeasurements of the two related samples, we can use appropriately the McNemer test.\\nWe take the null hypothesis ( H0) that there has been no change in people’s attitude before and\\nafter the experiment. This, in other words, means that the probability of favourable response before\\nand unfavourable response after is equal to the probability of unfavourable response before andfavourable response after i.e.,\\nH\\n0: P(A) = P (D)\\nWe can test this hypothesis against the alternative hypothesis ( Ha) viz.,\\nHa: P (A) ≠ P (D)Testing of Hypotheses-II 291\\nThe test statistic, utilising the McNemer test, can be worked out as under:\\nχ2221 200 100 1\\n200 100=−−\\n+=−−\\n+AD\\nADch\\nbgch\\nbg\\n        =×=99 99\\n3003267.\\nDegree of freedom = 1.\\nFrom the Chi-square distribution table, the value of χ2 for 1 degree of freedom at 5% level of\\nsignificance is 3.84. The calculated value of χ2 is 32.67 which is greater than the table value,\\nindicating that we should reject the null hypothesis. As such we conclude that the change in people’s\\nattitude before and after the experiment is significant.\\n4. Wilcoxon Matched-pairs Test (or Signed Rank Test )\\nIn various research situations in the context of two-related samples (i.e., case of matched paires\\nsuch as a study where husband and wife are matched or when we compare the output of two similarmachines or where some subjects are studied in context of before-after experiment) when we candetermine both direction and magnitude of difference between matched values, we can use animportant non-parametric test viz., Wilcoxon matched-paires test. While applying this test, we firstfind the differences ( d\\ni) between each pair of values and assign rank to the differences from the\\nsmallest to the largest without regard to sign. The actual signs of each difference are then put tocorresponding ranks and the test statistic T is calculated which happens to be the smaller of the two\\nsums viz., the sum of the negative ranks and the sum of the positive ranks.\\nWhile using this test, we may come across two types of tie situations. One situation arises when\\nthe two values of some matched pair(s) are equal i.e., the difference between values is zero in whichcase we drop out the pair(s) from our calculations. The other situation arises when two or more pairshave the same difference value in which case we assign ranks to such pairs by averaging their rankpositions. For instance, if two pairs have rank score of 5, we assign the rank of 5.5 i.e., (5 + 6)/2 = 5.5to each pair and rank the next largest difference as 7.\\nWhen the given number of matched pairs after considering the number of dropped out pair(s), if\\nany, as stated above is equal to or less than 25, we use the table of critical values of T (Table No. 7\\ngiven in appendix at the end of the book) for the purpose of accepting or rejecting the null hypothesisof no difference between the values of the given pairs of observations at a desired level of significance.For this test, the calculated value of T must be equal to or smaller than the table value in order to\\nreject the null hypothesis. In case the number exceeds 25, the sampling distribution of T is taken as\\napproximately normal with mean U\\nT = n(n + 1)/4 and standard deviation\\nσTnn n=+ + 12 1 2 4 bg b g /,\\nwhere n = [(number of given matched pairs) – (number of dropped out pairs, if any)] and in such\\nsituation the test statistic z is worked out as under:292 Research Methodology\\nzTUT\\nT=−\\nσ\\nWe may now explain the use of this test by an example.\\nIllustration 4\\nAn experiment is conducted to judge the effect of brand name on quality perception. 16 subjects are\\nrecruited for the purpose and are asked to taste and compare two samples of product on a set ofscale items judged to be ordinal. The following data are obtained:\\nPair Brand A Brand B\\n17 35 1\\n24 34 1\\n34 74 3\\n45 34 1\\n55 84 7\\n64 73 2\\n75 22 4\\n85 85 8\\n93 84 3\\n10 61 53\\n11 56 52\\n12 56 57\\n13 34 44\\n14 55 57\\n15 65 40\\n16 75 68\\nTest the hypothesis, using Wilcoxon matched-pairs test, that there is no difference between the\\nperceived quality of the two samples. Use 5% level of significance.\\nSolution: Let us first write the null and alternative hypotheses as under:\\nH0: There is no difference between the perceived quality of two samples.\\nHa: There is difference between the perceived quality of the two samples.\\nUsing Wilcoxon matched-pairs test, we work out the value of the test statistic T as under:\\nTable 12.4\\nPair Brand A Brand B Difference Rank of Rank with signs\\ndi|di| +–\\n17 3 5 12 2 1 31 3…\\n2 43 41 2 2.5 2.5 …\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Testing of Hypotheses-II 293\\nPair Brand A Brand B Difference Rank of Rank with signs\\ndi|di| +–\\n3 47 43 4 4.5 4.5 …\\n45 3 4 11 2 1 11 1…\\n55 8 4 71 1 1 01 0…64 7 3 21 5 1 21 2…\\n75 2 2 42 8 1 51 5…\\n85 8 5 80–––\\n93 8 4 3 – 5 6… – 6\\n10 61 53 8 8 8 …\\n11 56 52 4 4.5 4.5 …\\n12 56 57 –1 1 … –1\\n13 34 44 –10 9 … –9\\n14 55 57 –2 2.5 … –2.5\\n15 65 40 25 14 14 …\\n16 75 68 7 7 7 …\\nTOTAL 101.5 –18.5\\nHence, T = 18.5\\nWe drop out pair 8 as ‘ d’ value for this is zero and as such our n = (16 – 1) = 15 in the given\\nproblem.\\nThe table value of T at five percent level of significance when n = 15 is 25 (using a two-tailed\\ntest because our alternative hypothesis is that there is difference between the perceived quality of\\nthe two samples). The calculated value of T is 18.5 which is less than the table value of 25. As such\\nwe reject the null hypothesis and conclude that there is difference between the perceived quality ofthe two samples.\\n5. Rank Sum Tests\\nRank sum tests are a whole family of test, but we shall describe only two such tests commonly usedviz., the U test and the H test. U test is popularly known as Wilcoxon-Mann-Whitney test, whereas\\nH test is also known as Kruskal-Wallis test. A brief description of the said two tests is given below:\\n(a) Wilcoxon-Mann-Whitney test (or U-test): This is a very popular test amongst the rank sum\\ntests. This test is used to determine whether two independent samples have been drawn from thesame population. It uses more information than the sign test or the Fisher-Irwin test. This test appliesunder very general conditions and requires only that the populations sampled are continuous. However,in practice even the violation of this assumption does not affect the results very much.\\nTo perform this test, we first of all rank the data jointly, taking them as belonging to a single\\nsample in either an increasing or decreasing order of magnitude. We usually adopt low to highranking process which means we assign rank 1 to an item with lowest value, rank 2 to the next higheritem and so on. In case there are ties, then we would assign each of the tied observation the mean ofthe ranks which they jointly occupy. For example, if sixth, seventh and eighth values are identical, wewould assign each the rank (6 + 7 + 8)/3 = 7. After this we find the sum of the ranks assigned to the294 Research Methodology\\nvalues of the first sample (and call it R1) and also the sum of the ranks assigned to the values of the\\nsecond sample (and call it R2). Then we work out the test statistic i.e., U, which is a measurement of\\nthe difference between the ranked observations of the two samples as under:\\nUn nnnR =⋅++−1211\\n11\\n2bg\\nwhere n1, and n2 are the sample sizes and R1 is the sum of ranks assigned to the values of the first\\nsample. (In practice, whichever rank sum can be conveniently obtained can be taken as R1, since it\\nis immaterial which sample is called the first sample.)\\nIn applying U -test we take the null hypothesis that the two samples come from identical populations.\\nIf this hypothesis is true, it seems reasonable to suppose that the means of the ranks assigned to the\\nvalues of the two samples should be more or less the same. Under the alternative hypothesis, themeans of the two populations are not equal and if this is so, then most of the smaller ranks will go tothe values of one sample while most of the higher ranks will go to those of the other sample.\\nIf the null hypothesis that the n\\n1 + n2 observations came from identical populations is true, the\\nsaid ‘U’ statistic has a sampling distribution with\\nMean =µUnn=⋅12\\n2\\nand Standard deviation (or the standard error)\\n     =σUnn n n=++12 1 2 1\\n12bg\\nIf n1 and n2 are sufficiently large (i.e., both greater than 8), the sampling distribution of U  can be\\napproximated closely with normal distribution and the limits of the acceptance region can be determinedin the usual way at a given level of significance. But if either n\\n1 or n2 is so small that the normal curve\\napproximation to the sampling distribution of U cannot be used, then exact tests may be based on\\nspecial tables such as one given in the, appendix,* showing selected values of Wilcoxon’s (unpaired)\\ndistribution. We now can take an example to explain the operation of U test.\\nIllustration 5\\nThe values in one sample are 53, 38, 69, 57, 46, 39, 73, 48, 73, 74, 60 and 78. In another sample they\\nare 44, 40, 61, 52, 32, 44, 70, 41, 67, 72, 53 and 72. Test at the 10% level the hypothesis that theycome from populations with the same mean. Apply U -test.\\nSolution:  First of all we assign ranks to all observations, adopting low to high ranking process on the\\npresumption that all given items belong to a single sample. By doing so we get the following:\\n* Table No. 6 given in appendix at the end of the book.Testing of Hypotheses-II 295\\nTable 12.5\\nSize of sample item in Rank Name of related sample:\\nascending order [A for sample one and\\nB for sample two]\\n32 1 B\\n38 2 A\\n39 3 A\\n40 4 B\\n41 5 B\\n44 6.5 B\\n44 6.5 B\\n46 8 A\\n48 9 A\\n52 10 B\\n53 11.5 B\\n53 11.5 A\\n57 13 A\\n60 14 A\\n61 15 B\\n67 16 B\\n69 17 A\\n70 18 B\\n72 19.5 B\\n72 19.5 B\\n73 21.5 A\\n73 21.5 A\\n74 23 A\\n78 24 A\\nFrom the above we find that the sum of the ranks assigned to sample one items or R1 = 2 + 3 + 8 +\\n9 + 11.5 + 13 + 14 + 17 + 21.5 + 21.5 + 23 + 24 = 167.5 and similarly we find that the sum of ranks\\nassigned to sample two items or R2 = 1 + 4 + 5 + 6.5 + 6.5 + 10 + 11.5 + 15 + 16 + 18 + 19.5 + 19.5\\n= 132.5 and we have n1 = 12 and n2 = 12\\nHence, test statistic UnnnnR =1211\\n11\\n2⋅++−bg\\n    =1 2 1 212 12 1\\n21675 bg bgbg++−.\\n     = 144 + 78 – 167.5 = 54.5\\nSince in the given problem n1 and n2 both are greater than 8, so the sampling distribution of U\\napproximates closely with normal curve. Keeping this in view, we work out the mean and standarddeviation taking the null hypothesis that the two samples come from identical populations as under:296 Research Methodology\\nµUnn=12\\n212 12\\n272×==bg bg\\n         σUnn n n=++=++12 1 2 1\\n1212 12 12 12 1\\n12b g bg bg b g\\n       = 17.32\\nAs the alternative hypothesis is that the means of the two populations are not equal, a two-tailed\\ntest is appropriate. Accordingly the limits of acceptance region, keeping in view 10% level of\\nsignificance as given, can be worked out as under:\\nFig. 12.3\\nAs the z value for 0.45 of the area under the normal curve is 1.64, we have the following limits\\nof acceptance region:\\nUpper limit =  µσUU+= + =164 72 164 1732 10040.. . . bg\\nLower limit =  µσUU−= − =164 72 164 1732 4360.. . . bg\\nAs the observed value of U is 54.5 which is in the acceptance region, we accept the null hypothesis\\nand conclude that the two samples come from identical populations (or that the two populations havethe same mean) at 10% level.\\nWe can as well calculate the U statistic as under using R\\n2 value:\\nUnnnnR =1222\\n21\\n2⋅++−bg\\n           =1 2 1 212 12 1\\n21325 bg bgbg++−.\\n= 144 + 78 – 132.5 = 89.5\\nThe value of U also lies in the acceptance region and as such our conclusion remains the same, even\\nif we adopt this alternative way of finding U.\\nWe can take one more example concerning U test wherein n1 and n2 are both less than 8 and as\\nsuch we see the use of table given in the appendix concerning values of Wilcoxon’s distribution\\n(unpaired distribution).0.45 of area 0.45 of area0.05 of area 0.05 of areaLimit\\nLimit\\n43.6 100.4 /c109u/c6172/c109/c115uu/c43164. /c109/c115uu/c45164.\\n(Shaded portion indicates\\nrejection regions)Testing of Hypotheses-II 297\\nIllustration 6\\nTwo samples with values 90, 94, 36 and 44 in one case and the other with values 53, 39, 6, 24, and 33\\nare given. Test applying Wilcoxon test whether the two samples come from populations with thesame mean at 10% level against the alternative hypothesis that these samples come from populationswith different means.\\nSolution:  Let us first assign ranks as stated earlier and we get:\\nTable 12.6\\nSize of sample item Rank Name of related sample\\nin ascending order (Sample one as A\\nSample two as B)\\n61 B\\n24 2 B\\n33 3 B\\n36 4 A\\n39 5 B\\n44 6 A\\n53 7 B\\n90 8 A\\n94 9 A\\nSum of ranks assigned to items of sample one = 4 + 6 + 8 + 9 = 27\\nNo. of items in this sample = 4\\nSum of ranks assigned to items of sample two = 1 + 2 + 3 + 5 + 7 = 18\\nNo. of items in this sample = 5\\nAs the number of items in the two samples is less than 8, we cannot use the normal curve\\napproximation technique as stated above and shall use the table giving values of Wilcoxon’s distribution.\\nTo use this table, we denote ‘Ws’ as the smaller of the two sums and ‘ Wl’ the larger. Also, let ‘ s’ be\\nthe number of items in the sample with smaller sum and let ‘ l’ be the number of items in the sample\\nwith the larger sum. Taking these notations we have for our question the following values:\\nWs = 18; s = 5; Wl = 27; l = 4\\nThe value of Ws is 18 for sample two which has five items and as such s = 5. We now find the\\ndifference between Ws and the minimum value it might have taken, given the value of s. The minimum\\nvalue that Ws could have taken, given that s = 5, is the sum of ranks 1 through 5 and this comes as\\nequal to 1 + 2 + 3 + 4 + 5 = 15. Thus, ( Ws – Minimum Ws) = 18 – 15 = 3. To determine the probability\\nthat a result as extreme as this or more so would occur, we find the cell of the table which is in thecolumn headed by the number 3 and in the row for s = 5 and l = 4 (the specified values of l are given\\nin the second column of the table). The entry in this cell is 0.056 which is the required probability ofgetting a value as small as or smaller than 3 and now we should compare it with the significance levelof 10%. Since the alternative hypothesis is that the two samples come from populations with differentmeans, a two-tailed test is appropriate and accordingly 10% significance level will mean 5% in theleft tail and 5% in the right tail. In other words, we should compare the calculated probability with the298 Research Methodology\\nprobability of 0.05, given the null hypothesis and the significance level. If the calculated probability\\nhappens to be greater than 0.05 (which actually is so in the given case as 0.056 > 0.05), then weshould accept the null hypothesis. Hence, in the given problem, we must conclude that the twosamples come from populations with the same mean.\\n(The same result we can get by using the value of W\\nl. The only difference is that the value\\nmaximum Wl – Wl is required. Since for this problem, the maximum value of Wl (given s = 5 and\\nl= 4) is the sum of 6 through 9 i.e., 6 + 7 + 8 + 9 = 30, we have Max. Wl – Wl = 30 – 27 = 3 which\\nis the same value that we worked out earlier as Ws, – Minimum Ws. All other things then remain the\\nsame as we have stated above).\\n(b) The Kruskal-Wallis test (or H test ):This test is conducted in a way similar to the U test\\ndescribed above. This test is used to test the null hypothesis that ‘ k’ independent random samples\\ncome from identical universes against the alternative hypothesis that the means of these universes\\nare not equal. This test is analogous to the one-way analysis of variance, but unlike the latter it doesnot require the assumption that the samples come from approximately normal populations or theuniverses having the same standard deviation.\\nIn this test, like the U test, the data are ranked jointly from low to high or high to low as if they\\nconstituted a single sample. The test statistic is H for this test which is worked out as under:\\nHnnR\\nnni\\niik\\n=+−+\\n=∑12\\n1312\\n1 bgbg\\nwhere n = n1 + n2 + ... + nk and Ri being the sum of the ranks assigned to ni observations in the ith\\nsample.\\nIf the null hypothesis is true that there is no difference between the sample means and each\\nsample has at least five items*, then the sampling distribution of H  can be approximated with a chi-\\nsquare distribution with ( k – 1) degrees of freedom. As such we can reject the null hypothesis at a\\ngiven level of significance if H value calculated, as stated above, exceeds the concerned table value\\nof chi-square. Let us take an example to explain the operation of this test:\\nIllustration 7\\nUse the Kruskal-Wallis test at 5% level of significance to test the null hypothesis that a professional\\nbowler performs equally well with the four bowling balls, given the following results:\\nBowling Results in Five Games\\nWith Ball No. A 271 282 257 248 262\\nWith Ball No. B 252 275 302 268 276\\nWith Ball No. C 260 255 239 246 266\\nWith Ball No. D 279 242 297 270 258\\n* If any of the given samples has less than five items then chi-square distribution approximation can not be used and the\\nexact tests may be based on table meant for it given in the book “Non-parametric statistics for the behavioural sciences” byS. Siegel.Testing of Hypotheses-II 299\\nSolution:  To apply the H test or the Kruskal-Wallis test to this problem, we begin by ranking all the\\ngiven figures from the highest to the lowest, indicating besides each the name of the ball as under:\\nTable 12.7\\nBowling results Rank Name of the\\nball associated\\n302 1 B\\n297 2 D\\n282 3 A\\n279 4 D\\n276 5 B\\n275 6 B\\n271 7 A\\n270 8 D\\n268 9 B\\n266 10 C\\n262 11 A\\n260 12 C\\n258 13 D\\n257 14 A\\n255 15 C\\n252 16 B\\n248 17 A\\n246 18 C\\n242 19 D\\n239 20 C\\nFor finding the values of Ri, we arrange the above table as under:\\nTable 12.7 (a) :Bowling Results with Different Balls and Corresponding Rank\\nBall A Rank Ball B Rank Ball C Rank Ball D Rank\\n271 7 252 16 260 12 279 4\\n282 3 275 6 255 15 242 19\\n257 14 302 1 239 20 297 2\\n248 17 268 9 246 18 270 8262 11 276 5 266 10 158 13\\nn\\n1 = 5R1 = 52 n2 = 5 R2 = 37 n3 = 5 R3 = 75 n4 = 5 R4 = 46\\nNow we calculate H statistic as under:300 Research Methodology\\nHnnR\\nnni\\niik\\n=+−+\\n=∑12\\n1312\\n1 bgbg\\n     =++++RS|\\nT|UV|\\nW|−+12\\n20 20 152\\n537\\n575\\n546\\n532 0 12222\\nbgbg\\n    = (0.02857) (2362.8) – 63 = 67.51 – 63 = 4.51\\nAs the four samples have five items* each, the sampling distribution of H approximates closely\\nwith χ2 distribution. Now taking the null hypothesis that the bowler performs equally well with the\\nfour balls, we have the value of χ2 = 7.815 for ( k – 1) or 4 – 1 = 3 degrees of freedom at 5% level\\nof significance. Since the calculated value of H is only 4.51 and does not exceed the χ2 value of\\n7.815, so we accept the null hypothesis and conclude that bowler performs equally well with the four\\nbowling balls.\\n6. One Sample Runs Test\\nOne sample runs test is a test used to judge the randomness of a sample on the basis of the order in\\nwhich the observations are taken. There are many applications in which it is difficult to decidewhether the sample used is a random one or not. This is particularly true when we have little or nocontrol over the selection of the data. For instance, if we want to predict a retail store’s sales volumefor a given month, we have no choice but to use past sales data and perhaps prevailing conditions ingeneral. None of this information constitutes a random sample in the strict sense. To allow us to testsamples for the randomness of their order, statisticians have developed the theory of runs. A run is asuccession of identical letters (or other kinds of symbols) which is followed and preceded by differentletters or no letters at all. To illustrate, we take the following arrangement of healthy, H, and diseased,\\nD, mango trees that were planted many years ago along a certain road:\\nHH DD HHHHH DDD HHHH DDDDD HHHHHHHHH\\n12 3 4 5 7 st nd rd th th 6th th\\nUsing underlines to combine the letters which constitute the runs, we find that first there is a run oftwo H’s, then a run of two D’s, then a run of five H’s, then a run of three D’s, then a run of four H’s,\\nthen a run of five D’s and finally a run of nine H’s. In this way there are 7 runs in all or r = 7. If there\\nare too few runs, we might suspect a definite grouping or a trend; if there are too many runs, wemight suspect some sort of repeated alternating patterns. In the given case there seems some groupingi.e., the diseased trees seem to come in groups. Through one sample runs test which is based on theidea that too few or too many runs show that the items were not chosen randomly, we can saywhether the apparently seen grouping is significant or whether it can be attributed to chance. Weshall use the following symbols for a test of runs:\\nn\\n1 = number of occurrences of type 1 (say H in the given case)\\nn2 = number of occurrences of type 2 (say D in the given case)\\n* For the application of H  test, it is not necessary that all samples should have equal number of items.Testing of Hypotheses-II 301\\nr = number of runs.\\nIn the given case the values of n1, n2 and r would be as follows:\\nn1 = 20; n2 = 10; r = 7\\nThe sampling distribution of ‘ r’ statistic, the number of runs, is to be used and this distribution has\\nits mean\\nµrnn\\nnn=++2112\\n12\\nand the standard deviation σrnnnn n n\\nnn nn=−−\\n++ −22\\n11212 1 2\\n122\\n12 bg b g\\nIn the given case, we work out the values of µr and σr as follows:\\nµr=++=22 01 0\\n20 1011 4 3 3bg b g b g.\\nand          σr=××−−\\n++ −=2 20 10 2 20 10 20 10\\n20 10 20 10 12382bg b g b g b g\\nbg b g.\\nFor testing the null hypothesis concerning the randomness of the planted trees, we should have been\\ngiven the level of significance. Suppose it is 1% or 0.01. Since too many or too few runs wouldindicate that the process by which the trees were planted was not random, a two-tailed test isappropriate which can be indicated as follows on the assumption\\n* that the sampling distribution of r\\ncan be closely approximated by the normal distribution.\\nFig. 12.4\\n* This assumption can be applied when n1 and n2 are sufficiently large i.e., they should not be less than 10. But in case\\nn1 or n2 is so small that the normal curve approximation assumption cannot be used, then exact tests may be based on\\nspecial tables which can be seen in the book Non-parametric Statistics for the Behavioural Science by S. Siegel.0.495 of\\narea0.495 of\\narea0.005 of area 0.005 of areaLimit\\nLimit\\n8.19 20.47 /c109r/c6114 33.()/c109/c115rr/c4325 8. ()/c109/c115rr/c4525 8.\\n(Shaded area shows the\\nrejection regions)302 Research Methodology\\nBy using the table of area under normal curve, we find the appropriate z value for 0.495 of the\\narea under the curve and it is 2.58. Using this we now calculate the limits of the acceptance region:\\nUpper limit = µr + (2.58) (2.38) = 14.33 + 6.14 = 20.47 and\\nLower limit = µr – (2.58) (2.38) = 14.33 – 6.14 = 8.19\\nWe now find that the observed number of runs (i.e., r = 7) lies outside the acceptance region i.e.,\\nin the rejection region. Therefore, we cannot accept the null hypothesis of randomness at the given\\nlevel of significance viz., α = 0.01. As such we conclude that there is a strong indication that the\\ndiseased trees come in non-random grouping.\\nOne sample runs test, as explained above, is not limited only to test the randomness of series of\\nattributes. Even a sample consisting of numerical values can be treated similarly by using the letterssay ‘a’ and ‘b’ to denote respectively the values falling above and below the median of the sample.\\nNumbers equal to the median are omitted. The resulting series of a’s and b’s (representing the data\\nin their original order) can be tested for randomness on the basis of the total number of runs aboveand below the median, as per the procedure explained above.\\n(The method of runs above and below the median is helpful in testing for trends or cyclical\\npatterns concerning economic data. In case of an upward trend, there will be first mostly b’s and\\nlater mostly a’s, but in case of a downward trend, there will be first mostly a’s and later mostly b’s.\\nIn case of a cyclical pattern, there will be a systematic alternating of a’s and b’s and probably many\\nruns.)\\n7. Spearman ’s Rank Correlation\\nWhen the data are not available to use in numerical form for doing correlation analysis but when theinformation is sufficient to rank the data as first, second, third, and so forth, we quite often use therank correlation method and work out the coefficient of rank correlation. In fact, the rank correlationcoefficient is a measure of correlation that exists between the two sets of ranks. In other words, it isa measure of association that is based on the ranks of the observations and not on the numericalvalues of the data. It was developed by famous statistician Charles Spearman in the early 1900s andas such it is also known as Spearman’s rank correlation coefficient.\\nFor calculating rank correlation coefficient, first of all the actual observations be replaced by\\ntheir ranks, giving rank 1 to the highest value, rank 2 to the next highest value and following this veryorder ranks are assigned for all values. If two or more values happen to be equal, then the averageof the ranks which should have been assigned to such values had they been all different, is taken andthe same rank (equal to the said average) is given to concerning values. The second step is to recordthe difference between ranks (or ‘ d’) for each pair of observations, then square these differences to\\nobtain a total of such differences which can symbolically be stated as \\n∑di2. Finally, Spearman’s rank\\ncorrelation coefficient, r*, is worked out as under:\\nSpearman’s ‘ ’ = 1 – rd\\nnni6\\n12\\n2∑\\n−RS|\\nT|UV|\\nW| ej\\n*Some authors use the symbol Rho ( ρ) for this coefficient. Rho is to be used when the sample size does not exceed 30.Testing of Hypotheses-II 303\\nwhere n = number of paired observations.\\nThe value of Spearman’s rank correlation coefficient will always vary between ±1, +1, indicating\\na perfect positive correlation and –1 indicating perfect negative correlation between two variables.\\nAll other values of correlation coefficient will show different degrees of correlation.\\nSuppose we get r = 0.756 which suggests a substantial positive relationship between the concerning\\ntwo variables. But how we should test this value of 0.756? The testing device depends upon thevalue of n. For small values of n (i.e., n less than 30), the distribution of r is not normal and as such\\nwe use the table showing the values for Spearman’s Rank correlation (Table No. 5 given in Appendixat the end of the book) to determine the acceptance and rejection regions. Suppose we get r = 0.756\\nfor a problem where n = 15 and want to test at 5% level of significance the null hypothesis that there\\nis zero correlation in the concerning ranked data. In this case our problem is reduced to test the nullhypothesis that there is no correlation i.e., u\\nr =  0 against the alternative hypothesis that there is a\\ncorrelation i.e., µr≠0 at 5% level. In this case a two-tailed test is appropriate and we look in the\\nsaid table in row for n = 15 and the column for a significance level of 0.05 and find that the critical\\nvalues for r are ±05179. i.e., the upper limit of the acceptance region is 0.5179 and the lower limit\\nof the acceptance region is –0.5179. And since our calculated r = 0.756 is outside the limits of the\\nacceptance region, we reject the null hypothesis and accept the alternative hypothesis that there is acorrelation in the ranked data.\\nIn case the sample consists of more than 30 items, then the sampling distribution of r is\\napproximately normal with a mean of zero and a standard deviation of \\n11/n− and thus, the\\nstandard error of r is:\\n σrn=\\n−1\\n1\\nWe can use the table of area under normal curve to find the appropriate z values for testing\\nhypotheses about the population rank correlation and draw inference as usual. We can illustrate it, byan example.\\nIllustration 8\\nPersonnel manager of a certain company wants to hire 30 additional programmers for his corporation.\\nIn the past, hiring decisions had been made on the basis of interview and also on the basis of anaptitude test. The agency doing aptitude test had charged Rs. 100 for each test, but now wantsRs.200 for a test. Performance on the test has been a good predictor of a programmer’s ability andRs. 100 for a test was a reasonable price. But now the personnel manager is not sure that the testresults are worth Rs. 200. However, he has kept over the past few years records of the scoresassigned to applicants for programming positions on the basis of interviews taken by him. If hebecomes confident (using 0.01 level of significance) that the rank correlation between his interviewscores and the applicants’ scores on aptitude test is positive, then he will feel justified in discontinuingthe aptitude test in view of the increased cost of the test. What decision should he take on the basisof the following sample data concerning 35 applicants?304 Research Methodology\\nSample Data Concerning 35 Applicants\\nSerial Number Interview score Aptitude test score\\n1 81 113\\n28 8 8 8\\n35 5 7 6\\n4 83 129\\n57 8 9 9\\n6 93 142\\n76 5 9 3\\n8 87 136\\n99 5 8 2\\n10 76 91\\n11 60 83\\n12 85 96\\n13 93 126\\n14 66 108\\n15 90 95\\n16 69 65\\n17 87 96\\n18 68 101\\n19 81 111\\n20 84 121\\n21 82 83\\n22 90 79\\n23 63 71\\n24 78 109\\n25 73 68\\n26 79 121\\n27 72 109\\n28 95 121\\n29 81 140\\n30 87 132\\n31 93 135\\n32 85 143\\n33 91 118\\n34 94 147\\n35 94 138\\nSolution:  To solve this problem we should first work out the value of Spearman’s r as under:Testing of Hypotheses-II 305\\nTable 12.8: Calculation of Spearman\\x92s\\nS. No. Interview Aptitude Rank Rank Rank Differences squared\\nscore X test score X Y Difference ‘di’ di2\\nY (Rank X) –\\n(Rank Y)\\n1 81 113 21 15 6 36\\n2 88 88 11 27 –16 256\\n35 5 7 6 3 5 3 2 3 9\\n4 83 129 18 9 9 81\\n5 78 99 24.5 21 3.5 12.25\\n6 93 142 6 3 3 9\\n76 5 9 3 3 2 2 5 7 4 9\\n8 87 136 13 6 7 49\\n9 95 82 1.5 30 –28.5 812.25\\n10 76 91 26 26 0 0\\n11 60 83 34 28.5 5.5 30.25\\n12 85 96 15.5 22.5 –7 49\\n13 93 126 6 10 –4 16\\n14 66 108 31 18.5 12.5 156.25\\n15 90 95 9.5 24 –14.5 210.25\\n16 69 65 29 35 –6 36\\n17 87 96 13 22.5 –9.5 90.25\\n18 68 101 30 20 10 100\\n19 81 111 21 16 5 25\\n20 84 121 17 12 5 25\\n21 82 83 19 28.5 –9.5 90.25\\n22 90 79 9.5 31 –21.5 462.25\\n23 63 71 33 33 0 0\\n24 78 108 24.5 18.5 6 36\\n25 73 68 27 34 –7 49\\n26 79 121 23 12 11 121\\n27 72 109 28 17 11 121\\n28 95 121 1.5 12 –10.5 110.25\\n29 81 140 21 4 17 289\\n30 87 132 13 8 5 25\\n31 93 135 6 7 –1 1\\n32 85 143 15.5 2 13.5 182.25\\n33 91 118 8 14 –6 36\\n34 94 147 3.5 1 2.5 6.25\\n35 94 138 3.5 5 –1.5 225\\nn = 35 ∑=di23583306 Research Methodology\\n   Spearman’s ‘ ’ = 1 – rd\\nnni6\\n116 3583\\n35 35 12\\n22∑\\n−RS|\\nT|UV|\\nW|=−×\\n−RS|\\nT|UV|\\nW| ej e j\\n=− =121498\\n428400498.\\nSince n = 35 the sampling distribution of  r is approximately normal with a mean of zero and a\\nstandard deviation of 11/n−. Hence the standard error of r is\\nσrn=\\n−=\\n−=1\\n11\\n35 101715.\\nAs the personnel manager wishes to test his hypothesis at 0.01 level of significance, the problem\\ncan be stated:\\nNull hypothesis that there is no correlation between interview score and aptitude test score i.e.,\\nµr= 0.\\nAlternative hypothesis that there is positive correlation between interview score and aptitude\\ntest score i.e., µr > 0.\\nAs such one-tailed test is appropriate which can be indicated as under in the given case:\\nFig. 12.5\\nBy using the table of area under normal curve, we find the appropriate z value for 0.49 of the area\\nunder normal curve and it is 2.32. Using this we now work out the limit (on the upper side as\\nalternative hypothesis is of  > type) of the acceptance region as under:\\n     µr + (2.32) (0.1715)\\n= 0 + 0.3978\\n= 0.39780.49 of area0.01 of areaLimit\\n0.3978 /c109r/c610/c109/c115r r/c4323 2.()\\n(Shaded area shows\\nrejection region)Testing of Hypotheses-II 307\\nWe now find the observed r = 0.498 and as such it comes in the rejection region and, therefore,\\nwe reject the null hypothesis at 1% level and accept the alternative hypothesis. Hence we conclude\\nthat correlation between interview score and aptitude test score is positive. Accordingly personnelmanager should decide that the aptitude test be discontinued.\\n8. Kendall’s Coefficient of Concordance\\nKendall’s coefficient of concordance, represented by the symbol W, is an important non-parametric\\nmeasure of relationship. It is  used for determining the degree of association among several ( k) sets\\nof ranking of N objects or individuals. When there are only two sets of rankings of N objects, we\\ngenerally work out Spearman’s coefficient of correlation, but Kendall’s coefficient of concordance\\n(W) is considered an appropriate measure of studying the degree of association among three or more\\nsets of rankings. This descriptive measure of the agreement has special applications in providing astandard method of ordering objects according to consensus when we do not have an objective orderof the objects.\\nThe basis of Kendall’s coefficient of concordance is to imagine how the given data would look if\\nthere were no agreement among the several sets of rankings, and then to imagine how it would lookif there were perfect agreement among the several sets.  For instance, in case of, say, four interviewers\\ninterviewing, say, six job applicants and assigning rank order on suitability for employment, if there isobserved perfect agreement amongst the interviewers, then one applicant would be assigned rank 1by all the four and sum of his ranks would be 1 + 1 + 1 + 1 = 4. Another applicant would be assigned\\na rank 2 by all four and the sum of his ranks will be 2 + 2 + 2 + 2 = 8. The sum of ranks for the sixapplicants would be 4, 8, 12, 16, 20 and 24 (not necessarily in this very order). In general, whenperfect agreement exists among ranks assigned by k judges to N  objects, the rank sums are k , 2k,\\n3k, … Nk. The, total sum of N ranks for k judges is kN(N + 1)/2 and the mean rank sum is k(N + 1)/\\n2. The degree of agreement between judges reflects itself in the variation in the rank sums. When alljudges agree, this sum is a maximum. Disagreement between judges reflects itself in a reduction inthe variation of rank sums. For maximum disagreement, the rank sums will tend to be more or lessequal. This provides the basis for the definition of a coefficient of concordance. When perfectagreement exists between judges, W equals to 1. When maximum disagreement exists,  W equals to\\n0. It may be noted that W does not take negative values because of the fact that with more than two\\njudges complete disagreement cannot take place. Thus, coefficient of concordance ( W) is an index\\nof divergence of the actual agreement shown in the data from the perfect agreement.\\nThe procedure for computing and interpreting Kendall’s coefficient of concordance ( W) is as\\nfollows:\\n(a) All the objects, N, should be ranked by all k judges in the usual fashion and this information\\nmay be put in the form of a k by N matrix;\\n(b) For each object determine the sum of ranks ( R\\nj) assigned by all the k judges;\\n(c) Determine Rj and then obtain the value of s as under:\\nsR Rjj=∑ − di2\\n(d) Work out the value of W using the following formula:308 Research Methodology\\nWs\\nkN N=\\n−1\\n1223ej\\nwhere sR Rjj=∑ − di2\\n;\\n       k = no. of sets of rankings i.e., the number of judges;\\n      N = number of objects ranked;\\n1\\n1223kN N− ej = maximum possible sum of the squared deviations i.e., the sum s which\\n        would occur with perfect agreement among k rankings.\\nCase of Tied Ranks\\nWhere tied ranks occur, the average method of assigning ranks be adopted i.e., assign to each\\nmember the average rank which the tied observations occupy. If the ties are not numerous, we maycompute ‘ W’ as stated above without making any adjustment in the formula; but if the ties are\\nnumerous, a correction factor is calculated for each set of ranks. This correction fact is\\nTtt\\n=∑−3\\n12ej\\nwhere t = number of observations in a group tied for a given rank.\\nFor instance, if the ranks on X are 1, 2, 3.5, 5, 6, 3.5, 8, 10, 8, 8, we have two groups of ties, one\\nof two ranks and one of three ranks. The correction factor for this set of ranks for X would be\\nT=−+ −\\n=2233\\n122533ej e j.\\nA correction factor T is calculated for each of the k sets of ranks and these are added together\\nover the k sets to obtain ∑T. We then use the formula for finding the value of ‘ W’ as under:\\nWs\\nkN N k T=\\n−− ∑1\\n1223ej\\nThe application of the correction in this formula tends to increase the size of W, but the correction\\nfactor has a very limited effect unless the ties are quite numerous.\\n(e) The method for judging whether the calculated value of W is significantly different from\\nzero depends on the size of N as stated below:\\n(i) If N is 7 or smaller, Table No. 9 given in appendix at the end of the book gives critical\\nvalues of s associated with W’s significance at 5% and 1% levels. If an observed s is\\nequal to or greater than that shown in the table for a particular level of significance,then H\\n0 T (i.e., k sets of rankings are independent) may be rejected at that level of\\nsignificance.Testing of Hypotheses-II 309\\n(ii) If N is larger than 7, we may use χ2 value to be worked out as: χ2 = k(N – 1). W with\\nd.f. = (N – 1) for judging W’s significance at a given level in the usual way of using χ2\\nvalues.\\n(f) Significant value of W may be interpreted and understood as if the judges are applying\\nessentially the same standard in ranking the N objects under consideration, but this should\\nnever mean that the orderings observed are correct for the simple reason that all judges\\ncan agree in ordering objects because they all might employ ‘wrong’ criterion. Kendall,therefore, suggests that the best estimate of the ‘true’ rankings of N objects is provided,\\nwhen W is significant, by the order of the various sums of ranks, R\\nj. If one accepts the\\ncriterion which the various judges have agreed upon, then the best estimate of the ‘true’ranking is provided by the order of the sums of ranks. The best estimate is related to thelowest value observed amongst R\\nj.\\nThis can be illustrated with the help of an example.\\nIllustration 9\\nSeven individuals have been assigned ranks by four judges at a certain music competition as shown\\nin the following matrix:\\nIndividuals\\nABCDE F G\\nJudge 1 13257 4 6\\nJudge 2 24137 5 6\\nJudge 3 34127 6 5\\nJudge 4 12546 3 7\\nIs there significant agreement in ranking assigned by different judges? Test at 5% level. Also pointout the best estimate of the true rankings.\\nSolution:  As there are four sets of rankings, we can work out the coefficient of concordance ( W) for\\njudging significant agreement in ranking by different judges. For this purpose we first develop the\\ngiven matrix as under:\\nTable 12.9\\nK = 4 Individuals ∴ N = 7\\nABCD E F G\\nJudge 1 1 3 2 5 7 4 6\\nJudge 2 2 4 1 3 7 5 6\\nJudge 3 3 4 1 2 7 6 5\\nJudge 4 1 2 5 4 6 3 7\\nSum of ranks ( Rj) 71 3 91 42 71 8 2 4 ∑=Rj112\\nRRjj− di281 9 49 4 121 4 64 ∴ s = 332310 Research Methodology\\nQRR\\nNjj=∑\\n==112\\n716\\nQ   s = 332\\n∴Ws\\nkN N=\\n−=\\n−== =1\\n12332\\n1\\n1247 7332\\n16\\n12336332\\n4480741\\n23 23ej bg ej bg.\\nTo judge the significance of this W, we look into the Table No. 9 given in appendix for finding the\\nvalue of s at 5% level for k = 4 and N = 7. This value is 217.0 and thus for accepting the null\\nhypothesis ( H0) that k sets of rankings are independent) our calculated value of s should be less than\\n217. But the worked out value of s is 332 which is higher than the table value which fact shows that\\nW = 0.741 is significant. Hence, we reject the null hypothesis and infer that the judges are applying\\nessentially the same standard in ranking the N objects i.e., there is significant agreement in ranking\\nby different judges at 5% level in the given case. The lowest value observed amongst Rj is 7 and as\\nsuch the best estimate of true rankings is in the case of individual A i.e., all judges on the whole place\\nthe individual A as first in the said music competition.\\nIllustration 10\\nGiven is the following information:\\n k = 13\\nN = 20\\n    W = 0.577\\nDetermine the significance of W at 5% level.\\nSolution:  As N is larger than 7, we shall workout the value of χ2 for determining W’s significance\\nas under:\\nχ2 = k(N – 1)W with N – 1 degrees of freedom\\n∴ χ2 = 13(20 – 1) (0.577)\\nor χ2 = (247) (0.577) = 142.52\\nTable value of χ2 at 5% level for N – 1 = 20 – 1 = 19 d.f. is 30.144 but the calculated value of χ2\\nis 142.52 and this is considerably higher than the table value. This does not support the null hypothesis\\nof independence and as such we can infer that W is significant at 5% level.\\nRELATIONSHIP BETWEEN SPEARMAN\\x92S r \\x92s AND KENDALL\\x92S W\\nAs stated above, W is an appropriate measure of studying the degree of association among three or\\nmore sets of ranks, but we can as well determine the degree of association among k sets of rankings\\nby averaging the Spearman’s correlation coefficients ( r’s) between all possible pairs (i.e., kC2 or\\nk (k – 1)/2) of rankings keeping in view that W bears a linear relation to the average r’s taken overTesting of Hypotheses-II 311\\nall possible pairs. The relationship between the average of Spearman’s r’s and Kendall’s W can be\\nput in the following form:\\naverage of r’s = (kW – 1)/(k – 1)\\nBut the method of finding W using average of Spearman’s r’s between all possible pairs is quite\\ntedious, particularly when k happens to be a big figure and as such this method is rarely used in\\npractice for finding W.\\nIllustration 11\\nUsing data of illustration No. 9 above, find W using average of Spearman’s r’s.\\nSolution:  As k = 4 in the given question, the possible pairs are equal to k(k – 1)/2 = 4(4 – 1)/2 = 6 and\\nwe work out Spearman’s r for each of these pairs as shown in Table 12.10.\\nNow we can find W  using the following relationship formula between r’s average and W\\nAverage of r’s = (kW – 1)/(k – 1)\\nor 0.655 = (4 W – 1)/(4 – 1)\\nor     (0.655) (3) = 4 W – 1\\nor     W=+==0655 3 1\\n42965\\n40741. ..bg b g\\n[Note:This value of W  is exactly the same as we had worked out using the formula:\\nW = s/[(1/12) (k2) (N3 – N)]\\nCHARACTERISTICS OF DISTRIBUTION-FREE OR NON-PARAMETRIC TESTS\\nFrom what has been stated above in respect of important non-parametric tests, we can say that\\nthese tests share in main the following characteristics:\\n1. They do not suppose any particular distribution and the consequential assumptions.\\n2. They are rather quick and easy to use i.e., they do not require laborious computations since\\nin many cases the observations are replaced by their rank order and in many others we\\nsimply use signs.\\n3. They are often not as efficient or ‘sharp’ as tests of significance or the parametric tests.\\nAn interval estimate with 95% confidence may be twice as large with the use of non-parametric tests as with regular standard methods. The reason being that these tests do notuse all the available information but rather use groupings or rankings and the price we payis a loss in efficiency. In fact, when we use non-parametric tests, we make a trade-off: weloose sharpness in estimating intervals, but we gain the ability to use less information and tocalculate faster.\\n4. When our measurements are not as accurate as is necessary for standard tests of\\nsignificance, then non-parametric methods come to our rescue which can be used fairlysatisfactorily.\\n5. Parametric tests cannot apply to ordinal or nominal scale data but non-parametric tests do\\nnot suffer from any such limitation.\\n6. The parametric tests of difference like ‘ t’ or ‘F’ make assumption about the homogeneity\\nof the variances whereas this is not necessary for non-parametric tests of difference.312 Research MethodologyTable 12.10 :Difference between Ranks | di| Assigned by k = 4 Judges and the Square\\nValues of such Differences ( di2) for all Possible Pairs of Judges\\nIndividuals Pair 1 – 2 Pair 1 – 3 Pair 1 – 4 Pair 2 – 3 Pair 2 – 4 Pair 3 – 4\\n|d | d2|d | d2|d | d2|d |d2|d |d2|d |d2\\nA 1 1 2 4 0 0 1 1 11 24\\nB 1 1 1 1 1 1 0 0 24 24\\nC – 1 1 1 13 90 0 4 1 6 4 1 6\\nD – 2 4 3 91 11 1 1 1 2 4\\nE 0 0 0 0 1 1 0 011 11\\nF 1 1 2 4 1 1 1 124 39\\nG 0 0 1 1 1 1 1 111 24\\n∑=di28 ∑=di220 ∑=di214 ∑=di24 ∑=di228 ∑=di242\\nSpearman’s\\nCoefficient of\\nCorrelation\\nrd\\nNNi=−∑\\n−16\\n12\\n2e j   r12= 0.857 r13= 0.643 r14= 0.750 r23= 0.929 r24= 0.500 r34= 0.250\\nAverage of  Spearman’ s ’s=0.857+0.643+0.750+0.929+0.500+r0250\\n6.\\n             ==3929\\n60655..Testing of Hypotheses-II 313\\nCONCLUSION\\nThere are many situations in which the various assumptions required for standard tests of significance\\n(such as that population is normal, samples are independent, standard deviation is known, etc.) cannotbe met, then we can use non-parametric methods. Moreover, they are easier to explain and easier tounderstand. This is the reason why such tests have become popular. But one should not forget thefact that they are usually less efficient/powerful as they are based on no assumption (or virtually noassumption) and we all know that the less one assumes, the less one can infer from a set of data. Butthen the other side must also be kept in view that the more one assumes, the more one limits theapplicability of one’s methods.\\nQuestions\\n1.Give your understanding of non-parametric or distribution free methods explaining their importantcharacteristics.\\n2.Narrate the various advantages of using non-parametric tests. Also point out their limitations.\\n3.Briefly describe the different non-parametric tests explaining the significance of each such test.\\n4.On 15 occasions Mr. Kalicharan had to wait 4, 8, 2, 7, 7, 5, 8, 6, 1, 9, 6, 6, 5, 9 and 5 minutes for the bus hetakes to reach his office. Use the sign test at 5% level of significance to test the bus company’s claim thaton the average Mr. Kalicharan should not have to wait more than 5 minutes for a bus.\\n5.The following are the numbers of tickets issued by two policemen on 20 days:\\nBy first policeman: 7, 10, 14, 12, 6, 9, 11, 13, 7, 6, 10, 8, 14, 8, 12, 11, 9, 8, 10 and 15.\\nBy second policeman: 10, 13, 14, 11,  10, 7, 15, 11,  10, 9, 8, 12, 16, 10, 10, 14, 10, 12, 8 and 14.\\nUse the sign test at 1% level of significance to test the null hypothesis that on the average the two\\npolicemen issue equal number of tickets against the alternative hypothesis that on the average thesecond policeman issues more tickets than the first one.\\n6.   (a) Under what circumstances is the Fisher-Irwin test used? Explain. What is the main limitation of this\\ntest?\\n(b) A housing contractor plans to build a large number of brick homes in the coming year. Two brick\\nmanufacturing concerns have given him nearly identical rates for supplying the bricks. But beforeplacing his order, he wants to apply a test at 5% level of significance. The nature of the test is tosubject each sampled brick to a force of 900 pounds. The test is performed on 8 bricks randomlychosen from a day’s production of concern A and on the same number of bricks randomly chosen\\nfrom a day’s production of concern B. The results were as follows:\\nOf the 8 bricks from concern A, two were broken and of the 8 bricks from concern B, five were broken.\\nOn the basis of these test results, determine whether the contractor should place order with concernA or with concern B if he prefers significantly stronger bricks.\\n7.Suppose that the breaking test described in problem 6(b) above is modified so that each brick is subjectedto an increasing force until it breaks. The force applied at the time the brick breaks (calling it the breakingpoint) is recorded as under:\\nBreaking-points\\nBricks of concern A 880, 950, 990, 975 895, 1030, 1025, 1010\\nBricks of concern B 915, 790, 905, 900, 890, 825, 810 885.314 Research Methodology\\nOn the basis of the above test results, determine whether the contractor should place order for bricks\\nwith concern A or with concern B (You should answer using U test or Wilcoxon-Mann-Whitney test).\\n8.The following are the kilometres per gallon which a test driver got for ten tankfuls each of three kinds ofgasoline:\\nGasoline A30, 41, 34, 43, 33, 34, 38, 26, 29, 36\\nGasoline B39, 28, 39, 29, 30, 31, 44, 43, 40, 33\\nGasoline C29, 41, 26, 36, 41, 43, 38, 38, 35, 40.\\nUse the Kruskal-Wallis test at the level of significance \\nα= 0.05 to test the null hypothesis that there is\\nno difference in the average kilometre yield of the three types of gasoline.\\n9.   (a) The following are the number of students absent from a college on 24 consecutive days:\\n29, 25, 31, 28, 30, 28, 33, 31, 35, 29, 31, 33, 35, 28, 36, 30, 33, 26, 30, 28, 32, 31, 38 and 27. Test forrandomness at 1% level of significance.\\n(b) The following arrangement indicates whether 25 consecutive persons interviewed by a social scientist\\nare for (F) or against ( A) an increase in the number of crimes in a certain locality:\\nF, F, F, F, F, F, A, F, F, F, F, F, A, F, F, F, F, A, A, F, F, F, F, F, F.\\nTest whether this arrangement of A’s and F’s may be regarded as random at 5% as well as at 10% level\\nof significance.\\n10.Use a rank correlation at the 1% significance level and determine if there is significant positive correlationbetween the two samples on the basis of the following information:\\nBlender A1A2A3BC1C2D1D2EF1F2G1G2H\\nmodel\\nSample 1 1 11 12 2 13 10 3 4 14 5697 8\\nSample 2 4 12 11 2 13 10 1 3 14 8659 7\\n11.Three interviewers rank-order a group of 10 applicants as follows:\\nInterviewers Applicants\\nab c d e f g h i j\\nA 1 234567891 0\\nB 2 345176981 0\\nC 5 4123671 098\\nCompute the coefficient of concordance ( W) and verify the same by using the relationship between\\naverage of Spearman’s r’s and the coefficient of concordance. Test the significance of W at 5% and 1%\\nlevels of significance and state what should be inferred from the same. Also point out the best estimate\\nof true rankings.\\n12.Given are the values of Spearman’s r’s as under:\\nr\\nab = 0.607\\nrac = 0.429\\nrbc = 0.393\\nCalculate Kendall’s coefficient of concordance W from the above information and test its significance at\\n5% level.Multivariate Analysis Techniques 315\\n13\\nMultivariate Analysis Techniques\\nAll statistical techniques which simultaneously analyse more than two variables on a sample of\\nobservations can be categorized as multivariate techniques. We may as well use the term ‘multivariateanalysis’ which is a collection of methods for analyzing data in which a number of observations areavailable for each object. In the analysis of many problems, it is helpful to have a number of scoresfor each object. For instance, in the field of intelligence testing if we start with the theory that generalintelligence is reflected in a variety of specific performance measures, then to study intelligence inthe context of this theory one must administer many tests of mental skills, such as vocabulary, speedof recall, mental arithmetic, verbal analogies and so on. The score on each test is one variable, X\\ni, and\\nthere are several, k , of such scores for each object, represented as X1, X2 …Xk. Most of the research\\nstudies involve more than two variables in which situation analysis is desired of the associationbetween one (at times many) criterion variable and several independent variables, or we may berequired to study the association between variables having no dependency relationships. All suchanalyses are termed as multivariate analyses or multivariate techniques. In brief, techniques thattake account of the various relationships among variables are termed multivariate analyses ormultivariate techniques.\\nGROWTH OF MULTIVARIATE TECHNIQUES\\nOf late, multivariate techniques have emerged as a powerful tool to analyse data represented interms of many variables. The main reason being that a series of univariate analysis carried outseparately for each variable may, at times, lead to incorrect interpretation of the result. This is sobecause univariate analysis does not consider the correlation or inter-dependence among the variables.As a result, during the last fifty years, a number of statisticians have contributed to the developmentof several multivariate techniques. Today, these techniques are being applied in many fields such aseconomics, sociology, psychology, agriculture, anthropology, biology and medicine. These techniquesare used in analyzing social, psychological, medical and economic data, specially when the variablesconcerning research studies of these fields are supposed to be correlated with each other and whenrigorous probabilistic models cannot be appropriately used. Applications of multivariate techniques inpractice have been accelerated in modern times because of the advent of high speed electroniccomputers.316 Research Methodology\\nCHARACTERISTICS AND APPLICATIONS\\nMultivariate techniques are largely empirical and deal with the reality; they possess the ability to\\nanalyse complex data. Accordingly in most of the applied and behavioural researches, we generallyresort to multivariate analysis techniques for realistic results. Besides being a tool for analyzing thedata, multivariate techniques also help in various types of decision-making. For example, take thecase of college entrance examination wherein a number of tests are administered to candidates, andthe candidates scoring high total marks based on many subjects are admitted. This system, thoughapparently fair, may at times be biased in favour of some subjects with the larger standard deviations.Multivariate techniques may be appropriately used in such situations for developing norms as to whoshould be admitted in college. We may also cite an example from medical field. Many medicalexaminations such as blood pressure and cholesterol tests are administered to patients. Each of theresults of such examinations has significance of its own, but it is also important to consider relationshipsbetween different test results or results of the same tests at different occasions in order to drawproper diagnostic conclusions and to determine an appropriate therapy. Multivariate techniques canassist us in such a situation. In view of all this, we can state that “if the researcher is interested inmaking probability statements on the basis of sampled multiple measurements, then the best strategyof data analysis is to use some suitable multivariate statistical technique.”\\n1\\nThe basic objective underlying multivariate techniques is to represent a collection of massive\\ndata in a simplified way. In other words, multivariate techniques transform a mass of observationsinto a smaller number of composite scores in such a way that they may reflect as much information\\nas possible contained in the raw data obtained concerning a research study. Thus, the main contribution\\nof these techniques is in arranging a large amount of complex information involved in the real datainto a simplified visible form. Mathematically, multivariate techniques consist in “forming a linearcomposite vector in a vector subspace, which can be represented in terms of projection of a vectoronto certain specified subspaces.”\\n2\\nFor better appreciation and understanding of multivariate techniques, one must be familiar with\\nfundamental concepts of linear algebra, vector spaces, orthogonal and oblique projections and univariateanalysis. Even then before applying multivariate techniques for meaningful results, one must considerthe nature and structure of the data and the real aim of the analysis. We should also not forget thatmultivariate techniques do involve several complex mathematical computations and as such can beutilized largely with the availability of computer facility.\\nCLASSIFICATION OF MULTIVARIATE TECHNIQUES\\nToday, there exist a great variety of multivariate techniques which can be conveniently classified intotwo broad categories viz., dependence methods and interdependence methods. This sort ofclassification depends upon the question: Are some of the involved variables dependent upon others?If the answer is ‘yes’, we have dependence methods; but in case the answer is ‘no’, we haveinterdependence methods. Two more questions are relevant for understanding the nature of multivariatetechniques. Firstly, in case some variables are dependent, the question is how many variables aredependent? The other question is, whether the data are metric or non-metric? This means whether\\n1K. Takeuchi, H. Yanai and B.N. Mukherji, The Foundations of Multivariate Analysis,  p. 54.\\n2 Ibid., p. iii.Multivariate Analysis Techniques 317\\nthe data are quantitative, collected on interval or ratio scale, or whether the data are qualitative,\\ncollected on nominal or ordinal scale. The technique to be used for a given situation depends upon theanswers to all these very questions. Jadish N. Sheth in his article on “The multivariate revolution inmarketing research”\\n3 has given the flow chart that clearly exhibits the nature of some important\\nmultivariate techniques as shown in Fig. 13.1.\\nThus, we have two types of multivariate techniques: one type for data containing both dependent\\nand independent variables, and the other type for data containing several variables without dependencyrelationship. In the former category are included techniques like multiple regression analysis, multiplediscriminant analysis, multivariate analysis of variance and canonical analysis, whereas in the lattercategory we put techniques like factor analysis, cluster analysis, multidimensional scaling or MDS(both metric and non-metric) and the latent structure analysis.\\nFig. 13.1\\n3Journal of Marketing, American Marketing Association, Vol. 35, No. 1 (Jan. 1971),  pp. 13–19.All multivariate methods\\nAre some\\nvariables\\ndependent?\\nYes No\\nOne\\nYes YesNo NoYes NoSeveralInterdependence\\nmethodsDependence\\nmethods\\nHow many\\nvariables\\nare dependent?Are inputs metric?\\nIs it metric?Are they\\nmetric?Factor\\nanalysisClustre\\nanalysisMetric\\nMDS\\nMultiple\\nregressionMultiple\\ndiscriminant\\nanalysisMultivariate\\nanalysis of\\nvarianceNon-metric\\nMDSLatent\\nstructure\\nanalysis\\nCanonical analysis318 Research Methodology\\nVARIABLES IN MULTIVARIATE ANALYSIS\\nBefore we describe the various multivariate techniques, it seems appropriate to have a clear idea\\nabout the term, ‘variables’ used in the context of multivariate analysis. Many variables used inmultivariate analysis can be classified into different categories from several points of view. Importantones are as under:\\n(i) Explanatory variable and criterion variable: If X may be considered to be the cause of Y,\\nthen X is described as explanatory variable (also termed as causal or independent variable) and Y is\\ndescribed as criterion variable (also termed as resultant or dependent variable). In some cases both\\nexplanatory variable and criterion variable may consist of a set of many variables in which case set(X\\n1, X2, X3, …., Xp) may be called a set of explanatory variables and the set ( Y1, Y2, Y3, …., Yq) may\\nbe called a set of criterion variables if the variation of the former may be supposed to cause thevariation of the latter as a whole. In economics, the explanatory variables are called external orexogenous variables and the criterion variables are called endogenous variables. Some people usethe term external criterion for explanatory variable and the term internal criterion for criterion variable.\\n(ii) Observable variables and latent variables: Explanatory variables described above are supposed\\nto be observable directly in some situations, and if this is so, the same are termed as observable\\nvariables. However, there are some unobservable variables which may influence the criterion variables.We call such unobservable variables as latent variables.\\n(iii) Discrete variable and continuous variable: Discrete variable is that variable which when\\nmeasured may take only the integer value whereas continuous variable is one which, when measured,\\ncan assume any real value (even in decimal points).\\n(iv) Dummy variable (or Pseudo variable ):This term is being used in a technical sense and is\\nuseful in algebraic manipulations in context of multivariate analysis. We call X\\ni ( i = 1, …., m) a\\ndummy variable, if only one of Xi is 1 and the others are all zero.\\nIMPORTANT MULTIVARIATE TECHNIQUES\\nA brief description of the various multivariate techniques named above (with special emphasis on\\nfactor analysis) is as under:\\n(i) Multiple regression*: In multiple regression we form a linear composite of explanatory variables\\nin such way that it has maximum correlation with a criterion variable. This technique is appropriate\\nwhen the researcher has a single, metric criterion variable. Which is supposed to be a function ofother explanatory variables. The main objective in using this technique is to predict the variability thedependent variable based on its covariance with all the independent variables. One can predict thelevel of the dependent phenomenon through multiple regression analysis model, given the levels of\\nindependent variables. Given a dependent variable, the linear-multiple regression problem is to estimate\\nconstants B\\n1, B2, ... Bk and A such that the expression Y = B1X1 + B2X2 + ... + BkXk + A pare rovides\\na good estimate of an individual’s Y score based on his X scores.\\nIn practice, Y and the several X variables are converted to standard  scores; zy, zl, z2, ... zk; each\\nz has a mean of 0 and standard deviation of 1. Then the problem is to estimate constants, βi, such\\nthat′=++ +zzz zyk k ββ β11 22 ...\\n* See Chapter 7 also for other relevant information about multiple regression.Multivariate Analysis Techniques 319\\nwhere z\\'y stands for the predicted value of the standardized Y score, zy. The expression on the right\\nside of the above equation is the linear combination of explanatory variables. The constant A is\\neliminated in the process of converting X’s to z’s.  The least-squares-method is used, to estimate the\\nbeta weights in such a way that the sum of the squared prediction errors is kept as small as possible\\ni.e., the expression ∑− ′zzyydi2\\n is minimized.  The predictive adequacy of a set of beta weights is\\nindicated by the size of the correlation coefficient rzy z y⋅′ between the predicted ′zy scores and the\\nactual zy scores. This special correlation coefficient from Karl Pearson is termed the multiple correlation\\ncoefficient ( R). The squared multiple correlation, R2, represents the proportion of criterion ( zy) variance\\naccounted for by the explanatory variables, i.e., the proportion of total variance that is ‘Common\\nVariance’.\\nSometimes the researcher may use step-wise regression techniques to have a better idea of the\\nindependent contribution of each explanatory variable.  Under these techniques, the investigatoradds the independent contribution of each explanatory variable into the prediction equation one byone, computing betas and R\\n2 at each step.  Formal computerized techniques are available for the\\npurpose and the same can be used in the context of a particular problem being studied by theresearcher.\\n(ii) Multiple discriminant analysis: Through discriminant analysis technique, researcher may classify\\nindividuals or objects into one of two or more mutually exclusive and exhaustive groups on the basis\\nof a set of independent variables.  Discriminant analysis requires interval independent variables anda nominal dependent variable.  For example, suppose that brand preference (say brand x or y) is the\\ndependent variable of interest and its relationship to an individual’s income, age, education, etc. isbeing investigated, then we should use the technique of discriminant analysis.  Regression analysis insuch a situation is not suitable because the dependent variable is, not intervally scaled.  Thus discriminantanalysis is considered an appropriate technique when the single dependent variable happens to benon-metric and is to be classified into two or more groups, depending upon its relationship withseveral independent variables which all happen to be metric.  The objective in discriminant analysishappens to be to predict an object’s likelihood of belonging to a particular group based on severalindependent variables.  In case we classify the dependent variable in more than two groups, then weuse the name multiple discriminant analysis; but in case only two groups are to be formed, we simplyuse the term discriminant analysis.\\nWe may briefly refer to the technical aspects\\n* relating to discriminant analysis.\\n(i) There happens to be a simple scoring system that assigns a score to each individual or\\nobject.  This score is a weighted average of the individual’s numerical values of hisindependent variables.  On the basis of this score, the individual is assigned to the ‘mostlikely’ category.  For example, an individual is 20 years old, has an annual income ofRs12,000,and has 10 years of formal education.  Let b\\n1, b2, and b3 be the weights attached\\nto the independent variables of age, income and education respectively.  The individual’sscore (z), assuming linear score, would be:\\nz = b\\n1 (20) + b2 (12000) + b3 (10)\\n* Based on Robert Ferber, ed., Handbook of Marketing Research.320 Research Methodology\\nThis numerical value of z can then be transformed into the probability that the individual is\\nan early user, a late user or a non-user of the newly marketed consumer product (here we\\nare making three categories viz. early user, late user or a non-user).\\n(ii)The numerical values and signs of the b ’s indicate the importance of the independent\\nvariables in their ability to discriminate among the different classes of individuals.  Thus,through the discriminant analysis, the researcher can as well determine which independentvariables are most useful in predicting whether the respondent is to be put into one group orthe other. In other words, discriminant analysis reveals which specific variables in theprofile account for the largest proportion of inter-group differences.\\n(iii) In case only two groups of the individuals are to be formed on the basis of several\\nindependent variables, we can then have a model like this\\nz\\ni = b0 + b1X1i + b2X2i + ... + bnXni\\nwhere Xji = the ith individual’s value of the jth independent variable;\\n bj = the discriminant coefficient of the j th variable;\\n zi = the ith individual’s discriminant score;\\nzcrit. = the critical value for the discriminant score.\\nThe classification procedure in such a case would be\\nIf zi > zcrit., classify individual i as belonging to Group I\\nIf zi < zcrit, classify individual i as belonging to Group II.\\nWhen n (the number of independent variables) is equal to 2, we have a straight line\\nclassification boundary.  Every individual on one side of the line is classified as Group I and\\non the other side, every one is classified as belonging to Group II.  When n = 3, the\\nclassification boundary is a two-dimensional plane in 3 space and in general the classificationboundary is an n – 1 dimensional hyper-plane in n space.\\n(iv) In n-group discriminant analysis, a discriminant function is formed for each pair of groups.\\nIf there are 6 groups to be formed, we would have 6(6 – 1)/2 = 15 pairs of groups, andhence 15 discriminant functions.  The b values for each function tell which variables are\\nimportant for discriminating between particular pairs of groups. The z score for each\\ndiscriminant function tells in which of these two groups the individual is more likely tobelong.  Then use is made of the transitivity of the relation “more likely than”.  For example,if group II is more likely than group I and group III is more likely than group II, then groupIII is also more likely than group I. This way all necessary comparisons are made and theindividual is assigned to the most likely of all the groups.  Thus, the multiple-group discriminantanalysis is just like the two-group discriminant analysis for the multiple groups are simplyexamined two at a time.\\n(v) For judging the statistical significance between two groups, we work out the Mahalanobis\\nstatistic, D\\n2, which happens to be a generalized distance between two groups, where each\\ngroup is characterized by the same set of n variables and where it is assumed that variance-\\ncovariance structure is identical for both groups.  It is worked out thus:\\nDU U v U U2\\n121\\n12 =− −′ − bg bg\\nwhere U1 = the mean vector for group IMultivariate Analysis Techniques 321\\nU2 = the mean vector for group II\\nv = the common variance matrix\\nBy transformation procedure, this D2 statistic becomes an F statistic which can be used to see if the\\ntwo groups are statistically different from each other.\\nFrom all this, we can conclude that the discriminant analysis provides a predictive equation,\\nmeasures the relative importance of each variable and is also a measure of the ability of the equation\\nto predict actual class-groups (two or more) concerning the dependent variable.\\n(iii) Multivariate analysis of variance: Multivariate analysis of variance is an extension of bivariate\\nanalysis of variance in which the ratio of among-groups variance to within-groups variance is calculatedon a set of variables instead of a single variable. This technique is considered appropriate whenseveral metric dependent variables are involved in a research study along with many non-metricexplanatory variables. (But if the study has only one metric dependent variable and several non-metric explanatory variables, then we use the ANOVA technique as explained earlier in the book.)In other words, multivariate analysis of variance is specially applied whenever the researcher wantsto test hypotheses concerning multivariate differences in group responses to experimentalmanipulations.  For instance, the market researcher may be interested in using one test market andone control market to examine the effect of an advertising campaign on sales as well as awareness,knowledge and attitudes.  In that case he should use the technique of multivariate analysis of variancefor meeting his objective.\\n(iv) Canonical correlation analysis: This technique was first developed by Hotelling wherein an\\neffort is made to simultaneously predict a set of criterion variables from their joint co-variance with\\na set of explanatory variables. Both metric and non-metric data can be used in the context of thismultivariate technique. The procedure followed is to obtain a set of weights for the dependent andindependent variables in such a way that linear composite of the criterion variables has a maximumcorrelation with the linear composite of the explanatory variables. For example, if we want to relategrade school adjustment to health and physical maturity of the child, we can then use canonicalcorrelation analysis, provided we have for each child a number of adjustment scores (such as tests,teacher’s ratings, parent’s ratings and so on) and also we have for each child a number of health andphysical maturity scores (such as heart rate, height, weight, index of intensity of illness and so on).The main objective of canonical correlation analysis is to discover factors separately in the two setsof variables such that the multiple correlation between sets of factors will be the maximum possible.Mathematically, in canonical correlation analysis, the weights of the two sets viz., a\\n1, a2, … ak and yl,\\ny2, y3, ... yj are so determined that the variables X = a1X1 + a2X2 +... + akXk + a and Y = y1Y1 + y2Y2\\n+ … yjYj + y have a maximum common variance.  The process of finding the weights requires factor\\nanalyses with two matrices.* The resulting canonical correlation solution then gives an over all\\ndescription of the presence or absence of a relationship between the two sets of variables.\\n(v) Factor analysis: Factor analysis is by far the most often used multivariate technique of research\\nstudies, specially pertaining to social and behavioural sciences.  It is a technique applicable when\\nthere is a systematic interdependence among a set of observed or manifest variables and the researcheris interested in finding out something more fundamental or latent which creates this commonality.For instance, we might have data, say, about an individual’s income, education, occupation and dwelling\\n* See, Eleanor W. Willemsen, Understanding Statistical Reasoning, p. 167–168.322 Research Methodology\\narea and want to infer from these  some factor (such as social class) which summarises the commonality\\nof all the said four variables. The technique used for such purpose is generally described as factoranalysis. Factor analysis, thus, seeks to resolve a large set of measured variables in terms of relativelyfew categories, known as factors. This technique allows the researcher to group variables intofactors (based on correlation between variables) and the factors so derived may be treated as newvariables (often termed as latent variables) and their value derived by summing the values of theoriginal variables which have been grouped into the factor. The meaning and name of such newvariable is subjectively determined by the researcher. Since the factors happen to be linear combinationsof data, the coordinates of each observation or variable is measured to obtain what are called factorloadings. Such factor loadings represent the correlation between the particular variable and thefactor, and are usually place in a matrix of correlations between the variable and the factors.\\nThe mathematical basis of factor analysis concerns a data matrix\\n* (also termed as score\\nmatrix), symbolized as S. The matrix contains the scores of N  persons of k measures. Thus a1 is the\\nscore of person 1 on measure a, a2 is the score of person 2 on measure a, and kN is the score of\\nperson N on measure k. The score matrix then take the form as shown following:\\nSCORE MATRIX (or Matrix S)\\nMeasures (variables)\\nabc k\\n1a1b1c1k1\\n2a2b2c2k2\\n3a3b3c3k3\\nPersons (objects) . . . . .\\n.. .. .\\n.. .. .\\nNaNbNcNkN\\nIt is assumed that scores on each measure are standardized [i.e., ( ) ]xX Xii i=−2/σ. This\\nbeing so, the sum of scores in any column of the matrix, S, is zero and the variance of scores in any\\ncolumn is 1.0. Then factors (a factor is any linear combination of the variables in a data matrix and\\ncan be stated in a general way like: A = Waa + Wbb + … + Wkk) are obtained (by any method of\\nfactoring). After this, we work out factor loadings (i.e., factor-variable correlations). Then communality,symbolized as h\\n2, the eigen value and the total sum of squares are obtained and the results interpreted.\\nFor realistic results, we resort to the technique of rotation, because such rotations reveal differentstructures in the data. Finally, factor scores are obtained which help in explaining what the factorsmean. They also facilitate comparison among groups of items as groups. With factor scores, one canalso perform several other multivariate analyses such as multiple regression, cluster analysis, multiplediscriminant analysis, etc.\\n*Alternatively the technique can be applied through the matrix of correlations, R as stated later on.Multivariate Analysis Techniques 323\\nIMPORTANT METHODS OF FACTOR ANALYSIS\\nThere are several methods of factor analysis, but they do not necessarily give same results. As such\\nfactor analysis is not a single unique method but a set of techniques. Important methods of factoranalysis are:\\n(i) the centroid method;\\n(ii)the principal components method;\\n(ii)the maximum likelihood method.\\nBefore we describe these different methods of factor analysis, it seems appropriate that some\\nbasic terms relating to factor analysis be well understood.\\n(i) Factor: A factor is an underlying dimension that account for several observed variables. There\\ncan be one or more factors, depending upon the nature of the study and the number of variables\\ninvolved in it.\\n(ii) Factor-loadings:  Factor-loadings are those values which explain how closely the variables are\\nrelated to each one of the factors discovered. They are also known as factor-variable correlations.\\nIn fact, factor-loadings work as key to understanding what the factors mean. It is the absolute size(rather than the signs, plus or minus) of the loadings that is important in the interpretation of a factor.\\n(iii) Communality (h\\n2):Communality, symbolized as h2, shows how much of each variable is\\naccounted for by the underlying factor taken together. A high value of communality means that not\\nmuch of the variable is left over after whatever the factors represent is taken into consideration. It isworked out in respect of each variable as under:\\nh\\n2 of the ith variable  =  ( ith factor loading of factor A)2\\n+ (ith factor loading of factor B)2 + …\\n(iv) Eigen value (or latent root ):When we take the sum of squared values of factor loadings\\nrelating to a factor, then such sum is referred to as Eigen Value or latent root. Eigen value indicatesthe relative importance of each factor in accounting for the particular set of variables being analysed.\\n(v) Total sum of squares: When eigen values of all factors are totalled, the resulting value is termed\\nas the total sum of squares. This value, when divided by the number of variables (involved in a study),\\nresults in an index that shows how the particular solution accounts for what all the variables takentogether represent. If the variables are all very different from each other, this index will be low. Ifthey fall into one or more highly redundant groups, and if the extracted factors account for all thegroups, the index will then approach unity.\\n(vi) Rotation: Rotation, in the context of factor analysis, is something like staining a microscope\\nslide. Just as different stains on it reveal different structures in the tissue, different rotations revealdifferent structures in the data. Though different rotations give results that appear to be entirelydifferent, but from a statistical point of view, all results are taken as equal, none superior or inferior toothers. However, from the standpoint of making sense of the results of factor analysis, one mustselect the right rotation. If the factors are independent orthogonal rotation is done and if the factorsare correlated, an oblique rotation is made. Communality for each variables will remain undisturbedregardless of rotation but the eigen values will change as result of rotation.324 Research Methodology\\n(vii) Factor scores: Factor score represents the degree to which each respondent gets high scores\\non the group of items that load high on each factor. Factor scores can help explain what the factors\\nmean. With such scores, several other multivariate analyses can be performed.\\nWe can now take up the important methods of factor analysis.\\n(A) Centroid Method of Factor Analysis\\nThis method of factor analysis, developed by L.L. Thurstone, was quite frequently used until about1950 before the advent of large capacity high speed computers.\\n* The centroid method tends to\\nmaximize the sum of loadings, disregarding signs; it is the method which extracts the largest sum ofabsolute loadings for each factor in turn. It is defined by linear combinations in which all weights areeither + 1.0 or – 1.0. The main merit of this method is that it is relatively simple, can be easilyunderstood and involves simpler computations. If one understands this method, it becomes easy tounderstand the mechanics involved in other methods of factor analysis.\\nVarious steps\\n** involved in this method are as follows:\\n(i) This method starts with the computation of a matrix of correlations, R, wherein unities are\\nplace in the diagonal spaces. The product moment formula is used for working out thecorrelation coefficients.\\n(ii) If the correlation matrix so obtained happens to be positive manifold (i.e., disregarding the\\ndiagonal elements each variable has a large sum of positive correlations than of negative\\ncorrelations), the centroid method requires that the weights for all variables be +1.0. In\\nother words, the variables are not weighted; they are simply summed. But in case thecorrelation matrix is not a positive manifold, then reflections must be made before the firstcentroid factor is obtained.\\n(iii)The first centroid factor is determined as under:\\n(a) The sum of the coefficients (including the diagonal unity) in each column of the correlation\\nmatrix is worked out.\\n(b) Then the sum of these column sums ( T) is obtained.\\n(c) The sum of each column obtained as per (a) above is divided by the square root of T\\nobtained in (b) above, resulting in what are called centroid loadings. This way eachcentroid loading (one loading for one variable) is computed. The full set of loadings soobtained constitute the first centroid factor (say A).\\n(iv) To obtain second centroid factor (say B), one must first obtain a matrix of residual\\ncoefficients. For this purpose, the loadings for the two variables on the first centroid factorare multiplied. This is done for all possible pairs of variables (in each diagonal space is thesquare of the particular factor loading). The resulting matrix of factor cross products maybe named as Q\\n1. Then Q1 is subtracted clement by element from the original matrix of\\n*But since 1950, Principal components method, to be discussed a little later, is being popularly used.\\n**See, Jum C. Nunnally, Psychometric Theory , 2nd ed., p. 349–357, for details.Multivariate Analysis Techniques 325\\ncorrelation, R, and the result is the first matrix of residual coefficients, R1.* After obtaining\\nR1, one must reflect some of the variables in it, meaning thereby that some of the variables\\nare given negative signs in the sum [This is usually done by inspection. The aim in doing this\\nshould be to obtain a reflected matrix, R\\'1, which will have the highest possible sum of\\ncoefficients ( T)]. For any variable which is so reflected, the signs of all coefficients in that\\ncolumn and row of the residual matrix are changed. When this is done, the matrix is namedas ‘reflected matrix’ form which the loadings are obtained in the usual way (already explainedin the context of first centroid factor), but the loadings of the variables which were reflectedmust be given negative signs. The full set of loadings so obtained constitutes the secondcentroid factor (say B). Thus loadings on the second centroid factor are obtained from R\\'\\n1.\\n(v) For subsequent factors ( C, D, etc.) the same process outlined above is repeated. After the\\nsecond centroid factor is obtained, cross products are computed forming, matrix, Q2. This\\nis then subtracted from R1 (and not from R\\'1) resulting in R2. To obtain a third factor ( C),\\none should operate on R2 in the same way as on R1. First, some of the variables would have\\nto be reflected to maximize the sum of loadings, which would produce R\\'2 . Loadings would\\nbe computed from R\\'2 as they were from R\\'1. Again, it would be necessary to give negative\\nsigns to the loadings of variables which were reflected which would result in third centroidfactor (C).\\nWe may now illustrate this method by an example.\\nIllustration 1\\nGiven is the following correlation matrix, R, relating to eight variables with unities in the diagonal spaces:\\nVariables\\n1 2345 678\\n1 1.000 .709 .204 .081 .626 .113 .155 .774\\n2 .709 1.000 .051 .089 .581 .098 .083 .652\\n3 .204 .051 1.000 .671 .123 .689 .582 .072\\nVariables 4 .081 .089 .671 1.000 .022 .798 .613 .111\\n5 .626 .581 .123 .022 1.000 .047 .201 .724\\n6 .113 .098 .689 .798 .047 1.000 .801 .120\\n7 .155 .083 .582 .613 .201 .801 1.000 .1528 .774 .652 .072 .111 .724 .120 .152 1.000\\nUsing the centroid method of factor analysis, work out the first and second centroid factors from the\\nabove information.\\n* One should understand the nature of the elements in R1 matrix. Each diagonal element is a partial variance i.e., the\\nvariance that remains after the influence of the first factor is partialed. Each off-diagonal element is a partial co-variance i.e.,the covariance between two variables after the influence of the first factor is removed. This can be verified by looking at thepartial correlation coefficient between any two variables say 1 and 2 when factor A is held constant\\nrrr r\\nrrAAA\\nAA1212 1 2\\n12\\n2211⋅=−⋅\\n−−\\n(The numerator in the above formula is what is found in R1 corresponding to the entry for variables 1 and 2. In the\\ndenominator, the square of the term on the left is exactly what is found in the diagonal element for variable 1 in R1. Likewise\\nthe partial variance for 2 is found in the diagonal space for that variable in the residual matrix.) contd.326 Research Methodology\\nSolution:  Given correlation matrix, R, is a positive manifold and as such the weights for all variables\\nbe +1.0. Accordingly, we calculate the first centroid factor ( A) as under:\\nTable 13.1(a)\\nVariables\\n1 234 5 6 7 8\\n1 1.000 .709 .204 .081 .626 .113 .155 .774\\n2 .709 1.000 .051 .089 .581 .098 .083 .652\\n3 .204 .051 1.000 .671 .123 .689 .582 .072\\nVariables 4 .081 .089 .671 1.000 .022 .798 .613 .111\\n5 .626 .581 .123 .022 1.000 .047 .201 .724\\n6 .113 .098 .689 .798 .047 1.000 .801 .1207 .155 .083 .582 .613 .201 .801 1.000 .152\\n8 .774 .652 .072 .111 .724 .120 .152 1.000\\nColumn sums 3.662 3.263 3.392 3.385 3.324 3.666 3.587 3.605\\nSum of the column sums ( T) = 27.884\\n∴=T5281.\\nFirst centroid factor A =3662\\n52813263\\n52813392\\n5281338552813324\\n52813666\\n52813587528136055281.\\n.,..,.\\n.,..,.\\n.,.\\n.,..,..\\n = .693, .618, .642, .641, .629, .694, .679, .683\\nWe can also state this information as under:\\nTable 13.1 (b)\\nVariables Factor loadings concerning\\nfirst Centroid factor A\\n1 .693\\n2 .618\\n3 .642\\n4 .641\\n5 .629\\n6 .694\\n7 .679\\n8 .683\\nTo obtain the second centroid factor B, we first of all develop (as shown on the next page) the\\nfirst matrix of factor cross product, Q1:\\nSince in R1 the diagonal terms are partial variances and the off-diagonal terms are partial covariances, it is easy to convert\\nthe entire table to a matrix of partial correlations. For this purpose one has to divide the elements in each row by the square-\\nroot of the diagonal element for that row and then dividing the elements in each column by the square-root of the diagonalelement for that column.Multivariate Analysis Techniques 327\\nFirst Matrix of Factor Cross Product ( Q1)\\nFirst centroid .693 .618 .642 .641 .629 .694 .679 .683\\nfactor A\\n.693 .480 .428 .445 .444 .436 .481 .471 .473\\n.618 .428 .382 .397 .396 .389 .429 .420 .422\\n.642 .445 .397 .412 .412 .404 .446 .436 .438.641 .444 .396 .412 .411 .403 .445 .435 .438\\n.629 .436 .389 .404 .403 .396 .437 .427 .430\\n.694 .481 .429 .446 .445 .437 .482 .471 .474.679 .471 .420 .436 .435 .427 .471 .461 .464\\n.683 .473 .422 .438 .438 .430 .474 .464 .466\\nNow we obtain first matrix of residual coefficient ( R1) by subtracting Q1 from R as shown\\nbelow:\\nFirst Matrix of Residual Coefficient ( R1)\\nVariables\\n12 3 4 56 7 8\\n1 .520 .281 – .241 – .363 .190 – .368 – .316 .301\\n2 .281 .618 –.346 –.307 .192 – .331 – .337 .230\\n3 –.241 –.346 .588 .259 – .281.243 .146 – .366\\nVariables 4 – .363 – .307 .259 .589 – .381.353 .178 – .327\\n5 .190 .192 – .281 – .381 .604 – .390 – .217 .294\\n6 – .368 – .331 .243 .353 – .390.518 .330 – .354\\n7 –.316 – .337.146 .178 – .226.330 .539 – .312\\n8 .301 .230 – .366 – .327 .294 – .354 – .312 .534\\nReflecting the variables 3, 4, 6 and 7, we obtain reflected matrix of residual coefficient ( R\\'1) as\\nunder and then we can extract the second centroid factor ( B) from it as shown on the next page.\\nReflected Matrix of Residual Coefficients ( R\\'1)\\nand Extraction of 2nd Centroid Factor ( B)\\nVariables\\n12 3*4*56*7*8\\n1 .520 .281 .241 .363 .190 .368 .316 .301\\n2 .281 .618 .346 .307 .192 .331 .337 .230\\n3*.241 .346 .588 .259 .281 .243 .146 .366\\nVariables    4*.363 .307 .259 .589 .381 .353 .178 .327\\n5 .190 .192 .281 .381 .604 .390 .217 .294\\n6*.368 .331 .243 .353 .390 .518 .330 .354\\n7*.316 .337 .146 .178 .226 .330 .539 .312\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○328 Research Methodology\\nVariables\\n12 3*4*56*7*8\\n                      8 .301 .230 .366 .327 .294 .354 .312 .534\\nColumn sums: 2.580 2.642 2.470 2.757 2.558 2.887 2.375 2.718\\nSum of column sums ( T) = 20.987 ∴=T4581.\\nSecond centroid factor B = .563    .577    –.539    –.602    .558    –.630    –.518    .593\\n*These variables were reflected.\\nNow we can write the matrix of factor loadings as under:\\nVariables Factor loadings\\nCentroid Factor Centroid Factor\\nAB\\n1 .693 .563\\n2 .618 .577\\n3 .642 –.539\\n4 .641 –.602\\n5 .629 .558\\n6 .694 –.630\\n7 .679 –.518\\n8 .683 .593\\nIllustration 2\\nWork out the communality and eigen values from the final results obtained in illustration No. 1 of this\\nchapter. Also explain what they (along with the said two factors) indicate.\\nSolution:  We work out the communality and eigen values for the given problem as under:\\nTable 13.2\\nVariables Factor loadings Communality (h2)\\nCentroid Factor Centroid Factor\\nAB\\n1 .693 .563 (.693)2 + (.563)2 = .797\\n2 .618 .577 (.618)2 + (.577)2 = .715\\n3 .642 –.539 (.642)2 + (–.539)2 = .703\\n4 .641 –.602 (.641)2 + (–.602)2 = .773\\n5 .629 .558 (.629)2 + (.558)2 = .707\\n6 .694 –.630 (.694)2 + (–.630)2 = .879\\n7 .679 –.518 (.679)2 + (–.518)2 = .729\\n8 .683 .593 (.683)2 + (.593)2 = .818\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Multivariate Analysis Techniques 329\\nVariables Factor loadings Communality (h2)\\nCentroid Factor Centroid Factor\\nAB\\nEigen value\\n(Variance\\naccounted for i.e., 3.490 2.631 6.121\\ncommon variance)\\nProportion of total .44 .33 .77\\nvariance (44%) (33%) (77%)\\nProportion of .57 .43 1.00\\ncommon variance (57%) (43%) (100%)\\nEach communality in the above table represents the proportion of variance in the corresponding\\n(row) variable and is accounted for by the two factors ( A and B). For instance, 79.7% of the variance\\nin variable one is accounted for by the centroid factor A and B and the remaining 20.3% of the total\\nvariance in variable one scores is thought of as being made up of two parts: a factor specific to the\\nattribute represented by variable one, and a portion due to errors of measurement involved in theassessment of variable one (but there is no mention of these portions in the above table because weusually concentrate on common variance in factor analysis).\\nIt has become customary in factor analysis literature for a loading of 0.33 to be the minimum\\nabsolute value to be interpreted. The portion of a variable’s variance accounted for by this minimumloading is approximately 10%. This criterion, though arbitrary, is being used more or less by way ofconvention, and as such must be kept in view when one reads and interprets the multivariate researchresults. In our example, factor A has loading in excess of 0.33 on all variables; such a factor is usually\\ncalled “the general factor ” and is taken to represent whatever it is that all of the variables have in\\ncommon. We might consider all the eight variables to be product of some unobserved variable (whichcan be named subjectively by the researcher considering the nature of his study). The factor name ischosen in such a way that it conveys what it is that all variables that correlate with it (that “load onit”) have in common. Factor B in our example has all loadings in excess of 0.33, but half of them are\\nwith negative signs. Such a factor is called a “ bipolar factor ” and is taken to represent a single\\ndimension with two poles. Each of these poles is defined by a cluster of variables—one pole by thosewith positive loadings and the other pole with negative loadings.\\nWe can give different names to the said two groups to help us interpret and name factor B. The\\nrows at the bottom of the above table give us further information about the usefulness of the twofactors in explaining the relations among the eight variables. The total variance ( V) in the analysis is\\ntaken as equal to the number of variables involved (on the presumption that variables are standardized).In this present example, then V = 8.0. The row labeled “Eigen value” or “Common variance” gives\\nthe numerical value of that portion of the variance attributed to the factor in the concerning columnabove it. These are found by summing up the squared values of the corresponding factor loadings.Thus the total value, 8.0, is partitioned into 3.490 as eigen value for factor A and 2.631 as eigen value\\nfor factor B and the total 6.121 as the sum of eigen values for these two factors. The corresponding\\nproportion of the total variance, 8.0, are shown in the next row; there we can notice that 77% of the330 Research Methodology\\ntotal variance is related to these two factors, i.e., approximately 77% of the total variance is common\\nvariance whereas remaining 23% of it is made up of portions unique to individual variables and thetechniques used to measure them. The last row shows that of the common variance approximately57% is accounted for by factor A and the other 43% by factor B. Thus it can be concluded that the\\ntwo factors together “explain” the common variance.\\n(B) Principal-components Method of Factor Analysis\\nPrincipal-components method (or simply P.C. method) of factor analysis, developed by H. Hotelling,seeks to maximize the sum of squared loadings of each factor extracted in turn. Accordingly PCfactor explains more variance than would the loadings obtained from any other method of factoring.\\nThe aim of the principal components method is the construction out of a given set of variables\\nX\\nj’s (j = 1, 2, …, k) of new variables ( pi), called principal components which are linear combinations\\nof the Xs\\np1 = a11 X1 + a12 X2 + ... + a1k Xk\\n p2 = a21 X1 + a22 X2 + … + a2k Xk\\n. .              .           .            .\\n. .              .           .            .\\npk = ak1 X1 + ak2 X2 + … + akk Xk\\nThe method is being applied mostly by using standardized variables, i.e., zX Xj jjj=−di2/σ.\\nThe aij’s are called loadings and are worked out in such a way that the extracted principal\\ncomponents satisfy two conditions: (i) principal components are uncorrelated (orthogonal) and (ii)thefirst principal component ( p\\n1) has the maximum variance, the second principal component ( p2) has\\nthe next maximum variance and so on.\\nFollowing steps are usually involved in principal components method\\n(i) Estimates of aij’s are obtained with which X’s are transformed into orthogonal variables\\ni.e., the principal components. A decision is also taken with regard to the question: how\\nmany of the components to retain into the analysis?\\n(ii) We then proceed with the regression of Y on these principal components i.e.,\\nYy p y p y pm kmm =++ + <$$ ... $11 22 bg\\n(iii)From the $aij and $yij, we may find bij of the original model, transferring back from the p’s\\ninto the standardized X’s.\\nAlternative method for finding the factor loadings is as under:\\n(i) Correlation coefficients (by the product moment method) between the pairs of k variables\\nare worked out and may be arranged in the form of a correlation matrix, R, as under:Multivariate Analysis Techniques 331\\nCorrelation Matrix, R\\nVariables\\nX1X2X3…. Xk\\nX1r11r12r13…. r1k\\nX2r21r22r23…. r3k\\nVariables X3r31r32r33…. r3k\\n.. . .\\n.. . .\\nXkrk1rk2rk3…. rkk\\nThe main diagonal spaces include unities since such elements are self-correlations. The\\ncorrelation matrix happens to be a symmetrical matrix.\\n(ii)Presuming the correlation matrix to be positive manifold (if this is not so, then reflections asmentioned in case of centroid method must be made), the first step is to obtain the sum ofcoefficients in each column, including the diagonal element. The vector of column sums isreferred to as U\\na1 and when Ua1 is normalized, we call it Va1. This is done by squaring and\\nsumming the column sums in Ua1 and then dividing each element in Ua1 by the square root\\nof the sum of squares (which may be termed as normalizing factor). Then elements in Va1\\nare accumulatively multiplied by the first row of R to obtain the first element in a new\\nvector Ua2. For instance, in multiplying Va1 by the first row of R, the first element in Va1\\nwould be multiplied by the r11 value and this would be added to the product of the second\\nelement in Va1 multiplied by the r12 value, which would be added to the product of third\\nelement in Va1 multiplied by the r13 value, and so on for all the corresponding elements in Va1\\nand the first row of R. To obtain the second element of Ua2, the same process would be\\nrepeated i.e., the elements in Va1 are accumulatively multiplied by the 2nd row of R. The\\nsame process would be repeated for each row of R and the result would be a new vector\\nUa2. Then Ua2 would be normalized to obtain Va2. One would then compare Va1 and Va2. If\\nthey are nearly identical, then convergence is said to have occurred (If convergence doesnot occur, one should go on using these trial vectors again and again till convergenceoccurs). Suppose the convergence occurs when we work out V\\na8 in which case Va7 will be\\ntaken as Va (the characteristic vector) which can be converted into loadings on the first\\nprincipal component when we multiply the said vector (i.e., each element of Va) by the\\nsquare root of the number we obtain for normalizing Ua8.\\n(iii) To obtain factor B, one seeks solutions for Vb, and the actual factor loadings for second\\ncomponent factor, B. The same procedures are used as we had adopted for finding the first\\nfactor, except that one operates off the first residual matrix, R1 rather than the original\\ncorrelation matrix R (We operate on R1 in just the same way as we did in case of centroid\\nmethod stated earlier).\\n(iv)This very procedure is repeated over and over again to obtain the successive PC factors(viz. C, D, etc.).332 Research Methodology\\nOther steps involved in factor analysis\\n(a) Next the question is: How many principal components to retain in a particular study? Various\\ncriteria for this purpose have been suggested, but one often used is Kaiser’s criterion.\\nAccording to this criterion only the principal components, having latent root greater thanone, are considered as essential and should be retained.\\n(b) The principal components so extracted and retained are then rotated from their beginning\\nposition to enhance the interpretability of the factors.\\n(c) Communality, symbolized, h\\n2, is then worked out which shows how much of each variable\\nis accounted for by the underlying factors taken together. A high communality figure meansthat not much of the variable is left over after whatever the factors represent is taken intoconsideration. It is worked out in respect of each variable as under:\\nh\\n2 of the ith variable = ( ith factor loading of factor A)2\\n+ (ith factor loading of factor B)2 + …\\nThen follows the task of interpretation. The amount of variance explained (sum of squaredloadings) by each PC factor is equal to the corresponding characteristic root. When theseroots are divided by the number of variables, they show the characteristic roots as proportionsof total variance explained.\\n(d) The variables are then regressed against each factor loading and the resulting regression\\ncoefficients are used to generate what are known as factor scores which are then used infurther analysis and can also be used as inputs in several other multivariate analyses.\\nIllustration 3\\nTake the correlation matrix, R, for eight variables of illustration 1 of this chapter and then compute:\\n(i) the first two principal component factors;\\n(ii)the communality for each variable on the basis of said two component factors;\\n(iii)the proportion of total variance as well as the proportion of common variance explained by\\neach of the two component factors.\\nSolution:  Since the given correlation matrix is a positive manifold, we work out the first principal\\ncomponent factor (using trial vectors) as under:\\nTable 13.3\\nVariables\\n12345 6 7 8\\n1 1.000 .709 .204 .081 .626 .113 .155 .774\\n2 .709 1.000 .051 .089 .581 .098 .083 .652\\n3 .204 .051 1.000 .671 .123 .689 .582 .0724 .081 .089 .671 1.000 .022 .798 .613 .111\\nVariables 5 .626 .581 .123 .022 1.000 .047 .201 .7246 .113 .098 .689 .798 .047 1.000 .801 .120\\nContd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○Multivariate Analysis Techniques 333\\n1 234 56 7 8\\n7 .155 .083 .582 .613 .201 .801 1.000 .152\\n8 .774 .652 .072 .111 .724 .120 .152 1.000\\nColumn 3.662 3.263 3.392 3.385 3.324 3.666 3.587 3.605\\nsums Ua1\\nNormalizingU\\na1 we\\nobtain Va1\\ni.e., Va1 = .371 .331 .344 .343 .337 .372 .363 .365\\nUa /Nor-\\nmalizing\\nfactor*\\n*Normalizing factor = 3662 3263 3392 3385 3324 3666 3587 360522222222........bg bg bg bg bg bg bg bg+++++++\\n     ==97372 9868..\\nThen we obtain Ua2 by accumulatively multiplying Va1 row by row into R  and the result comes as\\nunder:\\nUa2 : [1.296, 1.143, 1.201, 1.201, 1.165, 1.308, 1.280, 1.275]\\nNormalizing it we obtain (normalizing factor for Ua2 will be worked out as above and will be\\n=3.493):\\nVa2 : [.371, .327, .344, .344, .334, .374, .366, .365]\\nComparing Va1 and Va2, we find the two vectors are almost equal and this shows convergence\\nhas occurred. Hence Va1 is taken as the characteristic vector, Va. Finally, we compute the loadings on\\nthe first principal component by multiplying Va by the square root of the number that we obtain for\\nnormalizing Ua2. The result is as under:\\nVariables (Characteristic × normalizingfactor of Ua    2= Principal\\nvector Va ) Component I\\n1 .371 × 1.868 = .69\\n2 .331 × 1.868 = .62\\n3 .344 × 1.868 = .64\\n4 .343 × 1.868 = .64\\n5 .337 × 1.868 = .63\\n6 .372 × 1.868 = .70\\n7 .363 × 1.868 = .68\\n8 .365 × 1.868 = .68334 Research Methodology\\nFor finding principal component II, we have to proceed on similar lines (as stated in the context\\nof obtaining centroid factor B earlier in this chapter) to obtain the following result*:\\nVariables Principal Component II\\n1 +.57\\n2 +.59\\n3 –.52\\n4 –.59\\n5 +.57\\n6 –.61\\n7 –.49\\n8 –.61\\nThe other parts of the question can now be worked out (after first putting the above information in a\\nmatrix form) as given below:\\nVariables Principal Components Communality, h2\\nII I\\n1 .69 +.57 (.69)2 + (.57)2 = .801\\n2 .62 +.59 (.62)2 + (.59)2 = .733\\n3 .64 –.52 (.64)2 + (–.52)2 = .680\\n4 .64 –.59 (.64)2 + (–.59)2 = .758\\n5 .63 +.57 (.63)2 + (.57)2 = .722\\n6 .70 –.61 (.70)2 + (–.61)2 = .862\\n7 .68 –.49 (.68)2 + (–.49)2 = .703\\n8 .68 –.61 (.68)2 + (–.61)2 = .835\\nEigen value\\ni.e., common 3.4914 2.6007 6.0921\\nvariance\\nProportion .436 .325 .761\\nof total (43.6%) (32.5%) (76%)\\nvariance\\nProportion .573 .427 1.000\\nof common (57%) (43%) (100%)\\nvariance\\nAll these values can be interpreted in the same manner as stated earlier.\\n*This can easily be worked out. Actual working has been left as an exercise for the students.Multivariate Analysis Techniques 335\\n(C) Maximum Likelihood (ML) Method of Factor Analysis\\nThe ML method consists in obtaining sets of factor loadings successively in such a way that each, in\\nturn, explains as much as possible of the population correlation matrix as estimated from the samplecorrelation matrix. If R\\ns stands for the correlation matrix actually obtained from the data in a sample,\\nRp stands for the correlation matrix that would be obtained if the entire population were tested, then\\nthe ML method seeks to extrapolate what is known from Rs in the best possible way to estimate Rp\\n(but the PC method only maximizes the variance explained in Rs). Thus, the ML method is a statistical\\napproach in which one maximizes some relationship between the sample of data and the populationfrom which the sample was drawn.\\nThe arithmetic underlying the ML method is relatively difficult in comparison to that involved in\\nthe PC method and as such is understandable when one has adequate grounding in calculus, higheralgebra and matrix algebra in particular. Iterative  approach is employed in ML method also to find\\neach factor, but the iterative procedures have proved much more difficult than what we find in thecase of PC method. Hence the ML method is generally not used for factor analysis in practice.\\n*\\nThe loadings obtained on the first factor are employed in the usual way to obtain a matrix of the\\nresidual coefficients. A significance test is then applied to indicate whether it would be reasonable toextract a second factor. This goes on repeatedly in search of one factor after another. One stopsfactoring after the significance test fails to reject the null hypothesis for the residual matrix. The finalproduct is a matrix of factor loadings. The ML factor loadings can be interpreted in a similar fashionas we have explained in case of the centroid or the PC method.\\nROTATION IN FACTOR ANALYSIS\\nOne often talks about the rotated solutions in the context of factor analysis. This is done (i.e., a factormatrix is subjected to rotation) to attain what is technically called “simple structure” in data. Simplestructure according to L.L. Thurstone is obtained by rotating the axes\\n** until:\\n(i) Each row of the factor matrix has one zero.\\n(ii)Each column of the factor matrix has p zeros, where p is the number of factors.\\n(iii)For each pair of factors, there are several variables for which the loading on one is virtuallyzero and the loading on the other is substantial.\\n(iv) If there are many factors, then for each pair of factors there are many variables for which\\nboth loadings are zero.\\n(v) For every pair of factors, the number of variables with non-vanishing loadings on both of\\nthem is small.\\nAll these criteria simply imply that the factor analysis should reduce the complexity of all thevariables.\\n* The basic mathematical derivations of the ML method are well explained in S.A. Mulaik’s, The Foundations of Factor\\nAnalysis.\\n** Rotation constitutes the geometric aspects of factor analysis. Only the axes of the graph (wherein the points\\nrepresenting variables have been shown) are rotated keeping the location of these points relative to each other undisturbed.336 Research Methodology\\nThere are several methods of rotating the initial factor matrix (obtained by any of the methods of\\nfactor analysis) to attain this simple structure. Varimax rotation is one such method that maximizes\\n(simultaneously for all factors) the variance of the loadings within each factor. The variance of a\\nfactor is largest when its smallest loadings tend towards zero and its largest loadings tend towardsunity. In essence, the solution obtained through varimax rotation produces factors that are characterizedby large loadings on relatively few variables. The other method of rotation is known as quartimax\\nrotation wherein the factor loadings are transformed until the variance of the squared factor loadings\\nthroughout the matrix is maximized. As a result, the solution obtained through this method permits ageneral factor to emerge, whereas in case of varimax solution such a thing is not possible. But bothsolutions produce orthogonal factors i.e., uncorrelated factors. It should, however, be emphasisedthat right rotation must be selected for making sense of the results of factor analysis.\\nR-TYPE AND Q-TYPE FACTOR ANALYSES\\nFactor analysis may be R-type factor analysis or it may be Q-type factor analysis. In R-type factor\\nanalysis, high correlations occur when respondents who score high on variable 1 also score high on\\nvariable 2 and respondents who score low on variable 1 also score low on variable 2. Factors emergewhen there are high correlations within groups of variables. In Q-type factor analysis, the correlations\\nare computed between pairs of respondents instead of pairs of variables. High correlations occurwhen respondent 1’s pattern of responses on all the variables is much like respondent 2’s pattern ofresponses. Factors emerge when there are high correlations within groups of people. Q-type analysis\\nis useful when the object is to sort out people into groups based on their simultaneous responses to allthe variables.\\nFactor analysis has been mainly used in developing psychological tests (such as  IQ tests, personality\\ntests, and the like) in the realm of psychology. In marketing, this technique has been used to look atmedia readership profiles of people.\\nMerits: The main merits of factor analysis can be stated thus:\\n(i) The technique of factor analysis is quite useful when we want to condense and simplify the\\nmultivariate data.\\n(ii)The technique is helpful in pointing out important and interesting, relationships among\\nobserved data that were there all the time, but not easy to see from the data alone.\\n(iii)The technique can reveal the latent factors (i.e., underlying factors not directly observed)that determine relationships among several variables concerning a research study. Forexample, if people are asked to rate different cold drinks (say, Limca, Nova-cola, Gold Spotand so on) according to preference, a factor analysis may reveal some salient characteristicsof cold drinks that underlie the relative preferences.\\n(iv)The technique may be used in the context of empirical clustering of products, media orpeople i.e., for providing a classification scheme when data scored on various rating scaleshave to be grouped together.\\nLimitations:  One should also be aware of several limitations of factor analysis. Important ones are\\nas follows:Multivariate Analysis Techniques 337\\n(i) Factor analysis, like all multivariate techniques, involves laborious computations involving\\nheavy cost burden. With computer facility available these days, there is no doubt that factor\\nanalysis has become relatively faster and easier, but the cost factor continues to be thesame i.e., large factor analyses are still bound to be quite expensive.\\n(ii)The results of a single factor analysis are considered generally less reliable and dependablefor very often a factor analysis starts with a set of imperfect data. “The factors are nothingbut blurred averages, difficult to be identified.”\\n4 To overcome this difficulty, it has been\\nrealised that analysis should at least be done twice. If we get more or less similar resultsfrom all rounds of analyses, our confidence concerning such results increases.\\n(iii)Factor-analysis is a complicated decision tool that can be used only when one has thoroughknowledge and enough experience of handling this tool. Even then, at times it may not workwell and may even disappoint the user.\\nTo conclude, we can state that in spite of all the said limitations “when it works well, factor\\nanalysis helps the investigator make sense of large bodies of intertwined data. When it works unusuallywell, it also points out some interesting relationships that might not have been obvious from examinationof the input data alone”.\\n5\\n(vi) Cluster Analysis\\nCluster analysis consists of methods of classifying variables into clusters. Technically, a cluster\\nconsists of variables that correlate highly with one another and have comparatively low correlationswith variables in other clusters. The basic objective of cluster analysis is to determine how manymutually and exhaustive groups or clusters, based on the similarities of profiles among entities, reallyexist in the population and then to state the composition of such groups. Various groups to be determinedin cluster analysis are not predefined as happens to be the case in discriminant analysis.\\nSteps:In general, cluster analysis contains the following steps to be performed:\\n(i) First of all, if some variables have a negative sum of correlations in the correlation matrix,\\none must reflect variables so as to obtain a maximum sum of positive correlations for the\\nmatrix as a whole.\\n(ii)The second step consists in finding out the highest correlation in the correlation matrix andthe two variables involved (i.e., having the highest correlation in the matrix) form the nucleusof the first cluster.\\n(iii)Then one looks for those variables that correlate highly with the said two variables andincludes them in the cluster. This is how the first  cluster is formed.\\n(iv) To obtain the nucleus of the second cluster, we find two variables that correlate highly but\\nhave low correlations with members of the first cluster. Variables that correlate highly withthe said two variables are then found. Such variables along the said two variables thusconstitute the second cluster.\\n(v) One proceeds on similar lines to search for a third cluster and so on.\\n4 Srinibas Bhattacharya, Psychometrics and Behavioural Research, p. 177.\\n5 William D. Wells and Jagdish N. Sheth in their article on “Factor Analysis” forming chapter 9 in Robert Ferber, (ed.),\\nHandbook of Marketing Research, p. 2–471.338 Research Methodology\\nFrom the above description we find  that clustering methods in general are judgemental and are\\ndevoid of statistical inferences. For problems concerning large number of variables, various cut-and-\\ntry methods have been proposed for locating clusters. McQuitty has specially developed a number ofrather elaborate computational routines\\n* for that purpose.\\nIn spite of the above stated limitation, cluster analysis has been found useful in context of market\\nresearch studies. Through the use of this technique we can make segments of market of a producton the basis of several characteristics of the customers such as personality, socio-economicconsiderations, psychological factors, purchasing habits and like ones.\\n(vii) Multidimensional Scaling\\n**\\nMultidimensional scaling (MDS) allows a researcher to measure an item in more than one dimension\\nat a time. The basic assumption is that people perceive a set of objects as being more or less similarto one another on a number of dimensions (usually uncorrelated with one another) instead of onlyone.\\nThere are several MDS techniques (also known as techniques for dimensional reduction) often\\nused for the purpose of revealing patterns of one sort or another in interdependent data structures. Ifdata happen to be non-metric, MDS involves rank ordering each pair of objects in terms of similarity.Then the judged similarities are transformed into distances through statistical manipulations and areconsequently shown in n-dimensional space in a way that the interpoint distances best preserve the\\noriginal interpoint proximities. After this sort of mapping is performed, the dimensions are usuallyinterpreted and labeled by the researcher.\\nThe significance of MDS lies in the fact that it enables the researcher to study “The perceptual\\nstructure of a set of stimuli and the cognitive processes underlying the development of this structure....MDS provides a mechanism for determining the truly salient attributes without forcing the judge toappear irrational.”\\n6 With MDS, one can scale objects, individuals or both with a minimum of information.\\nThe MDS analysis will reveal the most salient attributes which happen to be the primary determinantsfor making a specific decision.\\n(viii) Latent Structure Analysis\\nThis type of analysis shares both of the objectives of factor analysis viz., to extract latent factors and\\nexpress relationship of observed (manifest) variables with these factors as their indicators and toclassify a population of respondents into pure types. This type of analysis is appropriate when thevariables involved in a study do not possess dependency relationship and happen to be non-metric.\\nIn addition to the above stated multivariate techniques, we may also describe the salient features\\nof what is known as “Path analysis”, a technique useful for decomposing the total correlation betweenany two variables in a causal system.\\n* These are beyond the scope of this book and hence have been omitted. Readers interested in such methods are referred\\nto “Cluster Analysis” by R. C. Tryon and D. E. Bailey.\\n** See, Chapter No. 5 of this book for other details about MDS.\\n6 Robert Ferber, ed., Handbook of Marketing Research, p. 3–52.Multivariate Analysis Techniques 339\\nPATH  ANALYSIS\\nThe term ‘path analysis’ was first introduced by the biologist Sewall Wright in 1934 in connection\\nwith decomposing the total correlation between any two variables in a causal system. The techniqueof path analysis is based on a series of multiple regression analyses with the added assumption ofcausal relationship between independent and dependent variables. This technique lays relativelyheavier emphasis on the heuristic use of visual diagram, technically described as a path diagram. Anillustrative path diagram showing interrelationships between Fathers’ education, Fathers’ occupation,Sons’ education, Sons’ first and Sons’ present occupation can be shown in the Fig. 13.2.\\nPath analysis makes use of standardized partial regression coefficients (known as beta weights)\\nas effect coefficients. In linear additive effects are assumed, then through path analysis a simple setof equations can be built up showing how each variable depends on preceding variables. “The mainprinciple of path analysis is that any correlation coefficient between two variables, or a gross oroverall measure of empirical relationship can be decomposed into a series of parts: separate paths ofinfluence leading through chronologically intermediate variable to which both the correlated variableshave links.”\\n7\\nThe merit of path analysis in comparison to correlational analysis is that it makes possible the\\nassessment of the relative influence of each antecedent or explanatory variable on the consequent orcriterion variables by first making explicit the assumptions underlying the causal connections andthen by elucidating the indirect effect of the explanatory variables.\\nFig.13.2\\n“The use of the path analysis technique requires the assumption that there are linear additive, a\\nsymmetric relationships among a set of variables which can be measured at least on a quasi-intervalscale. Each dependent variable is regarded as determined by the variables preceding it in the pathdiagram, and a residual variable, defined as uncorrelated with the other variables, is postulated toaccount for the unexplained portion of the variance in the dependent variable. The determiningvariables are assumed for the analysis to be given (exogenous in the model).”\\n8\\n7 K. Takeuchi, et al. op. cit., The Foundations  of Multivariate Analysis , p. 122.\\n8 Ibid., p. 121–122.Father’s\\neducation\\nFather’s\\noccupationSon’s\\neducation\\nSon’s\\nfirst\\noccupationSon’s\\npresent\\noccupation\\nPath analysis makes340 Research Methodology\\nWe may illustrate the path analysis technique in connection with a simple problem of testing a\\ncausal model with three explicit variables as shown in the following path diagram:\\nFig. 13.3\\nThe structural equation for the above can be written as:\\nX\\nX\\nXe\\npX e\\npX pX epX e1\\n2\\n31\\n21 1 2\\n31 2 32 2 3L\\nNMMMO\\nQPPP=\\n=\\n=+\\n++L\\nNMMMO\\nQPPP=+\\nwhere the X variables are measured as deviations from their respective means. p21 may be estimated\\nfrom the simple regression of X2 on X1 i.e., X2 = b21Xl and p31 and p32 may be estimated from the\\nregression of X3 on X2 and X1 as under:\\n$..XbXb X33 1 2 12 1 2=+\\nwhere b31.2 means the standardized partial regression coefficient for predicting variable 3 from\\nvariable 1 when the effect of variable 2 is held constant.\\nIn path analysis the beta coefficient indicates the direct effect of Xj (j = 1, 2, 3, ..., p) on the\\ndependent variable. Squaring the direct effect yields the proportion of the variance in the dependent\\nvariable Y which is due to each of the p number of independent variables Xj (i = 1, 2, 3, ..., p). After\\ncalculating the direct effect, one may then obtain a summary measure of the total indirect effect ofX\\nj on the dependent variable Y by subtracting from the zero correlation coefficient ryxj, the beta\\ncoefficient bj i.e.,\\nIndirect effect of Xj on Y = cjy = ryxj – bj\\n          for all j = 1, 2, ..., p.\\nSuch indirect effects include the unanalysed effects and spurious relationships due to antecedentvariables.\\nIn the end, it may again be emphasised that the main virtue of path analysis lies in making explicit\\nthe assumptions underlying the causal connections and in elucidating the indirect effects due toantecedent variables of the given system.\\nCONCLUSION\\nFrom the brief account of multivariate techniques presented above, we may conclude that suchtechniques are important for they make it possible to encompass all the data from an investigation inone analysis. They in fact result in a clearer and better account of the research effort than do the\\npiecemeal analyses of portions of data. These techniques yield more realistic probability statementsX1\\np31 p32p21\\nX3X2Path Diagram (with the variables)Multivariate Analysis Techniques 341\\nin hypothesis testing and interval estimation studies. Multivariate analysis (consequently the use of\\nmultivariate techniques) is specially important in behavioural sciences and applied researches formost of such studies involve problems in which several response variables are observed simultaneously.The common source of each individual observation generally results into dependence or correlationamong the dimensions and it is this feature that distinguishes multivariate data and techniques fromtheir univariate prototypes.\\nIn spite of all this, multivariate techniques are expensive and involve laborious computations. As\\nsuch their applications in the context of research studies have been accelerated only with the adventof high speed electronic computers since 1950’s.\\nQuestions\\n1.What do you mean by multivariate techniques? Explain their significance in context of research studies.\\n2.Write a brief essay on “Factor analysis” particularly pointing out its merits and limitations.\\n3.Name the important multivariate techniques and explain the important characteristic of each one of suchtechniques.\\n4.Enumerate the steps involved in Thurstone’s centroid method of factor analysis.\\n5.Write a short note on ‘ rotation’ in context of factor analysis.\\n6.Work out the first two centroid factors as well as first two principal components from the followingcorrelation matrix, R, relating to six variables:\\nVariables\\n123 4 56\\n1 1.00 .55 .43 .32 .28 .36\\n2 1.00 .50 .25 .31 .32\\nVariables 3 1.00 .39 .25 .33\\n4 1.00 .43 .49\\n5 1.00 .44\\n6 1.00\\nAnswers:\\nVariables Centroid factors Principal Components\\nII I I I I\\n1 .71 .40 .71 .39\\n2 .70 .46 .71 .48\\n3 .70 .37 .70 .32\\n4 .69 –.41 .69 –.42\\n5 .65 –.43 .64 –.45\\n6 .71 –.39 .71 –.38\\n7.Compute communality for each of the  variable based on first two centroid factors in question six above\\nand state what does it indicate.342 Research Methodology\\n8.Compute the proportion of total variance explained by the two factors worked out in question six above\\nby the principal components method. Also point out the proportion of common variance explained byeach of the two factors. ‘\\n9.What is the significance of using multiple discriminant analysis? Explain in brief the technical detailsinvolved in such a technique.\\n10.Write short notes on:\\n(i) Cluster analysis; (ii)Multidimensional scaling;\\n(iii)Reflections in context of factor analysis;\\n(iv)Maximum likelihood method of factor analysis; (v) Path analysis.Appendix: Summary Chart 343\\nAppendix\\nSummary Chart:\\nShowing the Appropriateness of a\\nParticular Multivariate Technique\\nTechniques of Number of\\nmultivariate analysis\\nExplanatory Criterion variables\\nvariables\\n1. Multiple regression\\nanalysis (along with\\npath analysis) many one\\n2. Multiple discriminant one (to be classified\\nanalysis many into many groups)\\n3. Multivariate analysis\\nof variance many many\\n4. Canonical\\ncorrelation analysis many many*1many*2\\n5. Factor analysis many\\n6. Cluster analysis many\\n7. Multidimensional\\nscaling (MDS) many many\\n8. Latent structure\\nanalysis many\\nAA A A\\nNature of data Non-metric metric Non-metric metric\\n*1 Any one of the two.\\n*2 Any one of the two.344 Research Methodology\\n14\\nInterpretation and Report Writing\\nAfter collecting and analyzing the data, the researcher has to accomplish the task of drawing inferences\\nfollowed by report writing. This has to be done very carefully, otherwise misleading conclusions maybe drawn and the whole purpose of doing research may get vitiated. It is only through interpretationthat the researcher can expose relations and processes that underlie his findings. In case of hypothesestesting studies, if hypotheses are tested and upheld several times, the researcher may arrive atgeneralizations. But in case the researcher had no hypothesis to start with, he would try to explain hisfindings on the basis of some theory. This may at times result in new questions, leading to furtherresearches. All this analytical information and consequential inference(s) may well be communicated,preferably through research report, to the consumers of research results who may be either anindividual or a group of individuals or some public/private organisation.\\nMEANING OF INTERPRETATION\\nInterpretation refers to the task of drawing inferences from the collected facts after an analyticaland/or experimental study. In fact, it is a search for broader meaning of research findings. The taskof interpretation has two major aspects viz., (i) the effort to establish continuity in research throughlinking the results of a given study with those of another, and (ii) the establishment of some explanatoryconcepts. “In one sense, interpretation is concerned with relationships within the collected data,partially overlapping analysis. Interpretation also extends beyond the data of the study to include theresults of other research, theory and hypotheses.”\\n1 Thus, interpretation is the device through which\\nthe factors that seem to explain what has been observed by researcher in the course of the study canbe better understood and it also provides a theoretical conception which can serve as a guide forfurther researches.\\nWHY INTERPRETATION?\\nInterpretation is essential for the simple reason that the usefulness and utility of research findings liein proper interpretation. It is being considered a basic component of research process because of thefollowing reasons:\\n1 C. William Emory, Business Research Methods, p. 336.Interpretation and Report Writing 345\\n(i) It is through interpretation that the researcher can well understand the abstract principle\\nthat works beneath his findings. Through this he can link up his findings with those of other\\nstudies, having the same abstract principle, and thereby can predict about the concreteworld of events. Fresh inquiries can test these predictions later on. This way the continuityin research can be maintained.\\n(ii)Interpretation leads to the establishment of explanatory concepts that can serve as a guidefor future research studies; it opens new avenues of intellectual adventure and stimulatesthe quest for more knowledge.\\n(iii)Researcher can better appreciate only through interpretation why his findings are whatthey are and can make others to understand the real significance of his research findings.\\n(iv)The interpretation of the findings of exploratory research study often results into hypothesesfor experimental research and as such interpretation is involved in the transition fromexploratory to experimental research. Since an exploratory study does not have a hypothesisto start with, the findings of such a study have to be interpreted on a post-factum basis in\\nwhich case the interpretation is technically described as ‘ post factum ’ interpretation.\\nTECHNIQUE OF INTERPRETATION\\nThe task of interpretation is not an easy job, rather it requires a great skill and dexterity on the part ofresearcher. Interpretation is an art that one learns through practice and experience. The researchermay, at times, seek the guidance from experts for accomplishing the task of interpretation.\\nThe technique of interpretation often involves the following steps:\\n(i) Researcher must give reasonable explanations of the relations which he has found and he\\nmust interpret the lines of relationship in terms of the underlying processes and must try tofind out the thread of uniformity that lies under the surface layer of his diversified researchfindings. In fact, this is the technique of how generalization should be done and concepts beformulated.\\n(ii)Extraneous information, if collected during the study, must be considered while interpretingthe final results of research study, for it may prove to be a key factor in understanding theproblem under consideration.\\n(iii) It is advisable, before embarking upon final interpretation, to consult someone having insight\\ninto the study and who is frank and honest and will not hesitate to point out omissions anderrors in logical argumentation. Such a consultation will result in correct interpretation and,thus, will enhance the utility of research results.\\n(iv)Researcher must accomplish the task of interpretation only after considering all relevantfactors affecting the problem to avoid false generalization. He must be in no hurry whileinterpreting results, for quite often the conclusions, which appear to be all right at thebeginning, may not at all be accurate.\\nPRECAUTIONS IN INTERPRETATION\\nOne should always remember that even if the data are properly collected and analysed, wronginterpretation would lead to inaccurate conclusions. It is, therefore, absolutely essential that the task346 Research Methodology\\nof interpretation be accomplished with patience in an impartial manner and also in correct perspective.\\nResearcher must pay attention to the following points for correct interpretation:\\n(i) At the outset, researcher must invariably satisfy himself that (a) the data are appropriate,\\ntrustworthy and adequate for drawing inferences; (b) the data reflect good homogeneity;and that (c) proper analysis has been done through statistical methods.\\n(ii)The researcher must remain cautious about the errors that can possibly arise in the processof interpreting results. Errors can arise due to false generalization and/or due to wronginterpretation of statistical measures, such as the application of findings beyond the rangeof observations, identification of correlation with causation and the like. Another majorpitfall is the tendency to affirm that definite relationships exist on the basis of confirmationof particular hypotheses. In fact, the positive test results accepting the hypothesis must beinterpreted as “being in accord” with the hypothesis, rather than as “confirming the validityof the hypothesis”. The researcher must remain vigilant about all such things so that falsegeneralization may not take place. He should be well equipped with and must know thecorrect use of statistical measures for drawing inferences concerning his study.\\n(iii) He must always keep in view that the task of interpretation is very much intertwined with\\nanalysis and cannot be distinctly separated. As such he must take the task of interpretationas a special aspect of analysis and accordingly must take all those precautions that oneusually observes while going through the process of analysis viz., precautions concerningthe reliability of data, computational checks, validation and comparison of results.\\n(iv) He must never lose sight of the fact that his task is not only to make sensitive observations\\nof relevant occurrences, but also to identify and disengage the factors that are initiallyhidden to the eye. This will enable him to do his job of interpretation on proper lines. Broadgeneralisation should be avoided as most research is not amenable to it because the coveragemay be restricted to a particular time, a particular area and particular conditions. Suchrestrictions, if any, must invariably be specified and the results must be framed within theirlimits.\\n(v) The researcher must remember that “ideally in the course of a research study, there should\\nbe constant interaction between initial hypothesis, empirical observation and theoreticalconceptions. It is exactly in this area of interaction between theoretical orientation andempirical observation that opportunities for originality and creativity lie.”\\n2 He must pay\\nspecial attention to this aspect while engaged in the task of interpretation.\\nSIGNIFICANCE OF REPORT WRITING\\nResearch report is considered a major component of the research study for the research task remainsincomplete till the report has been presented and/or written. As a matter of fact even the mostbrilliant hypothesis, highly well designed and conducted research study, and the most strikinggeneralizations and findings are of little value unless they are effectively communicated to others.The purpose of research is not well served unless the findings are made known to others. Researchresults must invariably enter the general store of knowledge. All this explains the significance of\\n2 Pauline V. Young, Scientific Social Surveys and Research, 4th ed., p. 488.Interpretation and Report Writing 347\\nwriting research report. There are people who do not consider writing of report as an integral part of\\nthe research process. But the general opinion is in favour of treating the presentation of researchresults or the writing of report as part and parcel of the research project. Writing of report is the laststep in a research study and requires a set of skills somewhat different from those called for inrespect of the earlier stages of research. This task should be accomplished by the researcher withutmost care; he may seek the assistance and guidance of experts for the purpose.\\nDIFFERENT STEPS IN WRITING REPORT\\nResearch reports are the product of slow, painstaking, accurate inductive work. The usual stepsinvolved in writing report are: (a) logical analysis of the subject-matter; (b) preparation of the finaloutline; (c) preparation of the rough draft; (d) rewriting and polishing; (c) preparation of the finalbibliography; and (f) writing the final draft. Though all these steps are self explanatory, yet a briefmention of each one of these will be appropriate for better understanding.\\nLogical analysis of the subject matter: It is the first step which is primarily concerned with the\\ndevelopment of a subject. There are two ways in which to develop a subject (a) logically and\\n(b) chronologically. The logical development is made on the basis of mental connections andassociations between the one thing and another by means of analysis. Logical treatment often consistsin developing the material from the simple possible to the most complex structures. Chronologicaldevelopment is based on a connection or sequence in time or occurrence. The directions for doing ormaking something usually follow the chronological order.\\nPreparation of the final outline: It is the next step in writing the research report “Outlines are the\\nframework upon which long written works are constructed. They are an aid to the logical organisation\\nof the material and a reminder of the points to be stressed in the report.”\\n3\\nPreparation of the rough draft: This follows the logical analysis of the subject and the preparation\\nof the final outline. Such a step is of utmost importance for the researcher now sits to write downwhat he has done in the context of his research study. He will write down the procedure adopted byhim in collecting the material for his study along with various limitations faced by him, the techniqueof analysis adopted by him, the broad findings and generalizations and the various suggestions hewants to offer regarding the problem concerned.\\nRewriting and polishing of the rough draft: This step happens to be most difficult part of all\\nformal writing. Usually this step requires more time than the writing of the rough draft. The careful\\nrevision makes the difference between a mediocre and a good piece of writing. While rewriting andpolishing, one should check the report for weaknesses in logical development or presentation. Theresearcher should also “see whether or not the material, as it is presented, has unity and cohesion;does the report stand upright and firm and exhibit a definite pattern, like a marble arch? Or does itresemble an old wall of moldering cement and loose brick.”\\n4 In addition the researcher should give\\ndue attention to the fact that in his rough draft he has been consistent or not. He should check themechanics of writing—grammar, spelling and usage.\\nPreparation of the final bibliography: Next in order comes the task of the preparation of the final\\nbibliography. The bibliography, which is generally appended to the research report, is a list of books\\n3 Elliott S.M. Gatner and Francesco Cordasco, Research and Report Writing, p. 37.\\n4 Ibid., p. 50.348 Research Methodology\\nin some way pertinent to the research which has been done. It should contain all those works which\\nthe researcher has consulted. The bibliography should be arranged alphabetically and may be dividedinto two parts; the first part may contain the names of books and pamphlets, and the second part maycontain the names of magazine and newspaper articles. Generally, this pattern of bibliography isconsidered convenient and satisfactory from the point of view of reader, though it is not the only wayof presenting bibliography. The entries in bibliography should be made adopting the following order:\\nFor books and pamphlets the order may be as under:\\n1. Name of author, last name first.\\n2. Title, underlined to indicate italics.\\n3. Place, publisher, and date of publication.\\n4. Number of volumes.\\nExample\\nKothari, C.R., Quantitative Techniques, New Delhi, Vikas Publishing House Pvt. Ltd., 1978.\\nFor magazines and newspapers the order may be as under:\\n1. Name of the author, last name first.\\n2. Title of article, in quotation marks.\\n3. Name of periodical, underlined to indicate italics.\\n4. The volume or volume and number.5. The date of the issue.\\n6. The pagination.\\nExample\\nRobert V. Roosa, “Coping with Short-term International Money Flows”, The Banker, London,\\nSeptember, 1971, p. 995.\\nThe above examples are just the samples for bibliography entries and may be used, but one\\nshould also remember that they are not the only acceptable forms. The only thing important is that,\\nwhatever method one selects, it must remain consistent.\\nWriting the final draft: This constitutes the last step. The final draft should be written in a concise\\nand objective style and in simple language, avoiding vague expressions such as “it seems”, “theremay be”, and the like ones. While writing the final draft, the researcher must avoid abstract terminologyand technical jargon. Illustrations and examples based on common experiences must be incorporatedin the final draft as they happen to be most effective in communicating the research findings toothers. A research report should not be dull, but must enthuse people and maintain interest and mustshow originality. It must be remembered that every report should be an attempt to solve someintellectual problem and must contribute to the solution of a problem and must add to the knowledgeof both the researcher and the reader.\\nLAYOUT OF THE RESEARCH REPORT\\nAnybody, who is reading the research report, must necessarily be conveyed enough about the studyso that he can place it in its general scientific context, judge the adequacy of its methods and thusInterpretation and Report Writing 349\\nform an opinion of how seriously the findings are to be taken. For this purpose there is the need of\\nproper layout of the report. The layout of the report means as to what the research report shouldcontain. A comprehensive layout of the research report should comprise (A) preliminary pages; (B)the main text; and (C) the end matter. Let us deal with them separately.\\n(A) Preliminary Pages\\nIn its preliminary pages the report should carry a title and date, followed by acknowledgements in\\nthe form of ‘Preface’ or ‘Foreword’. Then there should be a table of contents followed by list of\\ntables and illustrations so that the decision-maker or anybody interested in reading the report can\\neasily locate the required information in the report.\\n(B) Main Text\\nThe main text provides the complete outline of the research report along with all details. Title of theresearch study is repeated at the top of the first page of the main text and then follows the otherdetails on pages numbered consecutively, beginning with the second page. Each main section of thereport should begin on a new page. The main text of the report should have the following sections:(i) Introduction; (ii) Statement of findings and recommendations; (iii) The results; (iv) The implicationsdrawn from the results; and (v) The summary.\\n(i) Introduction: The purpose of introduction is to introduce the research project to the readers. It\\nshould contain a clear statement of the objectives of research i.e., enough background should be\\ngiven to make clear to the reader why the problem was considered worth investigating. A briefsummary of other relevant research may also be stated so that the present study can be seen in thatcontext. The hypotheses of study, if any, and the definitions of the major concepts employed in thestudy should be explicitly stated in the introduction of the report.\\nThe methodology adopted in conducting the study must be fully explained. The scientific reader\\nwould like to know in detail about such thing: How was the study carried out? What was its basicdesign? If the study was an experimental one, then what were the experimental manipulations? If thedata were collected by means of questionnaires or interviews, then exactly what questions wereasked (The questionnaire or interview schedule is usually given in an appendix)? If measurementswere based on observation, then what instructions were given to the observers? Regarding thesample used in the study the reader should be told: Who were the subjects? How many were there?How were they selected? All these questions are crucial for estimating the probable limits ofgeneralizability of the findings. The statistical analysis adopted must also be clearly stated. In additionto all this, the scope of the study should be stated and the boundary lines be demarcated. The variouslimitations, under which the research project was completed, must also be narrated.\\n(ii) Statement of findings and recommendations: After introduction, the research report must\\ncontain a statement of findings and recommendations in non-technical language so that it can be\\neasily understood by all concerned. If the findings happen to be extensive, at this point they should beput in the summarised form.350 Research Methodology\\n(iii) Results: A detailed presentation of the findings of the study, with supporting data in the form of\\ntables and charts together with a validation of results, is the next step in writing the main text of the\\nreport. This generally comprises the main body of the report, extending over several chapters. Theresult section of the report should contain statistical summaries and reductions of the data rather thanthe raw data. All the results should be presented in logical sequence and splitted into readily identifiablesections. All relevant results must find a place in the report. But how one is to decide about what isrelevant is the basic question. Quite often guidance comes primarily from the research problem andfrom the hypotheses, if any, with which the study was concerned. But ultimately the researcher mustrely on his own judgement in deciding the outline of his report. “Nevertheless, it is still necessary thathe states clearly the problem with which he was concerned, the procedure by which he worked onthe problem, the conclusions at which he arrived, and the bases for his conclusions.”\\n5\\n(iv) Implications of the results: Toward the end of the main text, the researcher should again put\\ndown the results of his research clearly and precisely. He should, state the implications that flowfrom the results of the study, for the general reader is interested in the implications for understandingthe human behaviour. Such implications may have three aspects as stated below:\\n(a) A statement of the inferences drawn from the present study which may be expected to\\napply in similar circumstances.\\n(b) The conditions of the present study which may limit the extent of legitimate generalizations\\nof the inferences drawn from the study.\\n(c) Thc relevant questions that still remain unanswered or new questions raised by the study\\nalong with suggestions for the kind of research that would provide answers for them.\\nIt is considered a good practice to finish the report with a short conclusion which summarises andrecapitulates the main points of the study. The conclusion drawn from the study should be clearlyrelated to the hypotheses that were stated in the introductory section. At the same time, a forecast ofthe probable future of the subject and an indication of the kind of research which needs to be done inthat particular field is useful and desirable.\\n(v) Summary: It has become customary to conclude the research report with a very brief summary,\\nresting in brief the research problem, the methodology, the major findings and the major conclusionsdrawn from the research results.\\n(C) End Matter\\nAt the end of the report, appendices should be enlisted in respect of all technical data such asquestionnaires, sample information, mathematical derivations and the like ones. Bibliography of sourcesconsulted should also be given. Index (an alphabetical listing of names, places and topics along withthe numbers of the pages in a book or report on which they are mentioned or discussed) shouldinvariably be given at the end of the report. The value of index lies in the fact that it works as a guideto the reader for the contents in the report.\\n5 Selltiz, Jahoda, Deutsch and Cook, Research Methods in Social Relations, p. 448.Interpretation and Report Writing 351\\nTYPES OF REPORTS\\nResearch reports vary greatly in length and type. In each individual case, both the length and the\\nform are largely dictated by the problems at hand. For instance, business firms prefer reports in theletter form, just one or two pages in length. Banks, insurance organisations and financial institutionsare generally fond of the short balance-sheet type of tabulation for their annual reports to theircustomers and shareholders. Mathematicians prefer to write the results of their investigations in theform of algebraic notations. Chemists report their results in symbols and formulae. Students ofliterature usually write long reports presenting the critical analysis of some writer or period or the likewith a liberal use of quotations from the works of the author under discussion. In the field of educationand psychology, the favourite form is the report on the results of experimentation accompanied bythe detailed statistical tabulations. Clinical psychologists and social pathologists frequently find itnecessary to make use of the case-history form.\\nNews items in the daily papers are also forms of report writing. They represent firsthand on-the-\\nscene accounts of the events described or compilations of interviews with persons who were on thescene. In such reports the first paragraph usually contains the important information in detail and thesucceeding paragraphs contain material which is progressively less and less important.\\nBook-reviews which analyze the content of the book and report on the author’s intentions, his\\nsuccess or failure in achieving his aims, his language, his style, scholarship, bias or his point of view.Such reviews also happen to be a kind of short report. The reports prepared by governmental bureaus,special commissions, and similar other organisations are generally very comprehensive reports onthe issues involved. Such reports are usually considered as important research products. Similarly,Ph.D. theses and dissertations are also a form of report-writing, usually completed by students inacademic institutions.\\nThe above narration throws light on the fact that the results of a research investigation can be\\npresented in a number of ways viz., a technical report, a popular report, an article, a monograph or attimes even in the form of oral presentation. Which method(s) of presentation to be used in a particularstudy depends on the circumstances under which the study arose and the nature of the results. Atechnical report is used whenever a full written report of the study is required whether for record-\\nkeeping or for public dissemination. A popular report is used if the research results have policy\\nimplications. We give below a few details about the said two types of reports:\\n(A) Technical Report\\nIn the technical report the main emphasis is on (i) the methods employed, (it) assumptions made inthe course of the study, (iii) the detailed presentation of the findings including their limitations andsupporting data.\\nA general outline of a technical report can be as follows:\\n1. Summary of results: A brief review of the main findings just in two or three pages.\\n2. Nature of the study: Description of the general objectives of study, formulation of the problem in\\noperational terms, the working hypothesis, the type of analysis and data required, etc.\\n3. Methods employed: Specific methods used in the study and their limitations. For instance, in\\nsampling studies we should give details of sample design viz., sample size, sample selection, etc.352 Research Methodology\\n4. Data:Discussion of data collected, their sources, characteristics and limitations. If secondary\\ndata are used, their suitability to the problem at hand be fully assessed. In case of a survey, the\\nmanner in which data were collected should be fully described.\\n5. Analysis of data and presentation of findings: The analysis of data and presentation of the\\nfindings of the study with supporting data in the form of tables and charts be fully narrated. This, in\\nfact, happens to be the main body of the report usually extending over several chapters.\\n6. Conclusions: A detailed summary of the findings and the policy implications drawn from the\\nresults be explained.\\n7. Bibliography: Bibliography of various sources consulted be prepared and attached.\\n8. Technical appendices: Appendices be given for all technical matters relating to questionnaire,\\nmathematical derivations, elaboration on particular technique of analysis and the like ones.9. Index:Index must be prepared and be given invariably in the report at the end.\\nThe order presented above only gives a general idea of the nature of a technical report; the order\\nof presentation may not necessarily be the same in all the technical reports. This, in other words,\\nmeans that the presentation may vary in different reports; even the different sections outlined abovewill not always be the same, nor will all these sections appear in any particular report.\\nIt should, however, be remembered that even in a technical report, simple presentation and ready\\navailability of the findings remain an important consideration and as such the liberal use of charts anddiagrams is considered desirable.\\n(B) Popular Report\\nThe popular report is one which gives emphasis on simplicity and attractiveness. The simplificationshould be sought through clear writing, minimization of technical, particularly mathematical, detailsand liberal use of charts and diagrams. Attractive layout along with large print, many subheadings,even an occasional cartoon now and then is another characteristic feature of the popular report.Besides, in such a report emphasis is given on practical aspects and policy implications.\\nWe give below a general outline of a popular report.\\n1. The findings and their implications: Emphasis in the report is given on the findings of most\\npractical interest and on the implications of these findings.\\n2. Recommendations for action: Recommendations for action on the basis of the findings of the\\nstudy is made in this section of the report.\\n3. Objective of the study: A general review of how the problem arise is presented along with the\\nspecific objectives of the project under study.\\n4. Methods employed: A brief and non-technical description of the methods and techniques used,\\nincluding a short review of the data on which the study is based, is given in this part of the report.\\n5. Results:This section constitutes the main body of the report wherein the results of the study are\\npresented in clear and non-technical terms with liberal use of all sorts of illustrations such as charts,\\ndiagrams and the like ones.\\n6. Technical appendices: More detailed information on methods used, forms, etc. is presented in\\nthe form of appendices. But the appendices are often not detailed if the report is entirely meant for\\ngeneral public.Interpretation and Report Writing 353\\nThere can be several variations of the form in which a popular report can be prepared. The only\\nimportant thing about such a report is that it gives emphasis on simplicity and policy implications from\\nthe operational point of view, avoiding the technical details of  all sorts to the extent possible.\\nORAL PRESENTATION\\nAt times oral presentation of the results of the study is considered effective, particularly in caseswhere policy recommendations are indicated by project results. The merit of this approach lies in thefact that it provides an opportunity for give-and-take decisions which generally lead to a betterunderstanding of the findings and their implications. But the main demerit of this sort of presentationis the lack of any permanent record concerning the research details and it may be just possible thatthe findings may fade away from people’s memory even before an action is taken. In order toovercome this difficulty, a written report may be circulated before the oral presentation and referredto frequently during the discussion. Oral presentation is effective when supplemented by variousvisual devices. Use of slides, wall charts and blackboards is quite helpful in contributing to clarity andin reducing the boredom, if any. Distributing a board outline, with a few important tables and chartsconcerning the research results, makes the listeners attentive who have a ready outline on which tofocus their thinking. This very often happens in academic institutions where the researcher discusseshis research findings and policy implications with others either in a seminar or in a group discussion.\\nThus, research results can be reported in more than one ways, but the usual practice adopted, in\\nacademic institutions particularly, is that of writing the Technical Report and then preparing severalresearch papers to be discussed at various forums in one form or the other. But in practical field andwith problems having policy implications, the technique followed is that of writing a popular report.Researches done on governmental account or on behalf of some major public or private organisationsare usually presented in the form of technical reports.\\nMECHANICS OF WRITING A RESEARCH REPORT\\nThere are very definite and set rules which should be followed in the actual preparation of theresearch report or paper. Once the techniques are finally decided, they should be scrupulously adheredto, and no deviation permitted. The criteria of format should be decided as soon as the materials forthe research paper have been assembled. The following points deserve mention so far as the mechanicsof writing a report are concerned:\\n1. Size and physical design: The manuscript should be written on unruled paper \\n812″ × 11″ in\\nsize. If it is to be written by hand, then black or blue-black ink should be used. A margin of at least\\none and one-half inches should be allowed at the left hand and of at least half an inch at the right handof the paper. There should also be one-inch margins, top and bottom. The paper should be neat andlegible. If the manuscript is to be typed, then all typing should be double-spaced on one side of thepage only except for the insertion of the long quotations.\\n2. Procedure: Various steps in writing the report should be strictly adhered (All such steps have\\nalready been explained earlier in this chapter).\\n3. Layout:Keeping in view the objective and nature of the problem, the layout of the report should\\nbe thought of and decided and accordingly adopted (The layout of the research report and various354 Research Methodology\\ntypes of reports have been described in this chapter earlier which should be taken as a guide for\\nreport-writing in case of a particular problem).\\n4. Treatment of quotations: Quotations should be placed in quotation marks and double spaced,\\nforming an immediate part of the text. But if a quotation is of a considerable length (more than four\\nor five type written lines) then it should be single-spaced and indented at least half an inch to the rightof the normal text margin.\\n5. The footnotes: Regarding footnotes one should keep in view the followings:\\n(a) The footnotes serve two purposes viz., the identification of materials used in quotations in\\nthe report and the notice of materials not immediately necessary to the body of the research\\ntext but still of supplemental value. In other words, footnotes are meant for cross references,citation of authorities and sources, acknowledgement and elucidation or explanation of apoint of view. It should always be kept in view that footnote is not an end nor a means ofthe display of scholarship. The modern tendency is to make the minimum use of footnotesfor scholarship does not need to be displayed.\\n(b) Footnotes are placed at the bottom of the page on which the reference or quotation which\\nthey identify or supplement ends. Footnotes are customarily separated from the textualmaterial by a space of half an inch and a line about one and a half inches long.\\n(c) Footnotes should be numbered consecutively, usually beginning with 1 in each chapter\\nseparately. The number should be put slightly above the line, say at the end of a quotation.At the foot of the page, again, the footnote number should be indented and typed a littleabove the line. Thus, consecutive numbers must be used to correlate the reference in thetext with its corresponding note at the bottom of the page, except in case of statisticaltables and other numerical material, where symbols such as the asterisk (*) or the like onemay be used to prevent confusion.\\n(d) Footnotes are always typed in single space though they are divided from one another by\\ndouble space.\\n6. Documentation style: Regarding documentation, the first footnote reference to any given work\\nshould be complete in its documentation, giving all the essential facts about the edition used. Suchdocumentary footnotes follow a general sequence. The common order may be described as under:\\n(i) Regarding the single-volume reference\\n1. Author’s name in normal order (and not beginning with the last name as in a bibliography)\\nfollowed by a comma;\\n2. Title of work, underlined to indicate italics;\\n3. Place and date of publication;\\n4. Pagination references (The page number).\\nExample\\nJohn Gassner , Masters of the Drama, New York: Dover Publications, Inc. 1954, p. 315.\\n(ii) Regarding multivolumed reference\\n1. Author’s name in the normal order;Interpretation and Report Writing 355\\n2. Title of work, underlined to indicate italics;\\n3. Place and date of publication;4. Number of volume;\\n5. Pagination references (The page number).\\n(iii) Regarding works arranged alphabetically\\nFor works arranged alphabetically such as encyclopedias and dictionaries, no pagination\\nreference is usually needed. In such cases the order is illustrated as under:\\nExample 1\\n“Salamanca,” Encyclopaedia Britannica, 14th Edition.\\nExample 2\\n“Mary Wollstonecraft Godwin,” Dictionary of national biography.\\nBut if there should be a detailed reference to a long encyclopedia article, volume andpagination reference may be found necessary.\\n(iv) Regarding periodicals reference\\n1. Name of the author in normal order;\\n2. Title of article, in quotation marks;3. Name of periodical, underlined to indicate italics;\\n4. Volume number;\\n5. Date of issuance;6. Pagination.\\n(v) Regarding anthologies and collections reference\\nQuotations from anthologies or collections of literary works must be acknowledged not\\nonly by author, but also by the name of the collector.\\n(vi) Regarding second-hand quotations reference\\nIn such cases the documentation should be handled as follows:\\n1. Original author and title;\\n2. “quoted or cited in,”;\\n3. Second author and work.\\nExample\\nJ.F. Jones, Life in Ploynesia, p. 16, quoted in History of the Pacific Ocean area, by R.B. Abel,\\np.191.\\n(vii) Case of multiple authorship\\nIf there are more than two authors or editors, then in the documentation the name of only the first\\nis given and the multiple authorship is indicated by “et al.” or “and others”.\\nSubsequent references to the same work need not be so detailed as stated above. If the work is\\ncited again without any other work intervening, it may be indicated as ibid, followed by a comma and356 Research Methodology\\nthe page number. A single page should be referred to as p., but more than one page be referred to as\\npp. If there are several pages referred to at a stretch, the practice is to use often the page number,for example, pp. 190ff, which means page number 190 and the following pages; but only for page 190and the following page ‘190f’. Roman numerical is generally used to indicate the number of thevolume of a book. Op. cit. (opera citato, in the work cited) or Loc. cit. (loco citato, in the place cited)are two of the very convenient abbreviations used in the footnotes. Op. cit. or Loc. cit. after thewriter’s name would suggest that the reference is to work by the writer which has been cited indetail in an earlier footnote but intervened by some other references.\\n7. Punctuation and abbreviations in footnotes: The first item after the number in the footnote is\\nthe author’s name, given in the normal signature order. This is followed by a comma. After the\\ncomma, the title of the book is given: the article (such as “A”, “An”, “The” etc.) is omitted and onlythe first word and proper nouns and adjectives are capitalized. The title is followed by a comma.Information concerning the edition is given next. This entry is followed by a comma. The place ofpublication is then stated; it may be mentioned in an abbreviated form, if the place happens to be afamous one such as Lond. for London, N.Y. for New York, N.D. for New Delhi and so on. Thisentry is followed by a comma. Then the name of the publisher is mentioned and this entry is closedby a comma. It is followed by the date of publication if the date is given on the title page. If the dateappears in the copyright notice on the reverse side of the title page or elsewhere in the volume, thecomma should be omitted and the date enclosed in square brackets [c 1978], [1978]. The entry isfollowed by a comma. Then follow the volume and page references and are separated by a commaif both are given. A period closes the complete documentary reference. But one should rememberthat the documentation regarding acknowledgements from magazine articles and periodical literaturefollow a different form as stated earlier while explaining the entries in the bibliography.\\nCertain English and Latin abbreviations are quite often used in bibliographies and footnotes to\\neliminate tedious repetition. The following is a partial list of the most common abbreviations frequentlyused in report-writing (the researcher should learn to recognise them as well as he should learn touse them):\\nanon., anonymous\\nante., before\\nart., article\\naug., augmented\\nbk., book\\nbull., bulletin\\ncf., compare\\nch., chapter\\ncol., column\\ndiss., dissertation\\ned., editor, edition, edited.\\ned. cit., edition cited\\ne.g., exempli gratia: for example\\neng., enlarged\\net.al., and othersInterpretation and Report Writing 357\\net seq., et sequens: and the following\\nex., example\\nf., ff., and the following\\nfig(s)., figure(s)\\nfn., footnote\\nibid., ibidem: in the same place (when two or more successive footnotes refer to the\\nsame work, it is not necessary to repeat complete reference for the second\\nfootnote. Ibid. may be used. If different pages are referred to, paginationmust be shown).\\nid., idem: the same\\nill., illus., orillust(s). illustrated, illustration(s)\\nIntro., intro., introduction\\nl, or ll, line(s)\\nloc. cit., in the place cited; used as op.cit., (when new reference\\nloco citato: is made to the same pagination as cited in the previous note)MS., MSS., Manuscript or ManuscriptsN.B., nota bene: note welln.d., no date\\nn.p., no place\\nno pub., no publisher\\nno(s)., number(s)\\no.p., out of print\\nop. cit: in the work cited (If reference has been made to a work\\nopera citato and new reference is to be made, ibid., may be used, if intervening\\nreference has been made to different works, op.cit. must be used. Thename of the author must precede.\\np. or pp., page(s)\\npassim: here and there\\npost: after\\nrev., revised\\ntr., trans., translator, translated, translation\\nvid or vide: see, refer to\\nviz., namely\\nvol. or vol(s)., volume(s)vs., versus: against\\n8. Use of statistics, charts and graphs: A judicious use of statistics in research reports is often\\nconsidered a virtue for it contributes a great deal towards the clarification and simplification of the\\nmaterial and research results. One may well remember that a good picture is often worth more than358 Research Methodology\\na thousand words. Statistics are usually presented in the form of tables, charts, bars and line-graphs\\nand pictograms. Such presentation should be self explanatory and complete in itself. It should besuitable and appropriate looking to the problem at hand. Finally, statistical presentation should be neatand attractive.\\n9. The final draft: Revising and rewriting the rough draft of the report should be done with great\\ncare before writing the final draft. For the purpose, the researcher should put to himself questions\\nlike: Are the sentences written in the report clear? Are they grammatically correct? Do they saywhat is meant’? Do the various points incorporated in the report fit together logically? “Having atleast one colleague read the report just before the final revision is extremely helpful. Sentences thatseem crystal-clear to the writer may prove quite confusing to other people; a connection that hadseemed self evident may strike others as a non-sequitur. A friendly critic, by pointing out passages\\nthat seem unclear or illogical, and perhaps suggesting ways of remedying the difficulties, can be aninvaluable aid in achieving the goal of adequate communication.”\\n6\\n10. Bibliography: Bibliography should be prepared and appended to the research report as discussed\\nearlier.\\n11. Preparation of the index: At the end of the report, an index should invariably be given, the\\nvalue of which lies in the fact that it acts as a good guide, to the reader. Index may be prepared both\\nas subject index and as author index. The former gives the names of the subject-topics or conceptsalong with the number of pages on which they have appeared or discussed in the report, whereas thelatter gives the similar information regarding the names of authors. The index should always bearranged alphabetically. Some people prefer to prepare only one index common for names of authors,\\nsubject-topics, concepts and the like ones.\\nPRECAUTIONS FOR WRITING RESEARCH REPORTS\\nResearch report is a channel of communicating the research findings to the readers of the report. A\\ngood research report is one which does this task efficiently and effectively. As such it must beprepared keeping the following precautions in view:\\n1. While determining the length of the report (since research reports vary greatly in length),\\none should keep in view the fact that it should be long enough to cover the subject but shortenough to maintain interest. In fact, report-writing should not be a means to learning moreand more about less and less.\\n2. A research report should not, if this can be avoided, be dull; it should be such as to sustain\\nreader’s interest.\\n3. Abstract terminology and technical jargon should be avoided in a research report. The\\nreport should be able to convey the matter as simply as possible. This, in other words,means that report should be written in an objective style in simple language, avoidingexpressions such as “it seems,” “there may be” and the like.\\n4. Readers are often interested in acquiring a quick knowledge of the main findings and as\\nsuch the report must provide a ready availability of the findings. For this purpose, charts,\\n6 Claire Selltiz and others, Research Methods in Social Relations rev., Methuen & Co. Ltd., London, 1959, p. 454.Interpretation and Report Writing 359\\ngraphs and the statistical tables may be used for the various results in the main report in\\naddition to the summary of important findings.\\n5. The layout of the report should be well thought out and must be appropriate and in accordance\\nwith the objective of the research problem.\\n6. The reports should be free from grammatical mistakes and must be prepared strictly in\\naccordance with the techniques of composition of report-writing such as the use of quotations,footnotes, documentation, proper punctuation and use of abbreviations in footnotes and thelike.\\n7. The report must present the logical analysis of the subject matter. It must reflect a structure\\nwherein the different pieces of analysis relating to the research problem fit well.\\n8. A research report should show originality and should necessarily be an attempt to solve\\nsome intellectual problem. It must contribute to the solution of a problem and must add tothe store of knowledge.\\n9. Towards the end, the report must also state the policy implications relating to the problem\\nunder consideration. It is usually considered desirable if the report makes a forecast of theprobable future of the subject concerned and indicates the kinds of research still needs tobe done in that particular field.\\n10. Appendices should be enlisted in respect of all the technical data in the report.\\n11. Bibliography of sources consulted is a must for a good report and must necessarily be\\ngiven.\\n12. Index is also considered an essential part of a good report and as such must be prepared\\nand appended at the end.\\n13. Report must be attractive in appearance, neat and clean, whether typed or printed.\\n14. Calculated confidence limits must be mentioned and the various constraints experienced in\\nconducting the research study may also be stated in the report.\\n15. Objective of the study, the nature of the problem, the methods employed and the analysis\\ntechniques adopted must all be clearly stated in the beginning of the report in the form of\\nintroduction.\\nCONCLUSION\\nIn spite of all that has been stated above, one should always keep in view the fact report-writing is anart which is learnt by practice and experience, rather than by mere doctrination.\\nQuestions\\n1.Write a brief note on the ‘task of interpretation’ in the context of research methodology.\\n2.“Interpretation is a fundamental component of research process”, Explain. Why so?\\n3.Describe the precautions that the researcher should take while interpreting his findings.\\n4.“Interpretation is an art of drawing inferences, depending upon the skill of the researcher”. Elucidate thegiven statement explaining the technique of interpretation.360 Research Methodology\\n5.“It is only through interpretation the researcher can expose the relations and processes that underlie his\\nfindings”. Explain, giving examples.\\n6.Explain the significance of a research report and narrate the various steps involved in writing such areport.\\n7.Describe, in brief, the layout of a research report, covering all relevant points.\\n8.Write a short note on ‘Documentation’ in the context of a research report.\\n9.Mention the different types of report, particularly pointing out the difference between a technical reportand a popular report.\\n10.Explain the technique and importance of oral presentation of research findings. Is only oral presentationsufficient? If not, why?\\n11.(a) What points will you keep in mind while preparing a research report? Explain.\\n(b)What are the different forms in which a research work may be reported. Describe.\\n(M. Phil. Exam. (EAFM) 1979, Uni. of Rajasthan )\\n12.“We can teach methods of analysis, yet any extensive research... requires something equally important:\\nan organisation or synthesis which provides the essential structure into which the pieces of analysis fit.”Examine this statement and show how a good research report may be prepared.\\n(M. Phil. Exam. (EAFM) 1978, Uni. of Rajasthan )\\n13.Write short notes on the following:\\n(a) The techniques of writing report;\\n(b) Characteristics of a good research report;\\n(c) Bibliography and its importance in context of research report;\\n(d) Rewriting and polishing of report.\\n14.“Report writing is more an art that hinges upon practice and experience”. Discuss.The Computer: Its Role in Research 361\\n15\\nThe Computer:\\nIts Role in Research\\nINTRODUCTION\\nProblem solving is an age old activity. The development of electronic devices, specially the computers,\\nhas given added impetus to this activity. Problems which could not be solved earlier due to sheeramount of computations involved can now be tackled with the aid of computers accurately and\\nrapidly. Computer is certainly one of the most versatile and ingenious developments of the modern\\ntechnological age. Today people use computers in almost every walk of life. No longer are they justbig boxes with flashing lights whose sole purpose is to do arithmetic at high speed but they make useof studies in philosophy, psychology, mathematics and linguistics to produce output that mimics thehuman mind. The sophistication in computer technology has reached the stage that it will not belonger before it is impossible to tell whether you are talking to man or machine. Indeed, the advancementin computers is astonishing.\\nTo the researcher, the use of computer to analyse complex data has made complicated research\\ndesigns practical. Electronic computers have by now become an indispensable part of researchstudents in the physical and behavioural sciences as well as in the humanities. The research student,in this age of computer technology, must be exposed to the methods and use of computers. A basicunderstanding of the manner in which a computer works helps a person to appreciate the utility ofthis powerful tool. Keeping all this in view, the present chapter introduces the basics of computers,especially it. answers questions like: What is a computer? How does it function? How does onecommunicate with it? How does it help in analysing data?\\nTHE COMPUTER AND COMPUTER TECHNOLOGY\\nA computer, as the name indicates, is nothing but a device that computes. In this sense, any device,however crude or sophisticated, that enables one to carry out mathematical manipulations becomesa computer. But what has made this term conspicuous today and, what we normally imply when wespeak of computers, are electronically operating machines which are used to carry out computations.362 Research Methodology\\nIn brief, computer is a machine capable of receiving, storing, manipulating and yielding information\\nsuch as numbers, words, pictures.\\nThe computer can be a digital computer or it can be a analogue computer. A digital computer\\nis one which operates essentially by counting (using information, including letters and symbols, incoded form) where as the analogue computer operates by measuring rather than counting. Digital\\ncomputer handles information as strings of binary numbers i.e., zeros and ones, with the help ofcounting process but analogue computer converts varying quantities such as temperature and pressureinto corresponding electrical voltages and then performs specified functions on the given signals.Thus, analogue computers are used for certain specialised engineering and scientific applications.Most computers are digital, so much so that the word computer is generally accepted as beingsynonymous with the term ‘digital computer’.\\nComputer technology has undergone a significant change over a period of four decades. The\\npresent day microcomputer is far more powerful and costs very little, compared to the world’s firstelectronic computer viz. Electronic Numerical Integrator and Calculator (ENIAC) completed in1946. The microcomputer works many times faster, is thousands of times more reliable and has alarge memory.\\nThe advances in computer technology are usually talked in terms of ‘generations’.\\n* Today we\\nhave the fourth generation computer in service and efforts are being made to develop the fifthgeneration computer, which is expected to be ready by 1990. The first generation computer started\\nin 1945 contained 18000 small bottle-sized valves which constituted its central processing unit (CPU).This machine did not have any facility for storing programs and the instructions had to be fed into it\\nby a readjustment of switches and wires. The second generation computer found the way for\\ndevelopment with the invention of the transistor in 1947. The transistor replaced the valve in all\\nelectronic devices and made them much smaller and more reliable. Such computers appeared in themarket in the early sixties. The third generation computer followed the invention of integrated\\ncircuit (IC) in 1959. Such machines, with their CPU and main store made of IC chips, appeared inthe market in the second half of the sixties. The fourth generation computers owe their birth to the\\nadvent of microprocessor—the king of chips—in 1972. The use of microprocessor as CPU in acomputer has made real the dream of ‘computer for the masses’. This device has enabled thedevelopment of microcomputers, personal computers, portable computers and the like. The fifth\\ngeneration computer, which is presently in the developing stage, may use new switch (such as the\\nHigh Electron Mobility Transistor) instead of the present one and it may herald the era ofsuperconducting computer. It is said that fifth generation computer will be 50 times or so more fasterthan the present day superfast machines.\\nSo far as input devices in computers are concerned, the card or tape-based data entry system\\nhas almost been replaced by direct entry devices, such as Visual Display Unit (VDU) which consistof a TV-like screen and a typewriter-like key board which is used for feeding data into the computer.Regarding output devices, the teleprinter has been substituted by various types of low-cost highspeed printers. VDU is also used as an output device. For storing data, the magnetic tapes and discs\\n* (i) First generation computers were those produced between 1945–60 such as IBM 650, IBM 701.\\n(ii)Second generation computers were those produced between 1960–65 such as IBM 1401 Honeywell 40.\\n(iii)Third generation computers were those produced between 1965–70 such as IBM System 360, 370.\\n(iv)Fourth generation computers are those produced between 1971 to this date such as IBM 3033, HP 3000,Burroughs B 7700.The Computer: Its Role in Research 363\\nare being replaced by devices such as bubble memories and optical video discs. In brief, computer\\ntechnology has become highly sophisticated and is being developed further at a very rapid speed.\\nTHE COMPUTER SYSTEM\\nIn general, all computer systems can be described as containing some kind of input devices, the CPUand some kind of output devices. Figure 15.1 depicts the components of a computer system and theirinter-relationship:\\nFig. 15.1\\nThe function of the input-output devices is to get information into, and out of, the CPU. The input\\ndevices translate the characters into binary, understandable by the CPU, and the output devicesretranslate them back into the familiar character i.e., in a human readable form. In other words, thepurpose of the input-output devices is to act as translating devices between our external world andthe internal world of the CPU i.e., they act as an interface between man and the machine. So far asCPU is concerned, it has three segments viz. (i) internal storage, (ii) control unit, and (iii) arithmeticlogical unit. When a computer program or data is input into the CPU, it is in fact input into the internalstorage of the CPU. The control unit serves to direct the sequence of computer system operation. Itsfunction extends to the input and output devices as well and does not just remain confined to thesequence of operation within the CPU. The arithmetic logical unit is concerned with performing thearithmetic operations and logical comparisons designated in the computer program.\\nIn terms of overall sequence of events, a computer program is input into the internal storage and\\nthen transmitted to the control unit, where it becomes the basis for overall sequencing and control ofcomputer system operations. Data that is input into the internal storage of the CPU is available forCentral Processing Unit\\n(CPU)\\nInstruction or data flow\\nControl functionControl Unit\\n(Interprets the computer\\nprogramme.Directs theoperation of all componentsand units of the system)\\nInternal Storage\\n(Holds the computer programme\\nand data, and makes themavailable for processing)Input Devices\\n(Enters the computer\\nprogramme and datainto internal storage)Output Devices\\n(Records result\\nreceived frominternal storage)\\nArithmetic-Logical Unit\\n(Performs all arithmetic\\noperations and logicalcomparisons)364 Research Methodology\\nprocessing by the arithmetic logical unit, which conveys the result of the calculations and comparisons\\nback to the internal storage. After the designated calculations and comparisons have been completed,output is obtained from the internal storage of the CPU.\\nIt would be appropriate to become familiar with the following terms as well in context of computers:\\n(a)Hardware: All the physical components (such as CPU, Input-output devices, storage devices,\\netc.) of computer are collectively called hardware.\\n(b)Software: It consists of computer programs written by the user which allow the computer\\nto execute instructions.\\n(c)Firmware: It is that software which is incorporated by the manufacturer into the electronic\\ncircuitry of computer.\\n(d)System software: It is that program which tells the computer how to function. It is also\\nknown as operating software and is normally supplied by the computer manufacturer.\\n(e)Application software: It is that program which tells the computer how to perform specific\\ntasks such as preparation of company pay roll or inventory management. This software iseither written by the user himself or supplied by ‘software houses’, the companies whosebusiness is to produce and sell software.\\n(f)Integrated circuit (IC): It is a complete electronic circuit fabricated on a single piece of\\npure silicon. Silicon is the most commonly used semiconductor—a material which is neithera good conductor of electricity nor a bad one. An IC may be small-scale, medium-scale ora large-scale depending upon the number of electronic components fabricated on the chip.\\n(g)Memory chips: These ICs form the secondary memory or storage of the computer. Theyhold data and instructions not needed immediately by the main memory contained in theCPU.\\n(h)Two-state devices: The transistors on an IC Chip take only two states—they are either on\\nor off, conducting or non-conducting. The on-state is represented by 1 and the off-state byzero. These two binary digits are called bits. A string of eight bits is termed byte and agroup of bits constitute a word. A chip is called 8-bit, 16-bit, 32-bit and so on, depending onthe number of bits contained in its standard word.\\nIMPORTANT CHARACTERISTICS\\nThe following characteristics of computers are note worthy:\\n(i)Speed: Computers can perform calculations in just a few seconds that human beings\\nwould need weeks to do by hand. This has led to many scientific projects which werepreviously impossible.\\n(ii)Diligence:  Being a machine, a computer does not suffer from the human traits of tireness\\nand lack of concentration. If two million calculations have to be performed, it will performthe two millionth with exactly the same accuracy and speed as the first.\\n(iii)Storage: Although the storage capacity of the present day computer is much more than its\\nearlier counterpart but even then the internal memory of the CPU is only large enough toretain a certain amount of information just as the human brain selects and retains what itfeels to be important and relegates unimportant details to the back of the mind or justThe Computer: Its Role in Research 365\\nforgets them. Hence, it is impossible to store all types of information inside the computer\\nrecords. If need be, all unimportant information/data can be stored in auxiliary storagedevices and the same may be brought into the main internal memory of the computer, asand when required for processing.\\n(iv)Accuracy: The computer’s accuracy is consistently high. Errors in the machinery can\\noccur but, due to increased efficiency in error-detecting techniques, these seldom lead tofalse results. Almost without exception, the errors in computing are due to human ratherthan to technological weaknesses, i.e., due to imprecise thinking by the programmer or dueto inaccurate data or due to poorly designed systems.\\n(v)Automation: Once a program is in the computer’s memory, all that is needed is the individual\\ninstructions to it which are transferred one after the other, to the control unit for execution.The CPU follows these instructions until it meets a last instruction which says ‘stop programexecution’.\\n(vi)Binary digits: Computers use only the binary number system (a system in which all the\\nnumbers are represented by a combination of two digits—one and zero) and thus operatesto the base of two, compared to the ordinary decimal arithmetic which operates on a baseof ten. (Binary system has been described in further details under separate heading in thischapter.) Computers use binary system because the electrical devices can understand only‘on’ (1) or ‘off’ (0).\\nTHE BINARY NUMBER SYSTEM\\nAn arithmetic concept which uses two levels, instead of ten, but operates on the same logic is calledthe binary system. The binary system uses two symbols ‘0’ and ‘1’, known as bits, to form numbers.The base of this number system is 2. The system is called binary because it allows only two symbolsfor the formation of numbers. Binary numbers can be constructed just like decimal numbers exceptthat the base is 2 instead of 10.\\nFor example,\\n523 (decimal) = 5 × 10\\n2 + 2 × 101 + 3 × 100\\nSimilarly,\\n      111 (binary) = 1 × 22 + 1 × 21 + 1 × 20 = 7 (decimal)\\nThus, in the example, we see that in the decimal system, the first place is for 1s, 2nd place is for 10sand the 3rd place is for 100. On the other hand, in the binary system, the factor being 2 instead of 10,the first place is still for 1s but the 2nd place is for 2s, the 3rd for 4s, the 4th for 8s and so on.\\nDecimal to Binary Conversion: A positive decimal integer can be easily converted to equivalent\\nbinary form by repeated division by 2. The method works as follows:\\nStart by dividing the given decimal integer by 2. Let R\\n1 be the remainder and ql the quotient.\\nNext, divide ql by 2 and let R2 and q2 be the remainder and quotient respectively. Continue this\\nprocess of division by 2 until a 0 is obtained as quotient. The equivalent binary number can be formed\\nby arranging the remainders as\\nRk Rk –1 ... R1\\nwhere Rk and R1 are the last and the first remainders respectively, obtained by the division process.366 Research Methodology\\nIllustration 1\\nFind the binary equivalents of 26 and 45.\\nSolution: Table for conversion of 26 into its Binary equivalent:\\nNumber to be Quotient Remainder\\ndivided by 2\\n26 13 0\\n13 6 1\\n63 0\\n31 1\\n10 1\\nCollecting the remainders obtained in the above table we find that\\n26(decimal) =11010 (binary)\\nor (26)10 = (11010)2\\nSimilarly, we can find the binary equivalent of 45 as under:\\nTable 15.1\\nNumber to be Quotient Remainder\\ndivided by 2\\n45 22 1\\n22 11 0\\n11 5 1\\n52 121 0\\n10 1\\nThus, we have (45)10 = (101101)2\\ni.e., the binary equivalent of 45 is 101101.\\nAlternative method: Another simple method for decimal to binary conversion is to first express the\\ngiven integer as a sum of powers of 2, written in ascending order. For example,\\n26 = 16 + 8 + 0 + 2 + 0 = 1 × 24 + 1 × 23 + 0 × 22 + 1 × 21 + 0 × 20\\nThen collect the multipliers of the powers to form the binary equivalent. For 26, we get, from the\\nabove mentioned expansion 11010 as the binary equivalent. This alternative method is convenient forconverting small decimal integers by hand.\\nBinary to Decimal Conversion: A simple method for converting a binary number to its decimal\\nequivalent is known as double-babble method. This can be described as follows:The Computer: Its Role in Research 367\\nBegin the conversion process by doubling the leftmost bit of the given number and add to it the bit\\nat its right. Then again double the sum and add to it the third bit from the left. Proceed in thismanner till all the bits have been considered. The final sum obtained by repeated doubling andadding is the desired decimal equivalent.\\nIllustration 2\\nConvert 1101 to its decimal equivalent using the double-babble method.Solution:\\n1. Doubling the leftmost bit we get 2.2. Adding to it the bit on its right we get 2 + 1 = 33. Doubling again the number obtained we get 6\\n4. Adding to it the next bit we get 6 + 0 = 6\\n5. Again doubling we get 126. Finally adding the last bit we get 12 + 1 = 13\\nThus, we have (1101)\\n2 = (13)10\\nIn other words, the decimal equivalent of binary 1101 is 13.\\n(Conversion of real number to binary number is also possible but it involves little bit more\\ncomplicated conversion process. Those interested may read any binary system book.)\\nComputations in Binary System\\n(a) Binary addition: Binary addition is just like decimal addition except that the rules are much\\nsimpler. The binary addition rules are as shown below:\\n0011\\n+ 0+  1+  0+  1\\n011 1 0\\nNote that sum of 1 and 1 is written as ‘10’ (a zero sum with a 1 carry) which is the equivalent of\\ndecimal digit ‘2’. We can now look at two examples of binary additions which make use of the aboverules.\\nIllustration 3\\nAdd 1010 and 101.\\nSolution:\\nBinary Decimal equivalent\\n1010 (10)\\n+101 +(5)\\n1111 (15)\\nIllustration 4Add 10111000 and 111011.368 Research Methodology\\nSolution:\\n                   Carry 111                Carry 11\\n10111000 184\\n+ 111011 + 59\\n11110011 243\\nIn Illustration 4, we find a new situation (1 + 1 + 1) brought about by the 1 carry. However, we\\ncan still handle this by using the four combinations already mentioned. We add the digits in turn.\\n1+ 1= 10 (a zero sum with a 1 carry). The third 1 is now added to this result to obtain 11 (a 1 sumwith a 1 carry).\\nThe computer performs all the other arithmetical operations (viz. ×, –, +) by a form of addition.\\nThis is easily seen in the case of multiplication, e.g., 6 × 8 may be thought of as essentially beingdetermined by evaluating, with necessary carry overs, 8 + 8 + 8 + 8 + 8 + 8. This idea of repeatedaddition may seem to be a longer way of doing things, but remember that computer is well suited tocarry out the operation at great speed. Subtraction and division are handled essentially by additionusing the principle of complementing.\\n(b) Complementary subtraction: Three steps are involved in this method:\\nStep 1. Find the ones complement of the number you are subtracting;\\nStep 2. Add this to number from which you are taking away;Step 3. If there is a carry of 1 add it to obtain the result; if there is no carry, add 0, recomplement\\nand attach a negative sign to obtain the result.\\nFollowing two examples illustrate this method.\\nIllustration 5Subtract 10 from 25.Solution:\\nDecimal Binary number According to complementary method\\nnumber\\n25 11001 11001\\nSubtract 10 01010 Step 1 + 10101 (Ones complement of 01010)\\n15 Step 2 101110Step 3 1 (add the carry of 1)\\nResult 1111 Its decimal equivalent is 15.\\nIllustration 6\\nSubtract 72 from 14.The Computer: Its Role in Research 369\\nSolution:\\nDecimal Binary According to complementary method\\nnumber number\\n14 0001110 0001110\\nSubtract 72 1001000 Step 1. + 0110111 (ones complement of 1001000)\\n–58 Step 2. 01000101\\nStep 3. 0 (add 0 as no carry)\\n1000101\\nResult – 0111010 (recomplement and attach a\\nnegative sign). Its decimalequivalent is –58.\\nThe computer performs the division operation essentially by repeating this complementary\\nsubtraction method. For example, 45 \\n÷ 9 may be thought of as 45 – 9 = 36 – 9 = 27 – 9 = 18 – 9\\n=9 – 9 = 0 (minus 9 five times).\\nBinary Fractions\\nJust as we use a decimal point to separate the whole and decimal fraction parts of a decimal number,\\nwe can use a binary point in binary numbers to separate the whole and fractional parts. The binaryfraction can be converted into decimal fraction as shown below:\\n0.101 (binary) = (1 × 2\\n–1) + (0 × 2–2)+ (1 × 2–3)\\n= 0.5 + 0.0 + 0.125\\n= 0.625 (decimal)\\nTo convert the decimal fraction to binary fraction, the following rules are applied:\\n(i) Multiply the decimal fraction repeatedly by 2. The whole number part of the first multiplication\\ngives the first 1 or 0 of the binary fraction;\\n(ii)The fractional part of the result is carried over and multiplied by 2;\\n(iii)The whole number part of the result gives the second 1 or 0 and so on.\\nIllustration 7Convert 0.625 into its equivalent binary fraction.\\nSolution:\\nApplying the above rules, this can be done as under:\\n0.625 × 2 = 1.250  \\n→ 1\\n0.250 × 2 = 0.500  → 0\\n0.500 × 2 = 1.000  → 1\\nHence, 0.101 is the required binary equivalent.370 Research Methodology\\nIllustration 8\\nConvert 3.375 into its equivalent binary number.Solution:\\nThis can be done in two stages. First (3)\\n10 = (11)2 as shown earlier. Secondly, (0.375)10 = (0.011)2 as\\nshown above. Hence, the required binary equivalent is 11.011.\\nFrom all this above description we find how computer arithmetic is based on addition. Exactly\\nhow this simplifies matters can only be understood in the context of binary (not in decimal). The\\nnumber of individual steps may indeed be increased because all computer arithmetic is reduced toaddition, but the computer can carry out binary additions at such great speed that this is not adisadvantage.\\nCOMPUTER APPLICATIONS\\nAt present, computers are widely used for varied purposes. Educational, commercial, industrial,administrative, transport, medical, social financial and several other organisations are increasinglydepending upon the help of computers to some degree or the other. Even if our work does not involvethe use of computers in our everyday work, as individuals, we are affected by them. “The motorists,the air passenger, hospital patients and those working in large departmental stores, are some of thepeople for whom computers process information. Everyone who pays for electricity or telephone hastheir bills processed by computers. Many people who are working in major organisations and receivemonthly salary have their salary slips prepared by computers. Thus, it is difficult to find anyone whoin some way or the other does not have some information concerning them processed by computer”.\\n1\\n“Computers can be used by just about anyone: doctors, policemen, pilots, scientists, engineers andrecently even house-wives. Computers are used not only in numeric applications but also in non-numeric applications such as proving theorems, playing chess, preparing menu, matrimonial match-making and so on. Without computers we might not have achieved a number of things. For example,man could not have landed on the moon nor could he have launched satellites. We might not havebuilt 100 storied buildings or high speed trains and planes.”\\n2\\nThe following table depicts some of the important applications and uses of computers:\\nTable 15.2\\nApplications in Some of the various uses\\n1. Education (i) Provide a large data bank of information;\\n(ii)Aid to time-tabling;\\n(iii)Carry out lengthy or complex calculations;\\n(iv)Assist teaching and learning processes;\\n(v) Provide students’ profiles;\\n(vi)Assist in career guidance.\\n1 N. Subramanian, “Introduction to Computers”, Tata McGraw-Hill Publishing Company Ltd., New Delhi, 1986,\\np. 192.\\n2 Ibid., p. 192–93.Contd.\\n○○○○○○○○○○○○○○○ ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○The Computer: Its Role in Research 371\\nApplications in Some of the various uses\\n2. Commerce (i)Assist the production of text material (known as word processing)\\nsuch as reports, letters, circulars etc.\\n(ii)Handle payroll of personnel, office accounts, invoicing, recordskeeping, sales analysis, stock control and financial forecasting.\\n3. Banks and Financial (i) Cheque handling;\\ninstitutions (ii)Updating of accounts;\\n(iii)Printing of customer statements;\\n(iv)Interest calculations.\\n4. Management (i) Planning of new enterprises;\\n(ii)Finding the best solution from several options;\\n(iii)Helpful in inventory management, sales forecasting andproduction planning;\\n(iv)Useful in scheduling of projects.\\n5. Industry (i) In process control;\\n(ii) In production control;\\n(iii)Used for load control by electricity authorities;\\n(iv)Computer aided designs to develop new products.\\n6. Communications (i) Helpful in electronic mail;\\nand Transportation (ii)Useful in aviation: Training of pilots, seat reservations, provideinformation to pilots about weather conditions;\\n(iii)Facilitate routine jobs such as crew schedules, time-tables,\\nmaintenance schedules, safety systems, etc.;\\n(iv)Helpful to railways, shipping companies;\\n(v) Used in traffic control and also in space flight.\\n7. Scientific Research (i) Model processing;\\n(ii)Performing computations;\\n(iii)Research and data analysis.\\n8. The homes (i) Used for playing games such as chess, draughts, etc.;\\n(ii) Can be used as an educational aid;\\n(iii)Home management is facilitated.\\nCOMPUTERS AND RESEARCHERS\\nPerforming calculations almost at the speed of light, the computer has become one of the most useful\\nresearch tools in modern times. Computers are ideally suited for data analysis concerning largeresearch projects. Researchers are essentially concerned with huge storage of data, their fasterretrieval when required and processing of data with the aid of various techniques. In all these operations,computers are of great help. Their use, apart expediting the research work, has reduced humandrudgery and added to the quality of research activity.372 Research Methodology\\nResearchers in economics and other social sciences have found, by now, electronic computers\\nto constitute an indispensable part of their research equipment. The computers can perform many\\nstatistical calculations easily and quickly. Computation of means, standard deviations, correlationcoefficients, ‘t’ tests, analysis of variance, analysis of covariance, multiple regression, factor analysisand various nonparametric analyses are just a few of the programs and subprograms that are availableat almost all computer centres. Similarly, canned programs for linear programming, multivariateanalysis, monte carlo simulation etc. are also available in the market. In brief, software packages arereadily available for the various simple and complicated analytical and quantitative techniques ofwhich researchers generally make use of. The only work a researcher has to do is to feed in the datahe/she gathered after loading the operating system and particular software package on the computer.The output, or to say the result, will be ready within seconds or minutes depending upon the quantumof work.\\nTechniques involving trial and error process are quite frequently employed in research methodology.\\nThis involves lot of calculations and work of repetitive nature. Computer is best suited for suchtechniques, thus reducing the drudgery of researchers on the one hand and producing the final resultrapidly on the other. Thus. different scenarios are made available to researchers by computers in notime which otherwise might have taken days or even months.\\nThe storage facility which the computers provide is of immense help to a researcher for he can\\nmake use of stored up data whenever he requires to do so.\\nThus, computers do facilitate the research work. Innumerable data can be processed and analyzed\\nwith greater ease and speed. Moreover, the results obtained are generally correct and reliable. Not\\nonly this, even the design, pictorial graphing and report are being developed with the help of computers.\\nHence, researchers should be given computer education and be trained in the line so that they canuse computers for their research work.\\nResearchers interested in developing skills in computer data analysis, while consulting the computer\\ncenters and reading the relevant literature, must be aware of the following steps:\\n(i) data organisation and coding;\\n(ii)storing the data in the computer;\\n(iii)selection of appropriate statistical measures/techniques;\\n(iv)selection of appropriate software package;\\n(v) execution of the computer program.\\nA brief mention about each of the above steps is appropriate and can be stated as under:\\nFirst of all, researcher must pay attention toward data organisation and coding prior to the input\\nstage of data analysis. If data are not properly organised, the researcher may face difficulty while\\nanalysing their meaning later on. For this purpose the data must be coded. Categorical data need tobe given a number to represent them. For instance, regarding sex, we may give number 1 for maleand 2 for female; regarding occupation, numbers 1, 2, and 3 may represent Farmer, Service andProfessional respectively. The researcher may as well code interval or ratio data. For instance, I.Q.Level with marks 120 and above may be given number 1, 90–119 number 2, 60–89 number 3, 30–59number 4 and 29 and below number 5. Similarly, the income data classified in class intervals such asRs. 4000 and above, Rs. 3000–3999, Rs. 2000–2999 and below Rs. 2000 may respectively berepresented or coded as 1, 2, 3 and 4. The coded data are to be put in coding forms (most systemsThe Computer: Its Role in Research 373\\ncall for a maximum of 80 columns per line in such forms) at the appropriate space meant for each\\nvariable. Once the researcher knows how many spaces each variable will occupy, the variables canbe assigned to their column numbers (from 1 to 80). If more than 80 spaces are required for eachsubject, then two or more lines will need to be assigned. The first few columns are generally devotedfor subject identity number. Remaining columns are used for variables. When large number of variablesare used in a study, separating the variables with spaces make the data easier to comprehend andeasier for use with other programs.\\nOnce the data is coded, it is ready to be stored in the computer. Input devices may be used for\\nthe purpose. After this, the researcher must decide the appropriate statistical measure(s) he will useto analyse the data. He will also have to select the appropriate program to be used. Most researchersprefer one of the canned programs easily available but others may manage to develop it with the helpof some specialised agency. Finally, the computer may be operated to execute instructions.\\nThe above description indicates clearly the usefulness of computers to researchers in data analysis.\\nResearchers, using computers, can carry on their task at faster speed and with greater reliability.The developments now taking place in computer technology will further enhance and facilitate theuse of computers for researchers. Programming knowledge would no longer remain an obstacle inthe use of a computer.\\nIn spite of all this sophistication we should not forget that basically computers are machines that\\nonly compute, they do not think. The human brain remains supreme and will continue to be so for alltimes. As such, researchers should be fully aware about the following limitations of computer-basedanalysis:\\n1. Computerised analysis requires setting up of an elaborate system of monitoring, collection\\nand feeding of data. All these require time, effort and money. Hence, computer basedanalysis may not prove economical in case of small projects.\\n2. Various items of detail which are not being specifically fed to computer may get lost sight\\nof.\\n3. The computer does not think; it can only execute the instructions of a thinking person. If\\npoor data or faulty programs are introduced into the computer, the data analysis would notbe worthwhile. The expression “garbage in, garbage out” describes this limitation verywell.\\nQuestions\\n1.What is a computer? Point out the difference between a digital computer and analogue computer.\\n2.How are computers used as a tool in research? Explain giving examples.\\n3.Explain the meaning of the following terms in context of computers:\\n(a) Hardware and Software\\n(b) The binary number system(c) Computer generations\\n(d) Central Processing Unit.\\n4.Describe some of the important applications and uses of computers in present times.374 Research Methodology\\n5.“The advancement in computers is astonishing”. Do you agree? Answer pointing out the various\\ncharacteristics of computers.\\n6.Write a note on “Computers and Researchers”.\\n7.“Inspite of the sophistication achieved in computer technology, one should not forget that basicallycomputers are machines that only compute, they do not think”. Comment.\\n8.Add 110011 and 1011. State the decimal equivalent of the sum you arrive at.\\n9.Explain the method of complementary subtraction.\\nSubtract 15 from 45 and 85 from 68 through this method using the binary equivalents of the given decimal\\nnumbers.\\n10.Workout the decimal equivalents of the following binary numbers:\\n(a) 111.110\\n(b) 0.111and binary equivalents of the following decimal numbers:\\n(a) 4.210\\n(b) 0.745\\n11.Convert 842 to binary and 10010101001 to decimal. Why binary system is being used in computer?\\n12.What do you understand by storage in a computer and how is that related to the generations?Appendix 375\\nAppendix\\n(Selected Statistical Tables)376 Research Methodology\\nTable 1 : Area Under Normal Curve\\nAn entry in the table is the proportion under the\\nentire curve which is between z = 0 and a positive\\nvalue of z . Areas for negative values for z are\\nobtained by symmetry.\\nAreas of a standard normal distribution\\nz.0 0.01 .02 .03 .04 .05 .06 .07 .08 .09\\n.0 .0000 .0040 .0080 .0120 .0160 .0199 .0239 .0279 .0319 .0359\\n.1 .0398 .0438 .0478 .0517 .0557 .0596 .0636 .0675 .0714 .0753\\n.2 .0793 .0832 .0871 .0910 .0948 .0987 .1026 .1064 .1103 .1141\\n.3 .1179 .1217 .1255 .1293 .1331 .1368 .1406 .1443 .1480 .1517.4 .1554 .1591 .1628 .1664 .1700 .1736 .1772 .1808 .1844 .1879\\n.5 .1915 .1950 .1985 .2019 .2054 .2088 .2123 .2157 .2190 .2224\\n.6 .2257 .2291 .2324 .2357 .2389 .2422 .2454 .2486 .2517 .2549\\n.7 .2580 .2611 .2642 .2673 .2903 .2734 .2764 .2794 .2823 .2852.8 .2881 .2910 .2939 .2967 .2995 .3023 .3051 .3078 .3106 .3133\\n.9 .3159 .3186 .3212 .3238 .3264 .3289 .3315 .3340 .3365 .3389\\n1.0 .3413 .3438 .3461 .3485 .3508 .3531 .3554 .3577 .3599 .3621\\n1.1 .3643 .3665 .3686 .3708 .3729 .3749 .3770 .3790 .3810 .3830\\n1.2 .3849 .3869 .3888 .3907 .3925 .3944 .3962 .3980 .3997 .4015\\n1.3 .4032 .4049 .4066 .4082 .4099 .4115 .4131 .4147 .4162 .4177\\n1.4 .4192 .4207 .4222 .4236 .4251 .4265 .4279 .4292 .4306 .43191.5 .4332 .4345 .4357 .4370 .4382 .4394 .4406 .4418 .4429 .4441\\n1.6 .4452 .4463 .4474 .4484 .4495 .4505 .4515 .4525 .4535 .4545\\n1.7 .4554 .4564 .4573 .4582 .4591 .4599 .4608 .4616 .4625 .46331.8 .4641 .4649 .4656 .4664 .4671 .4678 .4686 .4693 .4699 .4706\\n1.9 .4713 .4719 .4726 .4732 .4738 .4744 .4750 .4756 .4761 .4767\\n2.0 .4772 .4778 .4783 .4788 .4793 .4798 .4803 .4808 .4812 .4817\\n2.1 .4821 .4826 .4830 .4834 .4838 .4842 .4846 .4850 .4854 .4857\\n2.2 .4861 .4864 .4868 .4871 .4875 .4878 .4881 .4884 .4887 .4890\\n2.3 .4893 .4896 .4898 .4901 .4904 .4906 .4909 .4911 .4913 .4916\\n2.4 .4918 .4920 .4922 .4925 .4927 .4929 .4931 .4932 .4934 .49362.5 .4938 .4940 .4941 .4943 .4945 .4946 .4948 .4949 .4951 .4952\\n2.6 .4953 .4955 .4956 .4957 .4959 .4960 .4961 .4962 .4963 .4964\\n2.7 .4965 .4966 .4967 .4968 .4969 .4970 .4971 .4972 .4973 .49742.8 .4974 .4975 .4976 .4977 .4977 .4978 .4979 .4979 .4980 .4981\\n2.9 .4981 .4982 .4982 .4983 .4984 .4984 .4985 .4985 .4986 .4986\\n3.0 .4987 .4987 ..4987 .4988 .4988 .4989 .4989 .4989 .4990 .4990021Appendix 377\\nTable 2 :Critical Values of Student\\x92s t-Distribution\\nLevel of significance for two-tailed test\\nd.f. 0.20 0.10 0.05 0.02 0.01 d.f.\\nLevel of significance for one-tailed test\\n0.10 0.05 0.025 0.01 0.005\\n1 3.078 6.314 12.706 31.821 63.657 1\\n2 1.886 2.920 4.303 6.965 9.925 2\\n3 1.638 2.353 3.182 4.541 5.841 34 1.533 2.132 2.776 3.747 4.604 4\\n5 1.476 2.015 2.571 3.365 4.032 5\\n6 1.440 1.943 2.447 3.143 3.707 6\\n7 1.415 1.895 2.365 2.998 3.499 78 1.397 1.860 2.306 2.896 3.355 8\\n9 1.383 1.833 2.262 2.821 3.250 9\\n10 1.372 1.812 2.228 2.764 3.169 10\\n11 1.363 1.796 2.201 2.718 3.106 11\\n12 1.356 1.782 2.179 2.681 3.055 12\\n13 1.350 1.771 2.160 2.650 3.012 13\\n14 1.345 1.761 2.145 2.624 2.977 14\\n15 1.341 1.753 2.731 2.602 2.947 15\\n16 1.337 1.746 2.120 2.583 2.921 16\\n17 1.333 1.740 2.110 2.567 2.898 17\\n18 1.330 1.734 2.101 2.552 2.878 18\\n19 1.328 1.729 2.093 2.539 2.861 19\\n20 1.325 1.725 2.086 2.528 2.845 20\\n21 1.323 1.721 2.080 2.518 2.831 21\\n22 1.321 1.717 2.074 2.508 2.819 22\\n23 1.319 1.714 2.069 2.500 2.807 23\\n24 1.318 1.711 2.064 2.492 2.797 24\\n25 1.316 1.708 2.060 2.485 2.787 25\\n26 1.315 1.706 2.056 2.479 2.779 26\\n27 1.314 1.703 2.052 2.473 2.771 27\\n28 1.313 1.701 2.048 2.467 2.763 28\\n29 1.311 1.699 2.045 2.462 2.756 29\\nInfinity 1.282 1.645 1.960 2.326 2.576 Infinity378 Research Methodology\\nTable 3 :Critical Values of χ2\\nDegrees Probability under H0 that of χ2 > Chi square\\nof\\nfreedom .99 .95 .50 .10 .05 .02 .01\\n1 .000157 .00393 .455 2.706 3.841 5.412 6.635\\n2 .0201 .103 1.386 4.605 5.991 7.824 9.2103 .115 .352 2.366 6.251 7.815 9.837 11.341\\n4 .297 .711 3.357 7.779 9.488 11.668 13.277\\n5 .554 .1145 4.351 9.236 11.070 13.388 15.086\\n6 .872 1.635 5.348 10.645 12.592 15.033 16.812\\n7 1.239 2.167 6.346 12.017 14.067 16.622 18.475\\n8 1.646 2.733 7.344 13.362 15.507 18.168 20.0909 2.088 3.325 8.343 14.684 16.919 19.679 21.666\\n10 2.558 3.940 9.342 15.987 18.307 21.161 23.209\\n11 3.053 4.575 10.341 17.275 19.675 22.618 24.725\\n12 3.571 5.226 11.340 18.549 21.026 24.054 26.21713 4.107 5.892 12.340 19.812 22.362 25.472 72.688\\n14 4.660 6.571 13.339 21.064 23.685 26.873 29.141\\n15 4.229 7.261 14.339 22.307 24.996 28.259 30.578\\n16 5.812 7.962 15.338 23.542 26.296 29.633 32.000\\n17 6.408 8.672 16.338 24.769 27.587 30.995 33.409\\n18 7.015 9.390 17.338 25.989 28.869 32.346 34.80519 7.633 10.117 18.338 27.204 30.144 33.687 36.191\\n20 8.260 10.851 19.337 28.412 31.410 35.020 37.566\\n21 8.897 11.591 20.337 29.615 32.671 36.343 38.932\\n22 9.542 12.338 21.337 30.813 33.924 37.659 40.28923 10.196 13.091 22.337 32.007 35.172 38.968 41.638\\n24 10.856 13.848 23.337 32.196 36.415 40.270 42.980\\n25 11.524 14.611 24.337 34.382 37.652 41.566 44.314\\n26 12.198 15.379 25.336 35.363 38.885 41.856 45.642\\n27 12.879 16.151 26.336 36.741 40.113 44.140 46.963\\n28 13.565 16.928 27.336 37.916 41.337 45.419 48.27829 14.256 17.708 28.336 39.087 42.557 46.693 49.588\\n30 14.953 18.493 29.336 40.256 43.773 47.962 50.892\\nNote:For degrees of freedom greater than 30, the quantity 22 12χ−−d.f. may be used as a normal variate with unit\\nvariance i.e., zαχ=−−22 12d.f. .Appendix 379\\nTable 4(a) :Critical Values of F-Distribution (at 5 per cent)\\n      v112345681 22 4 ∞\\nv2\\n1 161.4 199.5 215.7 224.6 230.2 234.0 238.9 243.9 249.1 243.3\\n2 18.51 19.00 19.16 19.25 19.30 19.33 19.37 19.41 19.45 19.503 10.13 9.55 9.28 9.12 9.01 8.94 8.85 8.74 8.64 8.53\\n4 7.71 6.94 6.59 6.39 6.26 6.16 6.04 5.91 5.77 5.63\\n5 6.61 5.79 5.41 5.19 5.05 4.95 4.82 4.68 4.53 4.366 5.99 5.14 4.76 4.53 4.39 4.28 4.15 4.00 3.84 3.67\\n7 5.59 4.74 4.35 4.12 3.97 3.87 3.73 3.57 3.41 3.23\\n8 5.32 4.46 4.07 3.84 3.69 3.58 3.44 3.28 3.12 2.939 5.12 4.26 3.86 3.63 3.48 3.37 3.23 3.07 2.90 2.71\\n10 4.96 4.10 3.71 3.48 3.33 3.22 3.07 2.91 2.74 2.5411 4.84 3.98 3.59 3.36 3.20 3.09 2.95 2.79 2.61 2.4012 4.75 3.88 3.49 3.26 3.11 3.00 2.85 2.69 2.51 2.30\\n13 4.67 3.80 3.41 3.18 3.02 2.92 2.77 2.60 2.42 2.21\\n14 4.60 3.74 3.34 3.11 2.96 2.85 2.70 2.53 2.35 2.1315 4.54 3.68 3.29 3.06 2.90 2.79 2.64 2.48 2.29 2.07\\n16 4.49 3.63 3.24 3.01 2.85 2.74 2.59 2.42 2.24 2.01\\n17 4.45 3.59 3.20 2.96 2.81 2.70 2.55 2.38 2.19 1.9618 4.41 3.55 3.16 2.93 2.77 2.66 2.51 2.34 2.15 1.9219 4.38 3.52 3.13 2.90 2.74 2.63 2.48 2.31 2.11 1.88\\n20 4.35 3.49 3.10 2.87 2.71 2.60 2.45 2.28 2.08 1.84\\n21 4.32 3.47 3.07 2.84 2.68 2.57 2.42 2.25 2.05 1.8122 4.30 3.44 3.05 2.82 2.66 2.55 2.40 2.23 2.03 1.78\\n23 4.28 3.42 3.03 2.80 2.64 2.53 2.38 2.20 2.01 1.76\\n24 4.26 3.40 3.01 2.78 2.62 2.51 2.36 2.18 1.98 1.7325 4.24 3.38 2.99 2.76 2.60 2.49 2.34 2.16 1.96 1.71\\n26 4.22 3.37 2.98 2.74 2.59 2.47 2.32 2.15 1.95 1.69\\n27 4.21 3.35 2.96 2.73 2.57 2.46 2.31 2.13 1.93 1.6728 4.20 3.34 2.95 2.71 2.56 2.45 2.29 2.12 1.91 1.65\\n29 4.18 3.33 2.93 2.70 2.54 2.43 2.28 2.10 1.90 1.64\\n30 4.17 3.32 2.92 2.69 2.53 2.42 2.27 2.09 1.89 1.6240 4.08 3.23 2.84 2.61 2.45 2.34 2.18 2.00 1.79 1.51\\n60 4.00 3.15 2.76 2.52 2.37 2.25 2.10 1.92 1.70 1.39\\n120 3.92 3.07 2.68 2.45 2.29 2.17 2.02 1.83 1.61 1.25\\n∞ 3.84 2.99 2.60 2.37 2.21 2.10 1.94 1.75 1.52 1.00\\nv1 = Degrees of freedom for greater variance.\\nv2 = Degrees of freedom for smaller variance.380 Research Methodology\\nTable 4(b) :Critical Values of F-Distribution (at 1 per cent)\\n      v112345681 22 4 ∞\\nv2\\n1 4052 4999.55403 5625 5764 5859 5982 6106 6235 6366\\n2 98.50 99.00 99.17 99.25 99.30 99.33 99.37 99.42 99.46 99.50\\n3 34.12 30.82 29.46 28.71 28.24 27.91 27.49 27.05 26.60 26.13\\n4 21.20 18.00 16.69 15.98 15.52 15.21 14.80 14.37 13.93 13.45\\n5 16.26 13.27 12.06 11.39 10.97 10.67 10.29 9.89 9.47 9.026 13.75 10.92 9.78 9.15 8.75 8.47 8.10 7.72 7.31 6.88\\n7 12.25 9.55 8.45 7.85 7.46 7.19 6.84 6.47 6.07 5.65\\n8 11.26 8.65 7.59 7.01 6.63 6.37 6.03 5.67 5.28 4.869 10.56 8.02 6.99 6.42 6.06 5.80 5.47 5.11 4.73 4.31\\n10 10.04 7.56 6.55 5.99 5.64 5.39 5.06 4.71 4.33 3.9111 9.65 7.21 6.22 5.87 5.32 5.07 4.74 4.40 4.02 3.6012 9.33 6.93 5.95 5.41 5.06 4.82 4.50 4.16 3.78 3.36\\n13 9.07 6.70 5.74 5.21 4.86 4.62 4.30 3.96 3.59 3.17\\n14 8.86 6.51 5.56 5.04 4.69 4.46 4.14 3.80 3.43 3.0015 8.68 6.36 5.42 4.89 4.56 4.32 4.00 3.67 3.29 2.87\\n16 8.53 6.23 5.29 4.77 4.44 4.20 3.89 3.55 3.18 2.75\\n17 8.40 6.11 5.18 4.67 4.34 4.10 3.79 3.46 3.08 2.6518 8.29 6.01 5.09 4.58 4.25 4.01 3.71 3.37 3.00 2.5719 8.18 5.93 5.01 4.50 4.17 3.94 3.63 3.30 3.92 2.49\\n20 8.10 5.85 4.94 4.43 4.10 3.87 3.56 3.23 2.86 2.42\\n21 8.02 5.78 4.87 4.37 4.04 3.81 3.51 3.17 2.80 2.3622 7.95 5.72 4.82 4.31 3.99 3.76 3.45 3.12 2.75 2.31\\n23 7.88 5.66 4.76 4.26 3.94 3.71 3.41 3.07 2.70 2.26\\n24 7.82 5.61 4.72 4.22 3.90 3.67 3.36 3.03 2.66 2.2125 7.77 5.57 4.68 4.18 3.85 3.63 3.32 2.99 2.62 2.17\\n26 7.72 5.53 4.64 4.14 3.82 3.59 3.20 2.96 2.58 2.10\\n27 7.68 5.49 4.60 4.11 3.78 3.56 3.26 2.93 2.45 2.1328 7.64 5.45 4.57 4.07 3.75 3.53 3.23 2.90 2.52 2.06\\n29 7.60 5.42 4.54 4.04 3.73 3.50 3.20 2.87 2.49 2.03\\n30 7.56 5.39 4.51 4.02 3.70 3.47 3.17 2.84 2.47 2.0140 7.31 5.18 4.31 3.83 3.51 3.29 2.99 2.66 2.29 1.80\\n60 7.08 4.98 4.13 3.65 3.34 3.12 2.82 2.50 2.12 1.60\\n120 6.85 4.79 3.95 3.48 3.17 2.96 2.66 2.34 1.95 1.38\\n∞ 6.64 4.60 3.78 3.32 3.02 2.80 2.51 2.18 1.79 1.00\\nv1 = Degrees of freedom for greater variance.\\nv2 = Degrees of freedom for smaller variance.Appendix 381\\nTable 5 :Values for Spearman\\x92s Rank Correlation ( rs) for Combined Areas in Both Tails\\nn .20 .10 .05 .02 .01 .002\\n4 .8000 .8000 — — — —\\n5 .7000 .8000 .9000 .9000 — —\\n6 .6000 .7714 .8236 .8857 .9429 —7 .5357 .6786 .7450 .8571 .8929 .9643\\n8 .5000 .6190 .7143 .8095 .8571 .9286\\n9 .4667 .5833 .6833 .7667 .8167 .9000\\n10 .4424 .5515 .6364 .7333 .7818 .8667\\n11 .4182 .5273 .6091 .7000 .7455 .8364\\n12 .3986 .4965 .5804 .6713 .7273 .8182\\n13 .3791 .4780 .5549 .6429 .6978 .791214 .3626 .4593 .5341 .6220 .6747 .7670\\n15 .3500 .4429 .5179 .6000 .6536 .7464\\n16 .3382 .4265 .5000 .5824 .6324 .7265\\n17 .3260 .4118 .4853 .5637 .6152 .708318 .3148 .3994 .4716 .5480 .5975 .6904\\n19 .3070 .3895 .4579 .5333 .5825 .6737\\n20 .2977 .3789 .4451 .5203 .5684 .6586\\n21 .2909 .3688 .4351 .5078 .5545 .6455\\n22 .2829 .3597 .4241 .4963 .5426 .6318\\n23 .2767 .3518 .4150 .4852 .5306 .618624 .2704 .3435 .4061 .4748 .5200 .6070\\n25 .2646 .3362 .3977 .4654 .5100 .5962\\n26 .2588 .3299 .3894 .4564 .5002 .5856\\n27 .2540 .3236 .3822 .4481 .4915 .575728 .2480 .3175 .3749 .4401 .4828 .5660\\n29 .2443 .3113 .3685 .4320 .4744 .5567\\n30 .2400 .3059 .3620 .4251 .4665 .5479–.3986 +.398610% of area 10% of area( = sample size = 12)n382 Research MethodologyTable 6 : Selected Values of Wilcoxon\\x92s (Unpaired) Distribution\\n[Ws \\x96 Min Ws] or [Max. Wl \\x96 Wl]\\nslMi n M a x 0 1234 5 67 8 9 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0\\nWsWl\\n22 3 7\\n3 3 12 .100\\n4 3 18 .067 .1345 3 25 .048 .095 .190\\n6 3 33 .086 .071 .143\\n7 3 42 .028 .056 .1118 3 52 .022 .044 .089 .133\\n3 2 6 9 .100\\n3 6 15 .050 .1004 6 22 .029 .057 .1145 6 30 .018 .036 .071 .1256 6 39 .012 .024 .048 .083 .1317 6 49 .008 .017 .033 .058 .092 .1338 6 60 .006 .012 .024 .042 .067 .097 .139\\n4 2 10 11 .007 *\\n3 10 18 .029 .057 .1144 10 26 .014 .029 .057 .100\\n5 10 35 .008 .016 .032 .056 .095 .143\\n6 10 45 .005 .010 .019 .033 .057 .086 .1297 10 56 .003 .006 .012 .021 .036 .055 .082 .1158 10 68 .002 .004 .008 .014 .024 .036 .055 .077 .107\\n5 3 15 21 .018 .036 .071 .125 *\\n4 15 30 .008 .016 .032 .056 .095 .1435 15 40 .004 .008 .016 .028 .048 .075 .1116 15 51 .002 .004 .009 .015 .026 .041 .063 .089 .123\\n7 15 63 .001 .003 .005 .009 .015 .024 .037 .053 .074 .101\\n8 15 76 .001 .002 .003 .005 .009 .015 .023 .033 .047 .064 .085 .111\\n(Contd.)Appendix 383slMi n M a x 0 1234 5 67 8 9 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0\\nWsWl\\n6 3 21 24 .012 .024 *\\n4 21 34 .005 .010 .019 .033 .057 .086 .129 *\\n5 21 45 .002 .004 .009 .015 .026 .041 .063 .089 .123\\n6 21 57 .001 .002 .004 .008 .013 .021 .032 .047 .066 .090 .120\\n7 21 70 .001 .001 .002 .004 .007 .011 .017 .026 .037 .051 .069 .090 .117\\n8 21 84 .000 .001 .001 .002 .004 .006 .010 .015 .021 .030 .041 .054 .071 .091 .114\\n7 4 28 38 .003 .006 .012 .021 .036 .055*\\n5 28 50 .001 .003 .005 .009 .015 .024 .037 .053 .074 .101\\n6 28 63 .001 .001 .002 .004 .007 .011 .017 .026 .037 .051 .069 .090 .117\\n7 28 77 .000 .001 .001 .002 .003 .006 .009 .013 .019 .027 .036 .049 .064 .082 .104\\n8 28 92 .000 .000 .001 .001 .002 .003 .005 .007 .010 .014 .020 .027 .036 .047 .060 .076 .095 .116\\n8 4 36 42 .002 .004 .008 .014 *\\n5 36 55 .001 .002 .003 .005 .009 .015 .023 .033 .047 .064 *\\n6 36 69 .000 .001 .001 .002 .004 .006 .010 .015 .021 .030 .041 .054 .071 .091 .114\\n7 36 84 .000 .000 .001 .001 .002 .003 .005 .007 .010 .014 .020 .027 .036 .047 .060 .076 .095 .116\\n8 36 100 .000 .000 .000 .001 .001 .001 .002 .003 .005 .007 .010 .014 .019 .025 .032 .041 .052 .065 .080 .097 .117\\n* Indicates that the value at head of this column (add those values that are lar ger) are not possible for the given values of s and l in this row.384 Research Methodology\\nTable 7 : Critical Values of T in the Wilcoxon Matched Pairs Test\\nLevel of significance for one-tailed test\\n.025 .01 .005\\nLevel of significance for two-tailed test\\nn .05 .02 .01\\n60 ——\\n72 0—\\n84 2 096 3 2\\n10 8 5 3\\n11 11 7 5\\n12 14 10 7\\n13 17 13 10\\n14 21 16 13\\n15 25 20 16\\n16 30 24 20\\n17 35 28 23\\n18 40 33 28\\n19 46 38 32\\n20 52 43 38\\n21 59 49 43\\n22 66 56 49\\n23 73 62 55\\n24 81 69 61\\n25 89 77 68Appendix 385\\nTable 8 : Cumulative Binomial Probabilities: P ( r < r|n, p)\\nnr0.10 .25 .40 .50\\n1 0 .9000 .7500 .6000 .5000\\n1 1.0000 1.0000 1.0000 1.0000\\n2 0 .8100 .5625 .3600 .2500\\n1 .9900 .9375 .8400 .7500\\n2 1.0000 1.0000 1.0000 1.0000\\n5 0 .5905 .2373 .0778 .0313\\n1 .9185 .6328 .3370 .1875\\n2 .9914 .8965 .6826 .5000\\n3 .9995 .9844 .9130 .8125\\n4 .9999 .9990 .9898 .9687\\n5 1.0000 1.0000 1.0000 1.0000\\n10 0 .3487 .0563 .0060 .0010\\n1 .7361 .2440 .0463 .0108\\n2 .9298 .5256 .1672 .0547\\n3 .9872 .7759 .3822 .1719\\n4 .9984 .9219 .6330 .3770\\n5 .9999 .9803 .8337 .6230\\n6 1.0000 .9965 .9452 .8281\\n7 1.0000 .9996 .9877 .9453\\n8 1.0000 1.0000 .9983 .9892\\n9 1.0000 1.0000 .9999 .9990\\n10 1.0000 1.0000 1.0000 1.0000\\n12 0 .2824 .0317 .0022 .0002\\n1 .6590 .1584 .0196 .0031\\n2 .8891 .3907 .0835 .0192\\n3 .9740 .6488 .2254 .0729\\n4 .9963 .8424 .4382 .1937\\n5 .9999 .9456 .6652 .3871\\n6 1.0000 .9857 .8418 .6127\\n7 1.0000 .9972 .9427 .8064\\n8 1.0000 .9996 .9847 .9269\\n9 1.0000 1.0000 .9972 .9806\\n10 1.0000 1.0000 .9997 .9977\\n11 1.0000 1.0000 1.0000 1.0000\\n12 1.0000 1.0000 1.0000 1.0000\\n(Contd.)386 Research Methodology\\nnr0.10 .25 .40 .50\\n20 0 .1216 .0032 .0000 .0000\\n1 .3917 .0243 .0005 .0000\\n2 .6768 .0912 .0036 .0002\\n3 .8669 .2251 .0159 .0013\\n4 .9567 .4148 .0509 .0059\\n5 .9886 .6171 .1255 .0207\\n6 .9975 .7857 .2499 .0577\\n7 .9995 .8981 .4158 .1316\\n8 .9999 .9590 .5955 .2517\\n9 1.0000 .9861 .7552 .4119\\n10 1.0000 .9960 .8723 .5881\\n11 1.0000 .9990 .9433 .7483\\n12 1.0000 .9998 .9788 .8684\\n13 1.0000 1.0000 .9934 .9423\\n14 1.0000 1.0000 .9983 .9793\\n15 1.0000 1.0000 .9996 .9941\\n16 1.0000 1.0000 1.0000 .9987\\n17 1.0000 1.0000 1.0000 .9998\\n18 1.0000 1.0000 1.0000 1.0000\\n19 1.0000 1.0000 1.0000 1.0000\\n20 1.0000 1.0000 1.0000 1.0000Appendix 387\\nTable 9 : Selected Critical Values of S in the Kendall\\x92s Coefficient of Concordance\\nValues at 5% level of significance\\nkN Some additional\\nvalues for N = 3\\n34 56 7 ks\\n3 64.4 103.9 157.3 9 54.0\\n4 49.5 88.4 143.3 217.0 12 71.9\\n5 62.6 112.3 182.4 276.2 14 83.8\\n6 75.7 136.1 221.4 335.2 16 95.8\\n8 48.1 101.7 183.7 299.0 453.1 18 107.7\\n10 60.0 127.8 231.2 376.7 571.015 89.8 192.9 349.8 570.5 864.9\\n20 119.7 258.0 468.5 764.4 1158.7\\nValues at 1% level of significance\\n3 75.6 122.8 185.6 9 75.9\\n4 61.4 109.3 176.2 265.0 12 103.5\\n5 80.5 142.8 229.4 343.8 14 121.9\\n6 99.5 176.1 282.4 422.6 16 140.2\\n8 66.8 137.4 242.7 388.3 579.9 18 158.6\\n10 85.1 175.3 309.1 494.0 737.015 131.0 269.8 475.2 758.2 1129.520 177.0 364.2 641.2 1022.2 1521.9388 Research Methodology\\nTable 10 : Table Showing Critical Values of A-Statistic for any Given Value\\nof n \\x96 1, Corresponding to Various Levels of Probability\\n(A is significant at a given level if it is −<the value shown in the table)\\nn – 1*Level of significance for one-tailed test\\n.05 .025 .01 .005 .0005\\nLevel of significance for two-tailed test\\n.10 .05 .02 .01 .001\\n1 23 456\\n1 0.5125 0.5031 0.50049 0.50012 0.5000012\\n2 0.412 0.369 0.347 0.340 0.334\\n3 0.385 0.324 0.286 0.272 0.254\\n4 0.376 0.304 0.257 0.238 0.2115 0.372 0.293 0.240 0.218 0.184\\n6 0.370 0.286 0.230 0.205 0.167\\n7 0.369 0.281 0.222 0.196 0.155\\n8 0.368 0.278 0.217 0.190 0.146\\n9 0.368 0.276 0.213 0.185 0.139\\n10 0.368 0.274 0.210 0.181 0.134\\n11 0.368 0.273 0.207 0.178 0.130\\n12 0.368 0.271 0.205 0.176 0.126\\n13 0.368 0.270 0.204 0.174 0.124\\n14 0.368 0.270 0.202 0.172 0.12115 0.368 0.269 0.201 0.170 0.119\\n16 0.368 0.268 0.200 0.169 0.117\\n17 0.368 0.268 0.199 0.168 0.116\\n18 0.368 0.267 0.198 0.167 0.11419 0.368 0.267 0.197 0.166 0.113\\n20 0.368 0.266 0.197 0.165 0.112\\n21 0.368 0.266 0.196 0.165 0.111\\n22 0.368 0.266 0.196 0.164 0.110\\n23 0.368 0.266 0.195 0.163 0.10924 0.368 0.265 0.195 0.163 0.108\\n25 0.368 0.265 0.194 0.162 0.108\\n26 0.368 0.265 0.194 0.162 0.107\\n27 0.368 0.265 0.193 0.161 0.10728 0.368 0.265 0.193 0.161 0.106\\n29 0.368 0.264 0.193 0.161 0.106\\n30 0.368 0.264 0.193 0.160 0.105\\n(Contd.)Appendix 389\\n1 23 456\\n40 0.368 0.263 0.191 0.158 0.102\\n60 0.369 0.262 0.189 0.155 0.099\\n120 0.369 0.261 0.187 0.153 0.095\\n∞ 0.370 0.260 0.185 0.151 0.092\\n* n = number of pairs\\nSource:The Brit. J. Psychol , Volume XLVI, 1955, p. 226.390 Research Methodology\\nSelected References and\\nRecommended Readings\\n1. Ackoff, Russell L., The Design of Social Research, Chicago: University of Chicago Press, 1961.\\n2. Ackoff, Russell L., Scientific Method, New York: John Wiley & Sons, 1962.\\n3. Allen, T. Harrell, New Methods in Social Science Research, New York: Praeger Publishers, 1978.\\n4. Anderson, H.H., and Anderson, G.L., An Introduction to Projective Techniques and Other Devices for\\nUnderstanding the Dynamics of Human Behaviour , New York: Prentice Hall, 1951.\\n5. Anderson, T.W., An Introduction to Multivariate Analysis, New York: John Wiley & Sons, 1958.\\n6. Bailey, Kenneth D.,  “Methods of Social Research, ” New York, 1978.\\n7. Baker, R.P., and Howell, A.C., The Preparation of Reports, New York: Ronald Press, 1938.\\n8. Bartee, T.C., “ Digital Computer Fundamentals, ” 5th Ed., McGraw-Hill, International Book Co., 1981.\\n9. Barzun, Jacques, and Graff, Henery, F., The Modern Researcher, rev. ed., New York: Harcourt, Brace &\\nWorld, Inc., 1970.\\n10. Bell, J.E., Projective Techniques: A. Dynamic Approach to the Study of Personality, New York: Longmans\\nGreen, 1948.\\n11. Bellenger, Danny N., and Greenberg, Barnett A., Marketing Research—A Management Information\\nApproach, Homewood, Illinois: Richard D. Irwin, Inc., 1978.\\n12. Berdie, Douglas R., and Anderson, John F., Questionnaires: Design and Use, Metuchen N.J.: The\\nScarecrow Press, Inc., 1974.\\n13. Berelson, Bernard, Content Analysis in Communication Research, New York: Free Press, 1952.\\n14. Berenson, Conard, and Colton, Raymond, Research and Report Writing for Business and Economics,\\nNew York: Random House, 1971.\\n15. Best, John W., and Kahn, James V., “ Research in Education ,” 5th Ed., New Delhi: Prentice-Hall of India\\nPvt. Ltd., 1986.\\n16. Bhattacharya, Srinibas, Psychometrics & Behavioural Research, New Delhi: Sterling Publishers Pvt.\\nLtd., 1972.\\n17. Boot, John C.G., and Cox, Edwin B., Statistical Analysis for Managerial Decisions, 2nd ed. New Delhi:\\nMcGraw-Hill Publishing Co. Ltd., (International Student Edition), 1979.\\n18. Bowley, A.L., Elements of Statistics, 6th ed. London: P.S. King and Staples Ltd., 1937.Selected References and Recommended Readings 391\\n19. Burgess, Ernest W., “Research Methods in Sociology” in Georges Gurvitch and W.E. Moore (Ed.),\\nTwentieth Century Sociology, New York: New York Philosophical Library, 1949.\\n20. Chance, William A., Statistical Methods for Decision Making, Bombay: D.B. Taraporevala Sons & Co.\\nPvt. Ltd., 1975.\\n21. Chaturvedi, J.C., Mathematical Statistics, Agra: Nok Jhonk Karyalaya, 1953.\\n22. Chou, Ya-Lun, Statistical Analysis with Business and Economic Applications, 2nd ed. New York: Holt,\\nRinehart & Winston, 1974.\\n23. Clover, Vernon T., and Balsley, Howard L., Business Research Methods, Columbus, O.: Grid, Inc., 1974.\\n24. Cochran, W.G., Sampling Techniques, 2nd ed. New York: John Wiley & Sons., 1963.\\n25. Cooley, William W., and Lohnes, Paul R., Multivariate Data Analysis , New York: John Wiley & Sons.,\\n1971.\\n26. Croxton, F.E., Cowden, D.J., and Klein, S., Applied General Statistics, 3rd ed., New Delhi: Prentice-Hall of\\nIndia Pvt. Ltd., 1975.\\n27. Dass, S.L., Personality Assessment Through Projective Movie Pictures , New Delhi: S. Chand & Co.\\n(Pvt.) Ltd., 1974.\\n28. Davis, G.B., “ Introduction to Computers ,” 3rd ed., McGraw-Hill International Book Co., 1981.\\n29. Deming, W. Edwards., Sample Design in Business Research, New York: John Wiley & Sons., Inc., 1960.\\n30. Dennis, Child, The Essentials of Factor Analysis, New York: Holt, Rinehart and Winston, 1973.\\n31. Denzin, Norman, The Research Act, Chicago: Aldine, 1973.\\n32. Edwards, Allen, Statistical Methods, 2nd ed., New York: Holt, Rinehart & Winston, 1967.\\n33. Edwards, Allen L., Techniques of Attitude Scale Construction, New York: Appleton-Century-Crofts,\\n1957.\\n34. Emory, C. William, Business Research Methods , Illinois: Richard D. Irwin, Inc. Homewood, 1976.\\n35. Ferber, Robert (ed.), Handbook of Marketing Research, New York: McGraw-Hill, Inc., 1948.\\n36. Ferber, R., and Verdoorn, P.J., Research Methods in Economics and Business, New York: The Macmillan\\nCompany, 1962.\\n37. Ferguson, George A., Statistical Analysis in Psychology and Education , 4th ed., New York: McGraw-\\nHill Book Co., Inc., 1959.\\n38. Festinger, Leon and Katz, Daniel (Eds.), Research Methods in the Behavioral Sciences, New Delhi:\\nAmerind Publishing Co. Pvt. Ltd., Fourth Indian Reprint, 1976.\\n39. Fiebleman, J.K., Scientific Method , Netherlands: Martinus Nijhoff, The Hague, 1972.\\n40. Fisher, R.A., Statistical Methods for Research Workers, 13th ed., New York: Hafner Publishing Co., 1958.\\n41. Fisher, R.A., The Design of Experiments, 7th rev. ed., New York: Hafner Publishing Co., 1960.\\n42. Fox, James Harold, Criteria of Good Research, Phi Delta Kappa, Vol. 39 (March 1958).\\n43. Freedman, P., The Principles of Scientific Research, 2nd ed., New York: Pergamon Press, 1960.\\n44. Fruchter, Benjamin, Introduction to Factor Analysis, Princeton, N.J.: D.Van Nostrand, 1954.\\n45. Gatner, Elliot S.M., and Cordasco, Francesco, Research and Report Writing , New York: Barnes & Noble,\\nInc., 1956.\\n46. Gaum, Carl G., Graves, Harod F., and Hoffman, Lyne, S.S., Report Writing , 3rd ed., New York: Prentice-Hall,\\n1950.\\n47. Ghosh, B.N., Scientific Methods and Social Research, New Delhi: Sterling Publishers Pvt. Ltd., 1982.\\n48. Gibbons, J.D., Nonparametric Statistical  Inference, Tokyo: McGraw-Hill Kogakusha Ltd., (International\\nStudent Edition), 1971.392 Research Methodology\\n49. Giles, G.B., Marketing, 2nd ed., London: Macdonald & Evans Ltd., 1974.\\n50. Glock, Charles Y., Survey Research in the Social Sciences, New York: Russell Sage Foundation, 1967.\\n51. Godfrey, Arthur, Quantitative Methods for Managers, London: Edward Arnold (Publishers) Ltd., 1977.\\n52. Good, Carter V., and Douglas, E. Scates, Methods of Research—Educational, Psychological, Sociological,\\nNew York: Appleton-Century-Crofts, Inc., 1954.\\n53. Goode, William J., and Hatt, Paul K., Methods in Social Research, New York: McGraw-Hill, 1952.\\n54. Gopal, M.H., An Introduction to Research Procedure in Social Sciences,  Bombay: Asia Publishing\\nHouse, 1964.\\n55. Gopal, M.H., Research Reporting in Social Sciences, Dharwar: Karnatak University, 1965.\\n56. Gorden, Raymond L., Interviewing: Strategy, Techniques and Tactics, rev. ed., Homewood, Ill.: Dorsey\\nPress, 1975.\\n57. Green, Paul E. , Analyzing Multivariate Data, Hinsdale, Ill.: Dryden Press, 1978.\\n58. Green, Paul E., and Carmone, F.J., Multidimensional Scaling in Marketing Analysis, Boston: Allyn &\\nBacon, Inc., 1970.\\n59. Guilford, J.P., Psychometric Methods, New York: McGraw Hill, Inc., 1954.\\n60. Harnett, Donald L., and Murphy, James L., Introductory Statistical Analysis,  Philippines: Addison-\\nWesley Publishing Co., Inc., 1975.\\n61. Hillway, T.,  Introduction to Research, 2nd ed., Boston: Houghton Mifflin, 1964.\\n62. Hollander, Myles, and Wolfe, Douglas A., Nonparametric Statistical Methods, New York: John Wiley,\\n1973.\\n63. Hunt, R., and Shelley, J., “ Computers and Common Sense, ” 3rd ed., New Delhi: Prentice-Hall of India Ltd.,\\n1984.\\n64. Hyman, Herbert H., et al., Interviewing in Social Research, Chicago: University of Chicago Press, 1975.\\n65. John, Peter W.M., Statistical Design and Analysis of Experiments, New York: The Macmillan Co., 1971.\\n66. Johnson, Ellen, The Research Report: A Guide for the Beginner, New York: Ronald Press, 1951.\\n67. Johnson, Rodney D., and Siskin, Bernard R., Quantitative Techniques for Business Decisions, New\\nDelhi: Prentice-Hall of India Pvt. Ltd., 1977.\\n68. Kahn, Robert L. and Cannell, Charles F., The Dynamics of Interviewing , New York: John Wiley & Sons,\\n1957.\\n69. Karson, Marvin J., Multivariate Statistical Methods , Ames, Iowa: The Iowa State University Press, 1982.\\n70. Kendall, M.G., A Course in Multivariate Analysis, London, Griffin, 1961.\\n71. Kerlinger, Fred N. and Pedhazur, Elazar J., Multiple Regression in Behavioral Research, New York: Holt,\\nRinehart and Winston, 1973.\\n72. Kerlinger, Fred N., Foundations of Behavioral Research, 2nd ed., New York: Holt, Reinhart and Winston,\\n1973.\\n73. Kish, Leslie., Survey Sampling, New York: John Wiley & Sons, Inc., 1965.\\n74. Kothari, C.R., Quantitative Techniques, 2nd ed., New Delhi: Vikas Publishing House Pvt. Ltd., 1984.\\n75. Lastrucci, Carles L., The Scientific Approach: Basic Principles of the Scientific Method, Cambridge,\\nMass.: Schenkman Publishing Co., Inc., 1967.\\n76. Lazersfeld, Paul F.,  “Evidence and Inference in Social Research, ” in David Lerher, Evidence and Inference,\\nGlencoe: The Free Press, 1950.\\n77. Leonard Schatzman, and Anselm L. Strauss, Field Research, New Jersey: Prentice-Hall Inc., 1973.\\n78. Levin, Richard I.,  Statistics for Management, New Delhi: Prentice-Hall of India Pvt. Ltd., 1979.Selected References and Recommended Readings 393\\n79. Levine, S. and Elzey, Freeman F., A Programmed Introduction to Research, California: Wods Worth\\nPublishing Co., 1968.\\n80. Maranell, Gary M. (ed.), Scaling: A Source Book for Behavioral Scientists, Chicago: Aldine, 1974.\\n81. Maxwell, Albert E., Analyzing Qualitative Data, New York: John Wiley & Sons, 1961.\\n82. Meadows, R., and Parsons, A.J., “ Microprocessors: Essentials, Components and Systems ,” Pitman, 1983.\\n83. Meir, Robert C., Newell, William T., and Dazier, Harold L., Simulation in  Business and Economics ,\\nEnglewood Cliffs, N.J:  Prentice Hall, Inc., 1969.\\n84. Miller, Delbert C., Handbook of Research Design & Social Measurement , 3rd ed., New York: David\\nMckay Company, Inc., 1977.\\n85. Moroney, M.J., Facts from Figures, Baltimore: Penguin Books, 1956.\\n86. Morrison, Donald F., Multivariate Statistical Methods, New York: McGraw-Hill, 1967.\\n87. Nagel, Stuart S., and Neef, Marian, Policy Analysis in Social Science Research,  London: Sage Publications,\\n1979.\\n88. Nie, N.H., Bent, D.H., and Hull, C.H., Statistical Package for the Social Sciences, New York: McGraw-\\nHill, 1970.\\n89. Noether, G.E., Elements of Nonparametric Statistics, New York: John Wiley & Sons, Inc., 1967.\\n90. Nunnally, Jum C.,  Psychometric Theory, 2nd ed., New York: McGraw-Hill, 1978.\\n91. Odum, H.W., and Jocher, Katharine, An Introduction to Social Research , New York: Henry Holt and Co.,\\n1929.\\n92. Oppenheim, A.N., Questionnaire Design and Attitude Measurement, New York: Basic Books, 1966.\\n93. Ostle, Bernard, and Mensing, Richard W., Statistics in Research , 3rd ed., Ames Iowa: The Iowa State\\nUniversity Press, 1975.\\n94. Payne, Stanley, The Art of Asking Questions, Princeton: Princeton University Press, 1951.\\n95. Pearson, Karl, The Grammar of Science, New York: Meridian Books, Inc., 1957.\\n96. Phillips, Bernard S., Social Research, Strategy and Tactics , 2nd ed., New York: The Macmillan Company,\\n1971.\\n97. Piaget, Jean, Main Trends in Interdisciplinary Research , London: George Allen and Unwin Ltd., 1973.\\n98. Popper, Karl R., The Logic of Scientific Discovery, New York: Basic Books, 1959.\\n99. Rajaraman, V., “Fundamentals of Computers ,” New Delhi: Prentice-Hall of India Pvt. Ltd., 1985.\\n100.Ramchandran, P.,  Training in Research Methodology in Social Sciences in India, New Delhi: ICSSR\\n1971.\\n101.Redman, L.V., and Mory, A.V.H., The Romance of Research , 1923.\\n102.Roscoe, John T., Fundamental Research Statistics for the Behavioral Sciences, New York: Holt, Rinehart\\nand Winston, Inc., 1969.\\n103.Runyon, Richard P., Inferential Statistics, Philippines: Addison-Wesley Publishing Company, Inc., 1977.\\n104.Sadhu, A.N., and Singh, Amarjit, Research Methodology in Social Sciences,  Bombay: Himalaya Publishing\\nHouse, 1980.\\n105.Seboyar, G.E., Manual for Report and Thesis Writing, New York: F.S. Crofts & Co., 1929.\\n106.Selltiz, Claire: Jahoda, Marie, Deutsch, Morton, and Cook, Stuart W., Research Methods in Social\\nRelations, rev. ed. New York: Holt, Rinehart and Winston, Inc., 1959.\\n107.Sharma, B.A.V., et al., Research Methods in Social Sciences, New Delhi: Sterling Publishers Pvt. Ltd.,\\n1983.\\n108.Sharma, H.D., and Mukherji, S.P., Research in Economics and Commerce, Methodology and Surveys,\\nVaranasi: Indian Biographic Centre, 1976.394 Research Methodology\\n109.Siegel, S., Nonparametric Statistics for the Behavioral Sciences, New York: McGraw-Hill Publishing Co.,\\nInc., 1956.\\n110.Subramanian, N., “ Introduction to Computers ,” New Delhi: Tata McGraw-Hill Publishing Co. Ltd., 1986.\\n111.Summers, Gene F., (Ed.), Attitude Measurement, Chicago: Rand McNally & Co., 1970.\\n112. Takeuchi, K., Yanai, H. and Mukherjee, B.N., The Foundations of Multivariate Analysis, New Delhi:\\nWiley Eastern Ltd., 1982.\\n113. Tandon, B.C., Research Methodology in Social Sciences, Allahabad: Chaitanya Publishing House, 1979.\\n114.Thorndike, Robert L. and Hagen, Elizabeth P., Measurement and Evaluation in Psychology and Education,\\n4th ed., New York: John Wiley & Sons, 1977.\\n115.Thurstone, L.L., The Measurement of Values, Chicago: University of Chicago Press, 1959.\\n116. Torgerson, W., Theory and Methods of Scaling, New York: John Wiley & Sons, 1958.\\n117. Travers, Robert M.W., An Introduction to Educational Research, 4th ed., New York: Macmillan Publishing\\nCo., Inc., 1978.\\n118. Tryon, R.C., and Bailey, D.E., Cluster Analysis , New York: McGraw-Hill, 1970.\\n119. Ullman, Neil R., Elementary Statistics, New York: John Wiley & Sons, Inc., 1978.\\n120.Whitney, F.L., The Elements of Research, 3rd ed., New York: Prentice-Hall, 1950.\\n121. Wilkinson, T.S. and Bhandarkar, P.L., Methodology and Techniques of Social Research, Bombay: Himalaya\\nPublishing House, 1979.\\n122. Willemsen, Eleanor Walker, Understanding Statistical Reasoning , San Francisco: W.H. Freeman and\\nCompany, 1974.\\n123. Yamane, T.,  Statistics: An Introductory Analysis, 3rd ed., New York: Harper and Row, 1973.\\n124. Young, Pauline V., Scientific Social Surveys and Research, 3rd ed., New York: Prentice-Hall, 1960.Author Index 395\\nAuthor Index\\nAckoff, R.L.,    25, 390\\nAllen, T. Harrell,    390Anderson, G.L.,    390\\nAnderson, H.H.,    390\\nAnderson, John F.,    390Anderson, T.W.,    390\\nBailey, D.E.,    338, 394\\nBain, Read,    116\\nBaker, R.P.,    390\\nBalsey, Howard L.,    391Bartee, T.C.,    390\\nBarzun, Jacques,    390\\nBell, J.E.,    390Bellenger, Danny N.,    20, 91, 390\\nBent, D.H.,    393\\nBerdie, Douglas R.,    390Berelson, Bernard,    110, 390\\nBerenson, Conard,    390\\nBest, John W.,    86, 121, 390Bhandarkar, P.L.,    394\\nBhattacharya, Srinibas,    337, 390\\nBoot, John C.G.,    390Bowley, A.L.,    18, 113, 390\\nBurgess, Ernest W.,    113, 391\\nCannell, Charles F.,    392\\nChance, William A.,    391, 192Chaturvedi, J.C.,    158, 391\\nChou, Ya-Lun,    229, 391Clover, Vernon T.,    391\\nCochran, W.G.,    391\\nColton, Raymond,    390Cook, Stuart W.,    6, 350, 393\\nCooley, C.H.,    115\\nCooley, William W.,    391Cordasco, Francesco,    347, 391\\nCowden, D.J.,    391\\nCox, Edwin B.,    390Croxton, F.E.,    391\\nDass S.L.,    109, 391\\nDavis, G.B.,    391\\nDazier, Harold L.,    5, 393\\nDeming, W. Edwards,    391Dennis, Child,    391\\nDenzin, Norman,    391\\nDeutsch, Morton,    6, 350, 393Douglas, E. Scates,    392\\nEdwards, Allen,    391\\nEdwards, Allen L.,    86, 391\\nElzey, Freeman F.,    393\\nEmory, C. William,    53, 89, 130, 168, 185, 344, 391\\nFerber, Robert,    28, 92, 319, 337, 338, 391\\nFerguson, George A.,    275, 391396 Research Methodology\\nFestinger, Leon,    391\\nFiebleman, J.K.,    391\\nFisher, R.A.,    39, 61, 256, 391Fox, James Herold,    20, 391\\nFreedman, P.,    391\\nFruchter, Benjamin,    391\\nGatner, Elliott S.M.,    347, 391\\nGaum Carl G.,    391Ghosh, B N.,    391\\nGibbons, J.D.,    391\\nGiles, G.B.,    92, 110, 122, 392Glock, Charles Y.,    392\\nGodfrey, Arthur,    392\\nGood, Carter V.,    110, 392Goode, William J.,    392\\nGopal, M.H.,    392\\nGorden, Raymond L.,    392Gosset, Sir William S.,    160\\nGraff, Henry F.,    390\\nGraves, Harod F.,    391Green, Paul E.,    91, 92, 392Greenberg, Barnett A.,    20, 91, 390\\nGuilford, J.P.,    80, 392\\nGurvitch, Georges,    113Guttman, Louis,    87, 88, 89\\nHagen, Elizabeth P.,    73, 394\\nHarnett, Donald L.,    158, 195, 214, 257, 392\\nHatt, Paul K.,    392\\nHealy, William,    114Hillway, T.,    392\\nHoffman, Lyne S.S.,    391\\nHollander, Myles,    392Holtzman, W.H.,    108, 109\\nHotelling H.,    321, 330\\nHowell, A.C.,    390Hull, C.H.,    393\\nHunt, R.,    392\\nHyman, Herbert H.,    392Jahoda, Marie,    6, 350, 393\\nJocher, Katharine,    393\\nJohn, Peter W.H.,    392Johnson, Ellen,    392\\nJohnson, Rodney D.,    175, 392\\nKahn, James V.,    86, 121, 390\\nKahn, Robert L.,    392\\nKarson, Marvin J.,    392Katz, Daniel,    391\\nKendall, M.G.,    307, 311, 392\\nKenny, K.C.,    86Kerlinger, Fred N.,    392\\nKish, Leslie,    392\\nKlein, S.,    391Kothari, C.R.,    348, 392\\nLastrucci Carlos L.,    10, 392\\nLazersfeld, Paul F.,    76, 392\\nLeonard, Schatzman,    392\\nLevin, Richard I.,    158, 188, 392Levine, S.,    393Likert,    84, 85\\nLohnes, Paul R.,    391\\nMahalanobis,    320\\nMaranell, Gary M.,    393\\nMaxwell, Albert E.,    393McQuitty,    338\\nMeadows, R.,    393\\nMeir, Robert C.,    5, 393Mensing, Richard W.,    9, 393\\nMiller, Delbert C.,    393\\nMoore, W.E.,    113Moroney, M.J.,    393\\nMorrison, Donald F.,    393\\nMory, A.V.H.,    1, 393Mukherji, B.N.,    316, 393, 394\\nMukherji, S.P.,    393\\nMulaik, S.A.,    335Author Index 397\\nMurphy, James  L.,    158, 195, 214, 257, 392\\nNagel, Stuart S.,    393\\nNeiswanger, W.A.,    12\\nNewell, William T.,    5, 393\\nNie, N.H.,    393Noether, G.E.,    393\\nNunnally, Jum C.,    92, 324, 393\\nOdum, H.W.,    113, 393\\nOppenheim, A.N.,    393\\nOsgood, Charles E.,    90Ostle, Bernard,    9, 393\\nPayne, Stanley,    393\\nPearsons, A.J.,    393\\nPearson, Karl,    9, 393, 138–41\\nPedhazur, Elazar,    392Phillips, Bernard S.,    77, 393\\nPiaget, Jean,    393\\nPlay Frederic Le,    114Popper, Karl R.,    393\\nRajaraman, V.,    393\\nRamachandran, P.,    393Redman, L.V.,    1, 393\\nRoscoe, John T.,    393\\nRunyon, Richard P.,    162, 393\\nSadhu, A.N.,    393\\nSandler, Joseph,    162Scates Douglas E.,    110, 392\\nSeboyar, G.E.,    393\\nSelltiz Claire,    31, 38, 350, 358, 393Sharma, B.A.V.,    393\\nSharma, H.D.,    393\\nShedecor,    257Shelley, J.,    392\\nSheth, Jagdish N.,    91, 130, 317, 337Siegel, S.,    298, 301, 394Singh, Amarjit,    393\\nSiskih, Bernard R.,    175, 392Slesinger, D.,    1\\nSpearman, Charles,    138, 302\\nSpencer, Herbert,    114Stephenson, M.,    1\\nStrauss, Anselm L.,    392\\nStudent,    160, 162Subramaniam, N.,    370, 394\\nSuci, G.J.,    90\\nSummers, Gene F.,    394\\nTakeuchi, K.,    316, 339, 394\\nTandon, B.C.,    394Tannenbaum, P.H.,    90\\nThorndike, Robert L.,    73, 394\\nThurstone, L.L.,    80, 83, 84, 324, 394Tippett,    61\\nTorgerson, W.,    394\\nTravers, Robert M.W.,    53, 394Tryon, R.C.,    338, 394\\nUllman, Neil R.,    233, 394\\nVerdoorn, P.J.,    28, 391\\nWells, William D.,    337\\nWhitney, F.L.,    394\\nWilkinson, T.S.,    394\\nWillemsen, Eleanor W.,    321, 394Wolfe, Douglas, A.,    392\\nYamane, T.,    394\\nYanai, H.,    316, 394\\nYate, F.,    61, 246\\nYoung, Pauline V.,    3, 113, 116, 346, 394Yule,    145398 Research Methodology\\nSubject Index\\nAfter-only with control design,    41\\nAlpha error,    187Analysis of covariance (ANOCOVA),    275–79Analysis of data,    18–19, 122–23, 130–31, 151\\nclassification,    123–27coding,    18, 123editing,    18, 122–23tabulation,    18, 127–29types of analysis,    130–31\\nAnalysis of variance (ANOVA),    256–75\\none-way,    258–61two-way,    264–71\\nANOVA in Latin square design,    271–75Analytical research,    2–3Applied research,    3Area sampling,    16, 65\\nBefore-and-after design:\\nwith control,    41–42\\nwithout control,    41\\nBeta error,    187Bibliography,    19, 347–48, 358Binary digits,    365Bipolar factor,    329\\nCanonical correlation analysis,    130, 321\\nCase-study method,    113–16Census survey,    55Central limit theorem,    157–58Central processing unit,    363–64Centroid method of factor analysis,    324–30Chi-square test,    195, 233–50Classification,    123–27\\naccording to attributes,    124according to class-intervals,    124–25\\nCluster analysis,    337–38Cluster sampling,    16, 65Coding,    18, 123Coefficient of—\\nassociation,    144–47concordance,    307–09contingency,    147correlation,    139–40reproducibility,    89skewness,    137standard deviation,    135variation,    136\\nCollection of data,    95–116\\ninterview method,    97–100, 110, 119\\ndepth interviews,    110personal interviews,    97telephone interviews,    100\\nobservation method,    96–97questionnaires,    100–104\\nthrough schedules,    104–105\\nCompletely randomized design (C.R. Design), 42–45Composite standard method,    80Computer: 362–63\\nanalogue,    362digital,    362\\nConfidence level,    155Confounded relationship,    34Construct validity,    74Consumer panels,    106Subject Index 399\\nContent analysis,    110\\nContent validity,    74Contingency table,    146Continuous variable,    34, 318Control,    34Control groups,    35Convenience sampling,    15Correlation analysis,    130Criteria of good research,    20–21Criterion-related validity,    74Cross tabulation,    138–39\\nDeliberate sampling,    15\\nDepth interviews,    110Descriptive research,    2–3Descriptive research studies,    37–39Developing a research plan,    53–54Differential scales,    83–84Discrete variable,    34, 318Distributor audits,    106Distribution—free tests,    283–312\\n(See non-parametric tests)\\n“Don’t know” responses,    129\\nEditing,    122–23\\ncentral editing,    123\\nfield editing,    122\\nEmpirical research,    4Estimation,    167–74\\ninterval estimate,    168point estimate,    168\\nExperience survey,    28, 36Experiment,    35Experimental designs,    120–21\\nformal,    41–52\\nC.R. design,    42–45Factorial design,    47–52L.S. design,    46–47R.B. design,    45\\ninformal,    41–42\\nExperimental group,    35Experimental research,    34–35Experimental unit,    35Exploratory research studies,    35–37Ex-post facto research,    3, 71Extraneous variable,    34\\nF-distribution,    157, 196\\nF-test,    196, 225–28Factor analysis,    321–37\\nfactor loadings,    323\\nfactor scores,    324\\nFactorial designs,    47–52Fundamental research,    3\\nHoltzman Inkblot test (H.I.T),    108–109\\nHypothesis:\\nalternative,    185–86characteristics of,    185meaning,    184–85null,    185–86\\nHypothesis testing,    191–92Hypothesis testing, research studies,    39\\nIndex numbers,    147–48\\nInteraction effect,    47–50, 270–71Interaction variation,    267Interval,\\nestimates,    167scales,    71–72\\nInterview method,    97–100, 110, 119\\ndepth interviews,    110personal interviews,    97\\nclinical,    98focussed,    98non-directive,    98structured,    97unstructured,    98\\ntelephone interviews,    100\\nJudgement sampling,    15\\nKendall’s coefficient of concordance,    307–10\\nKruskal-Wallis test,    298–300\\nLatent structure analysis,    338\\nLatin square design (L.S. Design),    46–47Law of comparative judgement,    80Level of significance,    186Likert-type scales,    84–87Literature survey,    13, 28Longitudinal research,    4\\nMaximum likelihood method,    335\\nMeasures of central tendency,    132–34\\ngeometric mean,    133harmonic mean,    133–34mean,    132400 Research Methodology\\nmedian,    132–33\\nmode,    133–34\\nMeasures of dispersion,    134–37\\nmean deviation,    134–35range,    134standard deviation,    135–36\\nMeasures of relationship,    138–42Measures of skewness,    136–37\\nKurtosis,    137\\nMeasurement in research,    69–70\\ninterval data,    70nominal data,    70ordinal data,    70ratio data,    70\\nMeasurement scales,    71–72\\ninterval scale,    71–72nominal scale,    71ordinal scale,    71ratio scale,    72\\nMeasuring the power of a hypothesis test,    193–95Memory chips,    364Motivation research,    3Multicollinearity,    142Multi stage sampling,    16, 65–66Multivariate analysis techniques:    315–40\\nfactor analysis,    321–37multidimensional scaling,    91–92, 338\\nmetric approach,    91–92non-metric approach,    92\\nmultiple correlation,    142–43multiple discriminant analysis,    130, 319–21multiple regression,    130, 318–19multivariate analysis of variance,    130, 321\\nNominal scale,    71Non-parametric tests,    283–312\\nChi-square test,    195–96, 233–50Fisher-Irwin test,    288–89Kendall’s coefficient of concordance,    307–310McNemer test,    289–91\\nNull-hypothesis,    185–86\\nOne sample runs test,    300–302Signed rank test,    291–93Sign tests,    284–88Spearman’s rank correlation,    302–307Rank sum tests:    293\\nH-test,    298–300U-test,    293–98Observation method,    96–97\\ncontrolled observation,    97disguised observation,    96participant observation,    96structured observation,    96unstructured observation,    96\\nPaired t-test,    196\\nPantry audits,    106Parametric tests,    195–96Partial correlation,    143–44Path analysis,    339–40Pilot survey,    27Post factum interpretation,    344Precision,    154–55Primary data,    95Principal-components method,    330–31Principles of experimental designs:    39–40\\nlocal control,    40randomization,    40replication,    40\\nProblems of researchers,    21–22Processing operations,    122–29Projective techniques,    107–10\\nQ-type factor analysis,    336\\nQuartimax rotation,    336Questionnaire,    100–104Quota sampling,    16, 59\\nRandomized Block Design (R.B. Design),    45\\nRandom sampling,    15, 59–60Ranking scales,    80Rating scales,    78–80\\ngraphic rating,    78–79itemized rating,    79\\nRegression,    141–43Report writing,    19–20, 344–59Research:\\nmeaning of,    1–2motivation in,    2objectives of,    2significance of    5–7types of,    2–4\\nResearch approaches,    5Research design,    14, 31–39Research hypothesis,    34Research methods    7–8Research methodology,    8Subject Index 401\\nResearch Plan,    53–54\\nResearch Problem,    24–29Research Process,    10–20Roarhach test,    108Rosenzweig test,    108R-type factor analysis,    336\\nSample design,    14–17, 153\\nnon-probability sampling,    59probability sampling,    60random sampling,    59–60stratified sampling,    62–65\\nSample size,    56, 174–81Sample survey,    55Sampling:152–81\\ndesign,    31, 153distribution,    156meaning,    152need,    152theory,    158–60\\nSampling error,    58, 153–54Sampling frame,    56–57, 153Sampling unit,    56Sandler’s A-test,    162–63\\nScale construction techniques,    82–92\\narbitrary scales,    83cumulative scales,    87–89differential scales,    83–84factor scales,    89–92multidimensional scaling,    91–92semantic differential scales,    90–91summated scales,    84–87\\nScaling,    76–77Scalogram analysis,    87–88Scientific method,    9–10Secondary data,    95, 111–12\\ncollection of,    111–12\\nSequential sampling,    16, 67Significance level,    155Sociogram,    110Sociometry,    109–10Source list,    56Sources of error in measurement,    72–73Standard error,    163–65Stores audit,    106Stratified sampling,    16, 62–65Student’s t-test,    160, 196\\nSurvey design,    38, 120–21Systematic sampling,    15, 62Tabulation,    127–29\\naccepted principles of,    128–29\\nTally sheet,    126Technique of developing,\\nmeasurement tools,    75–76\\nTesting of Hypotheses,\\nbasic concepts concerning,    185–90\\nTests of hypotheses\\nnon-parametric tests,    283–312parametric tests,    184–229\\nTests of sound measurement,    73–75Thematic apperception test (T.A.T.),    108Thurstone-type scales,    83–84Time-series analysis,    148–49Tomkins-Horn picture arrangement test,    109t-test,    195–96\\nTwo-tailed and one-tailed test,    195–96Type I and Type II errors,    187Types of analysis,    130–31\\nbivariate,    130causal,    130correlation,    130descriptive,    130inferential,    131multivariate,    130unidimensional,    130\\nVariable,    33–34, 318\\ncontinuous,    34, 318criterion,    318dependent,    34, 318discrete,    34, 318dummy,    318explanatory,    318extraneous,    34independent,    34latent,    318observable,    318pseudo,    318\\nVarimax rotation,    336\\nWarranty cards,    106\\nWilcoxon-Mann-Whitney test,    293–94\\nYate’s correction,    246–49\\nYule’s coefficient of association,    145–46\\nZ-test,    196'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7J6nfqIQAGP",
        "outputId": "cca37c49-5b08-48bc-cb11-245a49255b79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for d3bac6cf-987f-416b-8425-d6b9abb53ff1-us-east1.db.astra.datastax.com:29042:da4b7bf4-d0da-4d63-9400-9ed0a495c23b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for d3bac6cf-987f-416b-8425-d6b9abb53ff1-us-east1.db.astra.datastax.com:29042:da4b7bf4-d0da-4d63-9400-9ed0a495c23b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(137059766273888) d3bac6cf-987f-416b-8425-d6b9abb53ff1-us-east1.db.astra.datastax.com:29042:da4b7bf4-d0da-4d63-9400-9ed0a495c23b> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for d3bac6cf-987f-416b-8425-d6b9abb53ff1-us-east1.db.astra.datastax.com:29042:da4b7bf4-d0da-4d63-9400-9ed0a495c23b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2gPoyfAQFun",
        "outputId": "7e55a143-68b1-47bc-ad36-d6300b8f29ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:115: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_system\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ],
      "metadata": {
        "id": "TrFfNxyhQbdX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL9PIuRfVHJn",
        "outputId": "86d96b53-16f3-4ccd-f6f1-cfb2119a284f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1824, which is longer than the specified 1800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:50]"
      ],
      "metadata": {
        "id": "Gb9KCFCDVLsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "astra_vector_store.add_texts(texts[:100])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[:100]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOB8n05rVOp3",
        "outputId": "a2186599-72d3-4460-e2b7-ff6ec63811ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 100 headlines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNBEfVTDWwEm",
        "outputId": "ae9808df-651c-4b5e-c693-1c65758e5856"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): \"Emprical reserach in india in particular creates so many problems for the researchers\" - Analyse the statement and provide the suitable justification.\n",
            "\n",
            "QUESTION: \"\"Emprical reserach in india in particular creates so many problems for the researchers\" - Analyse the statement and provide the suitable justification.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER: \"The statement highlights the difficulties faced by researchers in India, particularly in the field of empirical research. This type of research involves gathering and analyzing data from real-world situations, which can be challenging due to various factors. One of the major problems faced by researchers is the lack of scientific training in research methodology, which leads to subpar research and unreliable results. This is compounded by the shortage of competent researchers in the country.\n",
            "\n",
            "Another issue is the lack of interaction between research departments in universities and various industries and organizations. This hinders the collection of primary data, which is essential for conducting valid research. Efforts should be made to establish better liaison and collaboration between academia and the industry, as this can lead to more realistic and relevant research studies.\n",
            "\n",
            "Furthermore, there is a lack of trust and confidence among business units in sharing their data and information with researchers. This reluctance is fueled by the fear of misuse of confidential information. To overcome this, researchers need to build a code of conduct and assure businesses of the confidentiality of their data.\n",
            "\n",
            "In addition, there is a problem of duplication of research studies due to the lack of adequate information. This not only wastes resources but also delays the completion of research projects. Proper compilation and revision of research topics and areas can help prevent this issue.\n",
            "\n",
            "Lastly, researchers\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n",
            "    [0.9351] \"(1) Design of the research project;\n",
            "(2) Ex post facto research;\n",
            "(3) Motivation in re ...\"\n",
            "    [0.9232] \"1.The lack of a scientific training in the methodology of research  is a great imped ...\"\n",
            "    [0.9195] \"3. Most of the business units in our country do not have the confidence that the mat ...\"\n",
            "    [0.9192] \"2.Good research is logical:  This implies that research is guided by the rules of lo ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_NEO3yhWXLkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}